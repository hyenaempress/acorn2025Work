# 벡터와 차원 개념 정리

## 1. 차원별 데이터 표현

### 0차원 (스칼라)
- **특징**: 크기만 존재, 방향 없음
- **표현**: 단일 숫자 값
- **예시**: 온도, 무게 등의 단순 수치

### 1차원 (벡터)
- **특징**: 크기 + 방향
- **표현**: `[3]` 또는 `[-2]`
- **공간**: 수직선 상의 점
- **방향**: 좌우 두 방향만 존재

### 2차원 (벡터)
- **특징**: 2개 축 (X, Y)
- **표현**: `[3, 4]` 또는 `(3, 4)`
- **공간**: 평면 좌표계
- **방향**: 원점 기준 다양한 방향 가능

### 3차원 (벡터)
- **특징**: 3개 축 (X, Y, Z)
- **표현**: `[2, 0, -1]`
- **공간**: 3차원 좌표계

## 2. 벡터 표기법

### 프로그래밍/머신러닝 방식
```
[3, 4]  또는  (3, 4)
```

### 수학/선형대수 방식
```
횡벡터: [3  4]
열벡터: [3]
        [4]
```

## 3. 벡터의 기본 개념

### 벡터의 구성 요소
- **크기(Magnitude)**: 원점으로부터의 거리
- **방향(Direction)**: 화살표로 표시
- **좌표**: 각 축에서의 이동량

### 벡터의 시각적 표현
- 원점(0, 0)에서 시작하는 화살표
- 화살표 끝점이 좌표값
- 예: 벡터 A[3, 4] → X축으로 3칸, Y축으로 4칸 이동

## 4. 벡터의 본질적 특성

### 동일 벡터 판정 기준
벡터는 **위치에 관계없이** 다음 두 조건이 같으면 동일한 벡터:
1. **크기가 같음**
2. **방향이 같음**

### 평행이동의 자유성
- 벡터는 좌표평면 어디에 위치해도 크기와 방향이 같으면 동일
- 이 특성을 이용해 벡터 연산 수행

## 5. 벡터의 합성 (Vector Addition)

### 합성 방법

#### 1) 평행사변형 방법
1. 두 벡터를 원점에서 시작하도록 배치
2. 각 벡터를 한 변으로 하는 평행사변형 구성
3. 원점에서 대각선 끝점까지가 합성벡터

#### 2) 삼각형 방법
1. 첫 번째 벡터 그리기
2. 첫 번째 벡터의 끝점에서 두 번째 벡터 시작
3. 원점에서 최종 끝점까지가 합성벡터

### 벡터 덧셈 공식
```
벡터 A = [A₁, A₂]
벡터 B = [B₁, B₂]
벡터 A + B = [A₁ + B₁, A₂ + B₂]
```

## 6. 실수 공간과 부분집합

- **1차원**: 실수 R¹ 공간
- **2차원**: 실수 R² 공간  
- **3차원**: 실수 R³ 공간
- 각 차원의 데이터는 해당 실수 공간의 부분집합

## 7. 벡터의 동일성과 Word2Vec 개념

### 벡터 동일성 원리
- **위치 무관성**: 방향과 크기가 같으면 동일한 벡터
- **평행이동 자유성**: 벡터는 좌표평면 어디에 있어도 동일
- **계산 방법**: 끝점 좌표 - 시작점 좌표 = 이동벡터

### Word2Vec 응용 예시
```
단어 → 벡터 변환 → 좌표계 배치
왕자, 공주 → 유사한 위치 (성별 관계)
남자, 여자 → 유사한 위치 (성별 관계)  
사과, 오렌지 → 다른 위치 (과일 그룹)
```

### 코사인 유사도
- 벡터 간 방향 유사성 측정
- 유사한 단어들의 벡터는 비슷한 방향
- 높은 차원(100~200차원)에서 실제 동작

## 8. 선형 독립과 선형 종속

### 선형 독립 (Linear Independence)
- **정의**: 어떤 벡터도 나머지 벡터들의 선형결합으로 만들 수 없음
- **특징**: 서로 다른 방향을 가진 벡터들
- **결과**: 전체 공간을 채울 수 있음 (span)
- **베이스 벡터**: 공간을 구성하는 기본 벡터들

### 선형 종속 (Linear Dependence)  
- **정의**: 한 벡터가 다른 벡터들로 표현 가능
- **특징**: 같은 직선상에 위치하는 벡터들
- **결과**: 전체 공간을 채울 수 없음

### 선형 결합과 Span
```
벡터 A와 B가 선형독립일 때:
span{A, B} = {αA + βB | α, β ∈ ℝ}
→ 2차원 평면 전체를 채움
```

## 9. 초평면 (Hyperplane) 개념

### 3차원에서의 초평면
- 두 개의 독립 벡터로 생성되는 평면
- 선형결합을 통해 평면 공간 형성
- SVM(Support Vector Machine)에서 활용

### 초평면 생성 과정
1. 두 개의 독립 벡터 설정
2. 상수배와 덧셈을 통한 선형결합
3. 3차원 공간 내 평면 형성

## 10. 데이터 과학에서의 벡터 활용

### 실제 데이터 예시 (자동차 연비 데이터)
- **원인 변수**: 실린더 수, 배기량, 마력, 차체 무게 등
- **결과 변수**: 연비
- **벡터화**: 모든 특성을 벡터 요소로 처리

### 차원 축소의 필요성
- **문제**: 원인 변수가 많을 때 모델 복잡성 증가
- **해결**: PCA 등을 통한 차원 축소
- **조건**: 데이터를 벡터로 처리해야 가능

### 벡터 → 행렬 → 텐서
```
스칼라 (0차원) → 벡터 (1차원) → 행렬 (2차원) → 텐서 (3차원+)
```

## 11. 내적 (Dot Product) 개념과 계산

### 내적의 기하학적 의미
- **정의**: 두 벡터의 길이와 같은 방향성의 정도를 측정
- **공식**: A⃗ · B⃗ = |A⃗| × |B⃗| × cos(θ)
- **결과**: 항상 스칼라(실수) 값

### 삼각함수 복습
```
직각삼각형에서:
cos(θ) = 밑변/빗변
밑변 = 빗변 × cos(θ)

각도별 코사인 값:
- cos(0°) = 1 (같은 방향)
- cos(90°) = 0 (직교)
- cos(180°) = -1 (반대 방향)
```

### 내적의 기하학적 해석
1. **투영(Projection)**: 한 벡터를 다른 벡터 방향으로 정사영
2. **그림자 크기**: 투영된 벡터의 길이 × 대상 벡터의 크기
3. **방향성 판단**: 
   - 양수: 유사한 방향
   - 0: 직교 (관계없음)
   - 음수: 반대 방향

## 12. 내적의 계산 방법

### 방법 1: 기하학적 계산
```
A⃗ · B⃗ = |A⃗| × |B⃗| × cos(θ)
```
- 삼각함수 지식 필요
- 각도와 벡터 크기를 알아야 함

### 방법 2: 성분 기반 계산 (실용적)
```
2차원: A⃗ = [A₁, A₂], B⃗ = [B₁, B₂]
A⃗ · B⃗ = A₁×B₁ + A₂×B₂

3차원: A⃗ = [A₁, A₂, A₃], B⃗ = [B₁, B₂, B₃]
A⃗ · B⃗ = A₁×B₁ + A₂×B₂ + A₃×B₃
```

### 계산 예시
```
A⃗ = [1, 3], B⃗ = [3, 2]
A⃗ · B⃗ = 1×3 + 3×2 = 3 + 6 = 9
```

## 13. 내적의 유사도 측정 활용

### 벡터 간 관계 해석
- **내적 값이 클수록**: 두 벡터가 유사한 방향
- **내적 값이 0**: 두 벡터가 직교 (관계없음)
- **내적 값이 음수**: 두 벡터가 반대 방향

### 각도에 따른 내적 변화
- 0° → 90°: 최대값에서 0으로 감소
- 90° → 180°: 0에서 최소값(음수)으로 변화

## 14. 머신러닝에서의 내적 활용

### 신경망 모델 예시
```
입력 데이터: [온도, 풍속, 습도]
가중치: [W₁, W₂, W₃] (학습을 통해 조정)
출력 = 입력 · 가중치 = 온도×W₁ + 풍속×W₂ + 습도×W₃
```

### 학습 과정
1. **초기화**: 가중치에 난수 할당
2. **예측**: 입력과 가중치의 내적 계산
3. **비교**: 예측값과 실제값 비교
4. **갱신**: 오차에 따라 가중치 조정 (역전파)
5. **반복**: 정확도가 향상될 때까지 반복

### 패턴 인식
- 내적을 통해 입력 데이터와 학습된 패턴 간 유사도 측정
- 높은 유사도 → 해당 클래스로 분류
- 모델이 과거 데이터의 패턴을 학습하여 새로운 데이터 예측

## 15. 실제 적용 사례

### 감성 분석 예시
```
입력: [온도=25, 풍속=5, 습도=40] → 결과: "기분 좋음"
입력: [온도=37, 풍속=1, 습도=72] → 결과: "기분 나쁨"

새로운 입력: [온도=-1, 풍속=72, 습도=8] → 예측: ?
```

### 모델 성능
- **정확도**: 95% → 5% 오차율
- **현재 AI 성능**: 
  - 이미지 인식: 인간 수준 초과
  - 자연어 처리: 인간 수준 근접
  - 계산: 아직 완벽하지 않음 (검증 필요)

## 17. 벡터, 리스트, 배열의 구분

### 개념적 차이점
- **벡터**: 방향과 크기를 가진 수학적 개념
- **리스트**: Python의 기본 자료구조
- **배열(Array)**: NumPy의 ndarray 객체

### 핵심 포인트
- 데이터를 벡터로 취급 → 선형대수 연산 가능
- 벡터 차원 ≠ 배열 차원 (구분 필요)
- 머신러닝에서는 행렬곱이 주로 사용됨

## 18. NumPy 내적 실습

### 기본 내적 계산
```python
import numpy as np

# 1차원 벡터 내적
v = np.array([9, 11])
w = np.array([10, 12])

# 방법 1: Python 기본 연산 (느림)
result1 = v * w  # [90, 132] - 요소별 곱셈(Hadamard)

# 방법 2: NumPy 내적 (빠름)
result2 = np.dot(v, w)  # 219 - 실제 내적
result3 = v.dot(w)      # 219 - 동일한 결과
```

### 2차원 배열 내적
```python
# 2차원 배열 생성
x = np.array([[1, 2], [3, 4]])  # 2×2 행렬
y = np.array([5, 6, 7, 8])      # 1차원 배열

# 내적 계산 (행렬곱)
result = np.dot(x, y.reshape(2, 2))
# 결과: [[19, 22], [43, 50]]
```

### 내적 연산 규칙
- **차원 맞추기**: 첫 번째 행렬의 열 수 = 두 번째 행렬의 행 수
- **결과 차원**: (m×n) × (n×p) = (m×p)
- **에러 방지**: 차원이 안 맞으면 연산 불가

## 19. 유용한 NumPy 함수들

### 기본 통계 함수
```python
x = np.array([1, 2, 3, 4])

# 기본 연산
np.sum(x)        # 합계: 10
np.sum(x, axis=0)  # 열 방향 합계
np.sum(x, axis=1)  # 행 방향 합계

np.mean(x)       # 평균
np.max(x)        # 최댓값: 4
np.min(x)        # 최솟값: 1
```

### 인덱스 반환 함수
```python
# 최댓값/최솟값의 인덱스 반환
np.argmax(x)     # 최댓값 인덱스: 3
np.argmin(x)     # 최솟값 인덱스: 0

# 누적 함수
np.cumsum(x)     # 누적합: [1, 3, 6, 10]
np.cumprod(x)    # 누적곱: [1, 2, 6, 24]
```

## 20. 집합 연산

### 중복 제거와 집합 연산
```python
names1 = np.array(['Tom', 'James', 'Oscar', 'Tom'])
names2 = np.array(['Tom', 'Jerry', 'James'])

# 중복 제거
np.unique(names1)  # ['James', 'Oscar', 'Tom']

# 교집합
np.intersect1d(names1, names2)  # ['James', 'Tom']

# 합집합
np.union1d(names1, names2)  # ['James', 'Jerry', 'Oscar', 'Tom']
```

### 집합 연산 옵션
- **중복 허용/불허**: 옵션에 따라 다름
- **정렬**: 기본적으로 사전순 정렬
- **다양한 함수**: intersect1d, union1d, setdiff1d 등

## 21. 배열 변형과 전치

### 전치(Transpose) 연산
```python
# 2차원 배열 전치
x = np.array([[1, 2, 3], [4, 5, 6]])  # 2×3 행렬
x_t = x.T  # 3×2 행렬로 전치
# 결과: [[1, 4], [2, 5], [3, 6]]

# 3차원 배열도 전치 가능
arr = np.arange(1, 16).reshape(3, 5)  # 3×5 행렬
arr_t = arr.T  # 5×3 행렬로 전치
```

### 차원 변형
```python
# Flatten: 다차원 → 1차원
arr.flatten()  # 2차원 → 1차원으로 변환

# Reshape: 차원 재구성
arr.reshape(5, 3)  # 다른 형태로 재구성
```

## 22. 브로드캐스팅 (Broadcasting)

### 브로드캐스팅 개념
- **정의**: 서로 다른 크기의 배열 간 연산을 자동으로 처리
- **규칙**: 작은 배열이 큰 배열의 형태에 맞춰 자동 확장
- **장점**: 메모리 효율적, 코드 간결

### 브로드캐스팅 예시
```python
# 기본 예시
x = np.arange(1, 10).reshape(3, 3)  # 3×3 행렬
y = np.array([1, 0, 1])             # 1×3 벡터

# 브로드캐스팅 연산
result = x + y  # y가 자동으로 3×3으로 확장되어 연산
```

### 수동 브로드캐스팅 방법들

#### 방법 1: 반복문 사용
```python
z = np.empty_like(x)
for i in range(3):
    z[i] = x[i] + y
```

#### 방법 2: tile 함수 사용
```python
y_tiled = np.tile(y, (3, 1))  # y를 3번 복제
result = x + y_tiled
```

#### 방법 3: 자동 브로드캐스팅 (권장)
```python
result = x + y  # NumPy가 자동으로 처리
```

### 브로드캐스팅 규칙
1. **차원 맞추기**: 뒤에서부터 차원 비교
2. **크기 호환성**: 차원이 1이거나 같아야 함
3. **자동 확장**: 작은 배열이 큰 배열에 맞춰 확장

### 브로드캐스팅 제약 조건
- 호환되지 않는 차원에서는 에러 발생
- 메모리 효율성을 위해 실제 복사는 하지 않음
- 가상의 확장으로 연산 수행

## 24. 아다마르 곱 vs 내적

### 아다마르 곱 (Hadamard Product)
```python
v = np.array([9, 10])
w = np.array([11, 12])

# 아다마르 곱 (요소별 곱셈)
print(v * w)              # [99, 120]
print(np.multiply(v, w))  # [99, 120] - 동일한 결과
```

### 내적 (Dot Product)
```python
# 내적 연산
print(v.dot(w))     # 219 (99 + 120)
print(np.dot(v, w)) # 219 - 동일한 결과
```

### 아다마르 곱의 특징
1. **요소별 연산**: 벡터의 각 요소를 독립적으로 곱셈
2. **간단한 계산**: 벡터의 방향과 크기를 별도로 고려하지 않음
3. **효율성**: C 기반 NumPy로 빠른 계산
4. **머신러닝 활용**: 다양한 ML 모델에서 핵심 연산
5. **다양한 응용**: 이미지 처리, 자연어 처리 등에서 활용

### 내적과의 차이점
- **아다마르 곱**: 요소별 곱셈 → 벡터 결과
- **내적**: 성분 곱의 합 → 스칼라 결과
- **양수 내적**: 두 벡터가 둔각이 아님을 의미

## 25. 고급 NumPy 함수들

### 축(Axis) 기반 연산
```python
x = np.array([[1, 2], [3, 4]])

# 축 없음 - 전체 연산
np.sum(x)        # 10 (모든 요소의 합)

# axis=0 - 열 방향 연산 (세로 방향)
np.sum(x, axis=0)  # [4, 6] (각 열의 합)

# axis=1 - 행 방향 연산 (가로 방향)
np.sum(x, axis=1)  # [3, 7] (각 행의 합)
```

### 최댓값/최솟값과 인덱스
```python
# 값 반환
np.min(x)     # 최솟값
np.max(x)     # 최댓값

# 인덱스 반환 (중요!)
np.argmin(x)  # 최솟값의 인덱스
np.argmax(x)  # 최댓값의 인덱스
```

### 누적 연산
```python
np.cumsum(x)   # 누적합: [1, 3, 6, 10]
np.cumprod(x)  # 누적곱: [1, 2, 6, 24]
```

## 26. 문자열 배열과 집합 연산

### 집합 연산 함수들
```python
names = np.array(['tom', 'james', 'oscar', 'tom', 'oscar'])
names2 = np.array(['tom', 'page', 'john'])

# 기본 집합 연산
np.unique(names)              # 중복 제거
np.intersect1d(names, names2) # 교집합
np.union1d(names, names2)     # 합집합
np.setdiff1d(names, names2)   # 차집합 (names - names2)

# 고급 집합 연산
np.setdiff1d(names, names2, assume_unique=True)  # 성능 최적화
np.in1d(names, names2)        # 포함 여부 (불린 배열 반환)
```

## 27. 행렬 변형과 선형대수

### 전치(Transpose) 연산
```python
x = np.array([[1, 2], [3, 4]])

# 전치 방법들
x.T                  # 가장 간단한 방법
np.transpose(x)      # 명시적 함수 사용
```

### 선형대수 연산
```python
# 기본 선형대수 연산
np.linalg.inv(x)     # 역행렬 (정방행렬만 가능)
np.linalg.det(x)     # 행렬식 (determinant)
np.linalg.eig(x)     # 고유값과 고유벡터
```

### 다차원 배열 처리
```python
arr = np.arange(1, 15).reshape(3, 5)  # 3×5 배열

# 전치와 내적
arr.T                    # 5×3으로 전치
np.dot(arr, arr.T)       # 3×3 결과 (내적 가능)
```

## 28. 차원 변형 기법

### 차원 축소 방법들
```python
arr = np.array([[1, 2, 3], [4, 5, 6]])

# 1차원으로 변환
arr.flatten()           # 새로운 배열 생성
arr.ravel()            # 메모리 공유 (더 효율적)

# reshape을 이용한 변형
arr.reshape(1, -1)     # 1행으로 변환: [[1, 2, 3, 4, 5, 6]]
arr.reshape(-1, 1)     # 1열로 변환: [[1], [2], [3], [4], [5], [6]]
```

### reshape 활용 팁
- `-1` 사용: 자동으로 나머지 차원 계산
- `flatten()` vs `ravel()`: 메모리 사용량 차이
- 차원 변형 시 총 요소 개수는 동일해야 함

## 29. 실무 활용 종합

### 성능 최적화 전략
1. **NumPy 함수 우선**: Python 루프보다 C 기반 연산이 빠름
2. **적절한 axis 사용**: 불필요한 전체 연산 방지
3. **메모리 효율성**: `ravel()` vs `flatten()` 선택
4. **인덱스 활용**: `argmax`, `argmin`으로 효율적 탐색

### 머신러닝 연결점
- **아다마르 곱**: 요소별 가중치 적용
- **내적**: 유사도 측정, 선형 변환
- **전치**: 행렬 차원 맞추기
- **차원 변형**: 모델 입력 형태 조정

### 디버깅 체크리스트
1. 배열 형태 확인: `.shape`
2. 데이터 타입 확인: `.dtype`
3. 축 개념 이해: `axis=0` (열), `axis=1` (행)
4. 차원 호환성: 내적/행렬곱 시 차원 검증