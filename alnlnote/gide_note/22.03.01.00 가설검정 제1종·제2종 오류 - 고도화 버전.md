# 22.03.01 가설검정 제1종·제2종 오류 - 고도화 버전

## 🎯 학습 목표
이 문서는 기존 가설검정 이해를 바탕으로 **제1종·제2종 오류의 실무적 이해**와 **고급 의사결정 프레임워크**를 완전히 마스터하는 것을 목표로 합니다.

---

## 📚 목차
1. [제1종·제2종 오류 완전 이해](#-제1종제2종-오류-완전-이해)
2. [오류와 의사결정의 철학](#-오류와-의사결정의-철학)
3. [검정력과 효과크기](#-검정력과-효과크기)
4. [다중검정 문제와 해결책](#-다중검정-문제와-해결책)
5. [베이지안 관점에서의 가설검정](#-베이지안-관점에서의-가설검정)
6. [실무 의사결정 프레임워크](#-실무-의사결정-프레임워크)
7. [고급 시각화와 해석](#-고급-시각화와-해석)

---

## ⚠️ 제1종·제2종 오류 완전 이해

### 🎲 의사결정 매트릭스의 심화 이해

```python
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

def comprehensive_error_analysis():
    """제1종·제2종 오류의 종합적 분석"""
    
    print("⚠️ 통계적 의사결정의 4가지 시나리오")
    print("=" * 60)
    
    # 의사결정 매트릭스 (확장 버전)
    decision_scenarios = {
        "H₀가 참 & H₀ 채택": {
            "상황": "올바른 결정 (Correct Decision)",
            "확률": "1 - α",
            "의미": "참인 가설을 참이라고 올바르게 판단",
            "예시": "효과 없는 약을 '효과 없다'고 올바르게 결론",
            "비즈니스": "💰 자원 낭비 방지, 올바른 현상유지"
        },
        
        "H₀가 참 & H₀ 기각": {
            "상황": "제1종 오류 (Type I Error, α)",
            "확률": "α (유의수준)",
            "의미": "참인 가설을 거짓이라고 잘못 판단",
            "예시": "효과 없는 약을 '효과 있다'고 잘못 결론",
            "비즈니스": "💸 불필요한 투자, 잘못된 혁신"
        },
        
        "H₀가 거짓 & H₀ 채택": {
            "상황": "제2종 오류 (Type II Error, β)",
            "확률": "β",
            "의미": "거짓인 가설을 참이라고 잘못 판단",
            "예시": "효과 있는 약을 '효과 없다'고 잘못 결론",
            "비즈니스": "📉 기회 상실, 잘못된 현상유지"
        },
        
        "H₀가 거짓 & H₀ 기각": {
            "상황": "올바른 결정 (Statistical Power)",
            "확률": "1 - β (검정력)",
            "의미": "거짓인 가설을 거짓이라고 올바르게 판단",
            "예시": "효과 있는 약을 '효과 있다'고 올바르게 결론",
            "비즈니스": "🚀 올바른 혁신, 성공적 의사결정"
        }
    }
    
    # 각 시나리오별 상세 분석
    for scenario, details in decision_scenarios.items():
        print(f"\n📊 {scenario}")
        print("-" * 50)
        for key, value in details.items():
            print(f"   {key}: {value}")
    
    return decision_scenarios

comprehensive_error_analysis()
```

### 🎯 실무 관점에서의 오류 비용 분석

```python
def business_error_cost_analysis():
    """비즈니스 관점에서의 오류 비용 분석"""
    
    business_scenarios = {
        "신약 개발": {
            "제1종 오류 비용": {
                "시나리오": "효과 없는 약을 출시",
                "직접비용": "임상시험 비용 (수백억)",
                "간접비용": "회사 신뢰도 하락, 법적 리스크",
                "심각도": "🔴 매우 높음"
            },
            "제2종 오류 비용": {
                "시나리오": "효과 있는 약을 포기",
                "직접비용": "기회비용 (잠재 수익 상실)",
                "간접비용": "경쟁사에게 시장 선점 허용",
                "심각도": "🟡 중간"
            },
            "추천 전략": "제1종 오류를 더 엄격히 통제 (α = 0.01)"
        },
        
        "마케팅 캠페인": {
            "제1종 오류 비용": {
                "시나리오": "효과 없는 캠페인을 실행",
                "직접비용": "광고비 손실 (수천만~수억)",
                "간접비용": "브랜드 이미지 손상",
                "심각도": "🟡 중간"
            },
            "제2종 오류 비용": {
                "시나리오": "효과 있는 캠페인을 포기",
                "직접비용": "매출 증가 기회 상실",
                "간접비용": "경쟁 우위 상실",
                "심각도": "🟡 중간"
            },
            "추천 전략": "균형잡힌 접근 (α = 0.05)"
        },
        
        "품질 관리": {
            "제1종 오류 비용": {
                "시나리오": "정상 제품을 불량으로 판단",
                "직접비용": "제품 폐기 비용",
                "간접비용": "생산성 저하, 납기 지연",
                "심각도": "🟡 중간"
            },
            "제2종 오류 비용": {
                "시나리오": "불량 제품을 정상으로 판단",
                "직접비용": "리콜 비용, 배상",
                "간접비용": "고객 신뢰 상실, 브랜드 위험",
                "심각도": "🔴 매우 높음"
            },
            "추천 전략": "제2종 오류를 더 엄격히 통제 (β 최소화)"
        }
    }
    
    print("💼 비즈니스별 오류 비용 분석")
    print("=" * 50)
    
    for business, analysis in business_scenarios.items():
        print(f"\n🏢 {business}")
        print("-" * 30)
        
        for error_type, details in analysis.items():
            if error_type == "추천 전략":
                print(f"   ✅ {error_type}: {details}")
            else:
                print(f"\n   ⚠️ {error_type}:")
                for key, value in details.items():
                    print(f"     {key}: {value}")
    
    return business_scenarios

business_error_cost_analysis()
```

---

## 🧠 오류와 의사결정의 철학

### 💭 오류의 철학적 배경

```python
def philosophical_perspective_on_errors():
    """오류에 대한 철학적 관점"""
    
    philosophical_frameworks = {
        "보수주의 (Conservatism)": {
            "핵심 철학": "기존 질서 유지, 변화에 신중",
            "오류 선호": "제1종 오류를 더 경계 (α를 작게)",
            "의사결정": "확실한 증거가 있을 때만 변화",
            "적용 분야": "의료, 안전, 법률",
            "장점": "안정성, 신뢰성",
            "단점": "혁신 기회 상실"
        },
        
        "진보주의 (Progressivism)": {
            "핵심 철학": "적극적 혁신, 기회 포착",
            "오류 선호": "제2종 오류를 더 경계 (β를 작게)",
            "의사결정": "불확실해도 시도하며 학습",
            "적용 분야": "스타트업, R&D, 탐험적 연구",
            "장점": "혁신 가능성, 빠른 학습",
            "단점": "높은 실패 위험"
        },
        
        "균형주의 (Balanced Approach)": {
            "핵심 철학": "상황에 따른 유연한 접근",
            "오류 선호": "맥락에 따라 α, β 조정",
            "의사결정": "비용-편익 분석 기반",
            "적용 분야": "일반적 비즈니스, 정책",
            "장점": "상황 적응성",
            "단점": "명확한 기준 부족"
        }
    }
    
    print("🤔 오류에 대한 철학적 관점")
    print("=" * 40)
    
    for philosophy, details in philosophical_frameworks.items():
        print(f"\n📚 {philosophy}")
        print("-" * 25)
        for aspect, description in details.items():
            print(f"   {aspect}: {description}")
    
    # 철학별 유의수준 설정 가이드
    print(f"\n🎯 철학별 유의수준 설정 가이드:")
    philosophy_alpha = {
        "보수주의": "α = 0.01 (1% 위험만 허용)",
        "균형주의": "α = 0.05 (5% 위험 허용, 표준)",
        "진보주의": "α = 0.10 (10% 위험 허용, 관대)"
    }
    
    for philosophy, alpha_setting in philosophy_alpha.items():
        print(f"   {philosophy}: {alpha_setting}")
    
    return philosophical_frameworks

philosophical_perspective_on_errors()
```

### 🎭 역할별 관점의 차이

```python
def stakeholder_perspectives():
    """이해관계자별 오류에 대한 관점"""
    
    stakeholder_views = {
        "연구자 (Researcher)": {
            "주요 관심": "학문적 엄밀성, 재현 가능성",
            "선호하는 α": "0.05 (전통적 기준)",
            "제1종 오류 우려": "잘못된 발견 발표로 인한 신뢰도 손상",
            "제2종 오류 우려": "진짜 발견을 놓칠 가능성",
            "특징": "균형잡힌 접근, 학계 관습 준수"
        },
        
        "경영진 (Management)": {
            "주요 관심": "ROI, 비즈니스 성과",
            "선호하는 α": "상황에 따라 유연 (0.01~0.10)",
            "제1종 오류 우려": "불필요한 투자로 인한 손실",
            "제2종 오류 우려": "기회 상실로 인한 경쟁 열세",
            "특징": "비용-편익 중심의 의사결정"
        },
        
        "규제기관 (Regulator)": {
            "주요 관심": "공공 안전, 사회적 책임",
            "선호하는 α": "0.01 이하 (매우 보수적)",
            "제1종 오류 우려": "위험한 제품/서비스 승인",
            "제2종 오류 우려": "유용한 혁신 차단",
            "특징": "안전 우선, 예방 원칙"
        },
        
        "투자자 (Investor)": {
            "주요 관심": "수익률, 리스크 관리",
            "선호하는 α": "투자 성향에 따라 차등",
            "제1종 오류 우려": "수익성 없는 사업에 투자",
            "제2종 오류 우려": "수익성 높은 기회 놓침",
            "특징": "포트폴리오 다양화로 리스크 분산"
        }
    }
    
    print("👥 이해관계자별 오류 관점")
    print("=" * 35)
    
    for stakeholder, perspective in stakeholder_views.items():
        print(f"\n🎭 {stakeholder}")
        print("-" * 20)
        for aspect, view in perspective.items():
            print(f"   {aspect}: {view}")
    
    return stakeholder_views

stakeholder_perspectives()
```

---

## 🔋 검정력과 효과크기

### ⚡ 검정력(Statistical Power) 완전 분석

```python
def statistical_power_analysis():
    """검정력의 종합적 분석"""
    
    print("⚡ 검정력(Statistical Power) 완전 분석")
    print("=" * 50)
    
    power_concepts = {
        "정의": "실제로 차이가 있을 때 이를 올바르게 탐지할 확률",
        "수식": "검정력 = 1 - β (제2종 오류 확률)",
        "의미": "거짓인 귀무가설을 올바르게 기각할 확률",
        "범위": "0 ≤ Power ≤ 1 (높을수록 좋음)",
        "일반적 기준": "0.80 이상 (80% 이상)"
    }
    
    print("📊 검정력 기본 개념:")
    for concept, explanation in power_concepts.items():
        print(f"   {concept}: {explanation}")
    
    # 검정력에 영향을 주는 요인들
    power_factors = {
        "표본 크기 (n)": {
            "관계": "표본이 클수록 검정력 증가",
            "이유": "표준오차 감소로 차이 탐지 능력 향상",
            "실무 활용": "A/B 테스트 샘플 사이즈 설계"
        },
        
        "유의수준 (α)": {
            "관계": "α가 클수록 검정력 증가",
            "이유": "기각역이 넓어져 차이 탐지 쉬워짐",
            "트레이드오프": "제1종 오류 위험 증가"
        },
        
        "효과크기 (Effect Size)": {
            "관계": "실제 차이가 클수록 검정력 증가",
            "이유": "큰 차이는 탐지하기 쉬움",
            "실무 의미": "실질적 의미가 있는 차이 정의"
        },
        
        "측정 정밀도": {
            "관계": "측정이 정확할수록 검정력 증가",
            "이유": "노이즈 감소로 신호 탐지 향상",
            "실무 활용": "측정 도구 개선, 실험 설계 최적화"
        }
    }
    
    print(f"\n🎯 검정력 영향 요인:")
    for factor, details in power_factors.items():
        print(f"\n   📈 {factor}:")
        for aspect, description in details.items():
            print(f"     {aspect}: {description}")
    
    return power_concepts, power_factors

statistical_power_analysis()
```

### 📏 효과크기(Effect Size) 실무 가이드

```python
def effect_size_practical_guide():
    """효과크기의 실무적 이해와 활용"""
    
    print("📏 효과크기(Effect Size) 실무 가이드")
    print("=" * 45)
    
    effect_size_types = {
        "Cohen's d (두 그룹 평균 차이)": {
            "수식": "d = (μ₁ - μ₂) / σ",
            "해석 기준": {
                "작은 효과": "d = 0.20 (약간의 차이)",
                "중간 효과": "d = 0.50 (보통 차이)",
                "큰 효과": "d = 0.80 (명확한 차이)"
            },
            "실무 예시": {
                "d = 0.2": "남녀 키 차이 (실제 약 3-4cm)",
                "d = 0.5": "교육 프로그램 효과 (보통 수준)",
                "d = 0.8": "신약 vs 위약 효과 (큰 차이)"
            }
        },
        
        "상관계수 (r)": {
            "수식": "r = Pearson 상관계수",
            "해석 기준": {
                "작은 효과": "r = 0.10 (약한 상관)",
                "중간 효과": "r = 0.30 (보통 상관)",
                "큰 효과": "r = 0.50 (강한 상관)"
            },
            "실무 예시": {
                "r = 0.1": "키와 IQ의 상관관계",
                "r = 0.3": "교육 수준과 소득의 상관관계",
                "r = 0.5": "연습 시간과 실력의 상관관계"
            }
        },
        
        "결정계수 (R²)": {
            "수식": "R² = 설명된 분산 / 전체 분산",
            "해석 기준": {
                "작은 효과": "R² = 0.01 (1% 설명)",
                "중간 효과": "R² = 0.09 (9% 설명)",
                "큰 효과": "R² = 0.25 (25% 설명)"
            },
            "실무 활용": "회귀 모델의 설명력 평가"
        }
    }
    
    for measure, details in effect_size_types.items():
        print(f"\n📊 {measure}")
        print("-" * 30)
        print(f"   수식: {details['수식']}")
        
        if '해석 기준' in details:
            print(f"   해석 기준:")
            for level, criterion in details['해석 기준'].items():
                print(f"     • {level}: {criterion}")
        
        if '실무 예시' in details:
            print(f"   실무 예시:")
            for example, description in details['실무 예시'].items():
                print(f"     • {example}: {description}")
    
    return effect_size_types

effect_size_practical_guide()
```

### 🎯 검정력 분석을 위한 실무 도구

```python
def power_analysis_toolkit():
    """검정력 분석 실무 도구"""
    
    import numpy as np
    from scipy import stats
    
    def calculate_sample_size(effect_size, alpha=0.05, power=0.80):
        """필요한 표본 크기 계산"""
        # Cohen's convention을 사용한 근사 계산
        z_alpha = stats.norm.ppf(1 - alpha/2)  # 양측검정
        z_beta = stats.norm.ppf(power)
        
        n = 2 * ((z_alpha + z_beta) / effect_size) ** 2
        return int(np.ceil(n))
    
    def calculate_power(n, effect_size, alpha=0.05):
        """주어진 조건에서 검정력 계산"""
        z_alpha = stats.norm.ppf(1 - alpha/2)
        z_score = effect_size * np.sqrt(n/2) - z_alpha
        power = stats.norm.cdf(z_score)
        return power
    
    print("🎯 검정력 분석 실무 도구")
    print("=" * 35)
    
    # 실무 시나리오별 표본 크기 계산
    scenarios = {
        "A/B 테스트 (작은 효과)": {"effect_size": 0.2, "power": 0.80},
        "마케팅 캠페인 (중간 효과)": {"effect_size": 0.5, "power": 0.80},
        "신제품 테스트 (큰 효과)": {"effect_size": 0.8, "power": 0.80},
        "높은 검정력 필요": {"effect_size": 0.5, "power": 0.90}
    }
    
    print(f"\n📋 시나리오별 필요 표본 크기:")
    for scenario, params in scenarios.items():
        n_required = calculate_sample_size(
            params["effect_size"], 
            power=params["power"]
        )
        print(f"   {scenario}: {n_required}명 (각 그룹)")
    
    # 표본 크기별 검정력 계산
    print(f"\n⚡ 표본 크기별 검정력 (효과크기 0.5 기준):")
    sample_sizes = [30, 50, 100, 200, 500]
    for n in sample_sizes:
        power = calculate_power(n, 0.5)
        print(f"   n={n}: 검정력 {power:.3f} ({power*100:.1f}%)")
    
    return calculate_sample_size, calculate_power

sample_size_calc, power_calc = power_analysis_toolkit()
```

---

## 🔄 다중검정 문제와 해결책

### ⚠️ 다중검정 문제의 심각성

```python
def multiple_testing_problem():
    """다중검정 문제의 이해와 시뮬레이션"""
    
    import numpy as np
    from scipy import stats
    
    print("🔄 다중검정 문제 (Multiple Testing Problem)")
    print("=" * 50)
    
    # 다중검정 시 제1종 오류 확률 계산
    def family_wise_error_rate(num_tests, alpha=0.05):
        """전체 실험에서 최소 하나의 제1종 오류가 발생할 확률"""
        return 1 - (1 - alpha) ** num_tests
    
    print("📊 검정 횟수별 제1종 오류 발생 확률:")
    test_counts = [1, 5, 10, 20, 50, 100]
    
    for m in test_counts:
        fwer = family_wise_error_rate(m)
        print(f"   {m}번 검정 시: {fwer:.3f} ({fwer*100:.1f}%)")
    
    # 실제 시뮬레이션
    def simulate_multiple_testing(num_tests=20, num_simulations=10000, alpha=0.05):
        """다중검정 시뮬레이션"""
        false_discoveries = 0
        
        for _ in range(num_simulations):
            # 귀무가설이 모두 참인 상황 (차이가 없음)
            p_values = []
            for _ in range(num_tests):
                # 두 그룹 모두 동일한 분포에서 샘플링
                group1 = np.random.normal(0, 1, 30)
                group2 = np.random.normal(0, 1, 30)
                _, p_value = stats.ttest_ind(group1, group2)
                p_values.append(p_value)
            
            # 하나라도 유의한 결과가 나오면 거짓 발견
            if any(p < alpha for p in p_values):
                false_discoveries += 1
        
        return false_discoveries / num_simulations
    
    print(f"\n🎲 시뮬레이션 결과:")
    simulated_fwer = simulate_multiple_testing()
    theoretical_fwer = family_wise_error_rate(20)
    
    print(f"   이론적 FWER: {theoretical_fwer:.3f}")
    print(f"   시뮬레이션 FWER: {simulated_fwer:.3f}")
    print(f"   차이: {abs(theoretical_fwer - simulated_fwer):.3f}")
    
    return family_wise_error_rate, simulate_multiple_testing

fwer_calc, simulate_mt = multiple_testing_problem()
```

### 🛡️ 다중검정 보정 방법들

```python
def multiple_testing_corrections():
    """다중검정 보정 방법들의 비교"""
    
    import numpy as np
    from scipy import stats
    
    correction_methods = {
        "Bonferroni 보정": {
            "방법": "α_adjusted = α / m",
            "특징": "가장 보수적, 강한 통제",
            "장점": "간단하고 확실한 보정",
            "단점": "너무 보수적, 검정력 크게 감소",
            "적용": "중요한 의료/안전 연구"
        },
        
        "Holm 방법": {
            "방법": "순차적 보정 (Step-down)",
            "특징": "Bonferroni보다 덜 보수적",
            "장점": "검정력이 Bonferroni보다 높음",
            "단점": "여전히 보수적",
            "적용": "일반적인 다중 비교"
        },
        
        "FDR (Benjamini-Hochberg)": {
            "방법": "거짓 발견율 통제",
            "특징": "현대적 접근, 실용적",
            "장점": "검정력 높음, 실무 친화적",
            "단점": "개념 이해 필요",
            "적용": "탐색적 데이터 분석, 바이오인포매틱스"
        }
    }
    
    print("🛡️ 다중검정 보정 방법 비교")
    print("=" * 40)
    
    for method, details in correction_methods.items():
        print(f"\n📋 {method}")
        print("-" * 20)
        for aspect, description in details.items():
            print(f"   {aspect}: {description}")
    
    # 실제 보정 예시
    def apply_corrections(p_values, alpha=0.05):
        """다양한 보정 방법 적용"""
        p_values = np.array(p_values)
        m = len(p_values)
        
        # 1. Bonferroni 보정
        bonferroni_alpha = alpha / m
        bonferroni_significant = p_values < bonferroni_alpha
        
        # 2. Holm 방법
        sorted_indices = np.argsort(p_values)
        holm_significant = np.zeros(m, dtype=bool)
        
        for i, idx in enumerate(sorted_indices):
            holm_alpha = alpha / (m - i)
            if p_values[idx] < holm_alpha:
                holm_significant[idx] = True
            else:
                break
        
        # 3. FDR (Benjamini-Hochberg)
        sorted_p = np.sort(p_values)
        fdr_significant = np.zeros(m, dtype=bool)
        
        for i in range(m-1, -1, -1):
            if sorted_p[i] <= (i+1) / m * alpha:
                threshold = sorted_p[i]
                fdr_significant = p_values <= threshold
                break
        
        return {
            "original": p_values < alpha,
            "bonferroni": bonferroni_significant,
            "holm": holm_significant,
            "fdr": fdr_significant
        }
    
    # 예시 데이터로 보정 방법 비교
    example_p_values = [0.001, 0.01, 0.03, 0.04, 0.06, 0.08, 0.12, 0.15, 0.25, 0.45]
    results = apply_corrections(example_p_values)
    
    print(f"\n🧪 보정 방법 비교 (예시 데이터):")
    print(f"P-values: {example_p_values}")
    
    for method, significant in results.items():
        count = np.sum(significant)
        print(f"   {method}: {count}개 유의 {list(significant)}")
    
    return correction_methods, apply_corrections

corrections, apply_corr = multiple_testing_corrections()
```

---

## 🔮 베이지안 관점에서의 가설검정

### 🎯 빈도주의 vs 베이지안 패러다임

```python
def frequentist_vs_bayesian():
    """빈도주의와 베이지안 관점의 비교"""
    
    paradigm_comparison = {
        "확률의 의미": {
            "빈도주의": "장기적 빈도 (객관적 확률)",
            "베이지안": "믿음의 정도 (주관적 확률)",
            "예시": "동전 앞면 확률 50%의 의미"
        },
        
        "모수에 대한 관점": {
            "빈도주의": "모수는 고정된 상수 (알 수 없음)",
            "베이지안": "모수는 확률변수 (분포를 가짐)",
            "실무 차이": "점추정 vs 구간추정의 해석"
        },
        
        "가설검정 방법": {
            "빈도주의": "P-value, 유의성 검정",
            "베이지안": "Bayes Factor, 사후확률",
            "장점": "객관성 vs 직관성"
        },
        
        "사전 정보 활용": {
            "빈도주의": "사전 정보 무시",
            "베이지안": "사전 정보 적극 활용",
            "실무 가치": "전문가 지식 반영 가능"
        }
    }
    
    print("🔮 빈도주의 vs 베이지안 패러다임")
    print("=" * 45)
    
    for aspect, comparison in paradigm_comparison.items():
        print(f"\n📊 {aspect}:")
        for paradigm, description in comparison.items():
            print(f"   {paradigm}: {description}")
    
    return paradigm_comparison

paradigm_comp = frequentist_vs_bayesian()
```

### 🎲 베이지안 가설검정 실습

```python
def bayesian_hypothesis_testing():
    """베이지안 가설검정의 실제 적용"""
    
    import numpy as np
    from scipy import stats
    
    print("🎲 베이지안 가설검정 실습")
    print("=" * 35)
    
    # 예시: 동전의 공정성 검정
    def bayesian_coin_test(heads, total_flips, prior_alpha=1, prior_beta=1):
        """베이지안 동전 공정성 검정"""
        
        # 사전분포: Beta(α, β)
        # 사후분포: Beta(α + heads, β + tails)
        posterior_alpha = prior_alpha + heads
        posterior_beta = prior_beta + (total_flips - heads)
        
        # 사후 평균 (추정값)
        posterior_mean = posterior_alpha / (posterior_alpha + posterior_beta)
        
        # 95% 신뢰구간
        credible_interval = stats.beta.interval(
            0.95, posterior_alpha, posterior_beta
        )
        
        # H₀: p = 0.5에 대한 사후확률
        # 0.5 주변 작은 구간의 확률로 근사
        epsilon = 0.01
        prob_null = stats.beta.cdf(0.5 + epsilon, posterior_alpha, posterior_beta) - \
                   stats.beta.cdf(0.5 - epsilon, posterior_alpha, posterior_beta)
        
        return {
            "posterior_mean": posterior_mean,
            "credible_interval": credible_interval,
            "prob_around_null": prob_null / (2 * epsilon)  # 밀도로 변환
        }
    
    # 시나리오별 분석
    scenarios = {
        "공정한 동전": {"heads": 50, "total": 100},
        "편향된 동전": {"heads": 70, "total": 100},
        "적은 데이터": {"heads": 7, "total": 10}
    }
    
    print("🪙 동전 공정성 베이지안 검정:")
    
    for scenario, data in scenarios.items():
        result = bayesian_coin_test(data["heads"], data["total"])
        
        print(f"\n   📊 {scenario} ({data['heads']}/{data['total']}):")
        print(f"      사후 평균: {result['posterior_mean']:.3f}")
        print(f"      95% 신뢰구간: ({result['credible_interval'][0]:.3f}, {result['credible_interval'][1]:.3f})")
        
        # 공정성 판단
        if 0.5 >= result['credible_interval'][0] and 0.5 <= result['credible_interval'][1]:
            print(f"      결론: 공정할 가능성 있음")
        else:
            print(f"      결론: 편향되었을 가능성 높음")
    
    return bayesian_coin_test

bayes_coin_test = bayesian_hypothesis_testing()
```

---

## 💼 실무 의사결정 프레임워크

### 🎯 통계적 의사결정 체크리스트

```python
def statistical_decision_framework():
    """실무용 통계적 의사결정 프레임워크"""
    
    framework = {
        "1단계: 문제 정의": {
            "핵심 질문": [
                "해결하려는 비즈니스 문제가 무엇인가?",
                "통계적 검정이 정말 필요한가?",
                "의사결정에 미치는 영향은 얼마나 큰가?"
            ],
            "체크포인트": [
                "✅ 명확한 문제 정의",
                "✅ 이해관계자 식별",
                "✅ 의사결정 기준 설정"
            ]
        },
        
        "2단계: 오류 비용 분석": {
            "핵심 질문": [
                "제1종 오류의 비용은 얼마나 큰가?",
                "제2종 오류의 비용은 얼마나 큰가?",
                "어떤 오류가 더 치명적인가?"
            ],
            "체크포인트": [
                "✅ 오류별 비용 정량화",
                "✅ 리스크 허용 수준 결정",
                "✅ 유의수준 설정 근거 명확화"
            ]
        },
        
        "3단계: 검정 설계": {
            "핵심 질문": [
                "적절한 검정 방법은 무엇인가?",
                "필요한 표본 크기는 얼마인가?",
                "실무적으로 의미있는 효과크기는 얼마인가?"
            ],
            "체크포인트": [
                "✅ 검정력 분석 수행",
                "✅ 표본 크기 계산",
                "✅ 실험 설계 최적화"
            ]
        },
        
        "4단계: 결과 해석": {
            "핵심 질문": [
                "통계적 유의성이 실무적 의미를 가지는가?",
                "효과크기가 실질적으로 중요한가?",
                "결과가 비즈니스 맥락에서 합리적인가?"
            ],
            "체크포인트": [
                "✅ P-value와 효과크기 함께 고려",
                "✅ 신뢰구간 해석",
                "✅ 실무적 권고사항 도출"
            ]
        },
        
        "5단계: 의사결정과 후속조치": {
            "핵심 질문": [
                "이 결과를 바탕으로 어떤 행동을 취할 것인가?",
                "추가 검증이 필요한가?",
                "모니터링 계획은 무엇인가?"
            ],
            "체크포인트": [
                "✅ 명확한 행동 계획",
                "✅ 위험 관리 방안",
                "✅ 성과 추적 계획"
            ]
        }
    }
    
    print("💼 실무용 통계적 의사결정 프레임워크")
    print("=" * 50)
    
    for stage, details in framework.items():
        print(f"\n📋 {stage}")
        print("-" * 30)
        
        print("   🔍 핵심 질문:")
        for question in details["핵심 질문"]:
            print(f"     • {question}")
        
        print("   ✅ 체크포인트:")
        for checkpoint in details["체크포인트"]:
            print(f"     {checkpoint}")
    
    return framework

decision_framework = statistical_decision_framework()
```

### 🏢 산업별 적용 가이드

```python
def industry_specific_guidelines():
    """산업별 가설검정 적용 가이드"""
    
    industry_guides = {
        "제약/의료": {
            "특징": "생명과 직결, 규제 강화",
            "권장 α": "0.01 이하",
            "오류 우선순위": "제1종 오류 최소화",
            "추가 고려사항": [
                "다중 종료점 보정",
                "임상시험 프로토콜 준수",
                "규제기관 가이드라인 확인"
            ],
            "실무 팁": "안전성 먼저, 효과성 나중"
        },
        
        "금융/투자": {
            "특징": "높은 변동성, 빠른 의사결정",
            "권장 α": "0.05 (상황에 따라 조정)",
            "오류 우선순위": "상황별 차등 적용",
            "추가 고려사항": [
                "시장 변화에 따른 동적 조정",
                "포트폴리오 차원의 리스크 관리",
                "백테스팅 및 out-of-sample 검증"
            ],
            "실무 팁": "리스크-리턴 트레이드오프 고려"
        },
        
        "테크/IT": {
            "특징": "빠른 실험, 데이터 풍부",
            "권장 α": "0.05~0.10 (A/B 테스트)",
            "오류 우선순위": "제2종 오류 최소화",
            "추가 고려사항": [
                "다중 지표 최적화",
                "사용자 세그먼트별 분석",
                "장기 효과 vs 단기 효과"
            ],
            "실무 팁": "빠른 실험, 빠른 학습"
        },
        
        "제조/품질관리": {
            "특징": "공정 안정성, 품질 보증",
            "권장 α": "상황별 (불량품 탐지 vs 정상품 폐기)",
            "오류 우선순위": "공정에 따라 다름",
            "추가 고려사항": [
                "SPC(통계적 공정관리) 연계",
                "샘플링 전략 최적화",
                "비용-품질 균형"
            ],
            "실무 팁": "예방이 치료보다 경제적"
        }
    }
    
    print("🏢 산업별 가설검정 적용 가이드")
    print("=" * 45)
    
    for industry, guide in industry_guides.items():
        print(f"\n🏭 {industry}")
        print("-" * 20)
        
        for aspect, details in guide.items():
            if isinstance(details, list):
                print(f"   {aspect}:")
                for item in details:
                    print(f"     • {item}")
            else:
                print(f"   {aspect}: {details}")
    
    return industry_guides

industry_guides = industry_specific_guidelines()
```

---

## 📊 고급 시각화와 해석

### 🎨 시각화 도구킷

```python
def advanced_visualization_toolkit():
    """고급 통계 시각화 도구킷"""
    
    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    from scipy import stats
    
    # 한글 폰트 설정
    plt.rcParams['font.family'] = 'DejaVu Sans'
    plt.rcParams['axes.unicode_minus'] = False
    
    def plot_error_types_diagram():
        """제1종·제2종 오류 시각화"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # 분포 생성
        x = np.linspace(-4, 8, 1000)
        null_dist = stats.norm.pdf(x, 0, 1)  # H₀가 참일 때
        alt_dist = stats.norm.pdf(x, 3, 1)   # H₁이 참일 때
        
        # 임계값 설정
        critical_value = stats.norm.ppf(0.95, 0, 1)
        
        # 첫 번째 플롯: 제1종 오류
        ax1.plot(x, null_dist, 'b-', label='H₀가 참 (μ=0)', linewidth=2)
        ax1.fill_between(x[x >= critical_value], null_dist[x >= critical_value], 
                        alpha=0.3, color='red', label='제1종 오류 (α)')
        ax1.axvline(critical_value, color='red', linestyle='--', 
                   label=f'임계값 = {critical_value:.2f}')
        ax1.set_title('제1종 오류 (Type I Error)', fontsize=14, fontweight='bold')
        ax1.set_xlabel('검정 통계량')
        ax1.set_ylabel('확률 밀도')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 두 번째 플롯: 제2종 오류
        ax2.plot(x, null_dist, 'b-', label='H₀ 분포 (μ=0)', linewidth=2)
        ax2.plot(x, alt_dist, 'g-', label='H₁ 분포 (μ=3)', linewidth=2)
        ax2.fill_between(x[x < critical_value], alt_dist[x < critical_value], 
                        alpha=0.3, color='orange', label='제2종 오류 (β)')
        ax2.fill_between(x[x >= critical_value], alt_dist[x >= critical_value], 
                        alpha=0.3, color='lightgreen', label='검정력 (1-β)')
        ax2.axvline(critical_value, color='red', linestyle='--', 
                   label=f'임계값 = {critical_value:.2f}')
        ax2.set_title('제2종 오류 & 검정력', fontsize=14, fontweight='bold')
        ax2.set_xlabel('검정 통계량')
        ax2.set_ylabel('확률 밀도')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        return fig
    
    def plot_power_analysis():
        """검정력 분석 시각화"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. 표본 크기와 검정력의 관계
        sample_sizes = np.arange(10, 201, 10)
        powers = [1 - stats.norm.cdf(1.96 - 0.5 * np.sqrt(n/2)) for n in sample_sizes]
        
        ax1.plot(sample_sizes, powers, 'b-', linewidth=2, marker='o')
        ax1.axhline(y=0.8, color='r', linestyle='--', label='권장 검정력 (0.8)')
        ax1.set_title('표본 크기 vs 검정력', fontweight='bold')
        ax1.set_xlabel('표본 크기')
        ax1.set_ylabel('검정력')
        ax1.grid(True, alpha=0.3)
        ax1.legend()
        
        # 2. 효과크기와 검정력의 관계
        effect_sizes = np.linspace(0.1, 1.5, 50)
        powers_effect = [1 - stats.norm.cdf(1.96 - es * np.sqrt(50/2)) for es in effect_sizes]
        
        ax2.plot(effect_sizes, powers_effect, 'g-', linewidth=2)
        ax2.axhline(y=0.8, color='r', linestyle='--', label='권장 검정력 (0.8)')
        ax2.axvline(x=0.5, color='orange', linestyle='--', label='중간 효과크기')
        ax2.set_title('효과크기 vs 검정력', fontweight='bold')
        ax2.set_xlabel('효과크기 (Cohen\\'s d)')
        ax2.set_ylabel('검정력')
        ax2.grid(True, alpha=0.3)
        ax2.legend()
        
        # 3. 유의수준과 검정력의 관계
        alphas = np.linspace(0.01, 0.20, 50)
        powers_alpha = [1 - stats.norm.cdf(stats.norm.ppf(1-a/2) - 0.5 * np.sqrt(50/2)) 
                       for a in alphas]
        
        ax3.plot(alphas, powers_alpha, 'purple', linewidth=2)
        ax3.axvline(x=0.05, color='r', linestyle='--', label='일반적 α (0.05)')
        ax3.set_title('유의수준 vs 검정력', fontweight='bold')
        ax3.set_xlabel('유의수준 (α)')
        ax3.set_ylabel('검정력')
        ax3.grid(True, alpha=0.3)
        ax3.legend()
        
        # 4. ROC 곡선 스타일의 오류 트레이드오프
        alphas_roc = np.linspace(0.001, 0.5, 100)
        type1_errors = alphas_roc
        type2_errors = [stats.norm.cdf(stats.norm.ppf(1-a/2) - 0.5 * np.sqrt(50/2)) 
                       for a in alphas_roc]
        
        ax4.plot(type1_errors, type2_errors, 'red', linewidth=2)
        ax4.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='랜덤 선택')
        ax4.set_title('제1종 vs 제2종 오류 트레이드오프', fontweight='bold')
        ax4.set_xlabel('제1종 오류 확률 (α)')
        ax4.set_ylabel('제2종 오류 확률 (β)')
        ax4.grid(True, alpha=0.3)
        ax4.legend()
        
        plt.tight_layout()
        return fig
    
    print("🎨 고급 통계 시각화 도구킷")
    print("=" * 35)
    
    # 시각화 생성
    error_fig = plot_error_types_diagram()
    power_fig = plot_power_analysis()
    
    print("✅ 제1종·제2종 오류 다이어그램 생성 완료")
    print("✅ 검정력 분석 차트 생성 완료")
    
    return plot_error_types_diagram, plot_power_analysis

viz_toolkit = advanced_visualization_toolkit()
```

### 📈 대시보드 스타일 종합 리포트

```python
def comprehensive_hypothesis_testing_report():
    """종합적인 가설검정 리포트 생성"""
    
    def generate_report(data, test_type="t-test", alpha=0.05, **kwargs):
        """가설검정 종합 리포트 생성"""
        
        import pandas as pd
        from scipy import stats
        import numpy as np
        
        print("📊 가설검정 종합 리포트")
        print("=" * 60)
        
        # 1. 데이터 기본 정보
        print("📋 1. 데이터 개요")
        print("-" * 30)
        
        if isinstance(data, (list, np.ndarray)):
            data = np.array(data)
            n = len(data)
            mean = np.mean(data)
            std = np.std(data, ddof=1)
            
            print(f"   표본 크기: {n}")
            print(f"   평균: {mean:.4f}")
            print(f"   표준편차: {std:.4f}")
            print(f"   변동계수: {std/mean*100:.2f}%")
        
        # 2. 검정 실행
        print(f"\n🔬 2. 검정 결과 ({test_type})")
        print("-" * 30)
        
        if test_type == "t-test":
            test_value = kwargs.get('test_value', 0)
            t_stat, p_value = stats.ttest_1samp(data, test_value)
            
            print(f"   귀무가설: μ = {test_value}")
            print(f"   대립가설: μ ≠ {test_value}")
            print(f"   t-통계량: {t_stat:.4f}")
            print(f"   자유도: {n-1}")
            print(f"   P-value: {p_value:.6f}")
            
            # 효과크기 계산
            cohens_d = (mean - test_value) / std
            print(f"   Cohen's d: {cohens_d:.4f}")
            
            # 신뢰구간
            ci = stats.t.interval(1-alpha, n-1, mean, std/np.sqrt(n))
            print(f"   {(1-alpha)*100}% 신뢰구간: ({ci[0]:.4f}, {ci[1]:.4f})")
        
        # 3. 결과 해석
        print(f"\n📊 3. 결과 해석")
        print("-" * 30)
        
        if p_value < 0.001:
            significance = "매우 강한 증거 (***)"
            strength = "🔴"
        elif p_value < 0.01:
            significance = "강한 증거 (**)"
            strength = "🟠"
        elif p_value < alpha:
            significance = "보통 증거 (*)"
            strength = "🟡"
        elif p_value < 0.10:
            significance = "약한 증거 (·)"
            strength = "🟢"
        else:
            significance = "증거 없음 (n.s.)"
            strength = "⚪"
        
        print(f"   통계적 유의성: {strength} {significance}")
        
        if p_value < alpha:
            decision = "H₀ 기각"
            conclusion = "통계적으로 유의한 차이가 있음"
        else:
            decision = "H₀ 채택"
            conclusion = "통계적으로 유의한 차이가 없음"
        
        print(f"   의사결정: {decision}")
        print(f"   결론: {conclusion}")
        
        # 4. 실무적 권고
        print(f"\n💡 4. 실무적 권고사항")
        print("-" * 30)
        
        recommendations = []
        
        if abs(cohens_d) < 0.2:
            recommendations.append("효과크기가 작음 - 실무적 의미 재검토 필요")
        elif abs(cohens_d) < 0.5:
            recommendations.append("중간 정도 효과크기 - 비용-편익 분석 권장")
        else:
            recommendations.append("큰 효과크기 - 실무적으로 의미있는 차이")
        
        if n < 30:
            recommendations.append("표본 크기가 작음 - 추가 데이터 수집 고려")
        
        if p_value < alpha and abs(cohens_d) < 0.2:
            recommendations.append("통계적 유의하지만 효과 작음 - 실무 적용 신중 검토")
        
        for i, rec in enumerate(recommendations, 1):
            print(f"   {i}. {rec}")
        
        # 5. 검정력 분석
        print(f"\n⚡ 5. 검정력 분석")
        print("-" * 30)
        
        # 사후 검정력 계산 (근사)
        if test_type == "t-test":
            ncp = abs(t_stat)  # 비중심모수
            power = 1 - stats.t.cdf(stats.t.ppf(1-alpha/2, n-1), n-1, ncp)
            print(f"   관찰된 검정력: {power:.3f} ({power*100:.1f}%)")
            
            if power < 0.8:
                print("   ⚠️ 검정력이 낮음 - 표본 크기 증가 검토")
            else:
                print("   ✅ 충분한 검정력")
        
        return {
            "p_value": p_value,
            "effect_size": cohens_d if test_type == "t-test" else None,
            "decision": decision,
            "significance": significance,
            "power": power if test_type == "t-test" else None
        }
    
    # 예시 데이터로 리포트 생성
    np.random.seed(42)
    sample_data = np.random.normal(152, 10, 50)
    
    print("🧪 예시: 음식점 분량 검증 리포트")
    result = generate_report(sample_data, "t-test", test_value=150, alpha=0.05)
    
    return generate_report

report_generator = comprehensive_hypothesis_testing_report()
```

---

## 🎓 학습 완성도 체크

### ✅ 마스터리 체크리스트

```python
def mastery_checklist():
    """가설검정 마스터리 체크리스트"""
    
    checklist = {
        "🟢 기초 개념 (Basic Concepts)": {
            "제1종·제2종 오류 정의": "❓ 완벽히 이해하고 설명할 수 있는가?",
            "P-value 해석": "❓ 정확한 의미를 아는가?",
            "유의수준 설정": "❓ 상황에 맞는 α 선택 가능한가?",
            "효과크기 계산": "❓ Cohen's d를 계산하고 해석할 수 있는가?"
        },
        
        "🟡 중급 응용 (Intermediate Application)": {
            "검정력 분석": "❓ 표본 크기를 계산할 수 있는가?",
            "