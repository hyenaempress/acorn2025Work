# 14.1 판다스 파일 I/O 및 청크 처리 상세 가이드

## 14.1.1 다양한 파일 읽기 방법

### CSV 파일 읽기 (read_csv)

#### 기본 사용법
```python
import pandas as pd

# 로컬 파일 읽기 (공백 구분자 사용)
df = pd.read_csv('./code/0806/ex1.csv', sep=' ')
print(df, type(df))
print(df.info())
```

#### 온라인 CSV 파일 읽기
```python
# URL에서 직접 CSV 읽기
df = pd.read_csv('https://raw.githubusercontent.com/pykwon/python/refs/heads/master/testdata_utf8/ex2.csv')
print(df, type(df))
print(df.info())
```

#### 헤더가 없는 CSV 처리
```python
# header=None으로 첫 번째 행을 데이터로 처리
df = pd.read_csv('https://raw.githubusercontent.com/pykwon/python/refs/heads/master/testdata_utf8/ex2.csv', 
                 header=None)
print(df, type(df))
print(df.info())
```

#### 사용자 정의 컬럼명과 행 건너뛰기
```python
# 사용자 정의 컬럼명 지정 및 첫 번째 행 건너뛰기
df = pd.read_csv('https://raw.githubusercontent.com/pykwon/python/refs/heads/master/testdata_utf8/ex2.csv',
                 header=None, 
                 names=['a', 'b', 'c', 'd', 'msg'], 
                 skiprows=1)
print(df, type(df))
print(df.info())
```

### 텍스트 파일 읽기 (read_table)

```python
# 공백으로 구분된 텍스트 파일 읽기
df = pd.read_table('https://raw.githubusercontent.com/pykwon/python/refs/heads/master/testdata_utf8/ex3.txt',
                   sep='\s+')  # 정규식으로 하나 이상의 공백 문자 매칭
print(df, type(df))
print(df.info())
```

**주요 매개변수:**
- `sep='\s+'`: 정규식으로 하나 이상의 공백 문자를 구분자로 사용
- 탭, 공백 등 다양한 공백 문자 처리 가능

### 고정 폭 파일 읽기 (read_fwf)

```python
# Fixed Width Format 파일 읽기
df = pd.read_fwf('https://raw.githubusercontent.com/pykwon/python/refs/heads/master/testdata_utf8/data_fwt.txt',
                 widths=(10, 3, 5),  # 각 컬럼의 폭 지정
                 header=None, 
                 names=('date', 'name', 'price'), 
                 encoding='utf-8')
print(df, type(df))
print(df.info())
```

**주요 매개변수:**
- `widths`: 각 컬럼의 문자 폭을 튜플로 지정
- `header=None`: 헤더가 없음을 명시
- `names`: 컬럼명 직접 지정
- `encoding`: 파일 인코딩 지정

### HTML 테이블 읽기 (read_html)

```python
# 웹페이지의 HTML 테이블 읽기 (주석 처리된 예제)
url = "https://ko.wikipedia.org/wiki/%EB%A6%AC%EB%88%85%EC%8A%A4"
df = pd.read_html(url, encoding='utf-8')
print(df)
print(f"총 {len(df)}개의 테이블이 있습니다.")
```

**특징:**
- 웹페이지의 모든 `<table>` 태그를 자동으로 찾아서 DataFrame 리스트로 반환
- 여러 테이블이 있을 경우 리스트 형태로 반환

## 14.1.2 청크(Chunk) 처리 방식

### 청크 처리의 개념

청크 처리는 대량의 데이터 파일을 작은 단위로 나누어 순차적으로 처리하는 방식입니다.

### 청크 처리의 장단점

#### 장점
- **메모리 효율성**: 메모리 사용량을 크게 줄일 수 있음
- **대량 데이터 처리**: RAM 크기보다 큰 데이터도 처리 가능
- **스트리밍 처리**: 실시간 데이터 처리에 적합
- **분산 처리**: 배치 작업에 유용

#### 단점
- **처리 속도**: 전체 로드보다 일반적으로 느림
- **복잡성**: 코드가 복잡해질 수 있음

### 청크 처리 실제 예제

#### 1. 테스트 데이터 생성

```python
import time
import matplotlib.pyplot as plt
import numpy as np

plt.rc('font', family='Malgun Gothic')

n_rows = 10000
# 큰 데이터셋 생성 예제 (주석 처리됨)
data = {
    'id': range(1, n_rows + 1),
    'name': [f'Student_{i}' for i in range(1, n_rows + 1)],
    'score1': np.random.randint(50, 101, n_rows),
    'score2': np.random.randint(50, 101, n_rows)
}

df = pd.DataFrame(data)
df.to_csv('students.csv', index=False, encoding='utf-8-sig')
```

#### 2. 전체 데이터 한 번에 처리

```python
# 전체 데이터를 메모리에 로드하여 처리
start_all = time.time()
df_all = pd.read_csv('students.csv', encoding='utf-8-sig')
time_all = time.time() - start_all

# 평균 점수 계산
avg_score1 = (df_all['score1'] + df_all['score2']) / 2
print(f"전체 평균 점수: {avg_score1.mean():.2f}")
```

**주의사항:**
- 코드에서 `avg_score2 = (df_all['score2'] + df_all['score2']) / 2`는 오류
- 올바른 계산: `(df_all['score1'] + df_all['score2']) / 2`

#### 3. 청크 단위 처리

```python
# 청크 단위로 데이터 처리
chunk_size = 1000
total_score1 = 0
total_score2 = 0
total_count = 0

start_chunk_total = time.time()
for i, chunk in enumerate(pd.read_csv('students.csv', chunksize=chunk_size)):
    start_chunk = time.time()
    
    # 각 청크의 첫 번째 학생 정보 출력
    if i != 0:
        first_student = chunk.iloc[0]
        print(f"Chunk {i + 1}:")
        print(f"첫번째 학생 id={first_student['id']}")
        print(f"이름={first_student['name']}")
        print(f"점수1={first_student['score1']}")
        print(f"점수2={first_student['score2']}")
    
    # 누적 계산
    total_score1 += chunk['score1'].sum()
    total_score2 += chunk['score2'].sum()
    total_count += len(chunk)
    
    end_chunk = time.time()
    elapsed = end_chunk - start_chunk
    print(f"청크 {i + 1} 처리 시간: {elapsed:.4f}초")

time_chunk_total = time.time() - start_chunk_total

# 최종 평균 계산
average_score1 = total_score1 / total_count
average_score2 = total_score2 / total_count
```

### 청크 처리 핵심 개념

#### chunksize 매개변수
```python
pd.read_csv('file.csv', chunksize=1000)
```
- 한 번에 읽을 행의 수를 지정
- 메모리 사용량과 처리 속도의 트레이드오프 고려

#### 반복자(Iterator) 패턴
```python
for chunk in pd.read_csv('file.csv', chunksize=1000):
    # 각 청크에 대한 처리 로직
    process_chunk(chunk)
```

## 14.1.3 성능 비교 및 시각화

### 처리 시간 비교

```python
print('\n처리 결과 요약')
print(f"전체 학생 수: {total_count}")
print(f"Score1 총합: {total_score1}, 평균: {average_score1:.2f}")
print(f"Score2 총합: {total_score2}, 평균: {average_score2:.2f}")
print(f'전체 한 번에 처리 한 경우 소요 시간: {time_all:.4f}초')
print(f"청크 단위로 처리한 경우 소요 시간: {time_chunk_total:.4f}초")
```

### 성능 시각화

```python
# 막대 그래프로 처리 시간 비교
labels = ['전체 한번에 처리', '청크 단위로 처리']
times = [time_all, time_chunk_total]

plt.figure(figsize=(6, 4))
bars = plt.bar(labels, times, color=['skyblue', 'yellow'])

# 막대 위에 시간 값 표시
for bar, time_val in zip(bars, times):
    plt.text(bar.get_x() + bar.get_width() / 2, 
             bar.get_height() + 0.01, 
             f'{time_val:.4f}초',
             ha='center', va='bottom', fontsize=10)

plt.ylabel('처리시간(초)')
plt.title('전체 vs 청크 단위 처리 시간 비교')
plt.grid(alpha=0.5)
plt.tight_layout()
plt.show()
```

## 14.1.4 실무 활용 팁

### 언제 청크 처리를 사용할까?

1. **대용량 파일 처리**: 파일 크기가 사용 가능한 RAM보다 클 때
2. **실시간 처리**: 로그 파일 분석, 스트리밍 데이터 처리
3. **메모리 제약**: 제한된 메모리 환경에서 작업할 때
4. **배치 처리**: ETL 작업에서 데이터를 단계적으로 처리할 때

### 최적의 청크 크기 결정

```python
# 청크 크기별 성능 테스트 예제
chunk_sizes = [500, 1000, 2000, 5000]
for size in chunk_sizes:
    start_time = time.time()
    total_rows = 0
    for chunk in pd.read_csv('large_file.csv', chunksize=size):
        total_rows += len(chunk)
        # 실제 처리 로직
    end_time = time.time()
    print(f"청크 크기 {size}: {end_time - start_time:.4f}초")
```

### 메모리 사용량 모니터링

```python
import psutil
import os

def get_memory_usage():
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024  # MB

# 처리 전후 메모리 사용량 비교
before_memory = get_memory_usage()
# 데이터 처리
after_memory = get_memory_usage()
print(f"메모리 사용량 증가: {after_memory - before_memory:.2f} MB")
```

## 14.1.5 주요 매개변수 정리

### read_csv 주요 매개변수
- `sep`: 구분자 지정 (기본값: ',')
- `header`: 헤더 행 지정 (None이면 헤더 없음)
- `names`: 컬럼명 직접 지정
- `skiprows`: 건너뛸 행 수
- `chunksize`: 청크 크기 지정
- `encoding`: 파일 인코딩 (utf-8, utf-8-sig 등)
- `dtype`: 컬럼 데이터 타입 지정
- `na_values`: 결측치로 처리할 값들

### 성능 최적화 팁
1. **적절한 데이터 타입 지정**: `dtype` 매개변수 활용
2. **필요한 컬럼만 읽기**: `usecols` 매개변수 사용
3. **인덱스 설정**: `index_col` 매개변수로 인덱스 직접 지정
4. **청크 크기 조정**: 메모리와 성능의 균형점 찾기

이러한 방식으로 판다스의 다양한 파일 I/O 기능과 청크 처리 방식을 효율적으로 활용할 수 있습니다.