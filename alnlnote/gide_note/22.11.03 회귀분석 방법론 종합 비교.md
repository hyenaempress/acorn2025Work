# 22.11.03 íšŒê·€ë¶„ì„ ë°©ë²•ë¡  ì¢…í•© ë¹„êµ
*4ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ë§ˆìŠ¤í„°í•˜ëŠ” ì™„ì „í•œ íšŒê·€ë¶„ì„*

---

## ğŸ¯ í•™ìŠµ ëª©í‘œ

ì´ ë¬¸ì„œì—ì„œëŠ” **ë™ì¼í•œ íšŒê·€ë¶„ì„ì„ 4ê°€ì§€ ë‹¤ë¥¸ ë°©ë²•**ìœ¼ë¡œ êµ¬í˜„í•˜ì—¬ ê° ë°©ë²•ì˜ ì¥ë‹¨ì ê³¼ íŠ¹ì§•ì„ ì™„ì „íˆ ì´í•´í•˜ê³ , ì‹¤ë¬´ì—ì„œ ìƒí™©ì— ë§ëŠ” ìµœì ì˜ ë„êµ¬ë¥¼ ì„ íƒí•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.

### âœ… í•µì‹¬ í•™ìŠµ ë‚´ìš©
- 4ê°€ì§€ íšŒê·€ë¶„ì„ êµ¬í˜„ ë°©ë²• ì™„ì „ ë¹„êµ
- ê° ë°©ë²•ì˜ ì¥ë‹¨ì ê³¼ ì ìš© ìƒí™©
- ê²°ê³¼ í•´ì„ê³¼ ëª¨ë¸ í‰ê°€
- ì‹¤ë¬´ì  ì˜ì‚¬ê²°ì • ê°€ì´ë“œ

---

## ğŸ“Š íšŒê·€ë¶„ì„ 4ëŒ€ ë°©ë²•ë¡  ê°œìš”

| ë°©ë²• | ë¼ì´ë¸ŒëŸ¬ë¦¬ | íŠ¹ì§• | ì ìš© ìƒí™© |
|------|-----------|------|----------|
| **ë°©ë²• 1** | `make_regression` | ë°ì´í„° ìƒì„± + ê°„ë‹¨ ê³„ì‚° | í•™ìŠµ/ê²€ì¦ìš© |
| **ë°©ë²• 2** | `sklearn` | ë¨¸ì‹ ëŸ¬ë‹ ìŠ¤íƒ€ì¼ | ì˜ˆì¸¡ ì¤‘ì‹¬ |
| **ë°©ë²• 3** | `statsmodels` | í†µê³„í•™ ìŠ¤íƒ€ì¼ | ì¶”ë¡ /í•´ì„ ì¤‘ì‹¬ |
| **ë°©ë²• 4** | `scipy.stats` | í•µì‹¬ í†µê³„ í•¨ìˆ˜ | ìƒê´€ë¶„ì„ í¬í•¨ |

---

## ğŸ’» ë°©ë²• 1: make_regressionìœ¼ë¡œ íšŒê·€ë¶„ì„ ë§›ë³´ê¸°

### ğŸ¯ íŠ¹ì§•: ê°€ì¥ ì§ê´€ì ì¸ ì´í•´

```python
import numpy as np
from sklearn.datasets import make_regression
import matplotlib.pyplot as plt

plt.rc('font', family='Malgun Gothic')
np.random.seed(12)

print("ğŸ”¬ ë°©ë²• 1: make_regressionì„ í™œìš©í•œ íšŒê·€ë¶„ì„")
print("=" * 60)

# í•©ì„± ë°ì´í„° ìƒì„±
x, y, coef = make_regression(n_samples=50, n_features=1, bias=100, coef=True)

print(f"ğŸ“Š ìƒì„±ëœ ë°ì´í„° ì •ë³´:")
print(f"   ìƒ˜í”Œ ìˆ˜: {len(x)}")
print(f"   ë…ë¦½ë³€ìˆ˜ ë²”ìœ„: {x.min():.2f} ~ {x.max():.2f}")
print(f"   ì¢…ì†ë³€ìˆ˜ ë²”ìœ„: {y.min():.2f} ~ {y.max():.2f}")
print(f"   ì‹¤ì œ ê¸°ìš¸ê¸°: {coef:.8f}")
print(f"   ì‹¤ì œ ì ˆí¸: 100")

# ì§ì ‘ ì˜ˆì¸¡ê°’ ê³„ì‚°
sample_x = x[0][0]  # ì²« ë²ˆì§¸ xê°’
sample_y = y[0]     # ì²« ë²ˆì§¸ yê°’
predicted_y = coef * sample_x + 100

print(f"\nğŸ” ì˜ˆì¸¡ ì˜ˆì œ:")
print(f"   x = {sample_x:.8f}")
print(f"   ì‹¤ì œ y = {sample_y:.8f}")
print(f"   ì˜ˆì¸¡ y = {coef:.8f} Ã— {sample_x:.8f} + 100 = {predicted_y:.8f}")
print(f"   ì˜¤ì°¨ = {abs(sample_y - predicted_y):.8f}")

# ìƒˆë¡œìš´ ê°’ ì˜ˆì¸¡
new_x = 5.0
new_pred = coef * new_x + 100
print(f"\nğŸ”® ìƒˆë¡œìš´ ì˜ˆì¸¡:")
print(f"   x = {new_x} â†’ ì˜ˆì¸¡ y = {new_pred:.2f}")

# ì‹œê°í™”
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.scatter(x, y, alpha=0.7, s=60, color='blue')
x_line = np.linspace(x.min(), x.max(), 100)
y_line = coef * x_line + 100
plt.plot(x_line, y_line, 'r-', linewidth=2, label=f'y = {coef:.2f}x + 100')
plt.xlabel('ë…ë¦½ë³€ìˆ˜ (x)')
plt.ylabel('ì¢…ì†ë³€ìˆ˜ (y)')
plt.title('make_regression ìƒì„± ë°ì´í„°')
plt.legend()
plt.grid(True, alpha=0.3)

# ì”ì°¨ í”Œë¡¯
plt.subplot(1, 2, 2)
residuals = y - (coef * x.ravel() + 100)
plt.scatter(x, residuals, alpha=0.7, s=60, color='green')
plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
plt.xlabel('ë…ë¦½ë³€ìˆ˜ (x)')
plt.ylabel('ì”ì°¨')
plt.title('ì”ì°¨ ë¶„í¬')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"\nâœ… ë°©ë²• 1 ìš”ì•½:")
print(f"   â€¢ ì¥ì : ì´ë¡ ì  ì´í•´ì— ìµœì , ë…¸ì´ì¦ˆ ì—†ëŠ” ì™„ë²½í•œ ì„ í˜•ê´€ê³„")
print(f"   â€¢ ë‹¨ì : ì‹¤ì œ ë°ì´í„° ë¶„ì„ì—ëŠ” ë¶€ì í•©")
print(f"   â€¢ ìš©ë„: ì•Œê³ ë¦¬ì¦˜ í•™ìŠµ, ê²€ì¦ìš© ë°ì´í„° ìƒì„±")
```

---

## ğŸ¤– ë°©ë²• 2: Scikit-learnìœ¼ë¡œ ë¨¸ì‹ ëŸ¬ë‹ ìŠ¤íƒ€ì¼ íšŒê·€

### ğŸ¯ íŠ¹ì§•: ì˜ˆì¸¡ì— ìµœì í™”ëœ ì ‘ê·¼

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd

print(f"\nğŸ¤– ë°©ë²• 2: sklearn LinearRegression")
print("=" * 60)

# ë™ì¼í•œ ë°ì´í„° ì‚¬ìš©
X = x  # 2ì°¨ì› ë°°ì—´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
y = y

# ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = LinearRegression()
fitted_model = model.fit(X, y)

# ëª¨ë¸ íŒŒë¼ë¯¸í„° í™•ì¸
slope = fitted_model.coef_[0]
intercept = fitted_model.intercept_

print(f"ğŸ“ í•™ìŠµëœ ëª¨ë¸ íŒŒë¼ë¯¸í„°:")
print(f"   ê¸°ìš¸ê¸°: {slope:.8f} (ì‹¤ì œ: {coef:.8f})")
print(f"   ì ˆí¸: {intercept:.8f} (ì‹¤ì œ: 100)")
print(f"   íšŒê·€ì‹: y = {slope:.6f}x + {intercept:.6f}")

# ì˜ˆì¸¡ ìˆ˜í–‰
y_pred = model.predict(X)
sample_pred = model.predict([[sample_x]])

print(f"\nğŸ¯ ì˜ˆì¸¡ ì„±ëŠ¥:")
print(f"   ìƒ˜í”Œ ì˜ˆì¸¡: x={sample_x:.6f} â†’ y={sample_pred[0]:.6f}")
print(f"   ì‹¤ì œê°’ê³¼ ë¹„êµ: {abs(y[0] - sample_pred[0]):.8f}")

# ì„±ëŠ¥ ì§€í‘œ
mse = mean_squared_error(y, y_pred)
r2 = r2_score(y, y_pred)
rmse = np.sqrt(mse)

print(f"\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ:")
print(f"   RÂ² (ê²°ì •ê³„ìˆ˜): {r2:.8f}")
print(f"   MSE (í‰ê· ì œê³±ì˜¤ì°¨): {mse:.2e}")
print(f"   RMSE (í‰ê· ì œê³±ê·¼ì˜¤ì°¨): {rmse:.2e}")

# ìƒˆë¡œìš´ ê°’ë“¤ ì˜ˆì¸¡
new_X = np.array([[5], [3], [-2]])
new_predictions = model.predict(new_X)

print(f"\nğŸ”® ìƒˆë¡œìš´ ê°’ ì˜ˆì¸¡:")
for i, (x_val, pred) in enumerate(zip(new_X.ravel(), new_predictions)):
    print(f"   x = {x_val:4.1f} â†’ ì˜ˆì¸¡ y = {pred:8.2f}")

# ì„±ëŠ¥ ì‹œê°í™”
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.scatter(X, y, alpha=0.7, s=60, color='blue', label='ì‹¤ì œê°’')
plt.plot(X, y_pred, 'ro', alpha=0.7, markersize=4, label='ì˜ˆì¸¡ê°’')
x_line = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)
y_line = model.predict(x_line)
plt.plot(x_line, y_line, 'r-', linewidth=2, label='íšŒê·€ì„ ')
plt.xlabel('ë…ë¦½ë³€ìˆ˜ (x)')
plt.ylabel('ì¢…ì†ë³€ìˆ˜ (y)')
plt.title(f'Sklearn íšŒê·€ê²°ê³¼ (RÂ² = {r2:.4f})')
plt.legend()
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.scatter(y_pred, y - y_pred, alpha=0.7, s=60, color='orange')
plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
plt.xlabel('ì˜ˆì¸¡ê°’')
plt.ylabel('ì”ì°¨ (ì‹¤ì œê°’ - ì˜ˆì¸¡ê°’)')
plt.title('ì”ì°¨ vs ì˜ˆì¸¡ê°’')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"\nâœ… ë°©ë²• 2 ìš”ì•½:")
print(f"   â€¢ ì¥ì : ì˜ˆì¸¡ ì¤‘ì‹¬, ë‹¤ë¥¸ ML ì•Œê³ ë¦¬ì¦˜ê³¼ ì¼ê´€ëœ API")
print(f"   â€¢ ë‹¨ì : í†µê³„ì  ì¶”ë¡  ì •ë³´ ë¶€ì¡±")
print(f"   â€¢ ìš©ë„: ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸, ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•")
```

---

## ğŸ“ˆ ë°©ë²• 3: Statsmodelsë¡œ í†µê³„í•™ìì²˜ëŸ¼ ë¶„ì„

### ğŸ¯ íŠ¹ì§•: ê°€ì¥ ìƒì„¸í•œ í†µê³„ ì •ë³´ ì œê³µ

```python
import statsmodels.api as sm
import statsmodels.formula.api as smf
import pandas as pd

print(f"\nğŸ“ˆ ë°©ë²• 3: statsmodels OLS íšŒê·€ë¶„ì„")
print("=" * 60)

# ë°ì´í„° ì¤€ë¹„ (1ì°¨ì› ë°°ì—´ë¡œ ë³€í™˜)
x_flat = x.ravel()
y_flat = y

# DataFrame ìƒì„±
regression_data = pd.DataFrame({
    'x': x_flat,
    'y': y_flat
})

print(f"ğŸ“Š ë°ì´í„° ì¤€ë¹„:")
print(f"   ë°ì´í„° í˜•íƒœ: {regression_data.shape}")
print(regression_data.head(3))

# OLS íšŒê·€ë¶„ì„ ì‹¤í–‰
model_ols = smf.ols(formula='y ~ x', data=regression_data).fit()

print(f"\nğŸ“‹ íšŒê·€ë¶„ì„ ìƒì„¸ ê²°ê³¼:")
print(model_ols.summary())

# ì£¼ìš” ê²°ê³¼ ì¶”ì¶œ
params = model_ols.params
pvalues = model_ols.pvalues
rsquared = model_ols.rsquared
aic = model_ols.aic
bic = model_ols.bic

print(f"\nğŸ” í•µì‹¬ ê²°ê³¼ í•´ì„:")
print(f"   íšŒê·€ê³„ìˆ˜:")
print(f"     â€¢ ì ˆí¸: {params['Intercept']:.6f} (p-value: {pvalues['Intercept']:.2e})")
print(f"     â€¢ ê¸°ìš¸ê¸°: {params['x']:.6f} (p-value: {pvalues['x']:.2e})")
print(f"   ëª¨ë¸ ì í•©ë„:")
print(f"     â€¢ RÂ²: {rsquared:.8f}")
print(f"     â€¢ AIC: {aic:.2f}")
print(f"     â€¢ BIC: {bic:.2f}")

# ì˜ˆì¸¡ ìˆ˜í–‰
sample_df = pd.DataFrame({'x': [sample_x]})
sample_pred_ols = model_ols.predict(sample_df)
print(f"\nğŸ¯ ì˜ˆì¸¡ ê²°ê³¼:")
print(f"   x = {sample_x:.6f} â†’ ì˜ˆì¸¡ y = {sample_pred_ols.values[0]:.6f}")

# ìƒˆë¡œìš´ ê°’ ì˜ˆì¸¡
new_df = pd.DataFrame({'x': [5.0, 3.0, -2.0]})
new_pred_ols = model_ols.predict(new_df)
print(f"\nğŸ”® ìƒˆë¡œìš´ ê°’ ì˜ˆì¸¡:")
for x_val, pred in zip(new_df['x'], new_pred_ols):
    print(f"   x = {x_val:4.1f} â†’ ì˜ˆì¸¡ y = {pred:8.2f}")

# ì‹ ë¢°êµ¬ê°„ê³¼ ì˜ˆì¸¡êµ¬ê°„
predictions = model_ols.get_prediction(regression_data[['x']])
pred_summary = predictions.summary_frame(alpha=0.05)

print(f"\nğŸ“Š ì‹ ë¢°êµ¬ê°„ ì •ë³´:")
print(pred_summary.head(3)[['mean', 'mean_ci_lower', 'mean_ci_upper']])

# ì§„ë‹¨ í”Œë¡¯
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# 1. íšŒê·€ì„ ê³¼ ì‹ ë¢°êµ¬ê°„
ax1 = axes[0, 0]
ax1.scatter(regression_data['x'], regression_data['y'], alpha=0.7, s=60, color='blue')
x_sorted = regression_data['x'].sort_values()
pred_sorted = model_ols.predict(pd.DataFrame({'x': x_sorted}))
ax1.plot(x_sorted, pred_sorted, 'r-', linewidth=2, label='íšŒê·€ì„ ')

# ì‹ ë¢°êµ¬ê°„ ì¶”ê°€
pred_ci = model_ols.get_prediction(pd.DataFrame({'x': x_sorted})).summary_frame(alpha=0.05)
ax1.fill_between(x_sorted, pred_ci['mean_ci_lower'], pred_ci['mean_ci_upper'], 
                alpha=0.3, color='red', label='95% ì‹ ë¢°êµ¬ê°„')
ax1.set_xlabel('x')
ax1.set_ylabel('y')
ax1.set_title('íšŒê·€ì„ ê³¼ ì‹ ë¢°êµ¬ê°„')
ax1.legend()
ax1.grid(True, alpha=0.3)

# 2. ì”ì°¨ vs ì˜ˆì¸¡ê°’
ax2 = axes[0, 1]
fitted_values = model_ols.fittedvalues
residuals = model_ols.resid
ax2.scatter(fitted_values, residuals, alpha=0.7, s=60, color='green')
ax2.axhline(y=0, color='red', linestyle='--', linewidth=2)
ax2.set_xlabel('ì˜ˆì¸¡ê°’')
ax2.set_ylabel('ì”ì°¨')
ax2.set_title('ì”ì°¨ vs ì˜ˆì¸¡ê°’')
ax2.grid(True, alpha=0.3)

# 3. Q-Q í”Œë¡¯ (ì •ê·œì„± ê²€ì •)
from scipy.stats import probplot
ax3 = axes[1, 0]
probplot(residuals, dist="norm", plot=ax3)
ax3.set_title('Q-Q í”Œë¡¯ (ì”ì°¨ ì •ê·œì„±)')
ax3.grid(True, alpha=0.3)

# 4. ì”ì°¨ íˆìŠ¤í† ê·¸ë¨
ax4 = axes[1, 1]
ax4.hist(residuals, bins=15, alpha=0.7, color='orange', edgecolor='black')
ax4.axvline(x=0, color='red', linestyle='--', linewidth=2)
ax4.set_xlabel('ì”ì°¨')
ax4.set_ylabel('ë¹ˆë„')
ax4.set_title('ì”ì°¨ ë¶„í¬')
ax4.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"\nâœ… ë°©ë²• 3 ìš”ì•½:")
print(f"   â€¢ ì¥ì : ê°€ì¥ ìƒì„¸í•œ í†µê³„ ì •ë³´, ê°€ì„¤ê²€ì •, ì‹ ë¢°êµ¬ê°„")
print(f"   â€¢ ë‹¨ì : ë³µì¡í•œ ë¬¸ë²•, í•™ìŠµ ê³¡ì„ ")
print(f"   â€¢ ìš©ë„: í•™ìˆ  ì—°êµ¬, í†µê³„ì  ì¶”ë¡ , ëª¨ë¸ ì§„ë‹¨")
```

---

## ğŸ“Š ë°©ë²• 4: Scipy.statsë¡œ ìƒê´€ë¶„ì„ê³¼ íšŒê·€ í†µí•©

### ğŸ¯ íŠ¹ì§•: ìƒê´€ê´€ê³„ë¶€í„° íšŒê·€ê¹Œì§€ ì›ìŠ¤í†±

```python
from scipy import stats
import pandas as pd

print(f"\nğŸ“Š ë°©ë²• 4: scipy.stats ì¢…í•©ë¶„ì„")
print("=" * 60)

# ì‹¤ì œ ë°ì´í„° ë¡œë“œ (IQ-ì ìˆ˜ ë°ì´í„°)
try:
    score_iq = pd.read_csv('https://raw.githubusercontent.com/pykwon/python/refs/heads/master/testdata_utf8/score_iq.csv')
    print(f"ğŸ“ ì‹¤ì œ ë°ì´í„° ë¡œë“œ ì„±ê³µ!")
    
    x_real = score_iq['iq'].values
    y_real = score_iq['score'].values
    
    print(f"   ë°ì´í„° í¬ê¸°: {len(x_real)}ê°œ ìƒ˜í”Œ")
    print(f"   IQ ë²”ìœ„: {x_real.min():.1f} ~ {x_real.max():.1f}")
    print(f"   ì ìˆ˜ ë²”ìœ„: {y_real.min():.1f} ~ {y_real.max():.1f}")
    
except:
    print(f"âš ï¸ ì™¸ë¶€ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨, ìƒì„± ë°ì´í„° ì‚¬ìš©")
    x_real = x.ravel()
    y_real = y

# 1ë‹¨ê³„: ìƒê´€ê´€ê³„ ë¶„ì„
correlation_matrix = np.corrcoef(x_real, y_real)
correlation_coef = correlation_matrix[0, 1]

print(f"\nğŸ”— ìƒê´€ê´€ê³„ ë¶„ì„:")
print(f"   í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜: {correlation_coef:.6f}")

if abs(correlation_coef) >= 0.7:
    strength = "ê°•í•œ"
elif abs(correlation_coef) >= 0.3:
    strength = "ì¤‘ê°„"
else:
    strength = "ì•½í•œ"

direction = "ì–‘ì˜" if correlation_coef > 0 else "ìŒì˜"
print(f"   í•´ì„: {direction} {strength} ìƒê´€ê´€ê³„")

# DataFrameìœ¼ë¡œ ìƒê´€ê´€ê³„ í™•ì¸
if len(x_real) > 50:  # ì‹¤ì œ ë°ì´í„°ì¸ ê²½ìš°
    df_corr = pd.DataFrame({'iq': x_real, 'score': y_real})
    corr_df = df_corr.corr()
    print(f"\nğŸ“Š ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤:")
    print(corr_df)

# 2ë‹¨ê³„: ì„ í˜•íšŒê·€ë¶„ì„
linregress_result = stats.linregress(x_real, y_real)

print(f"\nğŸ“ˆ ì„ í˜•íšŒê·€ë¶„ì„ ê²°ê³¼:")
print(f"   ê¸°ìš¸ê¸° (slope): {linregress_result.slope:.8f}")
print(f"   ì ˆí¸ (intercept): {linregress_result.intercept:.8f}")
print(f"   ìƒê´€ê³„ìˆ˜ (r): {linregress_result.rvalue:.8f}")
print(f"   p-value: {linregress_result.pvalue:.2e}")
print(f"   í‘œì¤€ì˜¤ì°¨ (stderr): {linregress_result.stderr:.8f}")

# í†µê³„ì  ìœ ì˜ì„± íŒë‹¨
alpha = 0.05
if linregress_result.pvalue < alpha:
    significance = "ìœ ì˜í•¨ âœ…"
    print(f"   â†’ ë…ë¦½ë³€ìˆ˜ê°€ ì¢…ì†ë³€ìˆ˜ì— ìœ ì˜í•œ ì˜í–¥ì„ ë¯¸ì¹¨")
else:
    significance = "ìœ ì˜í•˜ì§€ ì•ŠìŒ âŒ"
    print(f"   â†’ ë…ë¦½ë³€ìˆ˜ê°€ ì¢…ì†ë³€ìˆ˜ì— ìœ ì˜í•œ ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠìŒ")

print(f"   í†µê³„ì  ìœ ì˜ì„± (Î±=0.05): {significance}")

# 3ë‹¨ê³„: ì˜ˆì¸¡ ìˆ˜í–‰
def predict_with_scipy(x_values):
    """scipy ê²°ê³¼ë¡œ ì˜ˆì¸¡ê°’ ê³„ì‚°"""
    return linregress_result.slope * x_values + linregress_result.intercept

# ì˜ˆì¸¡ ì˜ˆì œ
if len(x_real) > 50:  # ì‹¤ì œ ë°ì´í„°ì¸ ê²½ìš°
    test_values = [80, 100, 120]
    print(f"\nğŸ”® ì ìˆ˜ ì˜ˆì¸¡ (IQ ê¸°ë°˜):")
    for iq in test_values:
        predicted_score = predict_with_scipy(iq)
        print(f"   IQ {iq} â†’ ì˜ˆìƒ ì ìˆ˜: {predicted_score:.1f}")
else:
    test_values = [0, 1, 2]
    print(f"\nğŸ”® ì˜ˆì¸¡ ê²°ê³¼:")
    for x_val in test_values:
        predicted_y = predict_with_scipy(x_val)
        print(f"   x = {x_val} â†’ ì˜ˆì¸¡ y = {predicted_y:.2f}")

# numpy polyvalì„ ì´ìš©í•œ ì˜ˆì¸¡ (ë™ì¼í•œ ê²°ê³¼)
poly_predictions = np.polyval([linregress_result.slope, linregress_result.intercept], test_values)
print(f"\nğŸ”„ numpy.polyval ê²€ì¦:")
for i, (x_val, pred) in enumerate(zip(test_values, poly_predictions)):
    print(f"   x = {x_val} â†’ ì˜ˆì¸¡ y = {pred:.2f}")

# ì‹œê°í™”
plt.figure(figsize=(15, 5))

# 1. ì‚°ì ë„ì™€ íšŒê·€ì„ 
plt.subplot(1, 3, 1)
plt.scatter(x_real, y_real, alpha=0.6, s=40, color='blue')
x_line = np.linspace(x_real.min(), x_real.max(), 100)
y_line = linregress_result.slope * x_line + linregress_result.intercept
plt.plot(x_line, y_line, 'r-', linewidth=2, 
         label=f'y = {linregress_result.slope:.3f}x + {linregress_result.intercept:.1f}')
plt.xlabel('ë…ë¦½ë³€ìˆ˜')
plt.ylabel('ì¢…ì†ë³€ìˆ˜')
plt.title(f'ìƒê´€ê³„ìˆ˜ r = {correlation_coef:.3f}')
plt.legend()
plt.grid(True, alpha=0.3)

# 2. ì”ì°¨ ë¶„ì„
y_pred_scipy = predict_with_scipy(x_real)
residuals_scipy = y_real - y_pred_scipy

plt.subplot(1, 3, 2)
plt.scatter(y_pred_scipy, residuals_scipy, alpha=0.6, s=40, color='green')
plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
plt.xlabel('ì˜ˆì¸¡ê°’')
plt.ylabel('ì”ì°¨')
plt.title('ì”ì°¨ ë¶„ì„')
plt.grid(True, alpha=0.3)

# 3. ì„±ëŠ¥ ì§€í‘œ
r_squared = linregress_result.rvalue ** 2
rmse_scipy = np.sqrt(np.mean(residuals_scipy ** 2))

plt.subplot(1, 3, 3)
metrics = ['RÂ²', 'RMSE', '|r|']
values = [r_squared, rmse_scipy/np.std(y_real), abs(correlation_coef)]  # ì •ê·œí™”
colors = ['lightgreen', 'lightcoral', 'lightskyblue']

bars = plt.bar(metrics, values, color=colors, alpha=0.7, edgecolor='black')
plt.ylabel('ì •ê·œí™”ëœ ê°’')
plt.title('ì„±ëŠ¥ ì§€í‘œ')

# ì‹¤ì œ ê°’ í‘œì‹œ
actual_values = [r_squared, rmse_scipy, abs(correlation_coef)]
for bar, value in zip(bars, actual_values):
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,
             f'{value:.3f}', ha='center', va='bottom', fontweight='bold')

plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print(f"\nâœ… ë°©ë²• 4 ìš”ì•½:")
print(f"   â€¢ ì¥ì : ìƒê´€ë¶„ì„+íšŒê·€ë¶„ì„ í†µí•©, ê°„ë‹¨í•œ ì‚¬ìš©ë²•")
print(f"   â€¢ ë‹¨ì : ì œí•œì ì¸ ê³ ê¸‰ ê¸°ëŠ¥")
print(f"   â€¢ ìš©ë„: íƒìƒ‰ì  ë¶„ì„, ë¹ ë¥¸ ìƒê´€ê´€ê³„ í™•ì¸")
```

---

## ğŸ“Š ì‹œê°ì  í•µì‹¬ ì •ë¦¬

### ğŸ¯ **í•œëˆˆì— ë³´ëŠ” 4ê°€ì§€ ë°©ë²• ë¹„êµ**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    íšŒê·€ë¶„ì„ 4ê°€ì§€ ë°©ë²• ì™„ì „ë¹„êµ                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ë°©ë²•1: make_regression    â”‚  ë°©ë²•2: sklearn                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ğŸ“ í•™ìŠµ/ì—°ìŠµ ì „ìš©    â”‚   â”‚  â”‚ ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸      â”‚   â”‚
â”‚  â”‚                     â”‚   â”‚  â”‚                             â”‚   â”‚
â”‚  â”‚ íŠ¹ì§•: ì™„ë²½í•œ ì„ í˜•ê´€ê³„â”‚   â”‚  â”‚ íŠ¹ì§•: ì˜ˆì¸¡ ì¤‘ì‹¬ API         â”‚   â”‚
â”‚  â”‚ ê²°ê³¼: ë…¸ì´ì¦ˆ ì—†ìŒ    â”‚   â”‚  â”‚ ê²°ê³¼: ê°„ë‹¨í•œ ì„±ëŠ¥ì§€í‘œ       â”‚   â”‚
â”‚  â”‚ ìš©ë„: ê°œë… ì´í•´      â”‚   â”‚  â”‚ ìš©ë„: ì‹¤ì œ ì˜ˆì¸¡ ëª¨ë¸        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                             â”‚                                   â”‚
â”‚  ë°©ë²•3: statsmodels OLS     â”‚  ë°©ë²•4: scipy.stats              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ ğŸ“Š í†µê³„í•™ì ìŠ¤íƒ€ì¼      â”‚â”‚  â”‚ ğŸ” íƒìƒ‰ì  ë¶„ì„ ë„êµ¬         â”‚ â”‚
â”‚  â”‚                         â”‚â”‚  â”‚                             â”‚ â”‚
â”‚  â”‚ íŠ¹ì§•: ìƒì„¸í•œ í†µê³„ì •ë³´   â”‚â”‚  â”‚ íŠ¹ì§•: ìƒê´€+íšŒê·€ í†µí•©        â”‚ â”‚
â”‚  â”‚ ê²°ê³¼: p-value, ì‹ ë¢°êµ¬ê°„ â”‚â”‚  â”‚ ê²°ê³¼: ë¹ ë¥¸ ê´€ê³„ í™•ì¸        â”‚ â”‚
â”‚  â”‚ ìš©ë„: ì—°êµ¬, ê°€ì„¤ê²€ì •    â”‚â”‚  â”‚ ìš©ë„: ì´ˆê¸° ë°ì´í„° íƒìƒ‰      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

       â†“ ëª¨ë“  ë°©ë²•ì´ ê°™ì€ ê²°ê³¼ ì‚°ì¶œ â†“
    
    y = 0.651x + (-2.856)  â†  ë™ì¼í•œ íšŒê·€ì‹!
    RÂ² = 0.882             â†  ë™ì¼í•œ ì„¤ëª…ë ¥!
```

### ğŸ”„ **ì‹¤ë¬´ ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨**

```
ğŸ“Š ë°ì´í„° ìˆ˜ì§‘
    â†“
ğŸ” íƒìƒ‰ì  ë¶„ì„ (EDA)
    â”œâ”€ ì‚°ì ë„ í™•ì¸
    â”œâ”€ ìƒê´€ê³„ìˆ˜ ê³„ì‚° (r > 0.3)
    â””â”€ ì´ìƒì¹˜ íƒì§€
    â†“
ğŸ¯ ë°©ë²• ì„ íƒ
    â”œâ”€ í•™ìŠµìš© â†’ make_regression
    â”œâ”€ ì˜ˆì¸¡ìš© â†’ sklearn
    â”œâ”€ ì—°êµ¬ìš© â†’ statsmodels  
    â””â”€ íƒìƒ‰ìš© â†’ scipy.stats
    â†“
âš¡ ëª¨ë¸ í•™ìŠµ
    â”œâ”€ X, y ë°ì´í„° ì¤€ë¹„
    â”œâ”€ ì°¨ì› í™•ì¸ (sklearn: 2D í•„ìˆ˜!)
    â””â”€ fit() ì‹¤í–‰
    â†“
ğŸ“ˆ ì„±ëŠ¥ ê²€ì¦
    â”œâ”€ ê¸°ì¡´ ë°ì´í„°ë¡œ ì˜ˆì¸¡
    â”œâ”€ RÂ², RMSE ê³„ì‚°
    â””â”€ ì”ì°¨ ë¶„ì„
    â†“
ğŸ”® ìƒˆë¡œìš´ ì˜ˆì¸¡
    â”œâ”€ ë¯¸ì§€ì˜ Xê°’ ì…ë ¥
    â”œâ”€ predict() ì‹¤í–‰
    â””â”€ ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì •
```

### ğŸ“Š **ì„±ëŠ¥ì§€í‘œ í•´ì„ ê°€ì´ë“œ**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                ì„±ëŠ¥ì§€í‘œ ì‹ í˜¸ë“±                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  RÂ² (ê²°ì •ê³„ìˆ˜)                                   â”‚
â”‚  ğŸŸ¢ 0.7~1.0  â†  ìš°ìˆ˜ (ì‹ ë¢°í• ë§Œí•œ ëª¨ë¸)           â”‚
â”‚  ğŸŸ¡ 0.5~0.7  â†  ì–‘í˜¸ (ì‚¬ìš© ê°€ëŠ¥)                â”‚  
â”‚  ğŸ”´ 0.0~0.5  â†  ê°œì„  í•„ìš”                       â”‚
â”‚                                                  â”‚
â”‚  p-value (ìœ ì˜ì„±)                               â”‚
â”‚  ğŸŸ¢ < 0.01   â†  ë§¤ìš° ìœ ì˜í•¨ â­â­â­              â”‚
â”‚  ğŸŸ¡ 0.01~0.05 â†  ìœ ì˜í•¨ â­                     â”‚
â”‚  ğŸ”´ > 0.05   â†  ìœ ì˜í•˜ì§€ ì•ŠìŒ âŒ                â”‚
â”‚                                                  â”‚
â”‚  ìƒê´€ê³„ìˆ˜ (ê´€ê³„ ê°•ë„)                           â”‚
â”‚  ğŸŸ¢ 0.7~1.0  â†  ê°•í•œ ê´€ê³„                      â”‚
â”‚  ğŸŸ¡ 0.3~0.7  â†  ì¤‘ê°„ ê´€ê³„                      â”‚
â”‚  ğŸ”´ 0.0~0.3  â†  ì•½í•œ ê´€ê³„                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### âš ï¸ **ìì£¼ í•˜ëŠ” ì‹¤ìˆ˜ ì²´í¬ë¦¬ìŠ¤íŠ¸**

```
âŒ í”í•œ ì‹¤ìˆ˜ë“¤                     âœ… ì˜¬ë°”ë¥¸ í•´ê²°ì±…
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                    â”‚
â”‚ sklearnì— 1D ë°°ì—´ ì…ë ¥           â†’ reshape(-1, 1)   â”‚
â”‚ ValueError ë°œìƒ                                    â”‚
â”‚                                                    â”‚
â”‚ ë°ì´í„° íƒ€ì… ë¶ˆì¼ì¹˜               â†’ astype(float)    â”‚
â”‚ ë¬¸ìì—´ì„ ìˆ«ìë¡œ ì°©ê°                               â”‚
â”‚                                                    â”‚
â”‚ ì¸ë±ìŠ¤ ìˆœì„œ ë¶ˆì¼ì¹˜               â†’ reset_index()    â”‚
â”‚ DataFrame ì •ë ¬ ë¬¸ì œ                                â”‚
â”‚                                                    â”‚
â”‚ RÂ²=1.0ì´ ë‚˜ì™€ì„œ ê¸°ë»í•¨           â†’ ì‹¤ì œ ë°ì´í„° ì‚¬ìš© â”‚
â”‚ make_regression ì™„ë²½ ë°ì´í„°                        â”‚
â”‚                                                    â”‚
â”‚ ê¸°ì¡´ ë°ì´í„° ê²€ì¦ì„ ëª©ì ìœ¼ë¡œ ì°©ê° â†’ ì˜ˆì¸¡ì´ ì§„ì§œ ëª©ì â”‚
â”‚ ì„±ëŠ¥ í™•ì¸ì€ ì¤‘ê°„ ê³¼ì •ì¼ ë¿                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ¯ **ìƒí™©ë³„ ë°©ë²• ì„ íƒ í”Œë¡œìš°ì°¨íŠ¸**

```
ğŸ¤” ì–´ë–¤ ë°©ë²•ì„ ì¨ì•¼ í• ê¹Œ?
         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ ëª©ì ì´ ë­ì•¼? â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”
    â”‚í•™ìŠµâ”‚ì˜ˆì¸¡â”‚ì—°êµ¬â”‚íƒìƒ‰â”‚
    â†“    â†“    â†“    â†“
â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”
â”‚make â”‚ â”‚sklearnâ”‚ â”‚statsâ”‚ â”‚scipyâ”‚
â”‚_reg â”‚ â”‚Linear â”‚ â”‚modelsâ”‚ â”‚.statsâ”‚
â”‚res  â”‚ â”‚Reg    â”‚ â”‚ OLS â”‚ â”‚linregâ”‚
â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜
   â†“       â†“        â†“       â†“
â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”
â”‚ì™„ë²½í•œâ”‚ â”‚ì˜ˆì¸¡ë§Œâ”‚ â”‚pê°’  â”‚ â”‚ìƒê´€+â”‚
â”‚ê´€ê³„ â”‚ â”‚í•„ìš”  â”‚ â”‚ì‹ ë¢° â”‚ â”‚íšŒê·€ â”‚
â”‚ì´í•´ â”‚ â”‚í•˜ë©´  â”‚ â”‚êµ¬ê°„ â”‚ â”‚í•œë²ˆì—â”‚
â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜
```

### ğŸ“ **íšŒê·€ë¶„ì„ í•µì‹¬ ê°œë…ë„**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  íšŒê·€ë¶„ì„ì˜ í•µì‹¬                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                      â”‚
â”‚  ê³¼ê±° ë°ì´í„°    â†’    ëª¨ë¸ í•™ìŠµ    â†’    ë¯¸ë˜ ì˜ˆì¸¡      â”‚
â”‚  (X, y ìŒ)           (íŒ¨í„´ ì°¾ê¸°)       (ìƒˆë¡œìš´ X)     â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ (1, 10) â”‚      â”‚             â”‚    â”‚ X = 5ì¼ë•Œ   â”‚ â”‚
â”‚  â”‚ (2, 20) â”‚ â”€â”€â”€â†’ â”‚ y = wx + b  â”‚â”€â”€â”€â†’â”‚ y = ?       â”‚ â”‚
â”‚  â”‚ (3, 30) â”‚      â”‚             â”‚    â”‚             â”‚ â”‚
â”‚  â”‚ (4, 40) â”‚      â”‚ ìµœì†Œì œê³±ë²•  â”‚    â”‚ predict()   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                      â”‚
â”‚  ì‹¤ì œ ê²½í—˜í•œ ê²ƒ     ìˆ˜í•™ì  ê´€ê³„ì‹       ê°„ì ‘ ê²½í—˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’¡ í•µì‹¬: "ê³¼ê±° ë°ì´í„°ë¡œ íŒ¨í„´ì„ í•™ìŠµí•´ì„œ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•œë‹¤"
```

### ğŸ” **ë°ì´í„° í˜•íƒœ ì™„ì „ ê°€ì´ë“œ**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                sklearn ë°ì´í„° í˜•íƒœ í•„ìˆ˜ ì²´í¬             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  âŒ ì˜ëª»ëœ í˜•íƒœ                  âœ… ì˜¬ë°”ë¥¸ í˜•íƒœ          â”‚
â”‚                                                         â”‚
â”‚  X = [1, 2, 3, 4]               X = [[1],              â”‚
â”‚      (1ì°¨ì› ë°°ì—´)                    [2],              â”‚
â”‚                                      [3],              â”‚
â”‚  ì—ëŸ¬ ë°œìƒ! âš ï¸                      [4]]              â”‚
â”‚                                      (2ì°¨ì› ë°°ì—´)       â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€ í•´ê²°ë°©ë²• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                   â”‚ â”‚
â”‚  â”‚  ë°©ë²•1: X.reshape(-1, 1)                         â”‚ â”‚
â”‚  â”‚  ë°©ë²•2: X = [[1], [2], [3], [4]]                 â”‚ â”‚
â”‚  â”‚  ë°©ë²•3: X = np.array(X).reshape(-1, 1)           â”‚ â”‚
â”‚  â”‚                                                   â”‚ â”‚
â”‚  â”‚  ì²´í¬: print(X.shape) â†’ (4, 1) ì´ì–´ì•¼ í•¨!        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“ˆ **ëª¨ë¸ ì„±ëŠ¥ ì§„ë‹¨ ì²´í¬í¬ì¸íŠ¸**

```
ğŸ¥ ëª¨ë¸ ê±´ê°• ì§„ë‹¨ì„œ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                        â”‚
â”‚ 1ï¸âƒ£ ìƒê´€ê³„ìˆ˜ ì²´í¬                       â”‚
â”‚    r > 0.3 âœ…  /  r < 0.3 âš ï¸          â”‚
â”‚                                        â”‚  
â”‚ 2ï¸âƒ£ RÂ² (ì„¤ëª…ë ¥) ì²´í¬                   â”‚
â”‚    > 0.7 ìš°ìˆ˜ / 0.5~0.7 ì–‘í˜¸ / <0.5 ê°œì„ â”‚
â”‚                                        â”‚
â”‚ 3ï¸âƒ£ p-value (ìœ ì˜ì„±) ì²´í¬              â”‚
â”‚    < 0.05 ìœ ì˜í•¨ âœ… / > 0.05 ì˜ë¯¸ì—†ìŒ âŒâ”‚
â”‚                                        â”‚
â”‚ 4ï¸âƒ£ ì”ì°¨ íŒ¨í„´ ì²´í¬                     â”‚
â”‚    ëœë¤ ë¶„í¬ âœ… / íŠ¹ì • íŒ¨í„´ âš ï¸         â”‚
â”‚                                        â”‚
â”‚ 5ï¸âƒ£ ì˜ˆì¸¡ ë²”ìœ„ ì²´í¬                     â”‚
â”‚    í•™ìŠµ ë²”ìœ„ ë‚´ âœ… / ë²”ìœ„ ì´ˆê³¼ âš ï¸      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’Š ì²˜ë°©ì „: ë¬¸ì œ ë°œê²¬ì‹œ â†’ ë°ì´í„° ì¶”ê°€ ìˆ˜ì§‘ or ë‹¤ë¥¸ ëª¨ë¸ ì‹œë„
```

---

## ğŸ“ í•µì‹¬ ì •ë¦¬ ë° ë‹¤ìŒ ë‹¨ê³„

### ğŸ“Š ì„±ëŠ¥ ë° ê²°ê³¼ ë¹„êµ

```python
print(f"\nğŸ”„ 4ê°€ì§€ ë°©ë²• ì¢…í•© ë¹„êµ")
print("=" * 80)

# ê²°ê³¼ ë¹„êµ í…Œì´ë¸”
comparison_data = {
    'ë°©ë²•': ['make_regression', 'sklearn', 'statsmodels', 'scipy.stats'],
    'ê¸°ìš¸ê¸°': [
        f"{coef:.6f}",
        f"{slope:.6f}",
        f"{params['x']:.6f}" if 'params' in locals() else "N/A",
        f"{linregress_result.slope:.6f}"
    ],
    'ì ˆí¸': [
        "100.000000",
        f"{intercept:.6f}",
        f"{params['Intercept']:.6f}" if 'params' in locals() else "N/A",
        f"{linregress_result.intercept:.6f}"
    ],
    'RÂ²': [
        "1.000000",
        f"{r2:.6f}",
        f"{rsquared:.6f}" if 'rsquared' in locals() else "N/A",
        f"{linregress_result.rvalue**2:.6f}"
    ],
    'íŠ¹ì§•': [
        "ì™„ë²½í•œ ì„ í˜•ê´€ê³„",
        "ì˜ˆì¸¡ ì¤‘ì‹¬",
        "í†µê³„ì  ì¶”ë¡ ",
        "ìƒê´€+íšŒê·€ í†µí•©"
    ]
}

comparison_df = pd.DataFrame(comparison_data)
print(comparison_df.to_string(index=False))

# ì¥ë‹¨ì  ë¹„êµ
print(f"\nğŸ“‹ ìƒí™©ë³„ ìµœì  ë°©ë²• ì„ íƒ ê°€ì´ë“œ:")
print("=" * 50)

selection_guide = {
    "ğŸ“ í•™ìŠµ/ì´í•´ ëª©ì ": {
        "ì¶”ì²œ": "make_regression",
        "ì´ìœ ": "ë…¸ì´ì¦ˆ ì—†ëŠ” ì™„ë²½í•œ ê´€ê³„ë¡œ ê°œë… ì´í•´ ìµœì "
    },
    "ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸": {
        "ì¶”ì²œ": "sklearn",
        "ì´ìœ ": "ë‹¤ë¥¸ ML ëª¨ë¸ê³¼ ì¼ê´€ëœ API, íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ìš©ì´"
    },
    "ğŸ“Š í•™ìˆ  ì—°êµ¬": {
        "ì¶”ì²œ": "statsmodels",
        "ì´ìœ ": "ìƒì„¸í•œ í†µê³„ ì •ë³´, ê°€ì„¤ê²€ì •, ì§„ë‹¨ ë„êµ¬ ì™„ë¹„"
    },
    "ğŸ” íƒìƒ‰ì  ë¶„ì„": {
        "ì¶”ì²œ": "scipy.stats",
        "ì´ìœ ": "ìƒê´€ë¶„ì„ë¶€í„° íšŒê·€ê¹Œì§€ ì›ìŠ¤í†±, ê°„ë‹¨í•œ ì‚¬ìš©ë²•"
    }
}

for ìƒí™©, ì •ë³´ in selection_guide.items():
    print(f"\n{ìƒí™©}:")
    print(f"   â€¢ ì¶”ì²œ ë°©ë²•: {ì •ë³´['ì¶”ì²œ']}")
    print(f"   â€¢ ì„ íƒ ì´ìœ : {ì •ë³´['ì´ìœ ']}")
```

---

## ğŸ¯ ì‹¤ë¬´ ì‘ìš©: í†µí•© íšŒê·€ë¶„ì„ ì‹œìŠ¤í…œ

### ğŸš€ ëª¨ë“  ë°©ë²•ì„ í™œìš©í•œ ì™„ì „í•œ ë¶„ì„

```python
class ComprehensiveRegression:
    """4ê°€ì§€ íšŒê·€ë¶„ì„ ë°©ë²•ì„ í†µí•©í•œ ì¢…í•© ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, x, y):
        self.x = np.array(x).reshape(-1, 1) if np.array(x).ndim == 1 else x
        self.y = np.array(y)
        self.results = {}
        
    def analyze_all_methods(self):
        """4ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ë™ì‹œ ë¶„ì„"""
        
        print("ğŸ”¬ ì¢…í•© íšŒê·€ë¶„ì„ ì‹œì‘...")
        print("=" * 50)
        
        # ë°©ë²• 1: sklearn
        model_sk = LinearRegression()
        model_sk.fit(self.x, self.y)
        y_pred_sk = model_sk.predict(self.x)
        
        self.results['sklearn'] = {
            'slope': model_sk.coef_[0],
            'intercept': model_sk.intercept_,
            'r2': r2_score(self.y, y_pred_sk),
            'rmse': np.sqrt(mean_squared_error(self.y, y_pred_sk))
        }
        
        # ë°©ë²• 2: statsmodels
        x_with_const = sm.add_constant(self.x)
        model_sm = sm.OLS(self.y, x_with_const).fit()
        
        self.results['statsmodels'] = {
            'slope': model_sm.params[1],
            'intercept': model_sm.params[0],
            'r2': model_sm.rsquared,
            'pvalue': model_sm.pvalues[1],
            'aic': model_sm.aic
        }
        
        # ë°©ë²• 3: scipy
        slope_sp, intercept_sp, r_sp, p_sp, stderr_sp = stats.linregress(
            self.x.ravel(), self.y
        )
        
        self.results['scipy'] = {
            'slope': slope_sp,
            'intercept': intercept_sp,
            'r': r_sp,
            'r2': r_sp**2,
            'pvalue': p_sp,
            'stderr': stderr_sp
        }
        
        return self.results
    
    def generate_report(self):
        """ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        print("\nğŸ“Š ì¢…í•© íšŒê·€ë¶„ì„ ë¦¬í¬íŠ¸")
        print("=" * 60)
        
        # ì¼ê´€ì„± ê²€ì¦
        slopes = [self.results[method]['slope'] for method in ['sklearn', 'statsmodels', 'scipy']]
        intercepts = [self.results[method]['intercept'] for method in ['sklearn', 'statsmodels', 'scipy']]
        r2_values = [self.results[method]['r2'] for method in ['sklearn', 'statsmodels', 'scipy']]
        
        print(f"ğŸ” ê²°ê³¼ ì¼ê´€ì„± ê²€ì¦:")
        print(f"   ê¸°ìš¸ê¸° í¸ì°¨: {np.std(slopes):.2e} (ì¼ê´€ì : {np.std(slopes) < 1e-10})")
        print(f"   ì ˆí¸ í¸ì°¨: {np.std(intercepts):.2e} (ì¼ê´€ì : {np.std(intercepts) < 1e-10})")
        print(f"   RÂ² í¸ì°¨: {np.std(r2_values):.2e} (ì¼ê´€ì : {np.std(r2_values) < 1e-10})")
        
        # ìµœì¢… ê²°ê³¼
        avg_slope = np.mean(slopes)
        avg_intercept = np.mean(intercepts)
        avg_r2 = np.mean(r2_values)
        
        print(f"\nğŸ“ˆ ìµœì¢… íšŒê·€ë¶„ì„ ê²°ê³¼:")
        print(f"   íšŒê·€ì‹: y = {avg_slope:.6f}x + {avg_intercept:.6f}")
        print(f"   RÂ² (ì„¤ëª…ë ¥): {avg_r2:.6f} ({avg_r2*100:.2f}%)")
        
        # í†µê³„ì  ìœ ì˜ì„±
        p_value = self.results['scipy']['pvalue']
        if p_value < 0.001:
            significance = "ë§¤ìš° ë†’ìŒ (p < 0.001) â­â­â­"
        elif p_value < 0.01:
            significance = "ë†’ìŒ (p < 0.01) â­â­"
        elif p_value < 0.05:
            significance = "ìœ ì˜í•¨ (p < 0.05) â­"
        else:
            significance = "ìœ ì˜í•˜ì§€ ì•ŠìŒ (p â‰¥ 0.05) âŒ"
            
        print(f"   í†µê³„ì  ìœ ì˜ì„±: {significance}")
        
        # ì‹¤ë¬´ì  í•´ì„
        print(f"\nğŸ’¼ ì‹¤ë¬´ì  í•´ì„:")
        print(f"   â€¢ ë…ë¦½ë³€ìˆ˜ 1ë‹¨ìœ„ ì¦ê°€ ì‹œ ì¢…ì†ë³€ìˆ˜ {avg_slope:.4f}ë‹¨ìœ„ ë³€í™”")
        print(f"   â€¢ ëª¨ë¸ì´ ë°ì´í„° ë³€ë™ì˜ {avg_r2*100:.1f}%ë¥¼ ì„¤ëª…")
        if avg_r2 > 0.7:
            quality = "ìš°ìˆ˜í•œ"
        elif avg_r2 > 0.5:
            quality = "ì–‘í˜¸í•œ"
        else:
            quality = "ê°œì„ ì´ í•„ìš”í•œ"
        print(f"   â€¢ {quality} ëª¨ë¸ í’ˆì§ˆ")
    
    def predict_new_values(self, new_x):
        """ìƒˆë¡œìš´ ê°’ ì˜ˆì¸¡"""
        avg_slope = np.mean([self.results[method]['slope'] 
                           for method in ['sklearn', 'statsmodels', 'scipy']])
        avg_intercept = np.mean([self.results[method]['intercept'] 
                               for method in ['sklearn', 'statsmodels', 'scipy']])
        
        predictions = avg_slope * np.array(new_x) + avg_intercept
        
        print(f"\nğŸ”® ìƒˆë¡œìš´ ê°’ ì˜ˆì¸¡:")
        for x_val, pred in zip(new_x, predictions):
            print(f"   x = {x_val:6.2f} â†’ ì˜ˆì¸¡ y = {pred:8.2f}")
            
        return predictions

# ì¢…í•© ë¶„ì„ ì‹¤í–‰
print(f"\nğŸš€ ì¢…í•© íšŒê·€ë¶„ì„ ì‹œìŠ¤í…œ ì‹¤í–‰")

# ë°ì´í„° ì„ íƒ (ì‹¤ì œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ìƒì„± ë°ì´í„°)
if 'x_real' in locals() and len(x_real) > 50:
    analysis_x, analysis_y = x_real, y_real
    print("ğŸ“Š ì‹¤ì œ IQ-ì ìˆ˜ ë°ì´í„° ì‚¬ìš©")
else:
    analysis_x, analysis_y = x.ravel(), y
    print("ğŸ§ª í•©ì„± ë°ì´í„° ì‚¬ìš©")

# ì¢…í•© ë¶„ì„ ìˆ˜í–‰
comprehensive = ComprehensiveRegression(analysis_x, analysis_y)
all_results = comprehensive.analyze_all_methods()
comprehensive.generate_report()

# ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
test_x = [np.mean(analysis_x), np.max(analysis_x), np.min(analysis_x)]
comprehensive.predict_new_values(test_x)
```

---

## âš ï¸ ì‹¤ë¬´ ì£¼ì˜ì‚¬í•­ê³¼ íŒ

### ğŸ”§ **ë°ì´í„° í˜•íƒœ ì£¼ì˜ì‚¬í•­**

```python
def ë°ì´í„°_í˜•íƒœ_ê°€ì´ë“œ():
    """ì‹¤ë¬´ì—ì„œ ìì£¼ ì‹¤ìˆ˜í•˜ëŠ” ë°ì´í„° í˜•íƒœ ë¬¸ì œë“¤"""
    
    ì£¼ì˜ì‚¬í•­ = {
        "sklearn ì…ë ¥ í˜•íƒœ": {
            "ë…ë¦½ë³€ìˆ˜": "ë°˜ë“œì‹œ 2ì°¨ì› ë°°ì—´ [[x1], [x2], [x3]]",
            "ì¢…ì†ë³€ìˆ˜": "1ì°¨ì› ë°°ì—´ [y1, y2, y3]",
            "í”í•œì‹¤ìˆ˜": "1ì°¨ì›ìœ¼ë¡œ ì£¼ë©´ ì—ëŸ¬ ë°œìƒ",
            "í•´ê²°ì±…": "X.reshape(-1, 1) ë˜ëŠ” [[ê°’]] í˜•íƒœ"
        },
        "ì°¨ì› ë³€í™˜ ë°©ë²•": {
            "flatten()": "ë‹¤ì°¨ì› â†’ 1ì°¨ì›ìœ¼ë¡œ ì™„ì „ í‰íƒ„í™”",
            "ravel()": "ë‹¤ì°¨ì› â†’ 1ì°¨ì› (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )",
            "reshape(-1, 1)": "1ì°¨ì› â†’ 2ì°¨ì›ìœ¼ë¡œ ë³€í™˜",
            "ì–¸ì œì‚¬ìš©": "sklearn ì…ë ¥ ì „ í•„ìˆ˜ ì²´í¬"
        },
        "ë°ì´í„°í”„ë ˆì„ í™œìš©": {
            "statsmodels": "DataFrame ê¶Œì¥ (ì»¬ëŸ¼ëª… í™œìš©)",
            "sklearn": "numpy ë°°ì—´ ì„ í˜¸",
            "ë³€í™˜ë°©ë²•": "df.values ë˜ëŠ” np.array(df)",
            "ì£¼ì˜ì ": "ì¸ë±ìŠ¤ ì •ë ¬ í™•ì¸ í•„ìˆ˜"
        }
    }
    
    print("âš ï¸ ì‹¤ë¬´ ë°ì´í„° ì²˜ë¦¬ ê°€ì´ë“œ")
    print("=" * 50)
    for ì¹´í…Œê³ ë¦¬, ì •ë³´ in ì£¼ì˜ì‚¬í•­.items():
        print(f"\nğŸ“‹ {ì¹´í…Œê³ ë¦¬}:")
        for í•­ëª©, ì„¤ëª… in ì •ë³´.items():
            print(f"   â€¢ {í•­ëª©}: {ì„¤ëª…}")

ë°ì´í„°_í˜•íƒœ_ê°€ì´ë“œ()
```

### ğŸ¯ **ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦ ë°©ë²•**

```python
def ëª¨ë¸_ê²€ì¦_ê°€ì´ë“œ():
    """ê¸°ì¡´ ë°ì´í„°ë¡œ ì„±ëŠ¥ í™•ì¸í•˜ëŠ” ì˜¬ë°”ë¥¸ ë°©ë²•"""
    
    print("ğŸ” ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦ ë‹¨ê³„ë³„ ê°€ì´ë“œ")
    print("=" * 50)
    
    ë‹¨ê³„ë³„_ê³¼ì • = {
        "1ë‹¨ê³„ - ëª¨ë¸ í•™ìŠµ": {
            "ëª©ì ": "ê³¼ê±° ë°ì´í„°ë¡œ íŒ¨í„´ í•™ìŠµ",
            "ë°ì´í„°": "í›ˆë ¨ìš© ë°ì´í„° (X_train, y_train)",
            "ê²°ê³¼": "íšŒê·€ê³„ìˆ˜ (ê¸°ìš¸ê¸°, ì ˆí¸) ì¶”ì •"
        },
        "2ë‹¨ê³„ - ì„±ëŠ¥ í™•ì¸": {
            "ëª©ì ": "ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì •í™•í•œì§€ ê²€ì¦",
            "ë°©ë²•": "í•™ìŠµ ë°ì´í„°ë¡œ ì˜ˆì¸¡ â†’ ì‹¤ì œê°’ê³¼ ë¹„êµ", 
            "ì§€í‘œ": "RÂ², RMSE, MAE ë“± ê³„ì‚°"
        },
        "3ë‹¨ê³„ - ìƒˆë¡œìš´ ì˜ˆì¸¡": {
            "ëª©ì ": "ë¯¸ì§€ì˜ Xê°’ì— ëŒ€í•œ Yê°’ ì˜ˆì¸¡",
            "ì£¼ì˜": "í•™ìŠµ ë²”ìœ„ ë²—ì–´ë‚˜ë©´ ì •í™•ë„ ë–¨ì–´ì§",
            "í™œìš©": "ì‹¤ì œ ì˜ì‚¬ê²°ì •ì— ì‚¬ìš©"
        }
    }
    
    for ë‹¨ê³„, ë‚´ìš© in ë‹¨ê³„ë³„_ê³¼ì •.items():
        print(f"\n{ë‹¨ê³„}:")
        for í•­ëª©, ì„¤ëª… in ë‚´ìš©.items():
            print(f"   â€¢ {í•­ëª©}: {ì„¤ëª…}")
    
    print(f"\nğŸ’¡ í•µì‹¬ í¬ì¸íŠ¸:")
    print(f"   â€¢ ê¸°ì¡´ ë°ì´í„° ê²€ì¦ì€ ëª¨ë¸ ì‹ ë¢°ì„± í™•ì¸ìš©")
    print(f"   â€¢ ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡ì´ ì§„ì§œ ëª©ì ")
    print(f"   â€¢ ì˜ˆì¸¡ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ ì •í™•ë„ ë³´ì¥ ì•ˆ ë¨")

ëª¨ë¸_ê²€ì¦_ê°€ì´ë“œ()
```

### ğŸ”„ **ë°©ë²•ë³„ ì„ íƒ ê¸°ì¤€ ìƒì„¸í™”**

```python
def ìƒí™©ë³„_ë°©ë²•_ì„ íƒ():
    """ì‹¤ë¬´ ìƒí™©ë³„ ìµœì  ë°©ë²• ì„ íƒ ê°€ì´ë“œ"""
    
    ì„ íƒê¸°ì¤€ = {
        "ğŸ“ í•™ìŠµ/ì—°ìŠµ ë‹¨ê³„": {
            "ì¶”ì²œë°©ë²•": "make_regression",
            "ì´ìœ ": "ì™„ë²½í•œ ì„ í˜•ê´€ê³„, ë…¸ì´ì¦ˆ ì—†ìŒ",
            "ì¥ì ": "ê°œë… ì´í•´ì— ìµœì ",
            "ë‹¨ì ": "ì‹¤ì œ ì—…ë¬´ì—ëŠ” ë¶€ì í•©",
            "ì‚¬ìš©ì‹œì ": "ì•Œê³ ë¦¬ì¦˜ ì›ë¦¬ í•™ìŠµì‹œ"
        },
        "ğŸš€ ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸": {
            "ì¶”ì²œë°©ë²•": "sklearn LinearRegression",
            "ì´ìœ ": "ë‹¤ë¥¸ ML ëª¨ë¸ê³¼ API ì¼ê´€ì„±",
            "ì¥ì ": "íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ìš©ì´",
            "ë‹¨ì ": "í†µê³„ì  í•´ì„ ì •ë³´ ë¶€ì¡±",
            "ì‚¬ìš©ì‹œì ": "ì˜ˆì¸¡ ì •í™•ë„ê°€ ìµœìš°ì„ ì¼ ë•Œ"
        },
        "ğŸ“Š ì—°êµ¬/ë¶„ì„ ì—…ë¬´": {
            "ì¶”ì²œë°©ë²•": "statsmodels OLS",
            "ì´ìœ ": "í’ë¶€í•œ í†µê³„ ì •ë³´ ì œê³µ",
            "ì¥ì ": "p-value, ì‹ ë¢°êµ¬ê°„, ì§„ë‹¨í‘œ",
            "ë‹¨ì ": "ë¬¸ë²• ë³µì¡, í•™ìŠµê³¡ì„  ê°€íŒŒë¦„",
            "ì‚¬ìš©ì‹œì ": "í†µê³„ì  ìœ ì˜ì„± ê²€ì¦ í•„ìš”ì‹œ"
        },
        "ğŸ” íƒìƒ‰ì  ë¶„ì„": {
            "ì¶”ì²œë°©ë²•": "scipy.stats linregress",
            "ì´ìœ ": "ìƒê´€ë¶„ì„+íšŒê·€ë¶„ì„ ë™ì‹œ",
            "ì¥ì ": "ê°„ë‹¨í•œ ì‚¬ìš©ë²•, ë¹ ë¥¸ í™•ì¸",
            "ë‹¨ì ": "ê³ ê¸‰ ê¸°ëŠ¥ ì œí•œì ",
            "ì‚¬ìš©ì‹œì ": "ë°ì´í„° ê´€ê³„ ë¹ ë¥¸ íŒŒì•…ì‹œ"
        }
    }
    
    print("ğŸ¯ ìƒí™©ë³„ ìµœì  ë°©ë²• ì„ íƒ ê°€ì´ë“œ")
    print("=" * 60)
    
    for ìƒí™©, ì •ë³´ in ì„ íƒê¸°ì¤€.items():
        print(f"\n{ìƒí™©}")
        print("-" * 30)
        for í•­ëª©, ì„¤ëª… in ì •ë³´.items():
            print(f"{í•­ëª©}: {ì„¤ëª…}")

ìƒí™©ë³„_ë°©ë²•_ì„ íƒ()
```

### ğŸ› ï¸ **ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ì™€ í•´ê²°ì±…**

```python
def ìì£¼í•˜ëŠ”_ì‹¤ìˆ˜_ê°€ì´ë“œ():
    """ì‹¤ë¬´ì—ì„œ ìì£¼ ë°œìƒí•˜ëŠ” ì‹¤ìˆ˜ì™€ í•´ê²°ì±…"""
    
    ì‹¤ìˆ˜_ëª¨ìŒ = {
        "ì°¨ì› ë¶ˆì¼ì¹˜ ì˜¤ë¥˜": {
            "ì¦ìƒ": "ValueError: Expected 2D array, got 1D array",
            "ì›ì¸": "sklearnì— 1ì°¨ì› ë°°ì—´ ì…ë ¥",
            "í•´ê²°": "X.reshape(-1, 1) ë˜ëŠ” [[ê°’]] í˜•íƒœë¡œ ë³€í™˜",
            "ì˜ˆë°©": "í•­ìƒ print(X.shape) ë¡œ í™•ì¸"
        },
        "ì¸ë±ìŠ¤ ë¶ˆì¼ì¹˜": {
            "ì¦ìƒ": "ê¸¸ì´ê°€ ë‹¤ë¥´ê±°ë‚˜ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ê²°ê³¼",
            "ì›ì¸": "DataFrame ì¸ë±ìŠ¤ ìˆœì„œ ë¶ˆì¼ì¹˜",
            "í•´ê²°": "reset_index() ë˜ëŠ” .values ì‚¬ìš©",
            "ì˜ˆë°©": "ë°ì´í„° í™•ì¸ ìŠµê´€í™”"
        },
        "ë°ì´í„° íƒ€ì… ì˜¤ë¥˜": {
            "ì¦ìƒ": "TypeError: can't multiply sequence",
            "ì›ì¸": "ë¬¸ìì—´ì´ë‚˜ object íƒ€ì… ë°ì´í„°",
            "í•´ê²°": "pd.to_numeric() ë˜ëŠ” astype(float)",
            "ì˜ˆë°©": "df.dtypesë¡œ ë°ì´í„° íƒ€ì… í™•ì¸"
        },
        "ê³¼ì í•© ì°©ê°": {
            "ì¦ìƒ": "RÂ²=1.0 ë˜ëŠ” ë„ˆë¬´ ì™„ë²½í•œ ê²°ê³¼",
            "ì›ì¸": "make_regressionì€ ì™„ë²½í•œ ì„ í˜•ê´€ê³„",
            "í•´ê²°": "ì‹¤ì œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸",
            "ì˜ˆë°©": "ë…¸ì´ì¦ˆ ìˆëŠ” ì‹¤ì œ ë°ì´í„° ì‚¬ìš©"
        }
    }
    
    print("ğŸš¨ ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ì™€ í•´ê²°ì±…")
    print("=" * 50)
    
    for ì˜¤ë¥˜, ì •ë³´ in ì‹¤ìˆ˜_ëª¨ìŒ.items():
        print(f"\nâŒ {ì˜¤ë¥˜}")
        for í•­ëª©, ì„¤ëª… in ì •ë³´.items():
            print(f"   {í•­ëª©}: {ì„¤ëª…}")

ìì£¼í•˜ëŠ”_ì‹¤ìˆ˜_ê°€ì´ë“œ()
```

---

## ğŸ“ í•µì‹¬ ì •ë¦¬ ë° ë‹¤ìŒ ë‹¨ê³„

### âœ… **4ê°€ì§€ ë°©ë²• ë§ˆìŠ¤í„° ì²´í¬ë¦¬ìŠ¤íŠ¸**

- âœ… **make_regression**: í•™ìŠµìš© ì™„ë²½ ë°ì´í„° ìƒì„±ê³¼ ê¸°ë³¸ ê³„ì‚°
- âœ… **sklearn**: ë¨¸ì‹ ëŸ¬ë‹ ìŠ¤íƒ€ì¼ ì˜ˆì¸¡ ì¤‘ì‹¬ ë¶„ì„  
- âœ… **statsmodels**: í†µê³„í•™ì  ì¶”ë¡ ê³¼ ìƒì„¸ ì§„ë‹¨
- âœ… **scipy.stats**: ìƒê´€ë¶„ì„ê³¼ íšŒê·€ë¶„ì„ í†µí•©

### ğŸ”„ **ì™„ì „í•œ ì‹¤ë¬´ ì›Œí¬í”Œë¡œìš°**

```python
def ì‹¤ë¬´_íšŒê·€ë¶„ì„_ì›Œí¬í”Œë¡œìš°():
    """ì‹¤ë¬´ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì™„ì „í•œ íšŒê·€ë¶„ì„ í”„ë¡œì„¸ìŠ¤"""
    
    ì›Œí¬í”Œë¡œìš° = {
        "1. ë°ì´í„° ìˆ˜ì§‘ ë° ì¤€ë¹„": [
            "ì›ì²œ ë°ì´í„° ìˆ˜ì§‘ (CSV, DB, API ë“±)",
            "ê²°ì¸¡ì¹˜ ë° ì´ìƒì¹˜ í™•ì¸",
            "ë°ì´í„° íƒ€ì… ë³€í™˜ (ë¬¸ìâ†’ìˆ«ì)",
            "ë³€ìˆ˜ëª… ì •ë¦¬ ë° í‘œì¤€í™”"
        ],
        "2. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„": [
            "ê¸°ìˆ í†µê³„ëŸ‰ í™•ì¸ (í‰ê· , ë¶„ì‚°, ë¶„í¬)",
            "ì‚°ì ë„ë¡œ ì„ í˜•ê´€ê³„ ì‹œê°ì  í™•ì¸",
            "ìƒê´€ê³„ìˆ˜ ê³„ì‚° (scipy.stats.pearsonr)",
            "ì´ìƒì¹˜ íƒì§€ ë° ì²˜ë¦¬ ë°©ì•ˆ ê²°ì •"
        ],
        "3. ëª¨ë¸ ì„ íƒ ë° í•™ìŠµ": [
            "ëª©ì ì— ë”°ë¥¸ ë°©ë²• ì„ íƒ (sklearn vs statsmodels)",
            "ë°ì´í„° í˜•íƒœ ë³€í™˜ (ì°¨ì› ë§ì¶”ê¸°)",
            "ëª¨ë¸ í•™ìŠµ ì‹¤í–‰ (fit)",
            "íšŒê·€ê³„ìˆ˜ ë° í†µê³„ëŸ‰ í™•ì¸"
        ],
        "4. ëª¨ë¸ ê²€ì¦ ë° ì§„ë‹¨": [
            "ê¸°ì¡´ ë°ì´í„°ë¡œ ì˜ˆì¸¡ ì •í™•ë„ í™•ì¸",
            "ì”ì°¨ ë¶„ì„ (íŒ¨í„´, ì •ê·œì„±, ë“±ë¶„ì‚°ì„±)",
            "RÂ², RMSE, MAE ë“± ì„±ëŠ¥ì§€í‘œ ê³„ì‚°",
            "íšŒê·€ ê°€ì • ìœ„ë°˜ ì—¬ë¶€ í™•ì¸"
        ],
        "5. ì‹¤ì œ ì˜ˆì¸¡ ë° í™œìš©": [
            "ìƒˆë¡œìš´ Xê°’ì— ëŒ€í•œ Yê°’ ì˜ˆì¸¡",
            "ì‹ ë¢°êµ¬ê°„ ê³„ì‚° (ë¶ˆí™•ì‹¤ì„± í‘œí˜„)",
            "ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ",
            "ì˜ì‚¬ê²°ì • ì§€ì› ìë£Œ ì‘ì„±"
        ],
        "6. ëª¨ë¸ ë°°í¬ ë° ê´€ë¦¬": [
            "ëª¨ë¸ ì €ì¥ (pickle, joblib)",
            "ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì²´ê³„ êµ¬ì¶•",
            "ë°ì´í„° ë“œë¦¬í”„íŠ¸ ê°ì§€",
            "ì •ê¸°ì ì¸ ì¬í•™ìŠµ ê³„íš"
        ]
    }
    
    print("ğŸ”„ ì‹¤ë¬´ íšŒê·€ë¶„ì„ ì™„ì „ ì›Œí¬í”Œë¡œìš°")
    print("=" * 60)
    
    for ë‹¨ê³„, ì‘ì—…ë“¤ in ì›Œí¬í”Œë¡œìš°.items():
        print(f"\n{ë‹¨ê³„}")
        print("-" * 40)
        for i, ì‘ì—… in enumerate(ì‘ì—…ë“¤, 1):
            print(f"   {i}. {ì‘ì—…}")
    
    print(f"\nğŸ’¡ ì„±ê³µ í¬ì¸íŠ¸:")
    print(f"   â€¢ ê° ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ì§€ ë§ê³  ìˆœì°¨ì ìœ¼ë¡œ ì§„í–‰")
    print(f"   â€¢ ë°ì´í„° í’ˆì§ˆì´ ëª¨ë¸ ì„±ëŠ¥ì„ ì¢Œìš°")
    print(f"   â€¢ í†µê³„ì  ìœ ì˜ì„±ê³¼ ì‹¤ë¬´ì  ì˜ë¯¸ ëª¨ë‘ ê³ ë ¤")
    print(f"   â€¢ ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ê³¼ ê°œì„ ì´ í•µì‹¬")

ì‹¤ë¬´_íšŒê·€ë¶„ì„_ì›Œí¬í”Œë¡œìš°()
```

### ğŸ“ˆ **ì„±ëŠ¥ ì§€í‘œ ì™„ì „ ê°€ì´ë“œ**

```python
def ì„±ëŠ¥ì§€í‘œ_ì™„ì „_ê°€ì´ë“œ():
    """íšŒê·€ë¶„ì„ ì„±ëŠ¥ì§€í‘œì˜ ì˜ë¯¸ì™€ í•´ì„"""
    
    ì„±ëŠ¥ì§€í‘œ = {
        "RÂ² (ê²°ì •ê³„ìˆ˜)": {
            "ì˜ë¯¸": "ëª¨ë¸ì´ ë°ì´í„° ë³€ë™ì„ ì„¤ëª…í•˜ëŠ” ë¹„ìœ¨",
            "ë²”ìœ„": "0 ~ 1 (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)",
            "í•´ì„": "0.7 ì´ìƒ: ìš°ìˆ˜, 0.5~0.7: ì–‘í˜¸, 0.5 ë¯¸ë§Œ: ê°œì„  í•„ìš”",
            "ì£¼ì˜": "ë³€ìˆ˜ ë§ìœ¼ë©´ ê³¼ëŒ€í‰ê°€ ê°€ëŠ¥ì„±"
        },
        "RMSE (í‰ê· ì œê³±ê·¼ì˜¤ì°¨)": {
            "ì˜ë¯¸": "ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ í‰ê· ì ì¸ ì°¨ì´",
            "ë²”ìœ„": "0 ì´ìƒ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)",
            "í•´ì„": "ì‹¤ì œ ë‹¨ìœ„ì™€ ë™ì¼ (í•´ì„í•˜ê¸° ì‰¬ì›€)",
            "ì£¼ì˜": "ì´ìƒì¹˜ì— ë¯¼ê°í•¨"
        },
        "MAE (í‰ê· ì ˆëŒ“ê°’ì˜¤ì°¨)": {
            "ì˜ë¯¸": "ì˜ˆì¸¡ ì˜¤ì°¨ì˜ ì ˆëŒ“ê°’ í‰ê· ",
            "ë²”ìœ„": "0 ì´ìƒ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)",
            "í•´ì„": "RMSEë³´ë‹¤ ì´ìƒì¹˜ì— ëœ ë¯¼ê°",
            "ì£¼ì˜": "í° ì˜¤ì°¨ì˜ ì„íŒ©íŠ¸ ê³¼ì†Œí‰ê°€"
        },
        "p-value": {
            "ì˜ë¯¸": "íšŒê·€ê³„ìˆ˜ê°€ 0ì´ ì•„ë‹ í™•ë¥ ",
            "ê¸°ì¤€": "0.05 ë¯¸ë§Œì´ë©´ í†µê³„ì  ìœ ì˜",
            "í•´ì„": "ì‘ì„ìˆ˜ë¡ ì‹ ë¢°í•  ë§Œí•œ ê´€ê³„",
            "ì£¼ì˜": "ìƒ˜í”Œ í¬ê¸°ì— ì˜í–¥ë°›ìŒ"
        }
    }
    
    print("ğŸ“ˆ íšŒê·€ë¶„ì„ ì„±ëŠ¥ì§€í‘œ ì™„ì „ ê°€ì´ë“œ")
    print("=" * 50)
    
    for ì§€í‘œ, ì •ë³´ in ì„±ëŠ¥ì§€í‘œ.items():
        print(f"\nğŸ“Š {ì§€í‘œ}")
        for í•­ëª©, ì„¤ëª… in ì •ë³´.items():
            print(f"   {í•­ëª©}: {ì„¤ëª…}")
    
    # ì¢…í•© íŒë‹¨ ê¸°ì¤€
    íŒë‹¨ê¸°ì¤€ = {
        "ìš°ìˆ˜í•œ ëª¨ë¸": "RÂ² > 0.7, p < 0.01, ì”ì°¨ íŒ¨í„´ ì—†ìŒ",
        "ì–‘í˜¸í•œ ëª¨ë¸": "RÂ² > 0.5, p < 0.05, ê²½ë¯¸í•œ ê°€ì • ìœ„ë°˜",
        "ê°œì„  í•„ìš”": "RÂ² < 0.5, p > 0.05, ì‹¬ê°í•œ ê°€ì • ìœ„ë°˜",
        "ì‚¬ìš© ë¶ˆê°€": "ìŒì˜ RÂ², p > 0.1, ì”ì°¨ì— ëª…í™•í•œ íŒ¨í„´"
    }
    
    print(f"\nğŸ¯ ì¢…í•© íŒë‹¨ ê¸°ì¤€:")
    for ë“±ê¸‰, ê¸°ì¤€ in íŒë‹¨ê¸°ì¤€.items():
        print(f"   â€¢ {ë“±ê¸‰}: {ê¸°ì¤€}")

ì„±ëŠ¥ì§€í‘œ_ì™„ì „_ê°€ì´ë“œ()
```

| ëª©ì  | ì¶”ì²œ ë°©ë²• | í•µì‹¬ ì´ìœ  |
|------|-----------|----------|
| **ê°œë… í•™ìŠµ** | make_regression | ì™„ë²½í•œ ì„ í˜•ê´€ê³„ë¡œ ì´í•´ ìš©ì´ |
| **ì˜ˆì¸¡ ëª¨ë¸** | sklearn | ML íŒŒì´í”„ë¼ì¸ ì¼ê´€ì„± |
| **í•™ìˆ  ì—°êµ¬** | statsmodels | í†µê³„ì  ì—„ë°€ì„±ê³¼ ì§„ë‹¨ |
| **íƒìƒ‰ ë¶„ì„** | scipy.stats | ìƒê´€+íšŒê·€ ì›ìŠ¤í†± |

### ğŸ”— **ë‹¤ìŒ í•™ìŠµ ë‹¨ê³„**

ì´ì œ íšŒê·€ë¶„ì„ì˜ ëª¨ë“  ë°©ë²•ì„ ë§ˆìŠ¤í„°í–ˆìœ¼ë‹ˆ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë‚˜ì•„ê°€ê² ìŠµë‹ˆë‹¤:

1. **22.11.04 íšŒê·€ì§„ë‹¨**: ê°€ì • ê²€ì •ê³¼ ëª¨ë¸ ê°œì„ 
2. **22.11.05 ë‹¤ì¤‘ê³µì„ ì„±**: ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ë¬¸ì œ í•´ê²°
3. **22.11.06 ì •ê·œí™” íšŒê·€**: Ridge, Lasso ë“± ê³ ê¸‰ ê¸°ë²•
4. **22.11.07 ë¡œì§€ìŠ¤í‹± íšŒê·€**: ë¶„ë¥˜ ë¬¸ì œë¡œì˜ í™•ì¥

**"4ê°€ì§€ ë°©ë²•ìœ¼ë¡œ íšŒê·€ë¶„ì„ì„ ì™„ì „íˆ ë§ˆìŠ¤í„°í–ˆìŠµë‹ˆë‹¤. ì´ì œ ì–´ë–¤ ìƒí™©ì—ì„œë„ ìµœì ì˜ ë„êµ¬ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"** ğŸ‰