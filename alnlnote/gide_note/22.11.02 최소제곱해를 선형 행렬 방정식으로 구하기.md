# 22.11.02 ìµœì†Œì œê³±í•´ë¥¼ ì„ í˜• í–‰ë ¬ ë°©ì •ì‹ìœ¼ë¡œ êµ¬í•˜ê¸°
*ìˆ˜í•™ì  ì›ë¦¬ì—ì„œ ì‹¤ë¬´ êµ¬í˜„ê¹Œì§€ì˜ ì™„ì „í•œ ì—¬ì •*

---

## ğŸ¯ í•™ìŠµ ëª©í‘œ

ì´ ë¬¸ì„œëŠ” **ìµœì†Œì œê³±ë²•ì˜ í–‰ë ¬ í•´ë²•**ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì‹¤ë¬´ì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” **ì™„ì „í•œ ì„ í˜•íšŒê·€ ì‹œìŠ¤í…œ**ì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

### âœ… í•µì‹¬ í•™ìŠµ ë‚´ìš©
- ìµœì†Œì œê³±í•´ì˜ í–‰ë ¬ ë°©ì •ì‹ ì´í•´
- NumPyë¥¼ í™œìš©í•œ íš¨ìœ¨ì  êµ¬í˜„
- ì‚¬ìš©ì ì •ì˜ íšŒê·€ í´ë˜ìŠ¤ ì„¤ê³„
- ì‹¤ë¬´ ì˜ˆì¸¡ ì‹œìŠ¤í…œ êµ¬ì¶•

---

## ğŸ“ ìµœì†Œì œê³±í•´ì˜ í–‰ë ¬ í•´ë²•

### ğŸ¯ ê¸°ë³¸ ì›ë¦¬

ì„ í˜• íšŒê·€ ë¬¸ì œ `y = XÎ² + Îµ`ì—ì„œ ìµœì†Œì œê³±í•´ëŠ” ë‹¤ìŒê³¼ ê°™ì´ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

**ì •ê·œë°©ì •ì‹(Normal Equation):**
```
Î²Ì‚ = (X^T X)^(-1) X^T y
```

ì—¬ê¸°ì„œ:
- `X`: ì„¤ê³„ í–‰ë ¬(Design Matrix) - ë…ë¦½ë³€ìˆ˜ë“¤ê³¼ ìƒìˆ˜í•­
- `y`: ì¢…ì†ë³€ìˆ˜ ë²¡í„°
- `Î²`: íšŒê·€ê³„ìˆ˜ ë²¡í„° [ê¸°ìš¸ê¸°, ì ˆí¸]

### ğŸ”§ ì„¤ê³„ í–‰ë ¬ êµ¬ì„±

```python
import numpy as np

# ì˜ˆì œ ë°ì´í„°
x = np.array([0, 1, 2, 3])           # ë…ë¦½ë³€ìˆ˜
y = np.array([-1, 0.2, 0.5, 2.1])   # ì¢…ì†ë³€ìˆ˜

# ì„¤ê³„ í–‰ë ¬ A = [x, 1] í˜•íƒœë¡œ êµ¬ì„±
A = np.vstack([x, np.ones(len(x))]).T
print("ì„¤ê³„ í–‰ë ¬ A:")
print(A)
```

ì¶œë ¥:
```
ì„¤ê³„ í–‰ë ¬ A:
[[0. 1.]
 [1. 1.]
 [2. 1.]
 [3. 1.]]
```

---

## ğŸ’» NumPyë¥¼ í™œìš©í•œ ìµœì†Œì œê³±í•´ ê³„ì‚°

### ğŸ¯ ë°©ë²• 1: `numpy.linalg.lstsq` ì‚¬ìš©

```python
import numpy as np
import matplotlib.pyplot as plt
import numpy.linalg as lin

plt.rc('font', family='Malgun Gothic')  # í•œê¸€ í°íŠ¸ ì„¤ì •

def solve_least_squares_numpy(x, y):
    """NumPyë¥¼ ì‚¬ìš©í•œ ìµœì†Œì œê³±í•´ ê³„ì‚°"""
    
    # ì„¤ê³„ í–‰ë ¬ êµ¬ì„±
    A = np.vstack([x, np.ones(len(x))]).T
    print("ğŸ”§ ì„¤ê³„ í–‰ë ¬ A:")
    print(A)
    
    # ìµœì†Œì œê³±í•´ ê³„ì‚°
    w, b = lin.lstsq(A, y, rcond=None)[0]
    
    print(f"\nâš¡ ìµœì†Œì œê³±ë²• ê²°ê³¼:")
    print(f"   ê¸°ìš¸ê¸° (w): {w:.6f}")
    print(f"   ì ˆí¸ (b): {b:.6f}")
    print(f"   íšŒê·€ì‹: y = {w:.6f}x + {b:.6f}")
    
    return w, b

# ì˜ˆì œ ì‹¤í–‰
x = np.array([0, 1, 2, 3])
y = np.array([-1, 0.2, 0.5, 2.1])

w, b = solve_least_squares_numpy(x, y)

# ì˜ˆì¸¡ê°’ ê³„ì‚° ë° í‰ê°€
y_pred = w * x + b
print(f"\nğŸ“ˆ ì˜ˆì¸¡ ì„±ëŠ¥:")
print(f"   ì˜ˆì¸¡ê°’: {y_pred}")
print(f"   ì”ì°¨: {y - y_pred}")
print(f"   SSE: {np.sum((y - y_pred)**2):.6f}")

# ì‹œê°í™”
plt.figure(figsize=(10, 6))
plt.scatter(x, y, color='red', s=100, label='ì‹¤ì œ ë°ì´í„°', zorder=5)
plt.plot(x, y_pred, 'b-', linewidth=2, label=f'íšŒê·€ì„ : y={w:.3f}x+{b:.3f}')

# ì”ì°¨ í‘œì‹œ
for i in range(len(x)):
    plt.plot([x[i], x[i]], [y[i], y_pred[i]], 'g--', alpha=0.7)

plt.xlabel('x')
plt.ylabel('y')
plt.title('ìµœì†Œì œê³±ë²•ìœ¼ë¡œ êµ¬í•œ ìµœì  íšŒê·€ì„ ')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

---

## ğŸ“ ì‚¬ìš©ì ì •ì˜ ë‹¨ìˆœ ì„ í˜•íšŒê·€ í´ë˜ìŠ¤

### ğŸ—ï¸ ì™„ì „í•œ íšŒê·€ í´ë˜ìŠ¤ êµ¬í˜„

```python
import numpy as np

class MySimpleLinearRegression:
    """
    ì‚¬ìš©ì ì •ì˜ ë‹¨ìˆœ ì„ í˜•íšŒê·€ í´ë˜ìŠ¤
    ìˆ˜í•™ì  ê³µì‹ì„ ì§ì ‘ êµ¬í˜„í•˜ì—¬ ìµœì†Œì œê³±í•´ë¥¼ ê³„ì‚°
    """
    
    def __init__(self):
        """ìƒì„±ì: íšŒê·€ê³„ìˆ˜ ì´ˆê¸°í™”"""
        self.w = None  # ê¸°ìš¸ê¸° (ê°€ì¤‘ì¹˜, Weight)
        self.b = None  # ì ˆí¸ (í¸í–¥, Bias)
        
    def fit(self, x: np.ndarray, y: np.ndarray):
        """
        ìµœì†Œì œê³±ë²•ìœ¼ë¡œ íšŒê·€ê³„ìˆ˜ ì¶”ì •
        
        Parameters:
        -----------
        x : np.ndarray
            ë…ë¦½ë³€ìˆ˜ (1ì°¨ì› ë°°ì—´)
        y : np.ndarray  
            ì¢…ì†ë³€ìˆ˜ (1ì°¨ì› ë°°ì—´)
        """
        # í‰ê· ê°’ ê³„ì‚°
        x_mean = np.mean(x)
        y_mean = np.mean(y)
        
        # ìµœì†Œì œê³±ë²• ê³µì‹ ì ìš©
        numerator = np.sum((x - x_mean) * (y - y_mean))    # ë¶„ì
        denominator = np.sum((x - x_mean) ** 2)            # ë¶„ëª¨
        
        # íšŒê·€ê³„ìˆ˜ ê³„ì‚°
        self.w = numerator / denominator      # ê¸°ìš¸ê¸°
        self.b = y_mean - (self.w * x_mean)   # ì ˆí¸
        
        return self
        
    def predict(self, x: np.ndarray):
        """
        ìƒˆë¡œìš´ xê°’ì— ëŒ€í•œ yê°’ ì˜ˆì¸¡
        
        Parameters:
        -----------
        x : np.ndarray
            ì˜ˆì¸¡í•  xê°’ë“¤
            
        Returns:
        --------
        np.ndarray
            ì˜ˆì¸¡ëœ yê°’ë“¤
        """
        if self.w is None or self.b is None:
            raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. fit() ë©”ì†Œë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            
        return self.w * x + self.b
    
    def score(self, x: np.ndarray, y: np.ndarray):
        """
        ê²°ì •ê³„ìˆ˜(RÂ²) ê³„ì‚°
        
        Parameters:
        -----------
        x : np.ndarray
            ë…ë¦½ë³€ìˆ˜
        y : np.ndarray
            ì‹¤ì œ ì¢…ì†ë³€ìˆ˜ ê°’
            
        Returns:
        --------
        float
            RÂ² ìŠ¤ì½”ì–´ (0~1, ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
        """
        y_pred = self.predict(x)
        ss_res = np.sum((y - y_pred) ** 2)        # ì”ì°¨ì œê³±í•©
        ss_tot = np.sum((y - np.mean(y)) ** 2)    # ì´ì œê³±í•©
        
        return 1 - (ss_res / ss_tot)
    
    def get_params(self):
        """íšŒê·€ê³„ìˆ˜ ë°˜í™˜"""
        return {
            'weight': self.w,
            'bias': self.b,
            'equation': f'y = {self.w:.6f}x + {self.b:.6f}'
        }
    
    def plot_regression(self, x: np.ndarray, y: np.ndarray, title: str = "íšŒê·€ë¶„ì„ ê²°ê³¼"):
        """íšŒê·€ë¶„ì„ ê²°ê³¼ ì‹œê°í™”"""
        if self.w is None or self.b is None:
            raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. fit() ë©”ì†Œë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            
        y_pred = self.predict(x)
        residuals = y - y_pred
        
        plt.figure(figsize=(15, 10))
        
        # 1. ë©”ì¸ íšŒê·€ í”Œë¡¯
        plt.subplot(2, 3, 1)
        plt.scatter(x, y, color='blue', s=80, alpha=0.7, label='ì‹¤ì œ ë°ì´í„°')
        
        # íšŒê·€ì„ 
        x_range = np.linspace(x.min()-1, x.max()+1, 100)
        y_range_pred = self.predict(x_range)
        plt.plot(x_range, y_range_pred, 'r-', linewidth=2, 
                 label=f'íšŒê·€ì„  (RÂ²={self.score(x, y):.3f})')
        
        # ì”ì°¨ í‘œì‹œ
        for i in range(len(x)):
            plt.plot([x[i], x[i]], [y[i], y_pred[i]], 'g--', alpha=0.5)
        
        plt.xlabel('ë…ë¦½ë³€ìˆ˜ (x)')
        plt.ylabel('ì¢…ì†ë³€ìˆ˜ (y)')
        plt.title(title)
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 2. ì”ì°¨ í”Œë¡¯
        plt.subplot(2, 3, 2)
        plt.scatter(y_pred, residuals, color='green', s=60, alpha=0.7)
        plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
        plt.xlabel('ì˜ˆì¸¡ê°’')
        plt.ylabel('ì”ì°¨')
        plt.title('ì”ì°¨ í”Œë¡¯')
        plt.grid(True, alpha=0.3)
        
        # 3. ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’
        plt.subplot(2, 3, 3)
        plt.scatter(y, y_pred, color='purple', s=60, alpha=0.7)
        min_val = min(min(y), min(y_pred)) - 1
        max_val = max(max(y), max(y_pred)) + 1
        plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2,
                 label='ì™„ë²½í•œ ì˜ˆì¸¡ì„ ')
        plt.xlabel('ì‹¤ì œê°’')
        plt.ylabel('ì˜ˆì¸¡ê°’')
        plt.title('ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 4. ì”ì°¨ íˆìŠ¤í† ê·¸ë¨
        plt.subplot(2, 3, 4)
        plt.hist(residuals, bins=15, alpha=0.7, color='orange', edgecolor='black')
        plt.axvline(x=0, color='red', linestyle='--', linewidth=2)
        plt.xlabel('ì”ì°¨')
        plt.ylabel('ë¹ˆë„')
        plt.title('ì”ì°¨ ë¶„í¬')
        plt.grid(True, alpha=0.3)
        
        # 5. ì„±ëŠ¥ ì§€í‘œ
        plt.subplot(2, 3, 5)
        r2 = self.score(x, y)
        rmse = np.sqrt(np.mean(residuals**2))
        mae = np.mean(np.abs(residuals))
        
        metrics = ['RÂ²', 'RMSE', 'MAE']
        values = [r2, rmse/max(rmse, mae, 1), mae/max(rmse, mae, 1)]  # ì •ê·œí™”
        colors = ['lightgreen', 'lightcoral', 'lightskyblue']
        
        bars = plt.bar(metrics, values, color=colors, alpha=0.7, edgecolor='black')
        plt.ylabel('ì •ê·œí™”ëœ ê°’')
        plt.title('ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ')
        
        # ì‹¤ì œ ê°’ í‘œì‹œ
        actual_values = [r2, rmse, mae]
        for bar, value in zip(bars, actual_values):
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,
                     f'{value:.3f}', ha='center', va='bottom', fontweight='bold')
        
        plt.grid(True, alpha=0.3)
        
        # 6. ë°ì´í„° ë¶„í¬
        plt.subplot(2, 3, 6)
        plt.hist(x, alpha=0.5, label='ë…ë¦½ë³€ìˆ˜', color='blue', bins=15)
        plt.hist(y, alpha=0.5, label='ì¢…ì†ë³€ìˆ˜', color='red', bins=15)
        plt.xlabel('ê°’')
        plt.ylabel('ë¹ˆë„')
        plt.title('ë³€ìˆ˜ ë¶„í¬')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        # ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥
        print(f"\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½:")
        print(f"   RÂ² (ê²°ì •ê³„ìˆ˜): {r2:.4f}")
        print(f"   RMSE: {rmse:.4f}")
        print(f"   MAE: {mae:.4f}")
        print(f"   íšŒê·€ì‹: y = {self.w:.6f}x + {self.b:.6f}")
```

---

## ğŸ”¬ ì‹¤ë¬´ ì ìš©: í‚¤-ëª¸ë¬´ê²Œ ì˜ˆì¸¡ ì‹œìŠ¤í…œ

### ğŸ“Š ì‹¤ì œ ë°ì´í„°ë¥¼ í™œìš©í•œ ì¢…í•© ì˜ˆì œ

```python
def comprehensive_regression_example():
    """í‚¤-ëª¸ë¬´ê²Œ ë°ì´í„°ë¡œ ì¢…í•©ì ì¸ íšŒê·€ë¶„ì„ ìˆ˜í–‰"""
    
    np.random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ ì„¤ì •
    
    print("ğŸ‘¥ ì„±ì¸ ë‚¨ì„± í‚¤-ëª¸ë¬´ê²Œ ë°ì´í„° ë¶„ì„")
    print("=" * 60)
    
    # ê°€ìƒì˜ ì„±ì¸ ë‚¨ì„± ë°ì´í„° ìƒì„±
    n_samples = 10
    heights = np.random.normal(175, 5, n_samples)    # í‰ê·  175cm, í‘œì¤€í¸ì°¨ 5cm
    weights = np.random.normal(70, 10, n_samples)    # í‰ê·  70kg, í‘œì¤€í¸ì°¨ 10kg
    
    print("ğŸ“‹ ë°ì´í„°ì…‹:")
    for i in range(n_samples):
        print(f"   ì‚¬ëŒ {i+1:2d}: í‚¤ {heights[i]:6.2f}cm, ëª¸ë¬´ê²Œ {weights[i]:6.2f}kg")
    
    # ì‚¬ìš©ì ì •ì˜ íšŒê·€ ëª¨ë¸ í•™ìŠµ
    model = MySimpleLinearRegression()
    model.fit(heights, weights)
    
    # íšŒê·€ê³„ìˆ˜ ì¶œë ¥
    params = model.get_params()
    print(f"\nğŸ¯ íšŒê·€ë¶„ì„ ê²°ê³¼:")
    print(f"   ê¸°ìš¸ê¸° (w): {params['weight']:.6f}")
    print(f"   ì ˆí¸ (b): {params['bias']:.6f}")  
    print(f"   íšŒê·€ì‹: {params['equation']}")
    
    # ì˜ˆì¸¡ ìˆ˜í–‰
    weights_pred = model.predict(heights)
    
    # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
    r2_score = model.score(heights, weights)
    rmse = np.sqrt(np.mean((weights - weights_pred)**2))
    mae = np.mean(np.abs(weights - weights_pred))
    
    print(f"\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥:")
    print(f"   RÂ² (ê²°ì •ê³„ìˆ˜): {r2_score:.4f}")
    print(f"   RMSE (í‰ê· ì œê³±ê·¼ì˜¤ì°¨): {rmse:.4f}kg")
    print(f"   MAE (í‰ê· ì ˆëŒ“ê°’ì˜¤ì°¨): {mae:.4f}kg")
    
    # ê°œë³„ ì˜ˆì¸¡ ê²°ê³¼
    print(f"\nğŸ” ê°œë³„ ì˜ˆì¸¡ ê²°ê³¼:")
    print(f"{'ìˆœë²ˆ':>4} {'ì‹¤ì œí‚¤(cm)':>10} {'ì‹¤ì œëª¸ë¬´ê²Œ':>10} {'ì˜ˆì¸¡ëª¸ë¬´ê²Œ':>10} {'ì˜¤ì°¨(kg)':>10}")
    print("-" * 55)
    
    for i in range(len(heights)):
        error = weights[i] - weights_pred[i]
        print(f"{i+1:4d} {heights[i]:10.2f} {weights[i]:10.2f} {weights_pred[i]:10.2f} {error:10.2f}")
    
    # ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡
    test_heights = [160, 170, 180, 190, 199]
    print(f"\nğŸ”® ìƒˆë¡œìš´ í‚¤ì— ëŒ€í•œ ëª¸ë¬´ê²Œ ì˜ˆì¸¡:")
    
    for height in test_heights:
        pred_weight = model.predict(np.array([height]))[0]
        print(f"   í‚¤ {height}cm â†’ ì˜ˆì¸¡ ëª¸ë¬´ê²Œ: {pred_weight:.2f}kg")
    
    # ì™„ì „í•œ ì‹œê°í™” ì‚¬ìš©
    model.plot_regression(heights, weights, "ì„±ì¸ ë‚¨ì„± í‚¤-ëª¸ë¬´ê²Œ íšŒê·€ë¶„ì„")
    
    return model

# ì‹¤í–‰
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ìµœì†Œì œê³±í•´ë¥¼ ì´ìš©í•œ ì‹¤ë¬´ íšŒê·€ë¶„ì„ ì‹œìŠ¤í…œ")
    print("=" * 80)
    
    # ì¢…í•© ì˜ˆì œ ì‹¤í–‰
    trained_model = comprehensive_regression_example()
    
    print(f"\nâœ… íšŒê·€ë¶„ì„ ì™„ë£Œ!")
    print(f"   ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"   ìƒˆë¡œìš´ í‚¤ ë°ì´í„°ê°€ ì£¼ì–´ì§€ë©´ ëª¸ë¬´ê²Œë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    return trained_model

if __name__ == "__main__":
    model = main()
```

---

## ğŸ¯ ê³ ê¸‰ í™œìš©: ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ ì‹¤ìŠµ

### ğŸ“ˆ ì‹¤ìŠµ 2: ë¶€ë™ì‚° ê°€ê²© ì˜ˆì¸¡

```python
def real_estate_regression_example():
    """ë¶€ë™ì‚° í‰ìˆ˜ì™€ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸"""
    
    print("ğŸ  ë¶€ë™ì‚° ê°€ê²© ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    np.random.seed(123)
    
    # ì•„íŒŒíŠ¸ í‰ìˆ˜ì™€ ê°€ê²© ë°ì´í„° ìƒì„± (ë” í˜„ì‹¤ì )
    sizes = np.random.uniform(15, 60, 25)  # 15í‰~60í‰
    # í‰ë‹¹ ê°€ê²©ì„ í‰ìˆ˜ì— ë”°ë¼ ì°¨ë“± ì ìš©
    base_price_per_pyeong = 1000  # ê¸°ë³¸ í‰ë‹¹ 1000ë§Œì›
    price_variation = np.random.normal(0, 200, 25)  # ê°€ê²© ë³€ë™
    prices = sizes * base_price_per_pyeong + price_variation
    
    print("ğŸ“‹ ë¶€ë™ì‚° ë°ì´í„°ì…‹ (ì¼ë¶€):")
    for i in range(10):
        print(f"   {i+1:2d}. {sizes[i]:5.1f}í‰ â†’ {prices[i]:7.0f}ë§Œì›")
    
    # íšŒê·€ë¶„ì„ ìˆ˜í–‰
    estate_model = MySimpleLinearRegression()
    estate_model.fit(sizes, prices)
    
    # ê²°ê³¼ ë¶„ì„
    params = estate_model.get_params()
    print(f"\nğŸ¯ ë¶€ë™ì‚° ê°€ê²© ëª¨ë¸:")
    print(f"   {params['equation']}")
    print(f"   í•´ì„: 1í‰ ì¦ê°€ì‹œ {estate_model.w:.0f}ë§Œì› ìƒìŠ¹")
    
    # ì„±ëŠ¥ í‰ê°€
    r2 = estate_model.score(sizes, prices)
    prices_pred = estate_model.predict(sizes)
    rmse = np.sqrt(np.mean((prices - prices_pred)**2))
    
    print(f"\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥:")
    print(f"   RÂ²: {r2:.4f} ({'ì¢‹ìŒ' if r2 > 0.7 else 'ë³´í†µ' if r2 > 0.5 else 'ê°œì„  í•„ìš”'})")
    print(f"   RMSE: {rmse:.0f}ë§Œì›")
    
    # ì‹¤ì œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
    test_sizes = [20, 30, 40, 50]
    print(f"\nğŸ”® ì‹ ê·œ ë§¤ë¬¼ ê°€ê²© ì˜ˆì¸¡:")
    for size in test_sizes:
        pred_price = estate_model.predict(np.array([size]))[0]
        print(f"   {size:2d}í‰ ì•„íŒŒíŠ¸ â†’ ì˜ˆìƒê°€ê²©: {pred_price:,.0f}ë§Œì›")
    
    # ì‹œê°í™”
    estate_model.plot_regression(sizes, prices, "ë¶€ë™ì‚° í‰ìˆ˜-ê°€ê²© íšŒê·€ë¶„ì„")
    
    return estate_model

# ì‹¤í–‰
estate_model = real_estate_regression_example()
```

### ğŸ“š ì‹¤ìŠµ 3: í•™ìŠµì‹œê°„-ì„±ì  ì˜ˆì¸¡

```python
def study_score_regression():
    """í•™ìŠµì‹œê°„ê³¼ ì‹œí—˜ì„±ì  ê´€ê³„ ë¶„ì„"""
    
    print("ğŸ“š í•™ìŠµì‹œê°„-ì„±ì  ë¶„ì„ ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    np.random.seed(456)
    
    # ì£¼ê°„ í•™ìŠµì‹œê°„ (ì‹œê°„)ê³¼ ì‹œí—˜ì ìˆ˜
    study_hours = np.random.uniform(5, 50, 30)  # 5~50ì‹œê°„
    # ê¸°ë³¸ì ìœ¼ë¡œ í•™ìŠµì‹œê°„ì— ë¹„ë¡€í•˜ì§€ë§Œ ê°œì¸ì°¨ ì¡´ì¬
    base_score = 40 + study_hours * 1.2  # ê¸°ë³¸ ì ìˆ˜
    noise = np.random.normal(0, 8, 30)  # ê°œì¸ì°¨ (ë…¸ì´ì¦ˆ)
    test_scores = np.clip(base_score + noise, 0, 100)  # 0~100 ë²”ìœ„
    
    print("ğŸ“‹ í•™ìŠµ ë°ì´í„° ìƒ˜í”Œ:")
    for i in range(10):
        print(f"   í•™ìƒ {i+1:2d}: {study_hours[i]:4.1f}ì‹œê°„ â†’ {test_scores[i]:4.1f}ì ")
    
    # íšŒê·€ë¶„ì„
    study_model = MySimpleLinearRegression()
    study_model.fit(study_hours, test_scores)
    
    # ê²°ê³¼ í•´ì„
    params = study_model.get_params()
    print(f"\nğŸ¯ í•™ìŠµ íš¨ê³¼ ëª¨ë¸:")
    print(f"   {params['equation']}")
    print(f"   í•´ì„: 1ì‹œê°„ ì¶”ê°€ í•™ìŠµì‹œ {study_model.w:.2f}ì  í–¥ìƒ ì˜ˆìƒ")
    print(f"   ê¸°ë³¸ ì ìˆ˜: {study_model.b:.1f}ì  (í•™ìŠµ ì—†ì´)")
    
    # ì„±ëŠ¥ ê²€ì¦
    r2 = study_model.score(study_hours, test_scores)
    print(f"\nğŸ“Š ëª¨ë¸ ì„¤ëª…ë ¥: {r2:.1%}")
    
    # í•™ìŠµ ê³„íš ìˆ˜ë¦½
    target_score = 80
    required_hours = (target_score - study_model.b) / study_model.w
    print(f"\nğŸ¯ í•™ìŠµ ê³„íš:")
    print(f"   ëª©í‘œ ì ìˆ˜ {target_score}ì  ë‹¬ì„±ì„ ìœ„í•´ì„œëŠ”")
    print(f"   ì£¼ê°„ í•™ìŠµì‹œê°„: {required_hours:.1f}ì‹œê°„ í•„ìš”")
    
    # ì‹œê°í™”
    study_model.plot_regression(study_hours, test_scores, "í•™ìŠµì‹œê°„-ì„±ì  íšŒê·€ë¶„ì„")
    
    return study_model

# ì‹¤í–‰ 
study_model = study_score_regression()
```

---

## ğŸ”¬ ëª¨ë¸ ì§„ë‹¨ê³¼ ê°œì„ 

### ğŸ¯ ì”ì°¨ ë¶„ì„ì˜ ì¤‘ìš”ì„±

```python
def residual_analysis_guide():
    """ì”ì°¨ ë¶„ì„ì„ í†µí•œ ëª¨ë¸ ì§„ë‹¨"""
    
    print("ğŸ”¬ ì”ì°¨ ë¶„ì„ ì™„ì „ ê°€ì´ë“œ")
    print("=" * 50)
    
    # ì¢‹ì€ ëª¨ë¸ vs ë¬¸ì œìˆëŠ” ëª¨ë¸ ë¹„êµ
    np.random.seed(789)
    x = np.linspace(0, 10, 50)
    
    # 1. ì¢‹ì€ ì„ í˜• ê´€ê³„
    y_good = 2 * x + 1 + np.random.normal(0, 1, 50)
    
    # 2. ë¹„ì„ í˜• ê´€ê³„ (ì„ í˜•ëª¨ë¸ë¡œ ë¶€ì ì ˆ)
    y_nonlinear = x**2 + np.random.normal(0, 3, 50)
    
    # 3. ì´ìƒì¹˜ í¬í•¨
    y_outlier = 2 * x + 1 + np.random.normal(0, 1, 50)
    y_outlier[45] = 30  # ì´ìƒì¹˜ ì¶”ê°€
    
    datasets = [
        {"name": "ì ì ˆí•œ ì„ í˜•ê´€ê³„", "x": x, "y": y_good, "color": "green"},
        {"name": "ë¹„ì„ í˜•ê´€ê³„ (ë¬¸ì œ)", "x": x, "y": y_nonlinear, "color": "orange"}, 
        {"name": "ì´ìƒì¹˜ í¬í•¨ (ë¬¸ì œ)", "x": x, "y": y_outlier, "color": "red"}
    ]
    
    plt.figure(figsize=(18, 12))
    
    for i, data in enumerate(datasets):
        # ëª¨ë¸ í•™ìŠµ
        model = MySimpleLinearRegression()
        model.fit(data["x"], data["y"])
        
        y_pred = model.predict(data["x"])
        residuals = data["y"] - y_pred
        r2 = model.score(data["x"], data["y"])
        
        # ì›ë³¸ ë°ì´í„°ì™€ íšŒê·€ì„ 
        plt.subplot(3, 3, i*3 + 1)
        plt.scatter(data["x"], data["y"], alpha=0.6, color=data["color"], s=40)
        plt.plot(data["x"], y_pred, 'black', linewidth=2)
        plt.title(f'{data["name"]}\n(RÂ² = {r2:.3f})')
        plt.xlabel('x')
        plt.ylabel('y')
        plt.grid(True, alpha=0.3)
        
        # ì”ì°¨ í”Œë¡¯
        plt.subplot(3, 3, i*3 + 2)
        plt.scatter(y_pred, residuals, alpha=0.6, color=data["color"], s=40)
        plt.axhline(y=0, color='black', linestyle='--')
        plt.title(f'ì”ì°¨ í”Œë¡¯')
        plt.xlabel('ì˜ˆì¸¡ê°’')
        plt.ylabel('ì”ì°¨')
        plt.grid(True, alpha=0.3)
        
        # ì”ì°¨ íˆìŠ¤í† ê·¸ë¨
        plt.subplot(3, 3, i*3 + 3)
        plt.hist(residuals, bins=15, alpha=0.7, color=data["color"], edgecolor='black')
        plt.axvline(x=0, color='black', linestyle='--')
        plt.title('ì”ì°¨ ë¶„í¬')
        plt.xlabel('ì”ì°¨')
        plt.ylabel('ë¹ˆë„')
        plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print(f"\nâœ… ì¢‹ì€ ëª¨ë¸ì˜ íŠ¹ì§•:")
    print(f"   â€¢ ì”ì°¨ê°€ ì˜ˆì¸¡ê°’ì— ëŒ€í•´ ëœë¤í•˜ê²Œ ë¶„í¬")
    print(f"   â€¢ ì”ì°¨ì˜ í‰ê· ì´ 0ì— ê°€ê¹Œì›€")
    print(f"   â€¢ ì”ì°¨ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¦„")
    
    print(f"\nâŒ ë¬¸ì œìˆëŠ” ëª¨ë¸ì˜ ì‹ í˜¸:")
    print(f"   â€¢ ì”ì°¨ì— íŒ¨í„´ì´ ë³´ì„ (ê³¡ì„ , ê¹”ë•Œê¸° ëª¨ì–‘ ë“±)")
    print(f"   â€¢ ê·¹ë‹¨ì ì¸ ì´ìƒì¹˜ ì¡´ì¬")
    print(f"   â€¢ ì”ì°¨ì˜ ë¶„ì‚°ì´ ì¼ì •í•˜ì§€ ì•ŠìŒ (ì´ë¶„ì‚°ì„±)")

# ì‹¤í–‰
residual_analysis_guide()
```

### âœ… í•™ìŠµ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- âœ… **í–‰ë ¬ í•´ë²• ì´í•´**: ì •ê·œë°©ì •ì‹ê³¼ ì„¤ê³„í–‰ë ¬ êµ¬ì„±
- âœ… **NumPy í™œìš©**: `lstsq` í•¨ìˆ˜ë¥¼ í†µí•œ íš¨ìœ¨ì  ê³„ì‚°  
- âœ… **í´ë˜ìŠ¤ ì„¤ê³„**: ì¬ì‚¬ìš© ê°€ëŠ¥í•œ íšŒê·€ë¶„ì„ ì‹œìŠ¤í…œ
- âœ… **ì„±ëŠ¥ í‰ê°€**: RÂ², RMSE, MAEë¥¼ í†µí•œ ëª¨ë¸ ê²€ì¦
- âœ… **ì‹œê°í™”**: ì”ì°¨ ë¶„ì„ê³¼ ì§„ë‹¨ í”Œë¡¯

### ğŸš€ ë‹¤ìŒ ë‹¨ê³„: ê³ ê¸‰ íšŒê·€ë¶„ì„

```python
def next_steps_preview():
    """ë‹¤ìŒ í•™ìŠµ ë‹¨ê³„ ë¯¸ë¦¬ë³´ê¸°"""
    
    roadmap = {
        "22.11.03 ë‹¤ì¤‘ ì„ í˜•íšŒê·€": {
            "ëª©í‘œ": "ì—¬ëŸ¬ ë…ë¦½ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•œ ì˜ˆì¸¡ ëª¨ë¸",
            "ì£¼ìš”ë‚´ìš©": ["ë‹¤ì¤‘ê³µì„ ì„±", "ë³€ìˆ˜ ì„ íƒ", "ìƒí˜¸ì‘ìš© íš¨ê³¼"],
            "ì‹¤ìŠµ": "ë§ˆì¼€íŒ… ë¯¹ìŠ¤ ìµœì í™” ì‹œìŠ¤í…œ"
        },
        "22.11.04 íšŒê·€ ì§„ë‹¨": {
            "ëª©í‘œ": "ëª¨ë¸ ê°€ì • ê²€ì •ê³¼ ë¬¸ì œ í•´ê²°",
            "ì£¼ìš”ë‚´ìš©": ["ì •ê·œì„±", "ë“±ë¶„ì‚°ì„±", "ë…ë¦½ì„±", "ì„ í˜•ì„±"],
            "ì‹¤ìŠµ": "ì”ì°¨ ë¶„ì„ê³¼ ëª¨ë¸ ê°œì„ "
        },
        "22.11.05 ê³ ê¸‰ íšŒê·€": {
            "ëª©í‘œ": "ì •ê·œí™”ì™€ ë¹„ì„ í˜• íšŒê·€",
            "ì£¼ìš”ë‚´ìš©": ["Ridge/Lasso", "ë‹¤í•­ì‹ íšŒê·€", "ë¡œì§€ìŠ¤í‹± íšŒê·€"],
            "ì‹¤ìŠµ": "ë¨¸ì‹ ëŸ¬ë‹ ì—°ê²°ì "
        }
    }
    
    return roadmap

# ë¡œë“œë§µ ì¶œë ¥
next_roadmap = next_steps_preview()
print("\nğŸ—ºï¸ íšŒê·€ë¶„ì„ í•™ìŠµ ë¡œë“œë§µ")
print("=" * 50)

for chapter, details in next_roadmap.items():
    print(f"\nğŸ“š {chapter}")
    print(f"   ğŸ¯ ëª©í‘œ: {details['ëª©í‘œ']}")
    print(f"   ğŸ“‹ ì£¼ìš”ë‚´ìš©: {', '.join(details['ì£¼ìš”ë‚´ìš©'])}")
    print(f"   ğŸ’» ì‹¤ìŠµ: {details['ì‹¤ìŠµ']}")
```

### ğŸ’¡ ì‹¤ë¬´ í™œìš© íŒ

1. **ë°ì´í„° ì „ì²˜ë¦¬**: ì´ìƒì¹˜ ì œê±°ì™€ í‘œì¤€í™”
2. **ê°€ì • ê²€ì •**: ì„ í˜•ì„±, ë“±ë¶„ì‚°ì„±, ì •ê·œì„± í™•ì¸
3. **ëª¨ë¸ ê²€ì¦**: êµì°¨ê²€ì¦ê³¼ í™€ë“œì•„ì›ƒ ì„¸íŠ¸ í™œìš©
4. **í•´ì„**: íšŒê·€ê³„ìˆ˜ì˜ ì‹¤ë¬´ì  ì˜ë¯¸ íŒŒì•…
5. **ì˜ˆì¸¡**: ì‹ ë¢°êµ¬ê°„ê³¼ ì˜ˆì¸¡êµ¬ê°„ ì œê³µ

---

## ğŸ‰ ë§ˆë¬´ë¦¬

ì´ì œ **ìµœì†Œì œê³±í•´ì˜ í–‰ë ¬ í•´ë²•**ì„ ì™„ì „íˆ ë§ˆìŠ¤í„°í•˜ì…¨ìŠµë‹ˆë‹¤! 

**í•µì‹¬ ì„±ê³¼:**
- ìˆ˜í•™ì  ì›ë¦¬ì˜ ì‹¤ë¬´ êµ¬í˜„
- ì¬ì‚¬ìš© ê°€ëŠ¥í•œ íšŒê·€ë¶„ì„ í´ë˜ìŠ¤ 
- ì¢…í•©ì ì¸ ëª¨ë¸ í‰ê°€ ì‹œìŠ¤í…œ
- ì‹¤ì œ ë°ì´í„°ë¥¼ í™œìš©í•œ ì˜ˆì¸¡ ëª¨ë¸

ë‹¤ìŒ ë‹¨ê³„ì—ì„œëŠ” **ë‹¤ì¤‘ ì„ í˜•íšŒê·€**ë¡œ í™•ì¥í•˜ì—¬ ë”ìš± ê°•ë ¥í•œ ì˜ˆì¸¡ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•´ë³´ê² ìŠµë‹ˆë‹¤! ğŸš€