# 22.11.02 최소제곱해를 선형 행렬 방정식으로 구하기
*수학적 원리에서 실무 구현까지의 완전한 여정*

---

## 🎯 학습 목표

이 문서는 **최소제곱법의 행렬 해법**을 중심으로 실무에서 활용할 수 있는 **완전한 선형회귀 시스템**을 구축하는 것을 목표로 합니다.

### ✅ 핵심 학습 내용
- 최소제곱해의 행렬 방정식 이해
- NumPy를 활용한 효율적 구현
- 사용자 정의 회귀 클래스 설계
- 실무 예측 시스템 구축

---

## 📐 최소제곱해의 행렬 해법

### 🎯 기본 원리

선형 회귀 문제 `y = Xβ + ε`에서 최소제곱해는 다음과 같이 구할 수 있습니다:

**정규방정식(Normal Equation):**
```
β̂ = (X^T X)^(-1) X^T y
```

여기서:
- `X`: 설계 행렬(Design Matrix) - 독립변수들과 상수항
- `y`: 종속변수 벡터
- `β`: 회귀계수 벡터 [기울기, 절편]

### 🔧 설계 행렬 구성

```python
import numpy as np

# 예제 데이터
x = np.array([0, 1, 2, 3])           # 독립변수
y = np.array([-1, 0.2, 0.5, 2.1])   # 종속변수

# 설계 행렬 A = [x, 1] 형태로 구성
A = np.vstack([x, np.ones(len(x))]).T
print("설계 행렬 A:")
print(A)
```

출력:
```
설계 행렬 A:
[[0. 1.]
 [1. 1.]
 [2. 1.]
 [3. 1.]]
```

---

## 💻 NumPy를 활용한 최소제곱해 계산

### 🎯 방법 1: `numpy.linalg.lstsq` 사용

```python
import numpy as np
import matplotlib.pyplot as plt
import numpy.linalg as lin

plt.rc('font', family='Malgun Gothic')  # 한글 폰트 설정

def solve_least_squares_numpy(x, y):
    """NumPy를 사용한 최소제곱해 계산"""
    
    # 설계 행렬 구성
    A = np.vstack([x, np.ones(len(x))]).T
    print("🔧 설계 행렬 A:")
    print(A)
    
    # 최소제곱해 계산
    w, b = lin.lstsq(A, y, rcond=None)[0]
    
    print(f"\n⚡ 최소제곱법 결과:")
    print(f"   기울기 (w): {w:.6f}")
    print(f"   절편 (b): {b:.6f}")
    print(f"   회귀식: y = {w:.6f}x + {b:.6f}")
    
    return w, b

# 예제 실행
x = np.array([0, 1, 2, 3])
y = np.array([-1, 0.2, 0.5, 2.1])

w, b = solve_least_squares_numpy(x, y)

# 예측값 계산 및 평가
y_pred = w * x + b
print(f"\n📈 예측 성능:")
print(f"   예측값: {y_pred}")
print(f"   잔차: {y - y_pred}")
print(f"   SSE: {np.sum((y - y_pred)**2):.6f}")

# 시각화
plt.figure(figsize=(10, 6))
plt.scatter(x, y, color='red', s=100, label='실제 데이터', zorder=5)
plt.plot(x, y_pred, 'b-', linewidth=2, label=f'회귀선: y={w:.3f}x+{b:.3f}')

# 잔차 표시
for i in range(len(x)):
    plt.plot([x[i], x[i]], [y[i], y_pred[i]], 'g--', alpha=0.7)

plt.xlabel('x')
plt.ylabel('y')
plt.title('최소제곱법으로 구한 최적 회귀선')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

---

## 🎓 사용자 정의 단순 선형회귀 클래스

### 🏗️ 완전한 회귀 클래스 구현

```python
import numpy as np

class MySimpleLinearRegression:
    """
    사용자 정의 단순 선형회귀 클래스
    수학적 공식을 직접 구현하여 최소제곱해를 계산
    """
    
    def __init__(self):
        """생성자: 회귀계수 초기화"""
        self.w = None  # 기울기 (가중치, Weight)
        self.b = None  # 절편 (편향, Bias)
        
    def fit(self, x: np.ndarray, y: np.ndarray):
        """
        최소제곱법으로 회귀계수 추정
        
        Parameters:
        -----------
        x : np.ndarray
            독립변수 (1차원 배열)
        y : np.ndarray  
            종속변수 (1차원 배열)
        """
        # 평균값 계산
        x_mean = np.mean(x)
        y_mean = np.mean(y)
        
        # 최소제곱법 공식 적용
        numerator = np.sum((x - x_mean) * (y - y_mean))    # 분자
        denominator = np.sum((x - x_mean) ** 2)            # 분모
        
        # 회귀계수 계산
        self.w = numerator / denominator      # 기울기
        self.b = y_mean - (self.w * x_mean)   # 절편
        
        return self
        
    def predict(self, x: np.ndarray):
        """
        새로운 x값에 대한 y값 예측
        
        Parameters:
        -----------
        x : np.ndarray
            예측할 x값들
            
        Returns:
        --------
        np.ndarray
            예측된 y값들
        """
        if self.w is None or self.b is None:
            raise ValueError("모델이 학습되지 않았습니다. fit() 메소드를 먼저 실행하세요.")
            
        return self.w * x + self.b
    
    def score(self, x: np.ndarray, y: np.ndarray):
        """
        결정계수(R²) 계산
        
        Parameters:
        -----------
        x : np.ndarray
            독립변수
        y : np.ndarray
            실제 종속변수 값
            
        Returns:
        --------
        float
            R² 스코어 (0~1, 높을수록 좋음)
        """
        y_pred = self.predict(x)
        ss_res = np.sum((y - y_pred) ** 2)        # 잔차제곱합
        ss_tot = np.sum((y - np.mean(y)) ** 2)    # 총제곱합
        
        return 1 - (ss_res / ss_tot)
    
    def get_params(self):
        """회귀계수 반환"""
        return {
            'weight': self.w,
            'bias': self.b,
            'equation': f'y = {self.w:.6f}x + {self.b:.6f}'
        }
    
    def plot_regression(self, x: np.ndarray, y: np.ndarray, title: str = "회귀분석 결과"):
        """회귀분석 결과 시각화"""
        if self.w is None or self.b is None:
            raise ValueError("모델이 학습되지 않았습니다. fit() 메소드를 먼저 실행하세요.")
            
        y_pred = self.predict(x)
        residuals = y - y_pred
        
        plt.figure(figsize=(15, 10))
        
        # 1. 메인 회귀 플롯
        plt.subplot(2, 3, 1)
        plt.scatter(x, y, color='blue', s=80, alpha=0.7, label='실제 데이터')
        
        # 회귀선
        x_range = np.linspace(x.min()-1, x.max()+1, 100)
        y_range_pred = self.predict(x_range)
        plt.plot(x_range, y_range_pred, 'r-', linewidth=2, 
                 label=f'회귀선 (R²={self.score(x, y):.3f})')
        
        # 잔차 표시
        for i in range(len(x)):
            plt.plot([x[i], x[i]], [y[i], y_pred[i]], 'g--', alpha=0.5)
        
        plt.xlabel('독립변수 (x)')
        plt.ylabel('종속변수 (y)')
        plt.title(title)
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 2. 잔차 플롯
        plt.subplot(2, 3, 2)
        plt.scatter(y_pred, residuals, color='green', s=60, alpha=0.7)
        plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
        plt.xlabel('예측값')
        plt.ylabel('잔차')
        plt.title('잔차 플롯')
        plt.grid(True, alpha=0.3)
        
        # 3. 실제값 vs 예측값
        plt.subplot(2, 3, 3)
        plt.scatter(y, y_pred, color='purple', s=60, alpha=0.7)
        min_val = min(min(y), min(y_pred)) - 1
        max_val = max(max(y), max(y_pred)) + 1
        plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2,
                 label='완벽한 예측선')
        plt.xlabel('실제값')
        plt.ylabel('예측값')
        plt.title('실제값 vs 예측값')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 4. 잔차 히스토그램
        plt.subplot(2, 3, 4)
        plt.hist(residuals, bins=15, alpha=0.7, color='orange', edgecolor='black')
        plt.axvline(x=0, color='red', linestyle='--', linewidth=2)
        plt.xlabel('잔차')
        plt.ylabel('빈도')
        plt.title('잔차 분포')
        plt.grid(True, alpha=0.3)
        
        # 5. 성능 지표
        plt.subplot(2, 3, 5)
        r2 = self.score(x, y)
        rmse = np.sqrt(np.mean(residuals**2))
        mae = np.mean(np.abs(residuals))
        
        metrics = ['R²', 'RMSE', 'MAE']
        values = [r2, rmse/max(rmse, mae, 1), mae/max(rmse, mae, 1)]  # 정규화
        colors = ['lightgreen', 'lightcoral', 'lightskyblue']
        
        bars = plt.bar(metrics, values, color=colors, alpha=0.7, edgecolor='black')
        plt.ylabel('정규화된 값')
        plt.title('모델 성능 지표')
        
        # 실제 값 표시
        actual_values = [r2, rmse, mae]
        for bar, value in zip(bars, actual_values):
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,
                     f'{value:.3f}', ha='center', va='bottom', fontweight='bold')
        
        plt.grid(True, alpha=0.3)
        
        # 6. 데이터 분포
        plt.subplot(2, 3, 6)
        plt.hist(x, alpha=0.5, label='독립변수', color='blue', bins=15)
        plt.hist(y, alpha=0.5, label='종속변수', color='red', bins=15)
        plt.xlabel('값')
        plt.ylabel('빈도')
        plt.title('변수 분포')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        # 성능 요약 출력
        print(f"\n📊 모델 성능 요약:")
        print(f"   R² (결정계수): {r2:.4f}")
        print(f"   RMSE: {rmse:.4f}")
        print(f"   MAE: {mae:.4f}")
        print(f"   회귀식: y = {self.w:.6f}x + {self.b:.6f}")
```

---

## 🔬 실무 적용: 키-몸무게 예측 시스템

### 📊 실제 데이터를 활용한 종합 예제

```python
def comprehensive_regression_example():
    """키-몸무게 데이터로 종합적인 회귀분석 수행"""
    
    np.random.seed(42)  # 재현 가능한 결과를 위한 시드 설정
    
    print("👥 성인 남성 키-몸무게 데이터 분석")
    print("=" * 60)
    
    # 가상의 성인 남성 데이터 생성
    n_samples = 10
    heights = np.random.normal(175, 5, n_samples)    # 평균 175cm, 표준편차 5cm
    weights = np.random.normal(70, 10, n_samples)    # 평균 70kg, 표준편차 10kg
    
    print("📋 데이터셋:")
    for i in range(n_samples):
        print(f"   사람 {i+1:2d}: 키 {heights[i]:6.2f}cm, 몸무게 {weights[i]:6.2f}kg")
    
    # 사용자 정의 회귀 모델 학습
    model = MySimpleLinearRegression()
    model.fit(heights, weights)
    
    # 회귀계수 출력
    params = model.get_params()
    print(f"\n🎯 회귀분석 결과:")
    print(f"   기울기 (w): {params['weight']:.6f}")
    print(f"   절편 (b): {params['bias']:.6f}")  
    print(f"   회귀식: {params['equation']}")
    
    # 예측 수행
    weights_pred = model.predict(heights)
    
    # 모델 성능 평가
    r2_score = model.score(heights, weights)
    rmse = np.sqrt(np.mean((weights - weights_pred)**2))
    mae = np.mean(np.abs(weights - weights_pred))
    
    print(f"\n📊 모델 성능:")
    print(f"   R² (결정계수): {r2_score:.4f}")
    print(f"   RMSE (평균제곱근오차): {rmse:.4f}kg")
    print(f"   MAE (평균절댓값오차): {mae:.4f}kg")
    
    # 개별 예측 결과
    print(f"\n🔍 개별 예측 결과:")
    print(f"{'순번':>4} {'실제키(cm)':>10} {'실제몸무게':>10} {'예측몸무게':>10} {'오차(kg)':>10}")
    print("-" * 55)
    
    for i in range(len(heights)):
        error = weights[i] - weights_pred[i]
        print(f"{i+1:4d} {heights[i]:10.2f} {weights[i]:10.2f} {weights_pred[i]:10.2f} {error:10.2f}")
    
    # 새로운 데이터 예측
    test_heights = [160, 170, 180, 190, 199]
    print(f"\n🔮 새로운 키에 대한 몸무게 예측:")
    
    for height in test_heights:
        pred_weight = model.predict(np.array([height]))[0]
        print(f"   키 {height}cm → 예측 몸무게: {pred_weight:.2f}kg")
    
    # 완전한 시각화 사용
    model.plot_regression(heights, weights, "성인 남성 키-몸무게 회귀분석")
    
    return model

# 실행
def main():
    """메인 실행 함수"""
    print("🚀 최소제곱해를 이용한 실무 회귀분석 시스템")
    print("=" * 80)
    
    # 종합 예제 실행
    trained_model = comprehensive_regression_example()
    
    print(f"\n✅ 회귀분석 완료!")
    print(f"   모델이 성공적으로 학습되었습니다.")
    print(f"   새로운 키 데이터가 주어지면 몸무게를 예측할 수 있습니다.")
    
    return trained_model

if __name__ == "__main__":
    model = main()
```

---

## 🎯 고급 활용: 다양한 데이터셋 실습

### 📈 실습 2: 부동산 가격 예측

```python
def real_estate_regression_example():
    """부동산 평수와 가격 예측 모델"""
    
    print("🏠 부동산 가격 예측 시스템")
    print("=" * 60)
    
    np.random.seed(123)
    
    # 아파트 평수와 가격 데이터 생성 (더 현실적)
    sizes = np.random.uniform(15, 60, 25)  # 15평~60평
    # 평당 가격을 평수에 따라 차등 적용
    base_price_per_pyeong = 1000  # 기본 평당 1000만원
    price_variation = np.random.normal(0, 200, 25)  # 가격 변동
    prices = sizes * base_price_per_pyeong + price_variation
    
    print("📋 부동산 데이터셋 (일부):")
    for i in range(10):
        print(f"   {i+1:2d}. {sizes[i]:5.1f}평 → {prices[i]:7.0f}만원")
    
    # 회귀분석 수행
    estate_model = MySimpleLinearRegression()
    estate_model.fit(sizes, prices)
    
    # 결과 분석
    params = estate_model.get_params()
    print(f"\n🎯 부동산 가격 모델:")
    print(f"   {params['equation']}")
    print(f"   해석: 1평 증가시 {estate_model.w:.0f}만원 상승")
    
    # 성능 평가
    r2 = estate_model.score(sizes, prices)
    prices_pred = estate_model.predict(sizes)
    rmse = np.sqrt(np.mean((prices - prices_pred)**2))
    
    print(f"\n📊 모델 성능:")
    print(f"   R²: {r2:.4f} ({'좋음' if r2 > 0.7 else '보통' if r2 > 0.5 else '개선 필요'})")
    print(f"   RMSE: {rmse:.0f}만원")
    
    # 실제 예측 테스트
    test_sizes = [20, 30, 40, 50]
    print(f"\n🔮 신규 매물 가격 예측:")
    for size in test_sizes:
        pred_price = estate_model.predict(np.array([size]))[0]
        print(f"   {size:2d}평 아파트 → 예상가격: {pred_price:,.0f}만원")
    
    # 시각화
    estate_model.plot_regression(sizes, prices, "부동산 평수-가격 회귀분석")
    
    return estate_model

# 실행
estate_model = real_estate_regression_example()
```

### 📚 실습 3: 학습시간-성적 예측

```python
def study_score_regression():
    """학습시간과 시험성적 관계 분석"""
    
    print("📚 학습시간-성적 분석 시스템")
    print("=" * 60)
    
    np.random.seed(456)
    
    # 주간 학습시간 (시간)과 시험점수
    study_hours = np.random.uniform(5, 50, 30)  # 5~50시간
    # 기본적으로 학습시간에 비례하지만 개인차 존재
    base_score = 40 + study_hours * 1.2  # 기본 점수
    noise = np.random.normal(0, 8, 30)  # 개인차 (노이즈)
    test_scores = np.clip(base_score + noise, 0, 100)  # 0~100 범위
    
    print("📋 학습 데이터 샘플:")
    for i in range(10):
        print(f"   학생 {i+1:2d}: {study_hours[i]:4.1f}시간 → {test_scores[i]:4.1f}점")
    
    # 회귀분석
    study_model = MySimpleLinearRegression()
    study_model.fit(study_hours, test_scores)
    
    # 결과 해석
    params = study_model.get_params()
    print(f"\n🎯 학습 효과 모델:")
    print(f"   {params['equation']}")
    print(f"   해석: 1시간 추가 학습시 {study_model.w:.2f}점 향상 예상")
    print(f"   기본 점수: {study_model.b:.1f}점 (학습 없이)")
    
    # 성능 검증
    r2 = study_model.score(study_hours, test_scores)
    print(f"\n📊 모델 설명력: {r2:.1%}")
    
    # 학습 계획 수립
    target_score = 80
    required_hours = (target_score - study_model.b) / study_model.w
    print(f"\n🎯 학습 계획:")
    print(f"   목표 점수 {target_score}점 달성을 위해서는")
    print(f"   주간 학습시간: {required_hours:.1f}시간 필요")
    
    # 시각화
    study_model.plot_regression(study_hours, test_scores, "학습시간-성적 회귀분석")
    
    return study_model

# 실행 
study_model = study_score_regression()
```

---

## 🔬 모델 진단과 개선

### 🎯 잔차 분석의 중요성

```python
def residual_analysis_guide():
    """잔차 분석을 통한 모델 진단"""
    
    print("🔬 잔차 분석 완전 가이드")
    print("=" * 50)
    
    # 좋은 모델 vs 문제있는 모델 비교
    np.random.seed(789)
    x = np.linspace(0, 10, 50)
    
    # 1. 좋은 선형 관계
    y_good = 2 * x + 1 + np.random.normal(0, 1, 50)
    
    # 2. 비선형 관계 (선형모델로 부적절)
    y_nonlinear = x**2 + np.random.normal(0, 3, 50)
    
    # 3. 이상치 포함
    y_outlier = 2 * x + 1 + np.random.normal(0, 1, 50)
    y_outlier[45] = 30  # 이상치 추가
    
    datasets = [
        {"name": "적절한 선형관계", "x": x, "y": y_good, "color": "green"},
        {"name": "비선형관계 (문제)", "x": x, "y": y_nonlinear, "color": "orange"}, 
        {"name": "이상치 포함 (문제)", "x": x, "y": y_outlier, "color": "red"}
    ]
    
    plt.figure(figsize=(18, 12))
    
    for i, data in enumerate(datasets):
        # 모델 학습
        model = MySimpleLinearRegression()
        model.fit(data["x"], data["y"])
        
        y_pred = model.predict(data["x"])
        residuals = data["y"] - y_pred
        r2 = model.score(data["x"], data["y"])
        
        # 원본 데이터와 회귀선
        plt.subplot(3, 3, i*3 + 1)
        plt.scatter(data["x"], data["y"], alpha=0.6, color=data["color"], s=40)
        plt.plot(data["x"], y_pred, 'black', linewidth=2)
        plt.title(f'{data["name"]}\n(R² = {r2:.3f})')
        plt.xlabel('x')
        plt.ylabel('y')
        plt.grid(True, alpha=0.3)
        
        # 잔차 플롯
        plt.subplot(3, 3, i*3 + 2)
        plt.scatter(y_pred, residuals, alpha=0.6, color=data["color"], s=40)
        plt.axhline(y=0, color='black', linestyle='--')
        plt.title(f'잔차 플롯')
        plt.xlabel('예측값')
        plt.ylabel('잔차')
        plt.grid(True, alpha=0.3)
        
        # 잔차 히스토그램
        plt.subplot(3, 3, i*3 + 3)
        plt.hist(residuals, bins=15, alpha=0.7, color=data["color"], edgecolor='black')
        plt.axvline(x=0, color='black', linestyle='--')
        plt.title('잔차 분포')
        plt.xlabel('잔차')
        plt.ylabel('빈도')
        plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print(f"\n✅ 좋은 모델의 특징:")
    print(f"   • 잔차가 예측값에 대해 랜덤하게 분포")
    print(f"   • 잔차의 평균이 0에 가까움")
    print(f"   • 잔차가 정규분포를 따름")
    
    print(f"\n❌ 문제있는 모델의 신호:")
    print(f"   • 잔차에 패턴이 보임 (곡선, 깔때기 모양 등)")
    print(f"   • 극단적인 이상치 존재")
    print(f"   • 잔차의 분산이 일정하지 않음 (이분산성)")

# 실행
residual_analysis_guide()
```

### ✅ 학습 완료 체크리스트

- ✅ **행렬 해법 이해**: 정규방정식과 설계행렬 구성
- ✅ **NumPy 활용**: `lstsq` 함수를 통한 효율적 계산  
- ✅ **클래스 설계**: 재사용 가능한 회귀분석 시스템
- ✅ **성능 평가**: R², RMSE, MAE를 통한 모델 검증
- ✅ **시각화**: 잔차 분석과 진단 플롯

### 🚀 다음 단계: 고급 회귀분석

```python
def next_steps_preview():
    """다음 학습 단계 미리보기"""
    
    roadmap = {
        "22.11.03 다중 선형회귀": {
            "목표": "여러 독립변수를 사용한 예측 모델",
            "주요내용": ["다중공선성", "변수 선택", "상호작용 효과"],
            "실습": "마케팅 믹스 최적화 시스템"
        },
        "22.11.04 회귀 진단": {
            "목표": "모델 가정 검정과 문제 해결",
            "주요내용": ["정규성", "등분산성", "독립성", "선형성"],
            "실습": "잔차 분석과 모델 개선"
        },
        "22.11.05 고급 회귀": {
            "목표": "정규화와 비선형 회귀",
            "주요내용": ["Ridge/Lasso", "다항식 회귀", "로지스틱 회귀"],
            "실습": "머신러닝 연결점"
        }
    }
    
    return roadmap

# 로드맵 출력
next_roadmap = next_steps_preview()
print("\n🗺️ 회귀분석 학습 로드맵")
print("=" * 50)

for chapter, details in next_roadmap.items():
    print(f"\n📚 {chapter}")
    print(f"   🎯 목표: {details['목표']}")
    print(f"   📋 주요내용: {', '.join(details['주요내용'])}")
    print(f"   💻 실습: {details['실습']}")
```

### 💡 실무 활용 팁

1. **데이터 전처리**: 이상치 제거와 표준화
2. **가정 검정**: 선형성, 등분산성, 정규성 확인
3. **모델 검증**: 교차검증과 홀드아웃 세트 활용
4. **해석**: 회귀계수의 실무적 의미 파악
5. **예측**: 신뢰구간과 예측구간 제공

---

## 🎉 마무리

이제 **최소제곱해의 행렬 해법**을 완전히 마스터하셨습니다! 

**핵심 성과:**
- 수학적 원리의 실무 구현
- 재사용 가능한 회귀분석 클래스 
- 종합적인 모델 평가 시스템
- 실제 데이터를 활용한 예측 모델

다음 단계에서는 **다중 선형회귀**로 확장하여 더욱 강력한 예측 시스템을 구축해보겠습니다! 🚀