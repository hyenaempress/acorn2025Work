# ë™ì•„ì¼ë³´ ì›Œë“œí´ë¼ìš°ë“œ ì˜ˆì œ:

## ğŸ” **ì£¼ìš” ê°œì„ ì‚¬í•­ ìš”ì•½**

| êµ¬ë¶„ | 20.01 (ê¸°ì¡´) | 20.21 (ê°œì„ ) | ê°œì„  íš¨ê³¼ |
|------|-------------|-------------|-----------|
| **í‚¤ì›Œë“œ ì…ë ¥** | `input()` ë™ì  ì…ë ¥ | `"ë¬´ë”ìœ„"` ê³ ì •ê°’ | ğŸ¯ ì‹¤ìŠµ ì•ˆì •ì„± |
| **URL ì¸ì½”ë”©** | ëˆ„ë½ â†’ ì—ëŸ¬ ë°œìƒ | `quote()` ì ìš© | âœ… í•œê¸€ ì²˜ë¦¬ ì™„ë²½ |
| **íŒŒì„œ ì„¤ì •** | `'lxml.parser'` (ì˜¤íƒ€) | `'lxml'` | âœ… ì •í™•í•œ íŒŒì„œëª… |
| **ë³¸ë¬¸ ì¶”ì¶œ** | ë³µì¡í•œ ë¬¸ìì—´ ì²˜ë¦¬ | `find_all(string=True)` | ğŸš€ ì½”ë“œ ê°„ì†Œí™” |
| **í˜•íƒœì†Œ ë¶„ì„** | ì—†ìŒ | **Okt + Counter** | â­ **í•µì‹¬ ê¸°ëŠ¥ ì¶”ê°€** |
| **ì‹œê°í™”** | ì—†ìŒ | **pytagcloud + matplotlib** | ğŸ¨ **ì™„ì „í•œ ì›Œí¬í”Œë¡œìš°** |

---

## ğŸ“Š **ìƒì„¸ ì½”ë“œ ë¹„êµ**

### 1. **URL ì¸ì½”ë”© ì²˜ë¦¬**

#### âŒ 20.01 (ë¬¸ì œ ì½”ë“œ)
```python
# í•œê¸€ í‚¤ì›Œë“œê°€ URLì— ì œëŒ€ë¡œ ì „ë‹¬ë˜ì§€ ì•ŠìŒ
target_url = 'https://www.donga.com/news/search?query=' + keyword
```

#### âœ… 20.21 (ê°œì„  ì½”ë“œ)
```python
from urllib.parse import quote
target_url = "https://www.donga.com/news/search?query=" + quote(keyword)
# "ë¬´ë”ìœ„" â†’ "%EB%AC%B4%EB%8D%94%EC%9C%84"
```

### 2. **íŒŒì„œ ì´ë¦„ ìˆ˜ì •**

#### âŒ 20.01 (ì˜¤íƒ€)
```python
soup = BeautifulSoup(source_article, 'lxml.parser', from_encoding='utf-8')
```

#### âœ… 20.21 (ì •í™•)
```python
soup = BeautifulSoup(source_article, 'lxml', from_encoding='utf-8')
```

### 3. **ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¡œì§**

#### âŒ 20.01 (ë³µì¡í•˜ê³  ì—ëŸ¬ ìœ ë°œ)
```python
content = soup.select_one('div.article_txt').get_text()
for imsi in content:  # ë¬¸ì í•˜ë‚˜ì”© ìˆœíšŒ â†’ ë¹„íš¨ìœ¨
    item = str(imsi.find_all(text=True))  # ë¬¸ìì—´ì— find_all() ë¶ˆê°€
    mag += item
```

#### âœ… 20.21 (ê¹”ë”í•˜ê³  ì•ˆì •ì )
```python
contents = soup.select('div.article_txt')  # ì—¬ëŸ¬ ìš”ì†Œ ì²˜ë¦¬
for temp in contents:
    item = str(temp.find_all(string=True))  # string=Trueë¡œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
    msg += item
```

### 4. **í˜•íƒœì†Œ ë¶„ì„ ì¶”ê°€ (20.21ì˜ í•µì‹¬ ê°œì„ )**

```python
from konlpy.tag import Okt
from collections import Counter

# í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”
okt = Okt()
nouns = okt.nouns(msg)            # ëª…ì‚¬ë§Œ ì¶”ì¶œ

# 2ê¸€ì ì´ìƒ ëª…ì‚¬ í•„í„°ë§
result = []
for temp in nouns:
    if len(temp) > 1:
        result.append(temp)

# ë¹ˆë„ìˆ˜ ê³„ì‚° ë° ìƒìœ„ 50ê°œ ì¶”ì¶œ
count = Counter(result)
tag = count.most_common(50)
```

### 5. **ì™„ì„±í˜• ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±**

```python
import pytagcloud
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# ì›Œë“œí´ë¼ìš°ë“œ íƒœê·¸ ìƒì„±
taglist = pytagcloud.make_tags(tag, maxsize=100)

# ì´ë¯¸ì§€ íŒŒì¼ ìƒì„±
pytagcloud.create_tag_image(taglist,
                            './01_big_data_machine_learning/data/wordcloud.png',
                            size=(1000, 600),
                            background=(0,0,0),
                            fontname="korean",
                            rectangular=False)

# matplotlibë¡œ ì‹œê°í™”
img = mpimg.imread('./01_big_data_machine_learning/data/wordcloud.png')
plt.imshow(img)
plt.show()
```

---

## ğŸš€ **20.21 ì˜ˆì œì˜ í•™ìŠµ ê°€ì¹˜**

### â­ **ì™„ì „í•œ NLP íŒŒì´í”„ë¼ì¸ êµ¬í˜„**
1. **ì›¹ ìŠ¤í¬ë˜í•‘** â†’ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
2. **í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬** â†’ ë³¸ë¬¸ ì¶”ì¶œ ë° ì •ì œ
3. **í˜•íƒœì†Œ ë¶„ì„** â†’ ëª…ì‚¬ ì¶”ì¶œ (KoNLPy Okt)
4. **í†µê³„ ë¶„ì„** â†’ ë‹¨ì–´ ë¹ˆë„ ê³„ì‚° (Counter)
5. **ì‹œê°í™”** â†’ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± (pytagcloud)

### ğŸ¯ **ì‹¤ë¬´ í™œìš©ë„**
- **ë‰´ìŠ¤ í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„**
- **ë¸Œëœë“œ ì–¸ê¸‰ëŸ‰ ëª¨ë‹ˆí„°ë§**  
- **ê³ ê° ë¦¬ë·° í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ**
- **ì†Œì…œë¯¸ë””ì–´ í† í”½ ë¶„ì„**

### ğŸ› ï¸ **ê¸°ìˆ  ìŠ¤íƒ ì™„ì„±ë„**
```python
tech_stack = {
    "ì›¹í¬ë¡¤ë§": ["BeautifulSoup", "urllib", "requests"],
    "ìì—°ì–´ì²˜ë¦¬": ["KoNLPy", "Okt", "í˜•íƒœì†Œë¶„ì„"],
    "ë°ì´í„°ë¶„ì„": ["Collections.Counter", "ë¹ˆë„ë¶„ì„"],
    "ì‹œê°í™”": ["pytagcloud", "matplotlib", "ì›Œë“œí´ë¼ìš°ë“œ"]
}
```

---

## ğŸ“ **ì‹¤ìŠµìš© ì™„ì „ ì½”ë“œ (20.21 ê¸°ë°˜)**

```python
# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
# pip install beautifulsoup4 konlpy pytagcloud matplotlib

# ë™ì•„ì¼ë³´ ê²€ìƒ‰ ê¸°ëŠ¥ìœ¼ë¡œ ë¬¸ìì—´ì„ ì½ì–´ í˜•íƒœì†Œ ë¶„ì„ í›„ ì›Œë“œí´ë¼ìš°ë“œë¡œ ì¶œë ¥
from bs4 import BeautifulSoup
import urllib.request
from urllib.parse import quote
from konlpy.tag import Okt
from collections import Counter
import pytagcloud
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# ê²€ìƒ‰ í‚¤ì›Œë“œ ì„¤ì •
keyword = "ë¬´ë”ìœ„"
print(f"ê²€ìƒ‰ì–´: {keyword}")
print(f"URL ì¸ì½”ë”©: {quote(keyword)}")

# ë™ì•„ì¼ë³´ ê²€ìƒ‰ URL ìƒì„±
target_url = "https://www.donga.com/news/search?query=" + quote(keyword)
print(f"Target URL: {target_url}")

# ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ íŒŒì‹±
source_code = urllib.request.urlopen(target_url)
soup = BeautifulSoup(source_code, 'lxml', from_encoding='utf-8')

# ëª¨ë“  ê¸°ì‚¬ ë³¸ë¬¸ ìˆ˜ì§‘
msg = ""
for title in soup.find_all('h4', class_='tit'):
    title_link = title.select('a')
    if not title_link:  # ë§í¬ê°€ ì—†ëŠ” ê²½ìš° ìŠ¤í‚µ
        continue
        
    article_url = title_link[0]['href']
    print(f"ê¸°ì‚¬ URL: {article_url}")
    
    try:
        # ê°œë³„ ê¸°ì‚¬ í˜ì´ì§€ ì ‘ê·¼
        source_article = urllib.request.urlopen(article_url)
        article_soup = BeautifulSoup(source_article, 'lxml', from_encoding='utf-8')
        
        # ê¸°ì‚¬ ë³¸ë¬¸ ì¶”ì¶œ
        contents = article_soup.select('div.article_txt')
        for temp in contents:
            item = str(temp.find_all(string=True))
            msg += item
            
    except Exception as e:
        print(f"ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        continue

print(f"ìˆ˜ì§‘ëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(msg)} ë¬¸ì")

# í˜•íƒœì†Œ ë¶„ì„ (ëª…ì‚¬ ì¶”ì¶œ)
okt = Okt()
nouns = okt.nouns(msg)
print(f"ì¶”ì¶œëœ ëª…ì‚¬ ê°œìˆ˜: {len(nouns)}")

# 2ê¸€ì ì´ìƒ ëª…ì‚¬ë§Œ í•„í„°ë§
result = [noun for noun in nouns if len(noun) > 1]
print(f"í•„í„°ë§ í›„ ëª…ì‚¬ ê°œìˆ˜: {len(result)}")

# ë¹ˆë„ìˆ˜ ê³„ì‚° ë° ìƒìœ„ 50ê°œ ì¶”ì¶œ
count = Counter(result)
top_50 = count.most_common(50)

print("\n=== ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ ===")
for word, freq in top_50[:10]:
    print(f"{word}: {freq}íšŒ")

# ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
taglist = pytagcloud.make_tags(top_50, maxsize=100)

# ì›Œë“œí´ë¼ìš°ë“œ ì´ë¯¸ì§€ ì €ì¥
pytagcloud.create_tag_image(taglist,
                            './wordcloud_dongailbo.png',
                            size=(1000, 600),
                            background=(0, 0, 0),  # ê²€ì€ ë°°ê²½
                            fontname="korean",
                            rectangular=False)

# matplotlibë¡œ ì›Œë“œí´ë¼ìš°ë“œ í‘œì‹œ
img = mpimg.imread('./wordcloud_dongailbo.png')
plt.figure(figsize=(12, 8))
plt.imshow(img)
plt.axis('off')  # ì¶• ìˆ¨ê¸°ê¸°
plt.title(f"'{keyword}' ê´€ë ¨ ë‰´ìŠ¤ í‚¤ì›Œë“œ ë¶„ì„", fontsize=16, pad=20)
plt.tight_layout()
plt.show()

print(f"\nâœ… ì›Œë“œí´ë¼ìš°ë“œê°€ './wordcloud_dongailbo.png'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
```

---

## ğŸ¯ **í•™ìŠµìë¥¼ ìœ„í•œ ì‹¤ìŠµ ê°€ì´ë“œ**

### ğŸ“š **ë‹¨ê³„ë³„ ì‹¤ìŠµ ìˆœì„œ**
1. **í™˜ê²½ ì„¤ì •**: í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
2. **ì½”ë“œ ì´í•´**: ê° ì„¹ì…˜ë³„ ê¸°ëŠ¥ íŒŒì•…
3. **í‚¤ì›Œë“œ ë³€ê²½**: "ë¬´ë”ìœ„" â†’ "ì¸ê³µì§€ëŠ¥", "ê¸°í›„ë³€í™”" ë“±
4. **ê²°ê³¼ ë¶„ì„**: ìƒì„±ëœ ì›Œë“œí´ë¼ìš°ë“œ í•´ì„
5. **ì‘ìš© ì‹¤ìŠµ**: ë‹¤ë¥¸ ë‰´ìŠ¤ ì‚¬ì´íŠ¸ë¡œ í™•ì¥

### ğŸ”§ **ì»¤ìŠ¤í„°ë§ˆì´ì§• ì˜ˆì œ**
```python
# ë‹¤ì–‘í•œ í‚¤ì›Œë“œë¡œ ë¹„êµ ë¶„ì„
keywords = ["ì¸ê³µì§€ëŠ¥", "ê¸°í›„ë³€í™”", "ë¶€ë™ì‚°"]
for keyword in keywords:
    # ê° í‚¤ì›Œë“œë³„ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
    create_wordcloud(keyword)
```

### ğŸ’¡ **ì‹¤ë¬´ í™•ì¥ ì•„ì´ë””ì–´**
- **ì‹œê°„ëŒ€ë³„ íŠ¸ë Œë“œ ë¶„ì„**: ì›”ë³„/ë¶„ê¸°ë³„ í‚¤ì›Œë“œ ë³€í™”
- **ì–¸ë¡ ì‚¬ë³„ ë¹„êµ**: ë™ì•„ì¼ë³´ vs ì¡°ì„ ì¼ë³´ vs ì¤‘ì•™ì¼ë³´
- **ê°ì„± ë¶„ì„ ì—°ë™**: ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ ë¶„ë¥˜
- **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: ìŠ¤ì¼€ì¤„ëŸ¬ë¡œ ìë™ ìˆ˜ì§‘

# ë™ì•„ì¼ë³´ ì›Œë“œí´ë¼ìš°ë“œ ì‹¤ìŠµ - ê°•ì˜ ê¸°ë°˜ ë³´ì™„ ê°€ì´ë“œ

## ğŸ¤ **ê°•ì˜ì—ì„œ ë°œê²¬ëœ í•µì‹¬ ì´ìŠˆë“¤**

### 1. **í•œê¸€ í°íŠ¸ ë¬¸ì œ í•´ê²° (ê°€ì¥ ì¤‘ìš”!) ğŸ”¥**

#### ğŸ’¥ **ë¬¸ì œ ìƒí™©**
```python
# ì´ ì½”ë“œëŠ” í•œê¸€ í°íŠ¸ ì˜¤ë¥˜ë¡œ ì‹¤í–‰ ì‹¤íŒ¨
pytagcloud.create_tag_image(taglist,
                            './wordcloud_dongailbo.png',
                            fontname="korean",  # âŒ ì´ ë¶€ë¶„ì´ ë¬¸ì œ!
                            rectangular=False)
```

#### âœ… **ì™„ì „í•œ í•´ê²°ì±…**

```python
# 1ë‹¨ê³„: ì‹œìŠ¤í…œ í°íŠ¸ ê²½ë¡œ ì°¾ê¸°
import os
import platform

def find_korean_fonts():
    """ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í•œê¸€ í°íŠ¸ ì°¾ê¸°"""
    
    if platform.system() == "Windows":
        font_paths = [
            'C:/Windows/Fonts/malgun.ttf',     # ë§‘ì€ ê³ ë”• (ê¶Œì¥)
            'C:/Windows/Fonts/gulim.ttc',      # êµ´ë¦¼
            'C:/Windows/Fonts/batang.ttc',     # ë°”íƒ•
            'C:/Windows/Fonts/NanumGothic.ttf' # ë‚˜ëˆ”ê³ ë”•
        ]
    else:  # macOS, Linux
        font_paths = [
            '/System/Library/Fonts/AppleGothic.ttf',
            '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
        ]
    
    for path in font_paths:
        if os.path.exists(path):
            print(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸: {path}")
            return path
    
    print("âŒ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return None

# 2ë‹¨ê³„: pytagcloud ë¼ì´ë¸ŒëŸ¬ë¦¬ í°íŠ¸ ì„¤ì •
def setup_pytagcloud_font():
    """pytagcloud ë¼ì´ë¸ŒëŸ¬ë¦¬ì— í•œê¸€ í°íŠ¸ ë“±ë¡"""
    
    import pytagcloud
    import shutil
    
    # ë§‘ì€ ê³ ë”• í°íŠ¸ ê²½ë¡œ
    source_font = 'C:/Windows/Fonts/malgun.ttf'
    
    # pytagcloud ì„¤ì¹˜ ê²½ë¡œ ì°¾ê¸°
    pytagcloud_path = pytagcloud.__path__[0]
    fonts_dir = os.path.join(pytagcloud_path, 'fonts')
    target_font = os.path.join(fonts_dir, 'korean.ttf')
    
    # í°íŠ¸ ë³µì‚¬
    if os.path.exists(source_font) and os.path.exists(fonts_dir):
        shutil.copy2(source_font, target_font)
        print(f"âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ: {target_font}")
        return True
    
    return False

# 3ë‹¨ê³„: fonts.json íŒŒì¼ ìˆ˜ì • (ê°•ì˜ì—ì„œ ì–¸ê¸‰ëœ í•µì‹¬!)
def update_fonts_json():
    """pytagcloudì˜ fonts.json íŒŒì¼ì— í•œê¸€ í°íŠ¸ ë“±ë¡"""
    
    import json
    import pytagcloud
    
    # fonts.json íŒŒì¼ ê²½ë¡œ
    fonts_json_path = os.path.join(pytagcloud.__path__[0], 'fonts', 'fonts.json')
    
    try:
        # ê¸°ì¡´ í°íŠ¸ ì„¤ì • ì½ê¸°
        with open(fonts_json_path, 'r', encoding='utf-8') as f:
            fonts_config = json.load(f)
        
        # í•œê¸€ í°íŠ¸ ì¶”ê°€
        fonts_config['korean'] = 'korean.ttf'
        
        # ì„¤ì • ì €ì¥
        with open(fonts_json_path, 'w', encoding='utf-8') as f:
            json.dump(fonts_config, f, indent=2, ensure_ascii=False)
        
        print("âœ… fonts.json ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        return True
        
    except Exception as e:
        print(f"âŒ fonts.json ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return False

# ì™„ì „í•œ ì„¤ì • í•¨ìˆ˜
def complete_korean_font_setup():
    """í•œê¸€ í°íŠ¸ ì™„ì „ ì„¤ì •"""
    print("ğŸ”§ í•œê¸€ í°íŠ¸ ì„¤ì • ì‹œì‘...")
    
    # 1. í°íŠ¸ ì°¾ê¸°
    korean_font = find_korean_fonts()
    if not korean_font:
        return False
    
    # 2. pytagcloudì— í°íŠ¸ ë³µì‚¬
    if setup_pytagcloud_font():
        # 3. fonts.json ì—…ë°ì´íŠ¸
        if update_fonts_json():
            print("ğŸ‰ í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ! ì´ì œ ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return True
    
    return False
```

### 2. **CSS ì„ íƒì ë¬¸ì œ í•´ê²°**

#### ğŸ’¥ **ë™ì•„ì¼ë³´ ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½ ëŒ€ì‘**

```python
def robust_dongailbo_scraper(keyword):
    """ê²¬ê³ í•œ ë™ì•„ì¼ë³´ ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜"""
    
    from urllib.parse import quote
    import time
    import random
    
    # URL ìƒì„±
    target_url = "https://www.donga.com/news/search?query=" + quote(keyword)
    
    # í—¤ë” ì„¤ì • (ë´‡ ì°¨ë‹¨ ë°©ì§€)
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        # ì›¹ í˜ì´ì§€ ìš”ì²­
        response = requests.get(target_url, headers=headers)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'lxml')
        
        # ë‹¤ì–‘í•œ ì„ íƒì ì‹œë„ (ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½ ëŒ€ì‘)
        title_selectors = [
            'h4.tit',           # ê¸°ë³¸ ì„ íƒì
            'h3.tit',           # ëŒ€ì•ˆ 1
            '.article-title',   # ëŒ€ì•ˆ 2
            '.news-title'       # ëŒ€ì•ˆ 3
        ]
        
        titles = []
        for selector in title_selectors:
            titles = soup.select(selector)
            if titles:
                print(f"âœ… ì„±ê³µí•œ ì„ íƒì: {selector}")
                break
        
        if not titles:
            print("âŒ ê¸°ì‚¬ ì œëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´íŠ¸ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return ""
        
        # ê¸°ì‚¬ ë³¸ë¬¸ ìˆ˜ì§‘
        all_text = ""
        
        for i, title in enumerate(titles[:5]):  # ìµœëŒ€ 5ê°œ ê¸°ì‚¬ë§Œ
            try:
                # ë§í¬ ì¶”ì¶œ
                link = title.find('a')
                if not link or not link.get('href'):
                    continue
                
                article_url = link['href']
                if not article_url.startswith('http'):
                    article_url = 'https://www.donga.com' + article_url
                
                print(f"ğŸ“– ê¸°ì‚¬ {i+1} ì²˜ë¦¬ ì¤‘: {article_url}")
                
                # ê¸°ì‚¬ í˜ì´ì§€ ìš”ì²­
                time.sleep(random.uniform(1, 2))  # ëœë¤ ì§€ì—°
                article_response = requests.get(article_url, headers=headers)
                article_soup = BeautifulSoup(article_response.text, 'lxml')
                
                # ë³¸ë¬¸ ì¶”ì¶œ (ì—¬ëŸ¬ ì„ íƒì ì‹œë„)
                content_selectors = [
                    'div.article_txt',
                    'div.article-body',
                    'div.news-content',
                    '.article-content'
                ]
                
                for selector in content_selectors:
                    content = article_soup.select_one(selector)
                    if content:
                        text = content.get_text(strip=True)
                        all_text += " " + text
                        break
                
            except Exception as e:
                print(f"âš ï¸ ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        return all_text
        
    except Exception as e:
        print(f"âŒ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")
        return ""
```

### 3. **ì™„ì „í•œ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì½”ë“œ**

```python
def create_dongailbo_wordcloud(keyword="ë¬´ë”ìœ„"):
    """ë™ì•„ì¼ë³´ ë‰´ìŠ¤ë¡œ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± (ëª¨ë“  ë¬¸ì œ í•´ê²° ë²„ì „)"""
    
    print(f"ğŸ” '{keyword}' í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘...")
    
    # 1. í•œê¸€ í°íŠ¸ ì„¤ì •
    if not complete_korean_font_setup():
        print("âŒ í•œê¸€ í°íŠ¸ ì„¤ì • ì‹¤íŒ¨. ì˜ë¬¸ìœ¼ë¡œë§Œ í‘œì‹œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # 2. ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
    text_data = robust_dongailbo_scraper(keyword)
    
    if not text_data:
        print("âŒ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… ìˆ˜ì§‘ëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text_data)} ë¬¸ì")
    
    # 3. í˜•íƒœì†Œ ë¶„ì„
    from konlpy.tag import Okt
    from collections import Counter
    
    okt = Okt()
    nouns = okt.nouns(text_data)
    
    # 2ê¸€ì ì´ìƒ ëª…ì‚¬ë§Œ í•„í„°ë§
    filtered_nouns = [noun for noun in nouns if len(noun) >= 2]
    
    # ë¶ˆìš©ì–´ ì œê±° (ì„ íƒì‚¬í•­)
    stopwords = ['ê¸°ì', 'ë‰´ìŠ¤', 'ê¸°ì‚¬', 'ì˜¤ëŠ˜', 'ì–´ì œ', 'ë‚´ì¼', 'ì˜¬í•´', 'ì‘ë…„']
    filtered_nouns = [noun for noun in filtered_nouns if noun not in stopwords]
    
    # ë¹ˆë„ ê³„ì‚°
    counter = Counter(filtered_nouns)
    top_50 = counter.most_common(50)
    
    print(f"âœ… ì¶”ì¶œëœ ëª…ì‚¬ ê°œìˆ˜: {len(filtered_nouns)}")
    print("ğŸ” ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ:")
    for word, freq in top_50[:10]:
        print(f"   {word}: {freq}íšŒ")
    
    # 4. ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
    try:
        import pytagcloud
        import matplotlib.pyplot as plt
        import matplotlib.image as mpimg
        
        # íƒœê·¸ ìƒì„±
        taglist = pytagcloud.make_tags(top_50, maxsize=100)
        
        # ì´ë¯¸ì§€ ìƒì„±
        output_path = f'./wordcloud_{keyword}.png'
        pytagcloud.create_tag_image(taglist,
                                    output_path,
                                    size=(1000, 600),
                                    background=(0, 0, 0),  # ê²€ì€ ë°°ê²½
                                    fontname="korean",     # ì„¤ì •í•œ í•œê¸€ í°íŠ¸
                                    rectangular=False)
        
        # matplotlibë¡œ í‘œì‹œ
        img = mpimg.imread(output_path)
        plt.figure(figsize=(12, 8))
        plt.imshow(img)
        plt.axis('off')
        plt.title(f"'{keyword}' ê´€ë ¨ ë‰´ìŠ¤ í‚¤ì›Œë“œ ë¶„ì„", fontsize=16, pad=20)
        plt.tight_layout()
        plt.show()
        
        print(f"ğŸ‰ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì™„ë£Œ: {output_path}")
        
    except Exception as e:
        print(f"âŒ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì‹¤íŒ¨: {e}")
        
        # ëŒ€ì•ˆ: matplotlibì„ ì´ìš©í•œ ê°„ë‹¨í•œ ì‹œê°í™”
        import matplotlib.pyplot as plt
        
        words = [item[0] for item in top_50[:20]]
        counts = [item[1] for item in top_50[:20]]
        
        plt.figure(figsize=(12, 8))
        plt.barh(words, counts)
        plt.title(f"'{keyword}' ê´€ë ¨ ë‰´ìŠ¤ í‚¤ì›Œë“œ ë¹ˆë„", fontsize=16)
        plt.xlabel("ë¹ˆë„")
        plt.gca().invert_yaxis()
        plt.tight_layout()
        plt.show()

# ì‹¤í–‰
if __name__ == "__main__":
    create_dongailbo_wordcloud("ë¬´ë”ìœ„")
```

---

## ğŸ¯ **ê°•ì˜ì—ì„œ ì–¸ê¸‰ëœ í•µì‹¬ í¬ì¸íŠ¸ë“¤**

### 1. **Java í™˜ê²½ ë¬¸ì œ**
- **ë¬¸ì œ**: "JVMì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" ì—ëŸ¬
- **í•´ê²°**: BellSoft JDK 21 ì„¤ì¹˜ í›„ ì‹œìŠ¤í…œ ì¬ë¶€íŒ…

### 2. **íŒŒì„œ ì´ë¦„ ì˜¤íƒ€**
- **ì˜ëª»**: `'lxml.parser'`
- **ì˜¬ë°”ë¦„**: `'lxml'`

### 3. **URL ì¸ì½”ë”© í•„ìˆ˜**
- **ì˜ëª»**: `target_url + keyword`
- **ì˜¬ë°”ë¦„**: `target_url + quote(keyword)`

### 4. **í°íŠ¸ ì„¤ì •ì˜ ë³µì¡ì„±**
- pytagcloud ë¼ì´ë¸ŒëŸ¬ë¦¬ í´ë”ì— ì§ì ‘ í°íŠ¸ íŒŒì¼ ë³µì‚¬
- fonts.json íŒŒì¼ ìˆ˜ì • í•„ìš”
- ì‹œìŠ¤í…œ ì¬ë¶€íŒ… í›„ ì ìš©

### 5. **ì›¹ ìŠ¤í¬ë˜í•‘ ì˜ˆì˜**
- ìµœì†Œ 0.5ì´ˆ ì´ìƒ ì§€ì—° ì‹œê°„
- User-Agent í—¤ë” ì„¤ì •
- ë„ˆë¬´ ë§ì€ ìš”ì²­ ê¸ˆì§€

---

## ğŸ’¡ **ì¶”ê°€ ì‹¤ìŠµ ì•„ì´ë””ì–´**

### 1. **í‚¤ì›Œë“œ ë¹„êµ ë¶„ì„**
```python
keywords = ["ë¬´ë”ìœ„", "íƒœí’", "í­ì—¼"]
for keyword in keywords:
    create_dongailbo_wordcloud(keyword)
```

### 2. **ì‹œê°„ëŒ€ë³„ ë¶„ì„**
```python
# ìµœê·¼ 1ì£¼ì¼ ë‰´ìŠ¤ë§Œ ë¶„ì„
def analyze_recent_news(keyword, days=7):
    # ë‚ ì§œ í•„í„°ë§ ë¡œì§ ì¶”ê°€
    pass
```

### 3. **ì—¬ëŸ¬ ì–¸ë¡ ì‚¬ ë¹„êµ**
```python
news_sites = {
    "ë™ì•„ì¼ë³´": "https://www.donga.com/news/search?query=",
    "ì¡°ì„ ì¼ë³´": "https://www.chosun.com/search/",
    "ì¤‘ì•™ì¼ë³´": "https://www.joongang.co.kr/search/"
}
```
