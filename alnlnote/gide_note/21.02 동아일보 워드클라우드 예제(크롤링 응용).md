# 동아일보 워드클라우드 예제:

## 🔍 **주요 개선사항 요약**

| 구분 | 20.01 (기존) | 20.21 (개선) | 개선 효과 |
|------|-------------|-------------|-----------|
| **키워드 입력** | `input()` 동적 입력 | `"무더위"` 고정값 | 🎯 실습 안정성 |
| **URL 인코딩** | 누락 → 에러 발생 | `quote()` 적용 | ✅ 한글 처리 완벽 |
| **파서 설정** | `'lxml.parser'` (오타) | `'lxml'` | ✅ 정확한 파서명 |
| **본문 추출** | 복잡한 문자열 처리 | `find_all(string=True)` | 🚀 코드 간소화 |
| **형태소 분석** | 없음 | **Okt + Counter** | ⭐ **핵심 기능 추가** |
| **시각화** | 없음 | **pytagcloud + matplotlib** | 🎨 **완전한 워크플로우** |

---

## 📊 **상세 코드 비교**

### 1. **URL 인코딩 처리**

#### ❌ 20.01 (문제 코드)
```python
# 한글 키워드가 URL에 제대로 전달되지 않음
target_url = 'https://www.donga.com/news/search?query=' + keyword
```

#### ✅ 20.21 (개선 코드)
```python
from urllib.parse import quote
target_url = "https://www.donga.com/news/search?query=" + quote(keyword)
# "무더위" → "%EB%AC%B4%EB%8D%94%EC%9C%84"
```

### 2. **파서 이름 수정**

#### ❌ 20.01 (오타)
```python
soup = BeautifulSoup(source_article, 'lxml.parser', from_encoding='utf-8')
```

#### ✅ 20.21 (정확)
```python
soup = BeautifulSoup(source_article, 'lxml', from_encoding='utf-8')
```

### 3. **본문 텍스트 추출 로직**

#### ❌ 20.01 (복잡하고 에러 유발)
```python
content = soup.select_one('div.article_txt').get_text()
for imsi in content:  # 문자 하나씩 순회 → 비효율
    item = str(imsi.find_all(text=True))  # 문자열에 find_all() 불가
    mag += item
```

#### ✅ 20.21 (깔끔하고 안정적)
```python
contents = soup.select('div.article_txt')  # 여러 요소 처리
for temp in contents:
    item = str(temp.find_all(string=True))  # string=True로 텍스트만 추출
    msg += item
```

### 4. **형태소 분석 추가 (20.21의 핵심 개선)**

```python
from konlpy.tag import Okt
from collections import Counter

# 형태소 분석기 초기화
okt = Okt()
nouns = okt.nouns(msg)            # 명사만 추출

# 2글자 이상 명사 필터링
result = []
for temp in nouns:
    if len(temp) > 1:
        result.append(temp)

# 빈도수 계산 및 상위 50개 추출
count = Counter(result)
tag = count.most_common(50)
```

### 5. **완성형 워드클라우드 생성**

```python
import pytagcloud
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# 워드클라우드 태그 생성
taglist = pytagcloud.make_tags(tag, maxsize=100)

# 이미지 파일 생성
pytagcloud.create_tag_image(taglist,
                            './01_big_data_machine_learning/data/wordcloud.png',
                            size=(1000, 600),
                            background=(0,0,0),
                            fontname="korean",
                            rectangular=False)

# matplotlib로 시각화
img = mpimg.imread('./01_big_data_machine_learning/data/wordcloud.png')
plt.imshow(img)
plt.show()
```

---

## 🚀 **20.21 예제의 학습 가치**

### ⭐ **완전한 NLP 파이프라인 구현**
1. **웹 스크래핑** → 뉴스 데이터 수집
2. **텍스트 전처리** → 본문 추출 및 정제
3. **형태소 분석** → 명사 추출 (KoNLPy Okt)
4. **통계 분석** → 단어 빈도 계산 (Counter)
5. **시각화** → 워드클라우드 생성 (pytagcloud)

### 🎯 **실무 활용도**
- **뉴스 키워드 트렌드 분석**
- **브랜드 언급량 모니터링**  
- **고객 리뷰 핵심 키워드 추출**
- **소셜미디어 토픽 분석**

### 🛠️ **기술 스택 완성도**
```python
tech_stack = {
    "웹크롤링": ["BeautifulSoup", "urllib", "requests"],
    "자연어처리": ["KoNLPy", "Okt", "형태소분석"],
    "데이터분석": ["Collections.Counter", "빈도분석"],
    "시각화": ["pytagcloud", "matplotlib", "워드클라우드"]
}
```

---

## 📝 **실습용 완전 코드 (20.21 기반)**

```python
# 필수 라이브러리 설치
# pip install beautifulsoup4 konlpy pytagcloud matplotlib

# 동아일보 검색 기능으로 문자열을 읽어 형태소 분석 후 워드클라우드로 출력
from bs4 import BeautifulSoup
import urllib.request
from urllib.parse import quote
from konlpy.tag import Okt
from collections import Counter
import pytagcloud
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# 검색 키워드 설정
keyword = "무더위"
print(f"검색어: {keyword}")
print(f"URL 인코딩: {quote(keyword)}")

# 동아일보 검색 URL 생성
target_url = "https://www.donga.com/news/search?query=" + quote(keyword)
print(f"Target URL: {target_url}")

# 검색 결과 페이지 파싱
source_code = urllib.request.urlopen(target_url)
soup = BeautifulSoup(source_code, 'lxml', from_encoding='utf-8')

# 모든 기사 본문 수집
msg = ""
for title in soup.find_all('h4', class_='tit'):
    title_link = title.select('a')
    if not title_link:  # 링크가 없는 경우 스킵
        continue
        
    article_url = title_link[0]['href']
    print(f"기사 URL: {article_url}")
    
    try:
        # 개별 기사 페이지 접근
        source_article = urllib.request.urlopen(article_url)
        article_soup = BeautifulSoup(source_article, 'lxml', from_encoding='utf-8')
        
        # 기사 본문 추출
        contents = article_soup.select('div.article_txt')
        for temp in contents:
            item = str(temp.find_all(string=True))
            msg += item
            
    except Exception as e:
        print(f"기사 처리 중 오류: {e}")
        continue

print(f"수집된 텍스트 길이: {len(msg)} 문자")

# 형태소 분석 (명사 추출)
okt = Okt()
nouns = okt.nouns(msg)
print(f"추출된 명사 개수: {len(nouns)}")

# 2글자 이상 명사만 필터링
result = [noun for noun in nouns if len(noun) > 1]
print(f"필터링 후 명사 개수: {len(result)}")

# 빈도수 계산 및 상위 50개 추출
count = Counter(result)
top_50 = count.most_common(50)

print("\n=== 상위 10개 키워드 ===")
for word, freq in top_50[:10]:
    print(f"{word}: {freq}회")

# 워드클라우드 생성
taglist = pytagcloud.make_tags(top_50, maxsize=100)

# 워드클라우드 이미지 저장
pytagcloud.create_tag_image(taglist,
                            './wordcloud_dongailbo.png',
                            size=(1000, 600),
                            background=(0, 0, 0),  # 검은 배경
                            fontname="korean",
                            rectangular=False)

# matplotlib로 워드클라우드 표시
img = mpimg.imread('./wordcloud_dongailbo.png')
plt.figure(figsize=(12, 8))
plt.imshow(img)
plt.axis('off')  # 축 숨기기
plt.title(f"'{keyword}' 관련 뉴스 키워드 분석", fontsize=16, pad=20)
plt.tight_layout()
plt.show()

print(f"\n✅ 워드클라우드가 './wordcloud_dongailbo.png'에 저장되었습니다!")
```

---

## 🎯 **학습자를 위한 실습 가이드**

### 📚 **단계별 실습 순서**
1. **환경 설정**: 필수 라이브러리 설치
2. **코드 이해**: 각 섹션별 기능 파악
3. **키워드 변경**: "무더위" → "인공지능", "기후변화" 등
4. **결과 분석**: 생성된 워드클라우드 해석
5. **응용 실습**: 다른 뉴스 사이트로 확장

### 🔧 **커스터마이징 예제**
```python
# 다양한 키워드로 비교 분석
keywords = ["인공지능", "기후변화", "부동산"]
for keyword in keywords:
    # 각 키워드별 워드클라우드 생성
    create_wordcloud(keyword)
```

### 💡 **실무 확장 아이디어**
- **시간대별 트렌드 분석**: 월별/분기별 키워드 변화
- **언론사별 비교**: 동아일보 vs 조선일보 vs 중앙일보
- **감성 분석 연동**: 긍정/부정 키워드 분류
- **실시간 모니터링**: 스케줄러로 자동 수집

# 동아일보 워드클라우드 실습 - 강의 기반 보완 가이드

## 🎤 **강의에서 발견된 핵심 이슈들**

### 1. **한글 폰트 문제 해결 (가장 중요!) 🔥**

#### 💥 **문제 상황**
```python
# 이 코드는 한글 폰트 오류로 실행 실패
pytagcloud.create_tag_image(taglist,
                            './wordcloud_dongailbo.png',
                            fontname="korean",  # ❌ 이 부분이 문제!
                            rectangular=False)
```

#### ✅ **완전한 해결책**

```python
# 1단계: 시스템 폰트 경로 찾기
import os
import platform

def find_korean_fonts():
    """시스템에서 사용 가능한 한글 폰트 찾기"""
    
    if platform.system() == "Windows":
        font_paths = [
            'C:/Windows/Fonts/malgun.ttf',     # 맑은 고딕 (권장)
            'C:/Windows/Fonts/gulim.ttc',      # 굴림
            'C:/Windows/Fonts/batang.ttc',     # 바탕
            'C:/Windows/Fonts/NanumGothic.ttf' # 나눔고딕
        ]
    else:  # macOS, Linux
        font_paths = [
            '/System/Library/Fonts/AppleGothic.ttf',
            '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
        ]
    
    for path in font_paths:
        if os.path.exists(path):
            print(f"✅ 사용 가능한 폰트: {path}")
            return path
    
    print("❌ 한글 폰트를 찾을 수 없습니다.")
    return None

# 2단계: pytagcloud 라이브러리 폰트 설정
def setup_pytagcloud_font():
    """pytagcloud 라이브러리에 한글 폰트 등록"""
    
    import pytagcloud
    import shutil
    
    # 맑은 고딕 폰트 경로
    source_font = 'C:/Windows/Fonts/malgun.ttf'
    
    # pytagcloud 설치 경로 찾기
    pytagcloud_path = pytagcloud.__path__[0]
    fonts_dir = os.path.join(pytagcloud_path, 'fonts')
    target_font = os.path.join(fonts_dir, 'korean.ttf')
    
    # 폰트 복사
    if os.path.exists(source_font) and os.path.exists(fonts_dir):
        shutil.copy2(source_font, target_font)
        print(f"✅ 한글 폰트 설정 완료: {target_font}")
        return True
    
    return False

# 3단계: fonts.json 파일 수정 (강의에서 언급된 핵심!)
def update_fonts_json():
    """pytagcloud의 fonts.json 파일에 한글 폰트 등록"""
    
    import json
    import pytagcloud
    
    # fonts.json 파일 경로
    fonts_json_path = os.path.join(pytagcloud.__path__[0], 'fonts', 'fonts.json')
    
    try:
        # 기존 폰트 설정 읽기
        with open(fonts_json_path, 'r', encoding='utf-8') as f:
            fonts_config = json.load(f)
        
        # 한글 폰트 추가
        fonts_config['korean'] = 'korean.ttf'
        
        # 설정 저장
        with open(fonts_json_path, 'w', encoding='utf-8') as f:
            json.dump(fonts_config, f, indent=2, ensure_ascii=False)
        
        print("✅ fonts.json 업데이트 완료")
        return True
        
    except Exception as e:
        print(f"❌ fonts.json 업데이트 실패: {e}")
        return False

# 완전한 설정 함수
def complete_korean_font_setup():
    """한글 폰트 완전 설정"""
    print("🔧 한글 폰트 설정 시작...")
    
    # 1. 폰트 찾기
    korean_font = find_korean_fonts()
    if not korean_font:
        return False
    
    # 2. pytagcloud에 폰트 복사
    if setup_pytagcloud_font():
        # 3. fonts.json 업데이트
        if update_fonts_json():
            print("🎉 한글 폰트 설정 완료! 이제 워드클라우드를 생성할 수 있습니다.")
            return True
    
    return False
```

### 2. **CSS 선택자 문제 해결**

#### 💥 **동아일보 사이트 구조 변경 대응**

```python
def robust_dongailbo_scraper(keyword):
    """견고한 동아일보 스크래핑 함수"""
    
    from urllib.parse import quote
    import time
    import random
    
    # URL 생성
    target_url = "https://www.donga.com/news/search?query=" + quote(keyword)
    
    # 헤더 설정 (봇 차단 방지)
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        # 웹 페이지 요청
        response = requests.get(target_url, headers=headers)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'lxml')
        
        # 다양한 선택자 시도 (사이트 구조 변경 대응)
        title_selectors = [
            'h4.tit',           # 기본 선택자
            'h3.tit',           # 대안 1
            '.article-title',   # 대안 2
            '.news-title'       # 대안 3
        ]
        
        titles = []
        for selector in title_selectors:
            titles = soup.select(selector)
            if titles:
                print(f"✅ 성공한 선택자: {selector}")
                break
        
        if not titles:
            print("❌ 기사 제목을 찾을 수 없습니다. 사이트 구조가 변경되었을 수 있습니다.")
            return ""
        
        # 기사 본문 수집
        all_text = ""
        
        for i, title in enumerate(titles[:5]):  # 최대 5개 기사만
            try:
                # 링크 추출
                link = title.find('a')
                if not link or not link.get('href'):
                    continue
                
                article_url = link['href']
                if not article_url.startswith('http'):
                    article_url = 'https://www.donga.com' + article_url
                
                print(f"📖 기사 {i+1} 처리 중: {article_url}")
                
                # 기사 페이지 요청
                time.sleep(random.uniform(1, 2))  # 랜덤 지연
                article_response = requests.get(article_url, headers=headers)
                article_soup = BeautifulSoup(article_response.text, 'lxml')
                
                # 본문 추출 (여러 선택자 시도)
                content_selectors = [
                    'div.article_txt',
                    'div.article-body',
                    'div.news-content',
                    '.article-content'
                ]
                
                for selector in content_selectors:
                    content = article_soup.select_one(selector)
                    if content:
                        text = content.get_text(strip=True)
                        all_text += " " + text
                        break
                
            except Exception as e:
                print(f"⚠️ 기사 처리 중 오류: {e}")
                continue
        
        return all_text
        
    except Exception as e:
        print(f"❌ 스크래핑 오류: {e}")
        return ""
```

### 3. **완전한 워드클라우드 생성 코드**

```python
def create_dongailbo_wordcloud(keyword="무더위"):
    """동아일보 뉴스로 워드클라우드 생성 (모든 문제 해결 버전)"""
    
    print(f"🔍 '{keyword}' 키워드로 뉴스 분석 시작...")
    
    # 1. 한글 폰트 설정
    if not complete_korean_font_setup():
        print("❌ 한글 폰트 설정 실패. 영문으로만 표시될 수 있습니다.")
    
    # 2. 뉴스 데이터 수집
    text_data = robust_dongailbo_scraper(keyword)
    
    if not text_data:
        print("❌ 텍스트 데이터를 수집할 수 없습니다.")
        return
    
    print(f"✅ 수집된 텍스트 길이: {len(text_data)} 문자")
    
    # 3. 형태소 분석
    from konlpy.tag import Okt
    from collections import Counter
    
    okt = Okt()
    nouns = okt.nouns(text_data)
    
    # 2글자 이상 명사만 필터링
    filtered_nouns = [noun for noun in nouns if len(noun) >= 2]
    
    # 불용어 제거 (선택사항)
    stopwords = ['기자', '뉴스', '기사', '오늘', '어제', '내일', '올해', '작년']
    filtered_nouns = [noun for noun in filtered_nouns if noun not in stopwords]
    
    # 빈도 계산
    counter = Counter(filtered_nouns)
    top_50 = counter.most_common(50)
    
    print(f"✅ 추출된 명사 개수: {len(filtered_nouns)}")
    print("🔝 상위 10개 키워드:")
    for word, freq in top_50[:10]:
        print(f"   {word}: {freq}회")
    
    # 4. 워드클라우드 생성
    try:
        import pytagcloud
        import matplotlib.pyplot as plt
        import matplotlib.image as mpimg
        
        # 태그 생성
        taglist = pytagcloud.make_tags(top_50, maxsize=100)
        
        # 이미지 생성
        output_path = f'./wordcloud_{keyword}.png'
        pytagcloud.create_tag_image(taglist,
                                    output_path,
                                    size=(1000, 600),
                                    background=(0, 0, 0),  # 검은 배경
                                    fontname="korean",     # 설정한 한글 폰트
                                    rectangular=False)
        
        # matplotlib로 표시
        img = mpimg.imread(output_path)
        plt.figure(figsize=(12, 8))
        plt.imshow(img)
        plt.axis('off')
        plt.title(f"'{keyword}' 관련 뉴스 키워드 분석", fontsize=16, pad=20)
        plt.tight_layout()
        plt.show()
        
        print(f"🎉 워드클라우드 생성 완료: {output_path}")
        
    except Exception as e:
        print(f"❌ 워드클라우드 생성 실패: {e}")
        
        # 대안: matplotlib을 이용한 간단한 시각화
        import matplotlib.pyplot as plt
        
        words = [item[0] for item in top_50[:20]]
        counts = [item[1] for item in top_50[:20]]
        
        plt.figure(figsize=(12, 8))
        plt.barh(words, counts)
        plt.title(f"'{keyword}' 관련 뉴스 키워드 빈도", fontsize=16)
        plt.xlabel("빈도")
        plt.gca().invert_yaxis()
        plt.tight_layout()
        plt.show()

# 실행
if __name__ == "__main__":
    create_dongailbo_wordcloud("무더위")
```

---

## 🎯 **강의에서 언급된 핵심 포인트들**

### 1. **Java 환경 문제**
- **문제**: "JVM을 찾을 수 없습니다" 에러
- **해결**: BellSoft JDK 21 설치 후 시스템 재부팅

### 2. **파서 이름 오타**
- **잘못**: `'lxml.parser'`
- **올바름**: `'lxml'`

### 3. **URL 인코딩 필수**
- **잘못**: `target_url + keyword`
- **올바름**: `target_url + quote(keyword)`

### 4. **폰트 설정의 복잡성**
- pytagcloud 라이브러리 폴더에 직접 폰트 파일 복사
- fonts.json 파일 수정 필요
- 시스템 재부팅 후 적용

### 5. **웹 스크래핑 예의**
- 최소 0.5초 이상 지연 시간
- User-Agent 헤더 설정
- 너무 많은 요청 금지

---

## 💡 **추가 실습 아이디어**

### 1. **키워드 비교 분석**
```python
keywords = ["무더위", "태풍", "폭염"]
for keyword in keywords:
    create_dongailbo_wordcloud(keyword)
```

### 2. **시간대별 분석**
```python
# 최근 1주일 뉴스만 분석
def analyze_recent_news(keyword, days=7):
    # 날짜 필터링 로직 추가
    pass
```

### 3. **여러 언론사 비교**
```python
news_sites = {
    "동아일보": "https://www.donga.com/news/search?query=",
    "조선일보": "https://www.chosun.com/search/",
    "중앙일보": "https://www.joongang.co.kr/search/"
}
```
