# 14. 판다스 파일 저장 및 읽기 세부 기능 정리

## 📋 개요

판다스(Pandas)는 다양한 파일 형식의 데이터를 읽고 저장할 수 있는 강력한 I/O 기능을 제공합니다. 이 가이드는 실무에서 자주 사용되는 파일 입출력 기능들을 체계적으로 정리하고, 실제 코드 예제와 함께 설명합니다.

## 🔧 주요 파일 형식 지원

| 형식 | 읽기 함수 | 저장 메서드 | 특징 |
|------|----------|-------------|------|
| CSV | `pd.read_csv()` | `df.to_csv()` | 범용적, 경량 |
| Excel | `pd.read_excel()` | `df.to_excel()` | 다중 시트 지원 |
| JSON | `pd.read_json()` | `df.to_json()` | 웹 API 호환 |
| HTML | `pd.read_html()` | `df.to_html()` | 웹 스크래핑 |
| 텍스트 | `pd.read_table()` | - | 구분자 지정 |
| FWF | `pd.read_fwf()` | - | 고정 폭 파일 |

---

## 📂 CSV 파일 처리

### 기본 CSV 읽기 및 저장

```python
import pandas as pd
import numpy as np

# 기본 CSV 파일 읽기
df = pd.read_csv('data.csv')
print(df.head())

# 구분자 지정하여 읽기
df = pd.read_csv('data.csv', sep=',')  # 기본값
df = pd.read_csv('data.txt', sep='\s+')  # 공백으로 구분

# 기본 CSV 저장
df.to_csv('output.csv', index=False)  # 인덱스 제외하고 저장
```

### 고급 CSV 옵션

```python
# 헤더 처리
df = pd.read_csv('data.csv', header=None)  # 첫 줄을 헤더로 사용하지 않음
df = pd.read_csv('data.csv', names=['A', 'B', 'C'])  # 사용자 정의 컬럼명

# 특정 행 건너뛰기
df = pd.read_csv('data.csv', skiprows=1)  # 첫 번째 행 건너뛰기
df = pd.read_csv('data.csv', skiprows=[0, 2])  # 0번째, 2번째 행 건너뛰기

# 인코딩 처리
df = pd.read_csv('korean_data.csv', encoding='utf-8-sig')  # 한글 파일
df = pd.read_csv('data.csv', encoding='cp949')  # 윈도우 한글

# 결측값 처리
df = pd.read_csv('data.csv', na_values=['N/A', 'NULL', '-'])

# 데이터 타입 지정
dtype_dict = {'id': str, 'score': int}
df = pd.read_csv('data.csv', dtype=dtype_dict)
```

### 정규표현식을 이용한 구분자 처리

```python
# 공백으로 구분된 파일 읽기 (정규표현식 사용)
df = pd.read_table('data.txt', sep=r'\s+')

# 여러 종류의 구분자 처리
df = pd.read_csv('data.csv', sep=r'[,;|\t]', engine='python')
```

**💡 정규표현식 패턴**
- `\s+`: 하나 이상의 공백 문자
- `[,;|\t]`: 쉼표, 세미콜론, 파이프, 탭 중 하나
- 복잡한 패턴 처리 시 `engine='python'` 필요

### 대용량 파일 처리 (청크 단위)

```python
# 청크 단위로 파일 읽기
chunk_size = 10000
chunks = []

for chunk in pd.read_csv('big_data.csv', chunksize=chunk_size):
    # 각 청크에 대한 처리
    processed_chunk = chunk[chunk['score'] > 80]
    chunks.append(processed_chunk)

# 모든 청크 결합
result = pd.concat(chunks, ignore_index=True)
```

---

## 📊 Excel 파일 처리

### 기본 Excel 읽기 및 저장

```python
# Excel 파일 읽기
df = pd.read_excel('data.xlsx')  # 첫 번째 시트
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')  # 특정 시트

# Excel 파일 저장
df.to_excel('output.xlsx', index=False)
```

### 다중 시트 처리

```python
# 여러 시트 동시 읽기
excel_dict = pd.read_excel('data.xlsx', sheet_name=None)  # 모든 시트
print(excel_dict.keys())  # 시트 이름들

# 특정 시트들만 읽기
sheets_dict = pd.read_excel('data.xlsx', sheet_name=['Sheet1', 'Sheet2'])

# 여러 시트로 저장
with pd.ExcelWriter('multi_sheet.xlsx') as writer:
    df1.to_excel(writer, sheet_name='데이터1', index=False)
    df2.to_excel(writer, sheet_name='데이터2', index=False)
```

### Excel 고급 옵션

```python
# 특정 범위 읽기
df = pd.read_excel('data.xlsx', 
                  usecols='A:C',  # A부터 C열만
                  nrows=100)      # 100행만

# 헤더 행 지정
df = pd.read_excel('data.xlsx', header=[0, 1])  # 다중 헤더
```

---

## 🌐 JSON 파일 처리

### JSON 기본 처리

```python
# JSON 파일로 저장
df.to_json('data.json')
df.to_json('data.json', orient='records')  # 레코드 형태
df.to_json('data.json', orient='index')    # 인덱스 기반

# JSON 파일 읽기
df = pd.read_json('data.json')
```

### JSON 형태별 저장 방식

```python
# 샘플 데이터
data = {'name': ['Alice', 'Bob'], 'age': [25, 30]}
df = pd.DataFrame(data)

# 1. 기본 형태 (컬럼 기반)
df.to_json('basic.json')  
# {"name":{"0":"Alice","1":"Bob"},"age":{"0":25,"1":30}}

# 2. 레코드 형태 (웹 API에 적합)
df.to_json('records.json', orient='records')
# [{"name":"Alice","age":25},{"name":"Bob","age":30}]

# 3. 값만 저장
df.to_json('values.json', orient='values')
# [["Alice",25],["Bob",30]]
```

---

## 🌍 HTML 테이블 처리

### HTML 테이블 읽기 및 저장

```python
# 웹페이지에서 테이블 읽기
tables = pd.read_html('https://example.com/table')
df = tables[0]  # 첫 번째 테이블

# HTML 파일로 저장
df.to_html('table.html', index=False)

# 스타일링을 포함한 HTML 저장
df.to_html('styled_table.html', 
          index=False,
          table_id='data-table',
          classes='table table-striped')
```

---

## 🔧 고급 파일 처리 기법

### 1. 인코딩 문제 해결

```python
# 한글 파일 처리 시 권장 설정
encodings_to_try = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr']

def read_csv_safe(filepath):
    for encoding in encodings_to_try:
        try:
            df = pd.read_csv(filepath, encoding=encoding)
            print(f"성공: {encoding}")
            return df
        except UnicodeDecodeError:
            print(f"실패: {encoding}")
            continue
    return None
```

### 2. 파일 존재 여부 확인

```python
import os

def safe_read_csv(filepath):
    if os.path.exists(filepath):
        return pd.read_csv(filepath)
    else:
        print(f"파일을 찾을 수 없습니다: {filepath}")
        return None

# 사용 예시
df = safe_read_csv('data.csv')
if df is not None:
    print(df.head())
```

### 3. 메모리 최적화 데이터 타입

```python
# 메모리 효율적인 데이터 타입 지정
efficient_dtypes = {
    'id': 'int32',      # int64 → int32
    'category': 'category',  # object → category
    'score': 'float32'  # float64 → float32
}

df = pd.read_csv('data.csv', dtype=efficient_dtypes)
print(f"메모리 사용량: {df.memory_usage(deep=True).sum()} bytes")
```

### 4. 배치 파일 처리

```python
import glob

# 여러 CSV 파일을 하나로 합치기
csv_files = glob.glob("data_*.csv")
dataframes = []

for file in csv_files:
    df_temp = pd.read_csv(file)
    df_temp['source_file'] = file  # 출처 파일명 추가
    dataframes.append(df_temp)

# 모든 파일 결합
combined_df = pd.concat(dataframes, ignore_index=True)
combined_df.to_csv('combined_data.csv', index=False)
```

---

## 🎯 성능 비교 및 선택 가이드

### 파일 형식별 성능 특성

| 형식 | 읽기 속도 | 파일 크기 | 호환성 | 사용 사례 |
|------|-----------|-----------|--------|-----------|
| CSV | 빠름 | 보통 | 높음 | 범용 데이터 교환 |
| Excel | 보통 | 큼 | 보통 | 비즈니스 문서 |
| JSON | 보통 | 큼 | 높음 | 웹 API, 설정 파일 |
| Parquet | 매우 빠름 | 작음 | 낮음 | 빅데이터 분석 |

### 상황별 권장 형식

```python
# 상황별 권장 파일 형식

# 1. 범용 데이터 교환 → CSV
df.to_csv('data.csv', index=False)

# 2. 비즈니스 보고서 → Excel
df.to_excel('report.xlsx', index=False)

# 3. 웹 API 데이터 → JSON
df.to_json('api_data.json', orient='records')

# 4. 대용량 분석 데이터 → Parquet (별도 라이브러리 필요)
# df.to_parquet('big_data.parquet')

# 5. 웹 표시용 → HTML
df.to_html('table.html', index=False, table_id='data-table')
```

---

## 🚨 자주 발생하는 문제와 해결책

### 1. 인코딩 문제
```python
# 문제: UnicodeDecodeError
# 해결: 적절한 인코딩 지정
df = pd.read_csv('korean_data.csv', encoding='cp949')
```

### 2. 구분자 문제
```python
# 문제: 데이터가 제대로 분리되지 않음
# 해결: 정확한 구분자 지정
df = pd.read_csv('data.txt', sep='\t')  # 탭 구분
df = pd.read_csv('data.txt', sep=r'\s+')  # 공백 구분
```

### 3. 메모리 부족
```python
# 문제: 대용량 파일 처리 시 메모리 부족
# 해결: 청크 단위 처리
for chunk in pd.read_csv('big_file.csv', chunksize=10000):
    process_chunk(chunk)
```

---

## 📋 종합 실습 예제

```python
def comprehensive_file_io_example():
    """
    판다스 파일 입출력 종합 예제
    """
    
    # 1. 데이터 생성
    print("1. 샘플 데이터 생성")
    data = {
        'product_id': range(1, 101),
        'product_name': [f'Product_{i}' for i in range(1, 101)],
        'price': np.random.randint(1000, 100000, 100),
        'category': np.random.choice(['A', 'B', 'C'], 100),
        'stock': np.random.randint(0, 50, 100)
    }
    df = pd.DataFrame(data)
    print(f"데이터 형태: {df.shape}")
    
    # 2. 다양한 형식으로 저장
    print("\n2. 다양한 형식으로 저장")
    
    # CSV 저장
    df.to_csv('products.csv', index=False, encoding='utf-8-sig')
    print("✓ CSV 파일 저장 완료")
    
    # Excel 저장 (다중 시트)
    with pd.ExcelWriter('products.xlsx') as writer:
        df.to_excel(writer, sheet_name='전체데이터', index=False)
        df[df['category'] == 'A'].to_excel(writer, sheet_name='카테고리A', index=False)
        df[df['category'] == 'B'].to_excel(writer, sheet_name='카테고리B', index=False)
    print("✓ Excel 파일 저장 완료")
    
    # JSON 저장
    df.to_json('products.json', orient='records', indent=2)
    print("✓ JSON 파일 저장 완료")
    
    # 3. 파일 읽기 및 검증
    print("\n3. 파일 읽기 및 검증")
    
    # CSV 읽기
    df_csv = pd.read_csv('products.csv', encoding='utf-8-sig')
    print(f"CSV에서 읽은 데이터: {df_csv.shape}")
    
    # Excel 읽기
    df_excel = pd.read_excel('products.xlsx', sheet_name='전체데이터')
    print(f"Excel에서 읽은 데이터: {df_excel.shape}")
    
    # JSON 읽기
    df_json = pd.read_json('products.json')
    print(f"JSON에서 읽은 데이터: {df_json.shape}")
    
    # 4. 데이터 일치성 검증
    print(f"\n4. 데이터 일치성 검증")
    print(f"원본과 CSV 동일: {df.equals(df_csv)}")
    print(f"원본과 Excel 동일: {df.equals(df_excel)}")
    print(f"원본과 JSON 동일: {df.equals(df_json.sort_values('product_id').reset_index(drop=True))}")

# 실행
comprehensive_file_io_example()
```

---

## 🎯 핵심 요약

### 반드시 기억할 포인트

1. **파일 형식별 특징 이해**
   - CSV: 범용성, 가벼움, 빠른 처리
   - Excel: 비즈니스 친화적, 다중 시트, 서식 지원
   - JSON: 웹 친화적, 구조적 데이터, API 호환

2. **인코딩 처리**
   - 한글 파일: `encoding='utf-8-sig'` 또는 `encoding='cp949'`
   - 웹 데이터: `encoding='utf-8'`
   - 자동 감지: 여러 인코딩 시도

3. **성능 최적화**
   - 대용량 파일: 청크 처리 활용
   - 데이터 타입 최적화로 메모리 절약
   - 필요한 컬럼만 읽기 (`usecols` 활용)

4. **실무 활용 패턴**
   - 파일 존재 여부 확인
   - 예외 처리 구현
   - 배치 처리 자동화
   - 데이터 검증 프로세스

판다스의 파일 I/O 기능을 마스터하면 다양한 데이터 소스와의 연동이 가능해지며, 실무에서의 데이터 처리 효율성이 크게 향상됩니다! 💪
