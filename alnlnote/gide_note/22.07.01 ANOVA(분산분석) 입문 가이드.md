# 22.07.01 ANOVA(분산분석) 입문 가이드
*세 개 이상의 모집단 평균 비교의 핵심 도구*

---

## 🎯 분산분석(ANOVA)이란?

**ANOVA(ANalysis Of Variance, 분산분석)**는 Fisher가 개발한 통계 기법으로, **세 개 이상의 집단 평균을 동시에 비교**하는 방법입니다.

### 🤔 왜 t검정을 여러 번 하면 안 될까?

세 집단 A, B, C가 있을 때:
- A vs B: α = 0.05
- A vs C: α = 0.05  
- B vs C: α = 0.05

**전체 제1종 오류율**: 1 - (0.95)³ = **0.143 (14.3%)**

> 💡 **핵심**: 비교 횟수가 늘어날수록 잘못된 결론을 내릴 확률이 급격히 증가합니다!

---

## 🧠 분산분석의 핵심 아이디어

### 🔍 "분산"을 분석한다는 것

**분산분석**이라는 용어는 전체 분산이 발생한 과정을 분석하여:
- **요인에 의한 분산** (Between-group variance)
- **요인 내 각 집단의 분산** (Within-group variance)

으로 나누고, **요인에 의한 분산이 의미 있는 크기**를 가지는지 검정하는 것입니다.

### 📊 ANOVA의 마법 공식

```
F-value = 그룹 간 분산 (Between Variance) / 그룹 내 분산 (Within Variance)
```

#### 🎯 F-value 해석 가이드

| F-value 상황 | 의미 | 결론 |
|-------------|------|------|
| **F-value가 클 때** | 그룹 간 차이 > 그룹 내 변동 | 📈 **유의미한 차이 존재!** |
| **F-value가 작을 때** | 그룹 간 차이 ≤ 그룹 내 변동 | 📉 그냥 우연의 차이 |

#### 🔥 유의미성을 높이는 조건

1. **그룹 간 분산이 클 때**: 집단별 평균이 확실히 다름
2. **그룹 내 분산이 작을 때**: 각 집단 내 데이터가 일관성 있음

---

## 📚 실습 예제: 교육방법별 실기시험 비교

### 🎯 연구 설정

**상황**: 세 가지 서로 다른 교육방법을 1개월간 교육받은 교육생 80명을 대상으로 실기시험을 실시

**가설**:
- **귀무가설(H₀)**: 세 가지 교육방법을 통한 학생들의 실기시험 평균 점수에 차이가 없다
- **대립가설(H₁)**: 학생들의 실기시험 점수는 교육방법에 따라 다르다

**변수**:
- **독립변수**: 교육방법 (3가지 서로 다른 방법)
- **종속변수**: 시험 점수
- **분석 유형**: **일원분산분석(One-Way ANOVA)**

---

## 💻 Python 실습 코드

### 📥 1. 데이터 로딩 및 탐색

```python
import pandas as pd
import scipy.stats as stats
import matplotlib.pyplot as plt
from statsmodels.formula.api import ols
import statsmodels.api as sm

# 데이터 로딩
data = pd.read_csv('https://raw.githubusercontent.com/pykwon/python/refs/heads/master/testdata_utf8/three_sample.csv')

print("=== 데이터 기본 정보 ===")
print(data.head())
print(f"데이터 크기: {data.shape}")  # 80 x 4
print("\n=== 기술통계량 ===")
print(data.describe())
```

### 🔍 2. 이상치 탐지 및 제거

```python
# 이상치 시각화
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.hist(data.score, bins=20, alpha=0.7, color='skyblue')
plt.title('점수 분포 (이상치 포함)')
plt.xlabel('점수')

plt.subplot(1, 2, 2)
plt.boxplot(data.score)
plt.title('점수 박스플롯 (이상치 확인)')
plt.ylabel('점수')

plt.tight_layout()
plt.show()
plt.close()

# 이상치 제거 (100점 초과 데이터 제거)
data_clean = data.query('score <= 100')
print(f"이상치 제거 후 데이터 크기: {len(data_clean)}")  # 78개
```

### 📊 3. 집단별 데이터 분리

```python
# 교육방법별 데이터 분리
result = data_clean[['method', 'score']]

method1 = result[result['method'] == 1]['score']
method2 = result[result['method'] == 2]['score']  
method3 = result[result['method'] == 3]['score']

print("=== 집단별 기본 통계량 ===")
print(f"교육방법 1: 평균={method1.mean():.2f}, 표준편차={method1.std():.2f}, n={len(method1)}")
print(f"교육방법 2: 평균={method2.mean():.2f}, 표준편차={method2.std():.2f}, n={len(method2)}")
print(f"교육방법 3: 평균={method3.mean():.2f}, 표준편차={method3.std():.2f}, n={len(method3)}")
```

---

## 🔬 ANOVA 전제 조건 검정

### 📋 ANOVA 3대 전제 조건

1. **정규성(Normality)**: 각 집단의 데이터가 정규분포를 따라야 함
2. **등분산성(Homogeneity of Variance)**: 각 집단의 분산이 같아야 함
3. **독립성(Independence)**: 관측값들이 서로 독립적이어야 함

### 🧪 1. 정규성 검정 (Shapiro-Wilk Test)

```python
print("=== 정규성 검정 (Shapiro-Wilk Test) ===")
print(f"교육방법 1: p-value = {stats.shapiro(method1)[1]:.4f}")
print(f"교육방법 2: p-value = {stats.shapiro(method2)[1]:.4f}")
print(f"교육방법 3: p-value = {stats.shapiro(method3)[1]:.4f}")

# 해석: p > 0.05 → 정규성 가정 만족
```

### ⚖️ 2. 등분산성 검정

```python
print("\n=== 등분산성 검정 ===")
print(f"Levene Test: p-value = {stats.levene(method1, method2, method3)[1]:.4f}")
print(f"Fligner Test: p-value = {stats.fligner(method1, method2, method3)[1]:.4f}")
print(f"Bartlett Test: p-value = {stats.bartlett(method1, method2, method3)[1]:.4f}")

# 해석: p > 0.05 → 등분산성 가정 만족
```

#### 🛡️ 등분산성 검정 방법 비교

| 검정법 | 특징 | 언제 사용? |
|--------|------|----------|
| **Levene** | 가장 안전하고 일반적 | **실무 추천** ⭐ |
| **Fligner** | 가장 강건함 | 완전히 비모수적 상황 |
| **Bartlett** | 정규성 가정 강함 | 정규분포 확신할 때만 |

---

## 🎯 ANOVA 실행

### 📊 분산분석표 생성

```python
# 회귀 모델 설정
reg = ols("score ~ C(method)", data=data_clean).fit()

# ANOVA 분산분석표 생성
anova_table = sm.stats.anova_lm(reg, type=2)

print("=== ANOVA 분산분석표 ===")
print(anova_table)
```

#### 📋 분산분석표 해석

```
                 df    sum_sq     mean_sq         F    PR(>F)
C(method)       2.0    28.908     14.454    0.0623  0.9396
Residual       75.0  17397.207   231.963       NaN     NaN
```

**해석**:
- **F-value**: 0.0623 (매우 작음)
- **p-value**: 0.9396 > 0.05
- **결론**: 귀무가설 채택 → **교육방법 간 유의한 차이 없음**

---

## 🔍 사후검정 (Post Hoc Test)

ANOVA에서 유의한 차이를 발견했다면, **어느 집단들 간에 차이가 있는지** 구체적으로 알아야 합니다.

### 🎯 Tukey's HSD (Honestly Significant Difference) 검정

```python
from statsmodels.stats.multicomp import pairwise_tukeyhsd

# Tukey 사후검정 실행
tukey_result = pairwise_tukeyhsd(endog=data_clean.score, 
                                groups=data_clean.method)

print("=== Tukey 사후검정 결과 ===")
print(tukey_result)

# 결과 시각화
tukey_result.plot_simultaneous(xlabel='평균 차이', ylabel='집단')
plt.title('Tukey HSD 사후검정 결과')
plt.show()
plt.close()
```

#### 📊 Tukey 결과 해석

```
group1 group2 meandiff p-adj   lower   upper  reject
----------------------------------------------------
     1      2   0.9725 0.9702 -8.9458 10.8909  False
     1      3   1.4904 0.9363 -8.8183  11.799  False  
     2      3   0.5179 0.9918 -9.6125 10.6483  False
----------------------------------------------------
```

**해석**:
- **reject = False**: 모든 집단 간 쌍별 비교에서 유의한 차이 없음
- **p-adj > 0.05**: 다중비교 보정 후에도 유의하지 않음

---

## 🎨 결과 시각화

### 📊 집단별 분포 비교

```python
plt.figure(figsize=(15, 5))

# 1. 집단별 박스플롯
plt.subplot(1, 3, 1)
data_clean.boxplot(column='score', by='method', ax=plt.gca())
plt.title('교육방법별 점수 분포')
plt.suptitle('')  # 기본 제목 제거
plt.xlabel('교육방법')
plt.ylabel('점수')

# 2. 집단별 히스토그램
plt.subplot(1, 3, 2)
for i, method_data in enumerate([method1, method2, method3], 1):
    plt.hist(method_data, alpha=0.6, label=f'방법 {i}', bins=10)
plt.xlabel('점수')
plt.ylabel('빈도')
plt.title('집단별 점수 분포')
plt.legend()

# 3. 평균 비교 막대그래프
plt.subplot(1, 3, 3)
methods = ['방법 1', '방법 2', '방법 3']
means = [method1.mean(), method2.mean(), method3.mean()]
stds = [method1.std(), method2.std(), method3.std()]

plt.bar(methods, means, yerr=stds, capsize=5, alpha=0.7, color=['skyblue', 'lightgreen', 'salmon'])
plt.ylabel('평균 점수')
plt.title('교육방법별 평균 점수 비교')
plt.ylim(0, max(means) + max(stds) + 5)

plt.tight_layout()
plt.show()
plt.close()
```

---

## 🎯 결론 및 해석

### 📋 최종 결과 요약

| 항목 | 결과 |
|------|------|
| **F-통계량** | 0.0623 |
| **p-value** | 0.9396 |
| **유의수준** | 0.05 |
| **결론** | 교육방법 간 유의한 차이 **없음** |

### 💡 실무적 해석

1. **통계적 결론**: 세 가지 교육방법 간 실기시험 평균 점수에 통계적으로 유의한 차이가 없음
2. **실무적 의미**: 어떤 교육방법을 선택하더라도 학습 효과는 비슷함
3. **추가 고려사항**: 
   - 비용 효율성
   - 학습자 만족도
   - 실용성 및 접근성

### 🚨 주의사항

- **표본 크기**: 각 집단의 표본 크기가 충분한지 확인
- **효과 크기**: 통계적 유의성과 실무적 중요성은 다름
- **가정 위반**: ANOVA 전제조건 위반 시 대안 방법 고려

---

## 🔬 이원분산분석 (Two-way ANOVA) 심화

### 🎯 이원분산분석이란?

**두 개의 독립변수(요인)**가 종속변수에 미치는 영향을 동시에 분석하는 방법입니다.

#### 📋 분석 요소
1. **주효과 (Main Effect)**: 각 독립변수가 단독으로 미치는 영향
2. **상호작용 효과 (Interaction Effect)**: 두 독립변수가 결합되어 미치는 추가적 영향

### 💻 이원분산분석 예제: 독과 처치방법

**연구 상황**: 독의 종류와 처치방법이 독이 퍼지는 시간에 미치는 영향

```python
# 이원분산분석 실행
from statsmodels.formula.api import ols
import statsmodels.api as sm

# 모델 설정: 종속변수 ~ 독립변수1 + 독립변수2 + 교호작용
model = ols('time ~ C(poison) + C(treat) + C(poison):C(treat)', data=data).fit()
anova_table = sm.stats.anova_lm(model, type=2)

print("=== 이원분산분석 결과 ===")
print(anova_table)
```

#### 📊 이원분산분석 결과 해석

```
                       df    sum_sq   mean_sq          F        PR(>F)
C(poison)             2.0   1.033012  0.516506  23.221737  3.33e-07
C(treat)              3.0   0.921206  0.307069  13.805582  3.78e-06
C(poison):C(treat)    6.0   0.250138  0.041690   1.874333  0.112250
Residual             36.0   0.800725  0.022242        NaN       NaN
```

**해석**:

1. **독 종류(C(poison)) 주효과**
   - p-value = 3.33e-07 < 0.05 → **유의함** ✅
   - 독 종류에 따라 퍼지는 시간이 유의미하게 다름

2. **처치 방법(C(treat)) 주효과**  
   - p-value = 3.78e-06 < 0.05 → **유의함** ✅
   - 처치 방법에 따라 퍼지는 시간이 유의미하게 다름

3. **상호작용 효과(C(poison):C(treat))**
   - p-value = 0.112 > 0.05 → **유의하지 않음** ❌
   - 독 종류와 처치 방법의 조합 효과는 없음
   - 즉, 두 요인이 **독립적으로** 작용함

### 🔍 사후검정 (Post-hoc Test) 심화

#### 📋 사후검정 선택 가이드

| 조건 | 추천 사후검정 | 특징 |
|------|-------------|------|
| **정규성 + 등분산성 만족** | **Tukey's HSD** ⭐ | 가장 일반적, 보수적 |
| **등분산성 불만족** | **Games-Howell** | Welch 보정 적용 |
| **비모수 상황** | **Dunn's test** | Kruskal-Wallis 후 사용 |
| **대표본** | **Bonferroni** | 간단하지만 보수적 |

#### 🧪 Tukey HSD 결과 해석

```python
from statsmodels.stats.multicomp import pairwise_tukeyhsd

# 독 종류별 사후검정
tukey_poison = pairwise_tukeyhsd(data['time'], data['poison'])
print("=== 독 종류별 Tukey HSD 결과 ===")
print(tukey_poison)
```

**독 종류별 비교 결과**:
```
group1 group2 meandiff p-adj   lower   upper  reject
----------------------------------------------------
1      2  -0.0731 0.5882 -0.2525  0.1063  False
1      3  -0.3412 0.0001 -0.5206 -0.1619  True
2      3  -0.2681 0.0021 -0.4475 -0.0887  True
```

**해석**:
- **독 1 vs 독 2**: p=0.5882 > 0.05 → 차이 **없음**
- **독 1 vs 독 3**: p=0.0001 < 0.05 → **유의한 차이** ✅
- **독 2 vs 독 3**: p=0.0021 < 0.05 → **유의한 차이** ✅

**결론**: 독 3번이 다른 독들과 확실히 다른 효과를 보임

#### 🎨 사후검정 시각화

```python
# Tukey HSD 플롯
tukey_poison.plot_simultaneous(xlabel='평균 시간 차이', ylabel='독 종류')
plt.title('독 종류별 Tukey HSD 사후검정')
plt.axvline(x=0, color='red', linestyle='--', alpha=0.7)
plt.show()
```

**플롯 해석 가이드**:
- **X축**: 평균 차이
- **막대**: 95% 신뢰구간
- **겹치지 않는 막대**: 유의한 차이 존재
- **겹치는 막대**: 유의한 차이 없음
- **빨간 세로선(0)**: 차이가 없다는 기준선

---

## 📚 ANOVA 결과표 완전 해부

### 🔍 주요 용어 총정리

#### 📊 ANOVA 테이블 구성요소

```
                  sum_sq    df    mean_sq         F    PR(>F)
C(method)      28.907967   2.0  14.453984  0.062312  0.939639
Residual    17397.207418  75.0 231.962766       NaN       NaN
```

| 용어 | 영문 | 의미 | 해석 |
|------|------|------|------|
| **sum_sq** | Sum of Squares | **제곱합** | 각 요인이 설명하는 변동의 총량 |
| **df** | Degree of Freedom | **자유도** | 독립적인 정보의 개수 |
| **mean_sq** | Mean Square | **평균제곱** | sum_sq ÷ df (분산 추정치) |
| **F** | F-statistic | **F-통계량** | 집단 간 분산 ÷ 집단 내 분산 |
| **PR(>F)** | P-value | **유의확률** | F값이 우연히 나올 확률 |

#### 🧮 핵심 공식들

```
F-통계량 = 집단 간 평균제곱(MSB) / 집단 내 평균제곱(MSW)
F-통계량 = mean_sq(요인) / mean_sq(Residual)

자유도 계산:
- 요인 자유도 = 집단 수 - 1
- 오차 자유도 = 전체 관측치 수 - 집단 수
- 총 자유도 = 전체 관측치 수 - 1
```

#### 🎯 F-분포의 역할

**F-분포**는 "서로 다른 두 개 이상의 모집단 분산이 같은지"를 확인하는 분포입니다.

```
F = (분산 1) / (분산 2)  (단, 분자 ≥ 분모)
```

**F-분포 특징**:
- 항상 양수 (분산의 비율이므로)
- 두 개의 자유도 매개변수 (df₁, df₂)
- 오른쪽 꼬리 검정 (F > 임계값이면 유의)
- 자유도가 클수록 정규분포에 근사

### 📈 실제 해석 단계별 가이드

#### Step 1: F-통계량 확인
```
F = 0.062312 (매우 작음)
```
→ 집단 간 분산이 집단 내 분산보다 작음 = 차이 미미

#### Step 2: p-value 판단
```
PR(>F) = 0.939639 > 0.05
```
→ 귀무가설 채택 = 집단 평균에 유의한 차이 없음

#### Step 3: 효과 크기 계산
```python
# 효과크기 (η² - 에타제곱) 계산
eta_squared = sum_sq_factor / sum_sq_total
print(f"효과크기 η² = {eta_squared:.4f}")

# Cohen의 기준
# η² < 0.01: 작은 효과
# η² = 0.06: 중간 효과  
# η² ≥ 0.14: 큰 효과
```

---

## 🚀 다음 단계

### 📈 ANOVA 심화 학습

1. **반복측정 ANOVA**: 같은 대상의 반복 측정
2. **공분산분석 (ANCOVA)**: 공변량 통제
3. **혼합효과 모델**: 고정효과 + 랜덤효과
4. **비모수 대안**: Kruskal-Wallis 검정

### 🛠️ 실무 활용 팁

- **사전 표본크기 계산**: 검정력 분석 수행
- **효과크기 계산**: η² (에타 제곱) 활용
- **가정 위반 시 대안**: Welch's ANOVA, 비모수 검정
- **다중비교 보정**: Bonferroni, FDR 등 고려

---

## 🎓 핵심 요약

> **ANOVA는 "평균을 직접 비교하지 않고, 분산의 성질을 이용하여 집단의 평균이 서로 다른지 확인하는 방법"입니다.**

- ✅ **세 개 이상 집단** 평균 비교 시 필수
- ✅ **제1종 오류율 통제** (α = 0.05 유지)
- ✅ **F-분포 활용** (분산들의 비율 검정)
- ✅ **사후검정 필수** (어느 집단이 다른지 확인)

**다음 22.07.02에서는 ANOVA의 심화 활용과 실무 케이스를 다뤄보겠습니다!** 🚀