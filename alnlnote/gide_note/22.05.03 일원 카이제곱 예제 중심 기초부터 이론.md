# 22.05.03 일원 카이제곱 예제 중심 기초

> **강의 핵심**: "일원 카이제곱은 하나의 변수만 사용해서 적합도나 선호도를 검정하는 거예요. 실제 예제로 하나씩 배워보겠습니다!"

## 🎯 일원 카이제곱이란? (예제 중심 이해)

### 📊 가장 간단한 예제부터!

**예제 1: 동전 던지기**
```
동전을 100번 던졌더니...
앞면: 45번, 뒷면: 55번

질문: 이 동전이 공정한가?
```

### 🤔 일원 vs 이원 구분하기
```python
def 일원_vs_이원_구분():
    """실제 예제로 차이점 이해하기"""
    
    구분법 = {
        "일원 카이제곱": {
            "변수": "1개만!",
            "예시": [
                "동전 결과 (앞면/뒷면)",
                "주사위 결과 (1,2,3,4,5,6)",
                "좋아하는 색깔 (빨강/파랑/노랑/초록)"
            ],
            "질문": "관찰된 빈도가 예상과 같나?"
        },
        
        "이원 카이제곱": {
            "변수": "2개!",
            "예시": [
                "성별 × 선호도",
                "나이대 × 구매여부", 
                "지역 × 투표성향"
            ],
            "질문": "두 변수가 서로 관련 있나?"
        }
    }
    
    return 구분법

# 오늘은 일원 카이제곱만 집중!
print("📚 22.05.03 학습 목표:")
print("✅ 일원 카이제곱의 개념을 예제로 완전히 이해하기")
print("✅ 손으로 직접 계산해보기")
print("✅ Python으로 검증하기")
```

---

## 🪙 예제 1: 동전 던지기 (가장 기초!)

### 📊 문제 상황
```
🪙 동전을 100번 던진 결과:
- 앞면(Head): 45번
- 뒷면(Tail): 55번

🤔 질문: 이 동전이 공정한가?
```

### 🎯 가설 설정
```python
def 동전_가설설정():
    """동전 예제의 가설 설정"""
    
    가설 = {
        "H₀ (귀무가설)": "동전이 공정하다 (앞면 = 뒷면 = 50%)",
        "H₁ (대립가설)": "동전이 공정하지 않다 (앞면 ≠ 뒷면 ≠ 50%)"
    }
    
    print("🎯 가설 설정:")
    for 가설명, 내용 in 가설.items():
        print(f"   {가설명}: {내용}")
    
    return 가설

동전_가설설정()
```

### 🧮 단계별 계산 (손으로 해보기!)

```python
def 동전_카이제곱_계산():
    """동전 예제 단계별 계산"""
    
    print("🧮 단계별 계산 과정:")
    print("=" * 30)
    
    # 1단계: 관찰값과 기대값
    관찰값 = [45, 55]  # [앞면, 뒷면]
    기대값 = [50, 50]  # 공정하다면 각각 50번씩
    범주 = ['앞면', '뒷면']
    
    print("1️⃣ 데이터 정리:")
    print("범주    관찰값  기대값")
    print("-" * 20)
    for i, (범주명, 관찰, 기대) in enumerate(zip(범주, 관찰값, 기대값)):
        print(f"{범주명}      {관찰:>2}     {기대:>2}")
    print(f"합계      {sum(관찰값):>2}     {sum(기대값):>2}")
    
    # 2단계: χ² 통계량 계산
    print(f"\n2️⃣ χ² 통계량 계산:")
    print("공식: χ² = Σ[(관찰값 - 기대값)² / 기대값]")
    
    chi2_terms = []
    for i, (범주명, O, E) in enumerate(zip(범주, 관찰값, 기대값)):
        term = (O - E)**2 / E
        chi2_terms.append(term)
        print(f"   {범주명}: ({O} - {E})² / {E} = {O-E}² / {E} = {term:.3f}")
    
    chi2_stat = sum(chi2_terms)
    print(f"\n   χ² = {chi2_terms[0]:.3f} + {chi2_terms[1]:.3f} = {chi2_stat:.3f}")
    
    # 3단계: 자유도
    df = len(관찰값) - 1
    print(f"\n3️⃣ 자유도: df = (범주 수 - 1) = {len(관찰값)} - 1 = {df}")
    
    # 4단계: 임계값 (α = 0.05)
    from scipy.stats import chi2
    alpha = 0.05
    critical_value = chi2.ppf(1 - alpha, df)
    
    print(f"\n4️⃣ 임계값 (α = {alpha}):")
    print(f"   카이제곱 분포표에서 df={df}, α={alpha} → {critical_value:.3f}")
    
    # 5단계: 판정
    print(f"\n5️⃣ 판정:")
    print(f"   계산된 χ² = {chi2_stat:.3f}")
    print(f"   임계값 = {critical_value:.3f}")
    
    if chi2_stat > critical_value:
        print(f"   χ² > 임계값 → H₀ 기각")
        print("   🎯 결론: 동전이 공정하지 않다!")
    else:
        print(f"   χ² ≤ 임계값 → H₀ 채택")
        print("   🎯 결론: 동전이 공정하다!")
    
    # 6단계: p-value
    p_value = 1 - chi2.cdf(chi2_stat, df)
    print(f"\n6️⃣ p-value: {p_value:.6f}")
    if p_value < alpha:
        print(f"   p < {alpha} → 통계적으로 유의!")
    else:
        print(f"   p ≥ {alpha} → 통계적으로 유의하지 않음")

동전_카이제곱_계산()
```

---

## 🎲 예제 2: 주사위 공정성 검정

### 📊 문제 상황
```
🎲 주사위를 60번 던진 결과:
1: 8번, 2: 12번, 3: 10번, 4: 15번, 5: 9번, 6: 6번

🤔 질문: 이 주사위가 공정한가?
```

### 🧮 실제 계산해보기!

```python
def 주사위_카이제곱_실습():
    """주사위 예제로 직접 계산하기"""
    
    print("🎲 주사위 공정성 검정 - 직접 계산!")
    print("=" * 40)
    
    # 데이터 설정
    관찰값 = [8, 12, 10, 15, 9, 6]
    기대값 = [10, 10, 10, 10, 10, 10]  # 60번 ÷ 6면 = 10번씩
    주사위면 = ['1', '2', '3', '4', '5', '6']
    
    print("1️⃣ 관찰값 vs 기대값:")
    print("면   관찰  기대  차이")
    print("-" * 18)
    for 면, 관찰, 기대 in zip(주사위면, 관찰값, 기대값):
        차이 = 관찰 - 기대
        print(f" {면}   {관찰:>2}   {기대:>2}   {차이:>+2}")
    
    print(f"\n2️⃣ χ² 계산:")
    print("χ² = Σ[(O-E)²/E]")
    
    total_chi2 = 0
    계산과정 = []
    
    for i, (면, O, E) in enumerate(zip(주사위면, 관찰값, 기대값)):
        term = (O - E)**2 / E
        total_chi2 += term
        계산과정.append(f"({O}-{E})²/{E}")
        print(f"   면 {면}: ({O}-{E})²/{E} = {term:.3f}")
    
    print(f"\n   χ² = {' + '.join(계산과정)}")
    print(f"   χ² = {total_chi2:.3f}")
    
    # 임계값과 비교
    from scipy.stats import chi2
    df = len(관찰값) - 1
    alpha = 0.05
    critical_value = chi2.ppf(1 - alpha, df)
    
    print(f"\n3️⃣ 판정:")
    print(f"   자유도: {df}")
    print(f"   임계값 (α=0.05): {critical_value:.3f}")
    print(f"   계산된 χ²: {total_chi2:.3f}")
    
    if total_chi2 > critical_value:
        print("   ✅ χ² > 임계값 → 주사위가 공정하지 않다!")
    else:
        print("   ❌ χ² ≤ 임계값 → 주사위가 공정하다!")

주사위_카이제곱_실습()
```

---

## 🍕 예제 3: 피자 토핑 선호도 (균등성 검정)

### 📊 문제 상황
```
🍕 피자 토핑 선호도 조사 (총 400명):
- 페퍼로니: 120명
- 치즈: 95명  
- 야채: 85명
- 하와이안: 100명

🤔 질문: 모든 토핑의 선호도가 동일한가?
```

### 🎯 Python으로 검증하기

```python
def 피자_선호도_검정():
    """Python을 사용한 카이제곱 검정"""
    
    from scipy.stats import chisquare
    
    print("🍕 피자 토핑 선호도 검정")
    print("=" * 30)
    
    # 데이터
    토핑 = ['페퍼로니', '치즈', '야채', '하와이안']
    관찰값 = [120, 95, 85, 100]
    총응답자 = sum(관찰값)
    
    # 귀무가설: 모든 토핑 선호도 동일 (25%씩)
    기대값 = [총응답자/4] * 4  # [100, 100, 100, 100]
    
    print(f"총 응답자: {총응답자}명")
    print(f"귀무가설: 각 토핑 선호도 = 25% ({총응답자//4}명씩)")
    print()
    
    # 관찰값 vs 기대값 표시
    print("토핑        관찰  기대  비율")
    print("-" * 25)
    for 토핑명, 관찰, 기대 in zip(토핑, 관찰값, 기대값):
        비율 = 관찰/총응답자*100
        print(f"{토핑명:<8} {관찰:>3}  {기대:>3}  {비율:>4.1f}%")
    
    # 카이제곱 검정
    chi2_stat, p_value = chisquare(관찰값, 기대값)
    
    print(f"\n🔢 검정 결과:")
    print(f"χ² 통계량: {chi2_stat:.4f}")
    print(f"p-value: {p_value:.6f}")
    
    # 결론
    alpha = 0.05
    print(f"\n🎯 결론 (α = {alpha}):")
    
    if p_value < alpha:
        print("✅ H₀ 기각: 토핑별 선호도가 다르다!")
        print("💡 마케팅 시사점: 인기 토핑에 집중 투자")
        
        # 어떤 토핑이 가장/가장 덜 인기있는지
        최고인기_idx = 관찰값.index(max(관찰값))
        최저인기_idx = 관찰값.index(min(관찰값))
        print(f"   - 최고 인기: {토핑[최고인기_idx]} ({관찰값[최고인기_idx]}명)")
        print(f"   - 최저 인기: {토핑[최저인기_idx]} ({관찰값[최저인기_idx]}명)")
    else:
        print("❌ H₀ 채택: 토핑별 선호도가 동일하다!")
        print("💡 마케팅 시사점: 모든 토핑을 균등하게 준비")

피자_선호도_검정()
```

---

## 📊 Python 실습: 단계별 구현

### 🔧 방법 1: 수식으로 직접 계산

```python
def 손으로_카이제곱_계산(관찰값, 기대값=None):
    """수식을 이용한 직접 계산 - 이해를 위해!"""
    
    import numpy as np
    from scipy.stats import chi2
    
    print("🧮 수식으로 직접 계산해보기")
    print("-" * 30)
    
    관찰값 = np.array(관찰값)
    
    # 기대값이 없으면 균등분포 가정
    if 기대값 is None:
        평균 = np.mean(관찰값)
        기대값 = np.full(len(관찰값), 평균)
        print(f"✨ 균등분포 가정: 각 범주 기대값 = {평균:.1f}")
    else:
        기대값 = np.array(기대값)
    
    print(f"\n📊 데이터:")
    print(f"관찰값: {관찰값}")
    print(f"기대값: {기대값}")
    
    # χ² 계산
    print(f"\n🔢 χ² 계산 과정:")
    chi2_terms = []
    for i, (O, E) in enumerate(zip(관찰값, 기대값)):
        term = (O - E)**2 / E
        chi2_terms.append(term)
        print(f"   범주 {i+1}: ({O}-{E})²/{E} = {O-E}²/{E} = {term:.4f}")
    
    chi2_stat = sum(chi2_terms)
    print(f"\n   χ² = {' + '.join(f'{t:.4f}' for t in chi2_terms)}")
    print(f"   χ² = {chi2_stat:.4f}")
    
    # 자유도와 임계값
    df = len(관찰값) - 1
    alpha = 0.05
    critical_value = chi2.ppf(1 - alpha, df)
    p_value = 1 - chi2.cdf(chi2_stat, df)
    
    print(f"\n📋 결과:")
    print(f"   χ² 통계량: {chi2_stat:.4f}")
    print(f"   자유도: {df}")
    print(f"   임계값: {critical_value:.4f}")
    print(f"   p-value: {p_value:.6f}")
    
    # 결론
    if chi2_stat > critical_value:
        print("   ✅ χ² > 임계값 → H₀ 기각!")
    else:
        print("   ❌ χ² ≤ 임계값 → H₀ 채택!")
    
    return chi2_stat, p_value

# 예시 1: 동전 던지기
print("🪙 동전 던지기 예제:")
손으로_카이제곱_계산([45, 55], [50, 50])

print("\n" + "="*50)

# 예시 2: 주사위
print("🎲 주사위 예제:")
손으로_카이제곱_계산([8, 12, 10, 15, 9, 6], [10, 10, 10, 10, 10, 10])
```

### 🎯 방법 2: SciPy 함수 사용 (실무용)

```python
def 간편한_카이제곱_검정(관찰값, 기대값=None):
    """SciPy를 이용한 간편 검정 - 실무에서 사용!"""
    
    from scipy.stats import chisquare
    
    print("🔬 SciPy로 간편하게!")
    print("-" * 25)
    
    if 기대값 is None:
        chi2_stat, p_value = chisquare(관찰값)
        print("📊 균등분포 가정으로 검정")
    else:
        chi2_stat, p_value = chisquare(관찰값, 기대값)
        print("📊 사용자 지정 기대값으로 검정")
    
    print(f"관찰값: {관찰값}")
    if 기대값:
        print(f"기대값: {기대값}")
    
    print(f"\n🎯 결과:")
    print(f"χ² 통계량: {chi2_stat:.4f}")
    print(f"p-value: {p_value:.6f}")
    
    alpha = 0.05
    if p_value < alpha:
        print(f"✅ p < {alpha} → 유의한 차이 있음!")
    else:
        print(f"❌ p ≥ {alpha} → 유의한 차이 없음!")
    
    return chi2_stat, p_value

# 실습해보기
print("🔬 SciPy 함수로 검증:")
print("\n🪙 동전 검정:")
간편한_카이제곱_검정([45, 55], [50, 50])

print("\n🎲 주사위 검정:")
간편한_카이제곱_검정([8, 12, 10, 15, 9, 6])
```

---

## 💡 실습 문제: 스스로 해보기!

### 🎯 문제 1: M&M 초콜릿 색깔 분포

```
🍫 M&M 초콜릿 100개의 색깔 분포:
- 빨강: 23개
- 노랑: 18개  
- 파랑: 21개
- 초록: 19개
- 갈색: 19개

질문: 모든 색깔이 동일한 비율로 들어있는가?
```

**해결 과정:**
1. 가설 설정하기
2. 기대값 계산하기 (100 ÷ 5 = ?)
3. χ² 통계량 계산하기
4. 결론 내리기

### 🎯 문제 2: 요일별 매출 분석

```
🏪 편의점 요일별 매출 비교 (주간):
- 월: 850만원
- 화: 820만원
- 수: 880만원
- 목: 920만원
- 금: 1130만원
- 토: 1200만원
- 일: 1200만원

질문: 요일별 매출이 동일한가?
```

### 🔧 해답 코드 (스스로 해본 후 확인!)

```python
def 실습문제_해답():
    """실습 문제들의 해답"""
    
    from scipy.stats import chisquare
    
    print("🎯 실습 문제 해답")
    print("="*30)
    
    # 문제 1: M&M 초콜릿
    print("🍫 문제 1: M&M 초콜릿")
    print("-"*20)
    
    mnm_관찰값 = [23, 18, 21, 19, 19]
    mnm_색깔 = ['빨강', '노랑', '파랑', '초록', '갈색']
    총개수 = sum(mnm_관찰값)
    mnm_기대값 = [총개수/5] * 5  # [20, 20, 20, 20, 20]
    
    print(f"총 개수: {총개수}개")
    print("색깔  관찰  기대")
    for 색깔, 관찰, 기대 in zip(mnm_색깔, mnm_관찰값, mnm_기대값):
        print(f"{색깔:<3}   {관찰:>2}   {기대:>2}")
    
    chi2_1, p_1 = chisquare(mnm_관찰값, mnm_기대값)
    print(f"\nχ² = {chi2_1:.4f}, p = {p_1:.6f}")
    
    if p_1 < 0.05:
        print("✅ 색깔별 비율이 다르다!")
    else:
        print("❌ 색깔별 비율이 동일하다!")
    
    # 문제 2: 요일별 매출
    print(f"\n🏪 문제 2: 요일별 매출")
    print("-"*20)
    
    매출 = [850, 820, 880, 920, 1130, 1200, 1200]
    요일 = ['월', '화', '수', '목', '금', '토', '일']
    총매출 = sum(매출)
    평균매출 = 총매출 / 7
    기대매출 = [평균매출] * 7
    
    print(f"주간 총 매출: {총매출:,}만원")
    print(f"일평균 매출: {평균매출:.1f}만원")
    print("\n요일  관찰매출  기대매출")
    for 요일명, 관찰, 기대 in zip(요일, 매출, 기대매출):
        print(f" {요일명}   {관찰:>4}     {기대:>4.1f}")
    
    chi2_2, p_2 = chisquare(매출, 기대매출)
    print(f"\nχ² = {chi2_2:.4f}, p = {p_2:.6f}")
    
    if p_2 < 0.05:
        print("✅ 요일별 매출이 다르다!")
        print("💡 주말이 특히 높은 것 같네요!")
    else:
        print("❌ 요일별 매출이 동일하다!")

# 스스로 해본 후 실행해보세요!
# 실습문제_해답()
```

---

## ⚠️ 주의사항 및 조건

### 📋 일원 카이제곱의 가정과 조건

```python
def chi_square_assumptions():
    """카이제곱 검정의 가정과 조건"""
    
    assumptions = {
        "🔍 기본 가정": [
            "데이터가 범주형(명목척도)이어야 함",
            "각 관찰은 독립적이어야 함",
            "전체 표본이 하나의 모집단에서 추출되어야 함"
        ],
        
        "📊 표본 크기 조건": [
            "각 범주의 기대빈도가 5 이상이어야 함",
            "기대빈도 < 5인 범주가 전체의 20%를 넘지 않아야 함",
            "최소 표본 크기: 30 이상 권장"
        ],
        
        "⚠️ 위반 시 문제점": [
            "Type I 오류율 증가",
            "검정력(Power) 감소",
            "부정확한 p-value 계산"
        ],
        
        "🔧 해결 방법": [
            "범주 합치기 (인접 범주 병합)",
            "표본 크기 늘리기",
            "정확검정(Exact test) 사용",
            "몬테카를로 시뮬레이션"
        ]
    }
    
    print("⚠️ 카이제곱 검정 가정 및 조건")
    print("=" * 35)
    
    for category, items in assumptions.items():
        print(f"\n{category}:")
        for item in items:
            print(f"  • {item}")

chi_square_assumptions()
```

### 🔍 기대빈도 체크 함수

```python
def check_expected_frequency(observed, expected=None):
    """기대빈도 조건 확인"""
    
    import numpy as np
    
    observed = np.array(observed)
    
    if expected is None:
        expected = np.full(len(observed), np.mean(observed))
    else:
        expected = np.array(expected)
    
    print("🔍 기대빈도 조건 확인")
    print("-" * 25)
    
    # 조건 확인
    min_expected = np.min(expected)
    low_freq_count = np.sum(expected < 5)
    low_freq_ratio = low_freq_count / len(expected)
    
    print(f"범주 수: {len(expected)}")
    print(f"최소 기대빈도: {min_expected:.2f}")
    print(f"기대빈도 < 5인 범주: {low_freq_count}개 ({low_freq_ratio:.1%})")
    
    # 조건 판정
    condition_met = True
    
    if min_expected < 1:
        print("❌ 심각: 기대빈도 < 1인 범주 존재")
        condition_met = False
    elif min_expected < 5 and low_freq_ratio > 0.2:
        print("⚠️ 주의: 기대빈도 < 5인 범주가 20% 초과")
        condition_met = False
    elif min_expected < 5:
        print("⚠️ 주의: 기대빈도 < 5인 범주 존재하지만 20% 이하")
    else:
        print("✅ 양호: 모든 조건 충족")
    
    if condition_met:
        print("💡 결론: 카이제곱 검정 적용 가능")
    else:
        print("💡 권장: 범주 합치기 또는 다른 검정 고려")
    
    return condition_met

# 예시 실행
check_expected_frequency([45, 55, 48, 52, 47, 53], [50, 50, 50, 50, 50, 50])
```

---

## 📈 결과 해석 가이드

### 🎯 효과 크기와 실용적 의미

```python
def interpret_chi_square_results(chi2_stat, p_value, n, df):
    """카이제곱 검정 결과의 종합적 해석"""
    
    print("📈 카이제곱 검정 결과 해석 가이드")
    print("=" * 40)
    
    # 1. 통계적 유의성
    print("1️⃣ 통계적 유의성:")
    alpha_levels = [0.001, 0.01, 0.05, 0.1]
    
    for alpha in alpha_levels:
        if p_value < alpha:
            print(f"   p < {alpha}: 매우 강한 증거" if alpha == 0.001 
                  else f"   p < {alpha}: 강한 증거" if alpha == 0.01
                  else f"   p < {alpha}: 적당한 증거" if alpha == 0.05
                  else f"   p < {alpha}: 약한 증거")
            break
    else:
        print(f"   p ≥ 0.1: 유의한 차이 없음")
    
    # 2. 효과 크기 (Cramér's V)
    print(f"\n2️⃣ 효과 크기 (Cramér's V):")
    cramers_v = np.sqrt(chi2_stat / (n * df))
    
    print(f"   Cramér's V = √(χ²/n×df) = √({chi2_stat:.3f}/{n}×{df}) = {cramers_v:.3f}")
    
    if cramers_v < 0.1:
        effect_size = "무시할 수 있음"
    elif cramers_v < 0.3:
        effect_size = "작음"
    elif cramers_v < 0.5:
        effect_size = "중간"
    else:
        effect_size = "큼"
    
    print(f"   해석: {effect_size} 효과")
    
    # 3. 실용적 해석
    print(f"\n3️⃣ 실용적 해석:")
    if p_value < 0.05:
        if cramers_v > 0.3:
            print("   ✅ 통계적으로 유의하고 실용적으로도 의미 있음")
        else:
            print("   ⚠️ 통계적으로 유의하지만 실용적 의미는 제한적")
    else:
        print("   ❌ 통계적으로 유의하지 않음")
    
    return cramers_v

# 예시 사용
interpret_chi_square_results(chi2_stat=8.5, p_value=0.037, n=300, df=3)
```

---

## 📚 오늘 배운 내용 정리

### ✅ 22.05.03 학습 완료 체크리스트

```python
def 학습완료_체크리스트():
    """오늘 배운 내용들 체크하기"""
    
    체크리스트 = {
        "🎯 개념 이해": [
            "☐ 일원 카이제곱이 무엇인지 설명할 수 있다",
            "☐ 언제 사용하는지 알고 있다",
            "☐ 이원 카이제곱과의 차이를 안다"
        ],
        
        "🧮 계산 능력": [
            "☐ χ² 공식을 외우고 있다",
            "☐ 손으로 직접 계산할 수 있다", 
            "☐ 자유도 계산 방법을 안다",
            "☐ 임계값과 비교할 수 있다"
        ],
        
        "💻 Python 실습": [
            "☐ scipy.stats.chisquare 함수를 사용할 수 있다",
            "☐ p-value를 해석할 수 있다",
            "☐ 결과를 실무적으로 설명할 수 있다"
        ],
        
        "🤔 실무 적용": [
            "☐ 동전/주사위 공정성을 검정할 수 있다",
            "☐ 선호도 조사 결과를 분석할 수 있다",
            "☐ 비즈니스 관점에서 해석할 수 있다"
        ]
    }
    
    print("📚 22.05.03 학습 완료 체크리스트")
    print("="*40)
    
    for 영역, 항목들 in 체크리스트.items():
        print(f"\n{영역}")
        for 항목 in 항목들:
            print(f"  {항목}")
    
    print(f"\n🎉 모든 항목을 체크했다면 일원 카이제곱 마스터!")

학습완료_체크리스트()
```

### 🔗 다음 학습: 22.05.04 이원 카이제곱

```python
def 다음_학습_미리보기():
    """다음에 배울 내용 미리보기"""
    
    print("🔮 다음 시간 미리보기: 22.05.04 이원 카이제곱")
    print("="*50)
    
    예고 = {
        "✨ 새로 배울 것": [
            "교차분할표(Contingency Table) 만들기",
            "독립성 검정 vs 동질성 검정",
            "기대빈도를 다르게 계산하는 방법",
            "실제 설문조사 데이터 분석"
        ],
        
        "🔄 오늘과의 연결점": [
            "χ² 공식은 동일함",
            "자유도 계산만 달라짐: (행-1) × (열-1)",
            "Python 함수도 비슷함: chi2_contingency()",
            "해석 방법도 유사함"
        ],
        
        "📊 실습 예제 예고": [
            "성별 × 제품선호도",
            "나이대 × 구매패턴", 
            "지역 × 정치성향",
            "교육수준 × 소득수준"
        ]
    }
    
    for 섹션, 내용들 in 예고.items():
        print(f"\n{섹션}:")
        for 내용 in 내용들:
            print(f"  • {내용}")
    
    print(f"\n💡 핵심 포인트:")
    print("  오늘 배운 일원 카이제곱을 완벽히 이해했다면")
    print("  이원 카이제곱은 쉽게 확장할 수 있어요!")

다음_학습_미리보기()
```

### 🎯 실무에서 기억할 핵심 3가지

1. **🎲 일원 카이제곱의 핵심**
   - **하나의 변수**만 사용
   - **관찰 빈도 vs 기대 빈도** 비교
   - **적합도/선호도** 검정에 사용

2. **🧮 계산의 핵심**
   - **χ² = Σ[(O-E)²/E]** 공식
   - **자유도 = 범주 수 - 1**
   - **p < 0.05**면 유의한 차이

3. **💼 해석의 핵심**
   - **통계적 유의성 ≠ 실무적 중요성**
   - **효과 크기**도 함께 고려
   - **비즈니스 맥락**에서 해석

**🎉 22.05.03 일원 카이제곱 예제 중심 기초 완주! 이제 이원 카이제곱으로 확장할 준비가 되었습니다!**

---

## 📖 심화 이론: 카이제곱 검정의 수학적 배경

### 🧠 카이제곱 분포의 수학적 원리

#### 📊 카이제곱 분포의 탄생
```python
def 카이제곱분포_원리():
    """카이제곱 분포가 어떻게 만들어지는지"""
    
    print("🧮 카이제곱 분포의 수학적 원리")
    print("="*40)
    
    원리 = {
        "기원": {
            "정의": "표준정규분포를 따르는 독립변수들의 제곱합",
            "수식": "χ² = Z₁² + Z₂² + ... + Zₖ²",
            "조건": "Z₁, Z₂, ..., Zₖ ~ N(0,1), 서로 독립"
        },
        
        "특성": {
            "범위": "0 ≤ χ² < ∞ (항상 양수)",
            "모양": "오른쪽 꼬리가 긴 비대칭 분포",
            "매개변수": "자유도(df) 하나만으로 결정",
            "평균": "E[χ²] = df",
            "분산": "Var[χ²] = 2×df"
        },
        
        "자유도_의미": {
            "통계적": "독립적인 정보의 개수",
            "기하학적": "제약 조건 하에서 자유롭게 움직일 수 있는 차원",
            "일원카이제곱": "df = (범주 수 - 1)",
            "제약조건": "Σ(관찰빈도) = n (고정)"
        }
    }
    
    for 영역, 내용 in 원리.items():
        print(f"\n🔍 {영역}:")
        for 항목, 설명 in 내용.items():
            print(f"   {항목}: {설명}")

카이제곱분포_원리()
```

#### 🎯 Pearson의 카이제곱 통계량 유도

```python
def 피어슨_통계량_유도():
    """Karl Pearson의 카이제곱 통계량 수학적 유도"""
    
    print("\n👨‍🔬 Karl Pearson의 카이제곱 통계량 유도")
    print("="*50)
    
    유도과정 = {
        "1단계_가정": {
            "다항분포": "관찰빈도 (O₁, O₂, ..., Oₖ) ~ Multinomial(n, p₁, p₂, ..., pₖ)",
            "기대빈도": "E[Oᵢ] = n×pᵢ",
            "분산": "Var[Oᵢ] = n×pᵢ×(1-pᵢ)",
            "공분산": "Cov[Oᵢ, Oⱼ] = -n×pᵢ×pⱼ"
        },
        
        "2단계_표준화": {
            "표준화변수": "Zᵢ = (Oᵢ - E[Oᵢ])/√Var[Oᵢ]",
            "근사적분포": "n이 클 때, Zᵢ는 근사적으로 정규분포",
            "문제점": "Zᵢ들이 독립이 아님 (합이 n으로 고정)"
        },
        
        "3단계_변환": {
            "이차형식": "Q = Σ[(Oᵢ - Eᵢ)²/Eᵢ]",
            "점근분포": "n → ∞일 때, Q ~ χ²(k-1)",
            "자유도감소": "제약조건 Σ Oᵢ = n 때문에 df = k-1"
        },
        
        "4단계_결론": {
            "통계량": "χ² = Σ[(관찰빈도 - 기대빈도)²/기대빈도]",
            "귀무분포": "H₀ 하에서 χ² ~ χ²(k-1)",
            "적용조건": "모든 기대빈도 ≥ 5 (정규근사 조건)"
        }
    }
    
    for 단계, 내용 in 유도과정.items():
        print(f"\n📐 {단계}:")
        for 항목, 설명 in 내용.items():
            print(f"   • {항목}: {설명}")

피어슨_통계량_유도()
```

### 🔬 검정력과 효과크기 이론

#### 📊 검정력(Power) 분석
```python
def 검정력_이론():
    """카이제곱 검정의 검정력 이론"""
    
    print("\n⚡ 검정력(Statistical Power) 이론")
    print("="*40)
    
    검정력_개념 = {
        "정의": {
            "검정력": "실제로 차이가 있을 때 이를 올바르게 탐지할 확률",
            "수식": "Power = P(H₀ 기각 | H₁ 참) = 1 - β",
            "베타오류": "β = P(H₀ 채택 | H₁ 참) = Type II Error"
        },
        
        "영향요인": {
            "효과크기": "실제 차이가 클수록 검정력 증가",
            "표본크기": "n이 클수록 검정력 증가",
            "유의수준": "α가 클수록 검정력 증가 (but Type I 위험 증가)",
            "자유도": "범주가 많을수록 검정력 복잡하게 변화"
        },
        
        "효과크기측정": {
            "Cramér_V": "V = √(χ²/(n×min(r-1, c-1)))",
            "해석기준": "V < 0.1(무시), 0.1-0.3(작음), 0.3-0.5(중간), > 0.5(큼)",
            "Cohen_w": "w = √(Σ(pᵢ - p₀ᵢ)²/p₀ᵢ)",
            "표본크기계산": "필요한 n 계산에 사용"
        }
    }
    
    for 영역, 내용 in 검정력_개념.items():
        print(f"\n🎯 {영역}:")
        for 항목, 설명 in 내용.items():
            print(f"   {항목}: {설명}")

검정력_이론()
```

#### 🧮 효과크기 계산 실습
```python
def 효과크기_계산실습():
    """실제 데이터로 효과크기 계산"""
    
    import numpy as np
    import math
    
    print("\n📊 효과크기 계산 실습")
    print("="*30)
    
    # 피자 토핑 예제 재사용
    관찰값 = np.array([120, 95, 85, 100])
    기대값 = np.array([100, 100, 100, 100])
    n = sum(관찰값)
    k = len(관찰값)
    
    # χ² 통계량
    chi2_stat = sum((관찰값 - 기대값)**2 / 기대값)
    
    # Cramér's V 계산
    cramers_v = math.sqrt(chi2_stat / (n * (k - 1)))
    
    # Cohen's w 계산
    p_observed = 관찰값 / n
    p_expected = 기대값 / n
    cohens_w = math.sqrt(sum((p_observed - p_expected)**2 / p_expected))
    
    print(f"🍕 피자 토핑 예제 효과크기:")
    print(f"   χ² 통계량: {chi2_stat:.4f}")
    print(f"   표본 크기: {n}")
    print(f"   범주 수: {k}")
    print(f"   Cramér's V: {cramers_v:.4f}")
    print(f"   Cohen's w: {cohens_w:.4f}")
    
    # 효과크기 해석
    if cramers_v < 0.1:
        효과해석 = "무시할 수 있는 효과"
    elif cramers_v < 0.3:
        효과해석 = "작은 효과"
    elif cramers_v < 0.5:
        효과해석 = "중간 효과"
    else:
        효과해석 = "큰 효과"
    
    print(f"   해석: {효과해석}")
    
    # 필요 표본크기 계산 (중간 효과크기 w=0.3 기준)
    target_w = 0.3
    alpha = 0.05
    power = 0.8
    df = k - 1
    
    # 근사 공식 (정확한 계산은 더 복잡)
    from scipy.stats import chi2
    critical_value = chi2.ppf(1 - alpha, df)
    required_n = critical_value / (target_w**2)
    
    print(f"\n📈 표본크기 계산:")
    print(f"   목표 효과크기 (w): {target_w}")
    print(f"   유의수준 (α): {alpha}")
    print(f"   검정력 (1-β): {power}")
    print(f"   필요 표본크기: 약 {required_n:.0f}명")

효과크기_계산실습()
```

### 🎯 비모수 대안과 정확검정

#### 🔍 카이제곱 검정의 한계와 대안
```python
def 카이제곱_한계와_대안():
    """카이제곱 검정의 한계점과 대안 방법들"""
    
    print("\n⚠️ 카이제곱 검정의 한계와 대안")
    print("="*40)
    
    한계와_대안 = {
        "기대빈도_문제": {
            "한계": "기대빈도 < 5일 때 정규근사 부정확",
            "증상": "Type I 오류율 증가, 부정확한 p-value",
            "대안1": "Fisher의 정확검정 (2×2 표의 경우)",
            "대안2": "몬테카를로 시뮬레이션",
            "대안3": "범주 합치기 (adjacent categories)"
        },
        
        "표본크기_문제": {
            "한계": "매우 큰 표본에서 사소한 차이도 유의",
            "증상": "실용적 의미 없는 통계적 유의성",
            "대안1": "효과크기 중심 해석",
            "대안2": "실질적 유의성 기준 설정",
            "대안3": "베이지안 접근법"
        },
        
        "분포가정_문제": {
            "한계": "카이제곱 분포 가정이 부적절한 경우",
            "증상": "비정규성, 의존성, 이분산성",
            "대안1": "로그선형 모델",
            "대안2": "일반화 선형 모델 (GLM)",
            "대안3": "순열검정 (Permutation test)"
        }
    }
    
    for 문제영역, 내용 in 한계와_대안.items():
        print(f"\n🚨 {문제영역}:")
        for 항목, 설명 in 내용.items():
            print(f"   {항목}: {설명}")

카이제곱_한계와_대안()
```

#### 🎲 Fisher의 정확검정 원리
```python
def 피셔_정확검정_원리():
    """Fisher의 정확검정 수학적 원리"""
    
    print("\n🎯 Fisher의 정확검정 원리")
    print("="*35)
    
    원리설명 = {
        "적용상황": {
            "조건": "2×2 분할표에서 기대빈도 < 5",
            "예시": "소표본 임상시험, 희귀사건 분석",
            "장점": "정확한 p-value (근사 아님)"
        },
        
        "수학적원리": {
            "분포": "초기하분포 (Hypergeometric distribution)",
            "조건부확률": "행과 열의 합이 고정된 조건 하에서",
            "계산": "P(관찰된 결과 | 주변합 고정)",
            "수식": "P = (a+b)!(c+d)!(a+c)!(b+d)! / (n!×a!×b!×c!×d!)"
        },
        
        "계산예시": {
            "분할표": """
                    치료군  대조군  합계
            완치      a      b    a+b
            미완치    c      d    c+d
            합계    a+c    b+d     n
            """,
            "정확확률": "주변합이 고정된 상태에서 각 셀의 확률",
            "p_value": "관찰값보다 극단적인 모든 경우의 확률 합"
        }
    }
    
    for 영역, 내용 in 원리설명.items():
        print(f"\n📐 {영역}:")
        for 항목, 설명 in 내용.items():
            print(f"   {항목}: {설명}")

피셔_정확검정_원리()
```

### 🔬 베이지안 접근법

#### 🧮 베이지안 카이제곱 검정
```python
def 베이지안_카이제곱():
    """베이지안 관점에서의 카이제곱 검정"""
    
    print("\n🔮 베이지안 카이제곱 검정")
    print("="*30)
    
    베이지안_관점 = {
        "철학적차이": {
            "빈도주의": "p-value = P(데이터 | H₀ 참)",
            "베이지안": "P(H₀ | 데이터) 직접 계산",
            "장점": "직관적 해석, 사전정보 활용 가능"
        },
        
        "방법론": {
            "사전분포": "모수에 대한 사전 믿음 설정",
            "가능도": "데이터가 주어진 조건부 확률",
            "사후분포": "베이즈 정리로 사후 믿음 계산",
            "베이즈팩터": "BF = P(데이터|H₁) / P(데이터|H₀)"
        },
        
        "실용적장점": {
            "다중비교": "자연스러운 다중비교 보정",
            "표본크기": "순차적 분석 가능",
            "불확실성": "신뢰구간 대신 credible interval",
            "의사결정": "손실함수 기반 최적 결정"
        }
    }
    
    for 영역, 내용 in 베이지안_관점.items():
        print(f"\n🎯 {영역}:")
        for 항목, 설명 in 내용.items():
            print(f"   {항목}: {설명}")

베이지안_카이제곱()
```

### 📊 고급 응용: 로그선형 모델

#### 🔍 로그선형 모델 연결
```python
def 로그선형모델_연결():
    """카이제곱 검정과 로그선형 모델의 연결"""
    
    print("\n🌐 로그선형 모델과의 연결")
    print("="*35)
    
    연결점 = {
        "기본아이디어": {
            "카이제곱": "빈도 데이터의 적합도/독립성 검정",
            "로그선형": "빈도의 로그에 선형 모델 적용",
            "연결": "χ² 검정은 로그선형 모델의 특수한 경우"
        },
        
        "수학적표현": {
            "일원": "log(μᵢ) = α + βᵢ",
            "이원": "log(μᵢⱼ) = α + βᵢ + γⱼ + (βγ)ᵢⱼ",
            "독립성": "(βγ)ᵢⱼ = 0 ⟺ 독립",
            "우도비": "G² = 2Σ Oᵢⱼ log(Oᵢⱼ/Eᵢⱼ)"
        },
        
        "장점": {
            "확장성": "3원, 4원 이상으로 확장 가능",
            "유연성": "다양한 가설 검정 가능",
            "해석": "승산비(odds ratio) 직접 해석",
            "모델선택": "AIC, BIC로 모델 비교"
        }
    }
    
    for 영역, 내용 in 연결점.items():
        print(f"\n🔗 {영역}:")
        for 항목, 설명 in 내용.items():
            print(f"   {항목}: {설명}")

로그선형모델_연결()
```

### 🎯 현대적 발전: 머신러닝과의 연결

#### 🤖 카이제곱과 머신러닝
```python
def 머신러닝_연결():
    """카이제곱 검정과 머신러닝의 연결점"""
    
    print("\n🤖 카이제곱 검정과 머신러닝")
    print("="*35)
    
    연결점들 = {
        "특성선택": {
            "카이제곱검정": "범주형 변수 간 독립성 검정",
            "특성선택": "목표변수와 독립인 특성 제거",
            "활용": "sklearn.feature_selection.chi2",
            "장점": "빠른 계산, 해석 가능"
        },
        
        "A_B_테스트": {
            "전통방법": "카이제곱 검정으로 전환율 비교",
            "현대방법": "베이지안 밴딧, 다중무장강도",
            "연결": "통계적 유의성 vs 비즈니스 최적화",
            "도구": "Optimizely, Google Optimize"
        },
        
        "범주형데이터": {
            "전처리": "원-핫 인코딩 전 독립성 확인",
            "차원축소": "대응분석 (Correspondence Analysis)",
            "군집화": "카테고리컬 K-means",
            "연관규칙": "장바구니 분석의 기초"
        },
        
        "해석가능AI": {
            "중요도": "카이제곱 통계량으로 변수 중요도",
            "설명": "SHAP, LIME의 범주형 변수 처리",
            "인과추론": "독립성 가정 검증",
            "공정성": "편향 탐지 도구로 활용"
        }
    }
    
    for 영역, 내용 in 연결점들.items():
        print(f"\n🎯 {영역}:")
        for 항목, 설명 in 내용.items():
            print(f"   {항목}: {설명}")

머신러닝_연결()
```

### 📈 실무에서의 고급 고려사항

#### ⚖️ 다중비교 문제
```python
def 다중비교_문제():
    """카이제곱 검정에서의 다중비교 문제"""
    
    print("\n⚖️ 다중비교 문제와 해결법")
    print("="*35)
    
    다중비교 = {
        "문제상황": {
            "예시": "20개 범주에서 모든 쌍 비교 (190개 검정)",
            "위험": "Type I 오류율 급격히 증가",
            "계산": "전체 오류율 = 1 - (1-α)^m",
            "결과": "α=0.05, m=20이면 전체 오류율 ≈ 64%"
        },
        
        "보정방법": {
            "Bonferroni": "α_adj = α / m (보수적)",
            "Holm": "순차적 Bonferroni (덜 보수적)",
            "FDR": "False Discovery Rate 제어",
            "Benjamini_Hochberg": "FDR 보정의 대표 방법"
        },
        
        "실무적용": {
            "탐색적분석": "보정 없이 패턴 탐색",
            "확증적분석": "엄격한 보정 적용",
            "단계적접근": "1차 전체검정 → 2차 사후검정",
            "효과크기": "보정과 함께 효과크기 보고"
        }
    }
    
    for 영역, 내용 in 다중비교.items():
        print(f"\n📊 {영역}:")
        for 항목, 설명 in 내용.items():
            print(f"   {항목}: {설명}")

다중비교_문제()
```

#### 🎯 결론: 이론의 실무 적용
```python
def 이론의_실무적용():
    """복잡한 이론을 실무에 어떻게 적용할지"""
    
    print("\n🎯 이론의 실무 적용 가이드")
    print("="*35)
    
    적용가이드 = {
        "기초실무": {
            "알아야할것": "χ² 공식, 자유도, p-value 해석",
            "사용도구": "Excel, Python scipy.stats",
            "주의사항": "기대빈도 조건, 효과크기 확인"
        },
        
        "중급실무": {
            "추가지식": "검정력, 효과크기, 신뢰구간",
            "고급도구": "R, SPSS 고급 기능",
            "응용": "A/B 테스트, 시장조사 분석"
        },
        
        "고급실무": {
            "전문지식": "로그선형 모델, 베이지안 방법",
            "연구도구": "Stan, PyMC3, 전문 통계 소프트웨어",
            "활용분야": "학술연구, 고급 데이터 과학"
        },
        
        "실무팁": {
            "단순시작": "기본 개념부터 완전히 이해",
            "점진발전": "필요에 따라 단계적으로 고급 기법 학습",
            "도구활용": "이론보다는 올바른 해석에 집중",
            "지속학습": "최신 연구와 도구 동향 파악"
        }
    }
    
    for 단계, 내용 in 적용가이드.items():
        print(f"\n📈 {단계}:")
        for 항목, 설명 in 내용.items():
            print(f"   {항목}: {설명}")
    
    print(f"\n💡 핵심 메시지:")
    print("   이론을 알수록 더 정확하고 신뢰할 수 있는 분석이 가능하지만,")
    print("   실무에서는 '완벽한 이론'보다 '올바른 적용'이 더 중요합니다!")

이론의_실무적용()
```

---

## 🔬 마무리: 이론과 실무의 균형

### 📚 **오늘 배운 모든 것들**

1. **🎯 기초 예제**: 동전, 주사위, 피자로 직관 형성
2. **🧮 계산 과정**: 손으로 직접 계산하는 방법
3. **💻 Python 실습**: 실무에서 사용하는 도구
4. **📖 심화 이론**: 수학적 배경과 고급 개념

### 💡 **실무에서의 활용 레벨**

- **레벨 1**: 기본 계산과 해석 (오늘의 예제들)
- **레벨 2**: 효과크기와 검정력 고려 
- **레벨 3**: 다중비교 보정과 대안 방법
- **레벨 4**: 베이지안과 머신러닝 연결

**🎉 이제 일원 카이제곱을 이론부터 실무까지 완벽하게 마스터했습니다!**

---

## 🔗 다음 단계: 이원 카이제곱으로

### 🎯 학습 연결점

일원 카이제곱을 완전히 이해했다면, 다음은 **이원 카이제곱 검정(독립성 검정)**입니다:

```python
def next_learning_steps():
    """일원에서 이원 카이제곱으로의 연결"""
    
    progression = {
        "✅ 일원 카이제곱": {
            "변수": "1개",
            "목적": "적합도/선호도 검정",
            "질문": "관찰 빈도 = 기대 빈도?"
        },
        
        "🎯 이원 카이제곱": {
            "변수": "2개",
            "목적": "독립성/동질성 검정",
            "질문": "두 변수가 독립적인가?"
        },
        
        "🔄 공통점": [
            "카이제곱 분포 사용",
            "범주형 데이터 분석",
            "동일한 가정과 조건",
            "기대빈도 계산 원리"
        ],
        
        "🆕 추가 학습": [
            "교차분할표(Contingency Table)",
            "독립성 vs 동질성 검정",
            "잔차 분석(Residual Analysis)",
            "관련성 강도 측정"
        ]
    }
    
    print("🔗 다음 학습 단계")
    print("=" * 20)
    
    for stage, details in progression.items():
        print(f"\n{stage}:")
        if isinstance(details, dict) and 'variables' not in details:
            for key, value in details.items():
                print(f"  {key}: {value}")
        elif isinstance(details, list):
            for item in details:
                print(f"  • {item}")

next_learning_steps()
```

---

## 📚 요약 및 핵심 포인트

### 🎯 일원 카이제곱 검정 핵심 요약

1. **목적**: 관찰된 빈도가 기대되는 빈도와 일치하는지 검정
2. **적용**: 하나의 범주형 변수에 대한 적합도/선호도 검정
3. **공식**: χ² = Σ[(관찰빈도 - 기대빈도)²] / 기대빈도
4. **조건**: 기대빈도 ≥ 5, 독립성, 범주형 데이터
5. **해석**: p-value와 효과크기를 함께 고려

### 💡 기억할 핵심 메시지

> **강의에서 강조**: "수식을 외우는 것보다 언제, 왜 사용하는지 이해하는 것이 중요해요. 카이제곱은 범주형 데이터의 패턴을 찾는 도구입니다!"

**이제 일원 카이제곱 검정을 완벽하게 마스터했습니다! 🎉**