# ì›¹ ìŠ¤í¬ë˜í•‘ê³¼ ë°ì´í„° ì²˜ë¦¬ ê°•ì˜ ìš”ì•½

## ğŸ“ 1. ì›¹ ìŠ¤í¬ë˜í•‘ ê¸°ë³¸ ê°œë…

### ğŸ”§ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
```python
import requests
import urllib.request
from bs4 import BeautifulSoup
import pandas as pd
import time
```

### âš ï¸ ìŠ¤í¬ë˜í•‘ ì£¼ì˜ì‚¬í•­
1. **ì†ë„ ì œí•œ**: ë„ˆë¬´ ë¹ ë¥´ê²Œ ìš”ì²­í•˜ë©´ IP ì°¨ë‹¨ ê°€ëŠ¥
   - 0.5ì´ˆ ì´ìƒ ê°„ê²©ìœ¼ë¡œ ìš”ì²­
   - `time.sleep(0.5)` ì‚¬ìš©

2. **ì˜ˆì™¸ ì²˜ë¦¬**: ë„¤íŠ¸ì›Œí¬ ì‘ì—…ì€ ë°˜ë“œì‹œ try-except ì‚¬ìš©
```python
try:
    response = requests.get(url)
    response.raise_for_status()
except Exception as e:
    print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
```

3. **ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½**: ìŠ¤í¬ë˜í•‘ ì½”ë“œëŠ” ì–¸ì œë“  ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ

---

## ğŸ“ 2. BeautifulSoup í™œìš©

### ğŸ¯ HTML íŒŒì‹± ì˜ˆì œ
```python
# ì›¹í˜ì´ì§€ ìš”ì²­
url = "https://example.com"
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

# CSS ì„ íƒì ì‚¬ìš©
items = soup.select('dl.txt dt')  # í´ë˜ìŠ¤ê°€ txtì¸ dl í•˜ìœ„ì˜ dt íƒœê·¸
prices = soup.select('p.money strong')  # ê°€ê²© ì •ë³´ ì¶”ì¶œ

# í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì •ì œ
menu_names = [tag.text.strip() for tag in items]
```

### ğŸ” DOM êµ¬ì¡° ì´í•´
- **ë¶€ëª¨-ìì‹ ê´€ê³„**: `parent` â†’ `child`
- **í˜•ì œ ê´€ê³„**: `sibling`
- **ë£¨íŠ¸ ì—˜ë¦¬ë¨¼íŠ¸**: í•˜ë‚˜ë§Œ ì¡´ì¬

---

## ğŸ“ 3. ì‹¤ìŠµ ì˜ˆì œ: ì¹˜í‚¨ ë©”ë‰´ ìŠ¤í¬ë˜í•‘

### ğŸ“Š êµì´Œì¹˜í‚¨ ë©”ë‰´ ë° ê°€ê²© ìˆ˜ì§‘
```python
import requests
from bs4 import BeautifulSoup
import pandas as pd

# ì›¹í˜ì´ì§€ ìš”ì²­
url = "êµì´Œì¹˜í‚¨ ë©”ë‰´ í˜ì´ì§€"
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

# ë©”ë‰´ëª… ì¶”ì¶œ
menu_items = soup.select('dl.txt dt')
menu_names = [item.text.strip() for item in menu_items]

# ê°€ê²© ì¶”ì¶œ ë° ì •ì œ
price_items = soup.select('p.money strong')
prices = []
for price in price_items:
    # ì‰¼í‘œ ì œê±°í•˜ê³  ìˆ«ìë§Œ ì¶”ì¶œ
    clean_price = price.text.replace(',', '').replace('ì›', '')
    prices.append(int(clean_price))

# ë°ì´í„°í”„ë ˆì„ ìƒì„±
df = pd.DataFrame({
    'ìƒí’ˆëª…': menu_names,
    'ê°€ê²©': prices
})

# ê¸°ë³¸ í†µê³„ ê³„ì‚°
print(f"í‰ê·  ê°€ê²©: {df['ê°€ê²©'].mean():.2f}ì›")
print(f"í‘œì¤€í¸ì°¨: {df['ê°€ê²©'].std():.2f}ì›")
print(f"ìµœì €ê°€: {df['ê°€ê²©'].min()}ì›")
print(f"ìµœê³ ê°€: {df['ê°€ê²©'].max()}ì›")
```

---

## ğŸ“ 4. XML ë°ì´í„° ì²˜ë¦¬

### ğŸŒ¡ï¸ ê¸°ìƒì²­ ë‚ ì”¨ ë°ì´í„° ì˜ˆì œ
```python
import xml.etree.ElementTree as ET
import requests
from bs4 import BeautifulSoup

# XML íŒŒì¼ ì½ê¸°
with open('my.xml', 'r', encoding='utf-8') as f:
    soup = BeautifulSoup(f.read(), 'xml')

# ì•„ì´í…œ ìš”ì†Œ ì°¾ê¸°
items = soup.find_all('item')

# ë°ì´í„° ì¶”ì¶œ
data = []
for item in items:
    name = item.find('name').text
    tel = item.find('tel').text
    exam = item.find('exam').text
    data.append([name, tel, exam])

# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
df = pd.DataFrame(data, columns=['ì´ë¦„', 'ì „í™”ë²ˆí˜¸', 'ì‹œí—˜'])
```

### ğŸ”„ XMLì˜ íŠ¹ì§•
- ë¶€ëª¨-ìì‹ êµ¬ì¡°ê°€ ëª…í™•
- JSONë³´ë‹¤ ë³µì¡í•˜ì§€ë§Œ êµ¬ì¡°í™”ëœ ë°ì´í„°ì— ì í•©
- ìš”ì¦˜ì€ JSONì„ ë” ì„ í˜¸í•˜ëŠ” ì¶”ì„¸

---

## ğŸ“ 5. JSON ë°ì´í„° ì²˜ë¦¬

### ğŸ”„ JSON ì¸ì½”ë”©/ë””ì½”ë”©
```python
import json

# ë”•ì…”ë„ˆë¦¬ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜ (ì¸ì½”ë”©)
data = {'name': 'tom', 'age': 33, 'score': [90, 80, 100]}
json_string = json.dumps(data)
print(type(json_string))  # <class 'str'>

# JSON ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (ë””ì½”ë”©)
json_data = json.loads(json_string)
print(type(json_data))  # <class 'dict'>
print(json_data['name'])  # 'tom'
```

### ğŸŒ ì›¹ì—ì„œ JSON ë°ì´í„° ì½ê¸°
```python
import urllib.request
import json

# ì„œìš¸ì‹œ ë„ì„œê´€ ë°ì´í„° ì˜ˆì œ
url = "https://raw.githubusercontent.com/pykwon/python/master/seoullibtime5.json"

# ë°ì´í„° ì½ê¸°
response = urllib.request.urlopen(url)
plain_text = response.read().decode('utf-8')

# JSONìœ¼ë¡œ ë³€í™˜
json_data = json.loads(plain_text)

# ë°ì´í„° ì¶”ì¶œ
lib_data = json_data['seoulLibraryTime']['row']
for lib in lib_data:
    print(lib['LBRRY_NAME'], lib['TEL'], lib['ADRES'])

# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
df = pd.DataFrame(lib_data, columns=['LBRRY_NAME', 'TEL', 'ADRES'])
```

---

## ğŸ“ 6. ë°ì´í„° ì €ì¥ ë°©ë²•

### ğŸ’¾ ë‹¤ì–‘í•œ ì €ì¥ í˜•ì‹
```python
# CSV ì €ì¥
df.to_csv('weather.csv', index=False, encoding='utf-8')

# Excel ì €ì¥
df.to_excel('weather.xlsx', index=False)

# JSON ì €ì¥
df.to_json('weather.json', orient='records')

# ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
df.to_sql('weather_table', connection, if_exists='replace')
```

---

## ğŸ“ 7. ë°ì´í„° ë¶„ì„ ì›Œí¬í”Œë¡œìš°

### ğŸ”„ ì™„ì „í•œ í”„ë¡œì„¸ìŠ¤
```python
# 1. ë°ì´í„° ìˆ˜ì§‘ (ì›¹ ìŠ¤í¬ë˜í•‘)
url = "ë°ì´í„° ì†ŒìŠ¤ URL"
soup = BeautifulSoup(requests.get(url).text, 'html.parser')

# 2. ë°ì´í„° ì¶”ì¶œ ë° ì •ì œ
raw_data = soup.select('ì›í•˜ëŠ” ì„ íƒì')
clean_data = [item.text.strip() for item in raw_data]

# 3. ë°ì´í„°í”„ë ˆì„ ìƒì„±
df = pd.DataFrame(clean_data, columns=['ì»¬ëŸ¼ëª…'])

# 4. ê¸°ë³¸ ë¶„ì„
print(df.info())
print(df.describe())

# 5. ì¡°ê±´ í•„í„°ë§
filtered_df = df[df['ì˜¨ë„'] >= 30]

# 6. ì •ë ¬
sorted_df = df.sort_values(by='ì˜¨ë„', ascending=False)

# 7. ê²°ê³¼ ì €ì¥
df.to_csv('result.csv', index=False)
```

---

## ğŸ¯ í•µì‹¬ ë©”ì‹œì§€

### ğŸ’¡ ê°•ì˜ì˜ í•µì‹¬ í¬ì¸íŠ¸
1. **ì›¹ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²ƒì´ ëª©í‘œ**
2. **ìµœì¢…ì ìœ¼ë¡œëŠ” ëª¨ë“  ë°ì´í„°ë¥¼ pandas DataFrameìœ¼ë¡œ ë³€í™˜**
3. **DataFrameì—ë§Œ ë„£ìœ¼ë©´ pandasì˜ ëª¨ë“  ê¸°ëŠ¥ í™œìš© ê°€ëŠ¥**
4. **ë°ì´í„° ìˆ˜ì§‘(ETL)ì´ ë°ì´í„° ë¶„ì„ì—ì„œ ê°€ì¥ ì‹œê°„ê³¼ ë¹„ìš©ì´ ë§ì´ ë“œëŠ” ë¶€ë¶„**

### ğŸ”® ë‹¤ìŒ ë‹¨ê³„
- **ì‹œê°í™”**: matplotlibì„ ì´ìš©í•œ ë°ì´í„° ì‹œê°í™”
- **ê³ ê¸‰ ë¶„ì„**: í†µê³„ ë¶„ì„, ë¨¸ì‹ ëŸ¬ë‹
- **ì›¹ ê°œë°œ**: Djangoë¥¼ ì´ìš©í•œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•

### ğŸš€ ì‹¤ë¬´ ì ìš©
- ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬ì¶•
- ì •ê¸°ì ì¸ ë°ì´í„° ëª¨ë‹ˆí„°ë§
- ìë™í™”ëœ ë¦¬í¬íŠ¸ ìƒì„±
- ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ

---

## âš¡ ìš”ì•½

ì´ ê°•ì˜ëŠ” **ì›¹ ìŠ¤í¬ë˜í•‘ â†’ ë°ì´í„° ì •ì œ â†’ pandas ì²˜ë¦¬ â†’ ë¶„ì„/ì €ì¥**ì˜ ì™„ì „í•œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ ë‹¤ë£¨ë©°, ì‹¤ë¬´ì—ì„œ ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì‹¤ì „ ê¸°ìˆ ì„ ì œê³µí•©ë‹ˆë‹¤.
