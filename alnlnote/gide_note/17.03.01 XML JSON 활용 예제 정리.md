# 17.03 XML JSON 활용 예제

> **강의 연계**: 웹 크롤링 강의 내용을 바탕으로 한 실전 활용 예제  
> **목표**: XML과 JSON 데이터를 pandas로 효과적으로 처리하는 방법 마스터  
> **난이도**: ⭐⭐⭐ (중급)

---

## 🎯 학습 목표

- XML과 JSON의 실무 활용 패턴 익히기
- 다양한 공공 API 데이터 처리 방법 학습
- 복잡한 중첩 구조 데이터 정제 기술 습득
- 실시간 데이터 수집 및 분석 파이프라인 구축

---

## 📊 예제 1: 기상청 XML 데이터 고급 활용

### 🌡️ 실시간 날씨 데이터 분석 시스템

```python
import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json

class 실시간날씨분석기:
    def __init__(self):
        self.기상청_xml_url = "http://www.kma.go.kr/XML/weather/sfc_web_map.xml"
        self.데이터히스토리 = []
    
    def 실시간_날씨수집(self):
        """기상청 XML에서 실시간 날씨 데이터 수집"""
        try:
            response = requests.get(self.기상청_xml_url, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'xml')
            locals = soup.find_all("local")
            
            날씨데이터 = []
            for local in locals:
                지역명 = local.text.strip()
                온도 = float(local.get("ta", 0))
                습도 = int(local.get("hm", 0))
                풍속 = float(local.get("ws", 0))
                
                날씨데이터.append({
                    '수집시간': datetime.now(),
                    '지역': 지역명,
                    '온도': 온도,
                    '습도': 습도,
                    '풍속': 풍속
                })
            
            df = pd.DataFrame(날씨데이터)
            self.데이터히스토리.append(df)
            
            return df
            
        except Exception as e:
            print(f"❌ 날씨 데이터 수집 실패: {e}")
            return None
    
    def 지역별_온도분석(self, df):
        """지역별 온도 통계 분석"""
        분석결과 = df.groupby('지역').agg({
            '온도': ['mean', 'max', 'min', 'std'],
            '습도': 'mean',
            '풍속': 'mean'
        }).round(2)
        
        # 컬럼명 정리
        분석결과.columns = ['평균온도', '최고온도', '최저온도', '온도편차', '평균습도', '평균풍속']
        
        return 분석결과.reset_index()
    
    def 이상기후_탐지(self, df):
        """이상 기후 패턴 탐지"""
        # Z-score를 이용한 이상치 탐지
        df['온도_z점수'] = np.abs((df['온도'] - df['온도'].mean()) / df['온도'].std())
        
        이상지역 = df[df['온도_z점수'] > 2].copy()
        이상지역['이상유형'] = '극한온도'
        
        return 이상지역[['지역', '온도', '이상유형']]

# 실행 예제
날씨분석 = 실시간날씨분석기()
현재날씨 = 날씨분석.실시간_날씨수집()

if 현재날씨 is not None:
    print("🌡️ 실시간 날씨 데이터 (상위 5개 지역)")
    print(현재날씨.head())
    
    print("\n📊 지역별 온도 분석")
    지역분석 = 날씨분석.지역별_온도분석(현재날씨)
    print(지역분석.head())
    
    print("\n⚠️ 이상 기후 지역 탐지")
    이상지역 = 날씨분석.이상기후_탐지(현재날씨)
    print(이상지역)
```

---

## 🏛️ 예제 2: 공공 API JSON 데이터 마스터

### 📚 서울시 열린데이터 종합 분석

```python
class 서울시데이터분석기:
    def __init__(self):
        self.도서관_api = "https://raw.githubusercontent.com/pykwon/python/master/seoullibtime5.json"
        self.분석결과 = {}
    
    def 도서관_데이터_수집(self):
        """서울시 도서관 JSON 데이터 수집 및 정제"""
        try:
            response = requests.get(self.도서관_api)
            response.raise_for_status()
            
            json_data = response.json()
            
            # 중첩된 JSON 구조 파싱
            library_data = json_data['seoulLibraryTime']['row']
            
            # DataFrame으로 변환
            df = pd.DataFrame(library_data)
            
            # 데이터 정제
            df['ADRES'] = df['ADRES'].str.strip()  # 주소 공백 제거
            df['TEL'] = df['TEL'].str.replace(r'[^\d-]', '', regex=True)  # 전화번호 정제
            
            # 구별 정보 추출
            df['구'] = df['ADRES'].str.extract(r'([가-힣]+구)')
            
            return df
            
        except Exception as e:
            print(f"❌ 도서관 데이터 수집 실패: {e}")
            return None
    
    def 구별_도서관_분석(self, df):
        """구별 도서관 현황 분석"""
        구별통계 = df.groupby('구').agg({
            'LBRRY_NAME': 'count',
            'TEL': 'count'
        }).rename(columns={'LBRRY_NAME': '도서관수', 'TEL': '연락처보유수'})
        
        구별통계['연락처보유율'] = (구별통계['연락처보유수'] / 구별통계['도서관수'] * 100).round(1)
        
        return 구별통계.sort_values('도서관수', ascending=False)
    
    def 도서관_분포_지도데이터(self, df):
        """지도 시각화용 데이터 준비"""
        # 주소에서 구별 좌표 추출 (실제로는 geocoding API 사용)
        구별_좌표 = {
            '강남구': {'위도': 37.5173, '경도': 127.0473},
            '강동구': {'위도': 37.5301, '경도': 127.1238},
            '강북구': {'위도': 37.6398, '경도': 127.0256},
            '강서구': {'위도': 37.5509, '경도': 126.8495},
            # ... 더 많은 구 데이터
        }
        
        구별통계 = self.구별_도서관_분석(df)
        
        지도데이터 = []
        for 구명, 통계 in 구별통계.iterrows():
            if 구명 in 구별_좌표:
                지도데이터.append({
                    '구': 구명,
                    '도서관수': 통계['도서관수'],
                    '위도': 구별_좌표[구명]['위도'],
                    '경도': 구별_좌표[구명]['경도']
                })
        
        return pd.DataFrame(지도데이터)

# 실행 예제
서울분석 = 서울시데이터분석기()
도서관df = 서울분석.도서관_데이터_수집()

if 도서관df is not None:
    print("📚 서울시 도서관 데이터 (상위 10개)")
    print(도서관df[['LBRRY_NAME', '구', 'TEL']].head(10))
    
    print("\n📊 구별 도서관 현황")
    구별현황 = 서울분석.구별_도서관_분석(도서관df)
    print(구별현황.head())
    
    print("\n🗺️ 지도 시각화용 데이터")
    지도데이터 = 서울분석.도서관_분포_지도데이터(도서관df)
    print(지도데이터)
```

---

## 🔄 예제 3: 다중 API 데이터 통합 분석

### 🌐 실시간 다중 소스 데이터 파이프라인

```python
class 통합데이터파이프라인:
    def __init__(self):
        self.데이터소스 = {
            'weather': '기상청 XML',
            'library': '서울시 도서관 JSON',
            'news': '뉴스 RSS XML'
        }
        self.통합데이터 = {}
    
    def RSS_뉴스수집(self, rss_url="https://news.google.com/rss?topic=h&hl=ko&gl=KR&ceid=KR:ko"):
        """RSS XML에서 뉴스 데이터 수집"""
        try:
            response = requests.get(rss_url)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'xml')
            items = soup.find_all('item')
            
            뉴스데이터 = []
            for item in items:
                제목 = item.title.text if item.title else ""
                링크 = item.link.text if item.link else ""
                발행일 = item.pubDate.text if item.pubDate else ""
                
                뉴스데이터.append({
                    '제목': 제목,
                    '링크': 링크,
                    '발행일': pd.to_datetime(발행일, errors='coerce')
                })
            
            return pd.DataFrame(뉴스데이터)
            
        except Exception as e:
            print(f"❌ 뉴스 데이터 수집 실패: {e}")
            return None
    
    def 통합분석_대시보드(self):
        """모든 데이터소스를 통합한 종합 분석"""
        결과 = {
            '수집시간': datetime.now(),
            '데이터소스': len(self.데이터소스),
            '분석결과': {}
        }
        
        # 날씨 데이터 분석
        날씨분석 = 실시간날씨분석기()
        날씨df = 날씨분석.실시간_날씨수집()
        if 날씨df is not None:
            결과['분석결과']['날씨'] = {
                '평균온도': 날씨df['온도'].mean(),
                '최고온도': 날씨df['온도'].max(),
                '최저온도': 날씨df['온도'].min()
            }
        
        # 도서관 데이터 분석
        서울분석 = 서울시데이터분석기()
        도서관df = 서울분석.도서관_데이터_수집()
        if 도서관df is not None:
            결과['분석결과']['도서관'] = {
                '총도서관수': len(도서관df),
                '구별분포': len(도서관df['구'].unique())
            }
        
        # 뉴스 데이터 분석
        뉴스df = self.RSS_뉴스수집()
        if 뉴스df is not None:
            결과['분석결과']['뉴스'] = {
                '최신뉴스수': len(뉴스df),
                '최신뉴스제목': 뉴스df.iloc[0]['제목'][:50] + "..."
            }
        
        return 결과
    
    def 결과_JSON저장(self, 결과, 파일명="통합분석결과.json"):
        """분석 결과를 JSON 파일로 저장"""
        # datetime 객체 직렬화를 위한 커스텀 encoder
        class DateTimeEncoder(json.JSONEncoder):
            def default(self, obj):
                if isinstance(obj, datetime):
                    return obj.isoformat()
                return super().default(obj)
        
        with open(파일명, 'w', encoding='utf-8') as f:
            json.dump(결과, f, ensure_ascii=False, indent=2, cls=DateTimeEncoder)
        
        print(f"💾 분석 결과 저장 완료: {파일명}")

# 실행 예제
파이프라인 = 통합데이터파이프라인()

print("🔄 통합 데이터 파이프라인 실행 중...")
종합결과 = 파이프라인.통합분석_대시보드()

print("\n📊 통합 분석 결과")
for 카테고리, 데이터 in 종합결과['분석결과'].items():
    print(f"\n📈 {카테고리} 분석:")
    for 항목, 값 in 데이터.items():
        print(f"   • {항목}: {값}")

# JSON으로 결과 저장
파이프라인.결과_JSON저장(종합결과)
```

---

## 🛠️ 예제 4: 고급 XML/JSON 처리 기법

### 📊 복잡한 중첩 구조 데이터 처리

```python
class 고급데이터처리기:
    def __init__(self):
        self.복잡한_json_예제 = {
            "company": {
                "name": "테크스타트업",
                "employees": [
                    {
                        "id": 1,
                        "name": "김개발",
                        "department": "개발팀",
                        "skills": ["Python", "pandas", "ML"],
                        "projects": [
                            {"name": "AI 프로젝트", "progress": 75},
                            {"name": "데이터 분석", "progress": 90}
                        ]
                    },
                    {
                        "id": 2,
                        "name": "박분석",
                        "department": "분석팀",
                        "skills": ["SQL", "Tableau", "Statistics"],
                        "projects": [
                            {"name": "대시보드 구축", "progress": 60}
                        ]
                    }
                ]
            }
        }
    
    def 중첩JSON_평면화(self, data):
        """복잡한 중첩 JSON을 평면적인 DataFrame으로 변환"""
        평면화된_데이터 = []
        
        회사명 = data['company']['name']
        직원들 = data['company']['employees']
        
        for 직원 in 직원들:
            for 프로젝트 in 직원['projects']:
                행데이터 = {
                    '회사명': 회사명,
                    '직원ID': 직원['id'],
                    '직원명': 직원['name'],
                    '부서': 직원['department'],
                    '스킬수': len(직원['skills']),
                    '주요스킬': ', '.join(직원['skills'][:2]),  # 상위 2개 스킬
                    '프로젝트명': 프로젝트['name'],
                    '진행률': 프로젝트['progress']
                }
                평면화된_데이터.append(행데이터)
        
        return pd.DataFrame(평면화된_데이터)
    
    def XML_네임스페이스_처리(self, xml_content):
        """XML 네임스페이스가 있는 복잡한 XML 처리"""
        xml_예제 = """
        <root xmlns:company="http://company.com/ns" 
              xmlns:project="http://project.com/ns">
            <company:info>
                <company:name>테크기업</company:name>
                <company:location>서울</company:location>
            </company:info>
            <project:list>
                <project:item id="1">
                    <project:name>AI 개발</project:name>
                    <project:status>진행중</project:status>
                </project:item>
            </project:list>
        </root>
        """
        
        soup = BeautifulSoup(xml_예제, 'xml')
        
        # 네임스페이스 정의
        namespaces = {
            'company': 'http://company.com/ns',
            'project': 'http://project.com/ns'
        }
        
        결과 = {
            '회사명': soup.find('name').text,
            '위치': soup.find('location').text,
            '프로젝트': []
        }
        
        프로젝트들 = soup.find_all('item')
        for 프로젝트 in 프로젝트들:
            결과['프로젝트'].append({
                'ID': 프로젝트.get('id'),
                '이름': 프로젝트.find('name').text,
                '상태': 프로젝트.find('status').text
            })
        
        return 결과

# 실행 예제
고급처리 = 고급데이터처리기()

print("🔧 고급 JSON 처리 - 중첩 구조 평면화")
평면화_결과 = 고급처리.중첩JSON_평면화(고급처리.복잡한_json_예제)
print(평면화_결과)

print("\n🔧 고급 XML 처리 - 네임스페이스 처리")
xml_결과 = 고급처리.XML_네임스페이스_처리("")
print(f"회사: {xml_결과['회사명']} ({xml_결과['위치']})")
for 프로젝트 in xml_결과['프로젝트']:
    print(f"프로젝트: {프로젝트['이름']} - {프로젝트['상태']}")
```

---

## 🎓 실무 활용 팁

### 💡 XML vs JSON 선택 가이드

| 상황 | 추천 형식 | 이유 |
|------|-----------|------|
| 웹 API | JSON | 가볍고 파싱 빠름 |
| 정부 공공데이터 | XML | 스키마 검증 필요 |
| 설정 파일 | JSON | 가독성 좋음 |
| 문서 구조 | XML | 복잡한 구조 표현 |

### 🚨 주의사항

1. **인코딩 문제**
   ```python
   # 한글 데이터 처리시 주의
   response = requests.get(url)
   response.encoding = 'utf-8'  # 명시적 인코딩 설정
   ```

2. **메모리 관리**
   ```python
   # 대용량 XML/JSON 처리시
   import gc
   
   def 대용량_처리():
       # 데이터 처리
       gc.collect()  # 메모리 정리
   ```

3. **에러 처리**
   ```python
   try:
       data = json.loads(response.text)
   except json.JSONDecodeError as e:
       print(f"JSON 파싱 오류: {e}")
       # 대안 처리 로직
   ```

---

## 🚀 도전 과제

### 🎯 미니 프로젝트: "실시간 서울 생활 정보 대시보드"

**목표**: 다양한 공공 API를 활용하여 실시간 서울 생활 정보 제공

**요구사항**:
1. 날씨 정보 (XML)
2. 도서관 현황 (JSON)  
3. 지하철 실시간 도착 정보 (XML)
4. 공공자전거 대여소 현황 (JSON)

**구현 포인트**:
- 30분마다 자동 데이터 수집
- pandas DataFrame으로 데이터 통합
- 간단한 HTML 대시보드 생성
- JSON 파일로 결과 저장

이 프로젝트를 완성하면 XML과 JSON 처리의 실무 전문가가 됩니다! 🎓

---

## 📚 참고 자료

- **BeautifulSoup 공식 문서**: https://www.crummy.com/software/BeautifulSoup/
- **pandas JSON 정규화**: pd.json_normalize() 활용법
- **공공데이터 포털**: https://data.go.kr (무료 API 제공)
- **서울 열린데이터 광장**: https://data.seoul.go.kr
