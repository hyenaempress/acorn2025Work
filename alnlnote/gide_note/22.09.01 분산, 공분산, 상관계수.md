# 22.09 분산, 공분산, 상관계수 완전 가이드
*변수들 사이의 숨겨진 관계를 발견하는 통계의 핵심 도구*

---

## 🎯 왜 분산, 공분산, 상관계수를 배워야 할까?

**비율검정**에서는 개별 집단의 특성을 비교했다면, 이제는 **변수들이 서로 어떻게 연관되어 있는지**를 파악해야 합니다. 이것이 바로 **회귀분석과 머신러닝의 출발점**입니다!

### 🔍 핵심 질문들
- 키가 클수록 몸무게도 무거워질까? 🏃‍♂️
- 광고비를 많이 쓸수록 매출이 늘어날까? 💰
- 공부 시간과 성적은 정말 비례할까? 📚

> 💡 **핵심**: 개별 변수의 특성(분산)에서 시작해서, 두 변수의 관계(공분산), 그리고 관계의 강도(상관계수)까지 단계별로 이해해보겠습니다!

---

## 📊 1. 분산(Variance): 데이터가 얼마나 흩어져 있는가?

### 🎯 분산이란?

**분산**은 데이터가 평균에서 얼마나 멀리 떨어져 흩어져 있는지를 나타내는 값입니다. **데이터의 다양성**을 측정하는 핵심 지표입니다.

### 📐 분산 공식

#### **모집단 분산 (σ²)**
$$\sigma^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2$$

#### **표본 분산 (s²)**
$$s^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2$$

> ⚠️ **주의**: 표본 분산은 n-1로 나누는데, 이는 **베셀의 보정(Bessel's correction)**으로 불편추정량을 만들기 위함입니다.

### 💻 Python으로 분산 실습

```python
import numpy as np
import matplotlib.pyplot as plt

print("📊 분산의 개념 이해하기")
print("=" * 50)

# 두 가지 다른 분산을 가진 데이터셋 생성
np.random.seed(42)
data1 = np.random.normal(50, 5, 100)   # 평균 50, 표준편차 5 (분산 25)
data2 = np.random.normal(50, 15, 100)  # 평균 50, 표준편차 15 (분산 225)

print(f"📈 데이터셋 1:")
print(f"   • 평균: {np.mean(data1):.2f}")
print(f"   • 분산: {np.var(data1, ddof=1):.2f}")  # ddof=1: 표본 분산
print(f"   • 표준편차: {np.std(data1, ddof=1):.2f}")

print(f"\n📈 데이터셋 2:")
print(f"   • 평균: {np.mean(data2):.2f}")
print(f"   • 분산: {np.var(data2, ddof=1):.2f}")
print(f"   • 표준편차: {np.std(data2, ddof=1):.2f}")

# 시각화
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.hist(data1, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
plt.title(f'데이터셋 1 (분산: {np.var(data1, ddof=1):.1f})')
plt.xlabel('값')
plt.ylabel('빈도')
plt.axvline(np.mean(data1), color='red', linestyle='--', label=f'평균: {np.mean(data1):.1f}')
plt.legend()

plt.subplot(1, 2, 2)
plt.hist(data2, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')
plt.title(f'데이터셋 2 (분산: {np.var(data2, ddof=1):.1f})')
plt.xlabel('값')
plt.ylabel('빈도')
plt.axvline(np.mean(data2), color='red', linestyle='--', label=f'평균: {np.mean(data2):.1f}')
plt.legend()

plt.tight_layout()
plt.show()
```

### 🎯 분산의 의미

| 분산 크기 | 의미 | 시각적 특징 |
|---------|------|------------|
| **작은 분산** | 데이터가 평균 근처에 모여있음 | 좁고 높은 분포 |
| **큰 분산** | 데이터가 평균에서 멀리 퍼져있음 | 넓고 낮은 분포 |

---

## 📈 2. 공분산(Covariance): 두 변수가 함께 움직이는 패턴

### 🎯 공분산이란?

**공분산**은 두 변수의 변화가 서로 어떤 방향으로 관련되어 있는지 나타내는 값입니다. **"함께 변한다"**의 정도를 측정합니다.

### 📐 공분산 공식

$$\text{Cov}(X, Y) = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})$$

### 🔍 공분산의 해석

| 공분산 값 | 의미 | 관계 |
|---------|------|------|
| **양수 (+)** | 같은 방향으로 움직임 | X 증가 → Y 증가 |
| **음수 (-)** | 반대 방향으로 움직임 | X 증가 → Y 감소 |
| **0에 가까움** | 선형적 관계 없음 | 독립적 움직임 |

### 💻 공분산 실습: 다양한 패턴 탐색

```python
print("🔍 공분산으로 변수 간 관계 탐색하기")
print("=" * 50)

# 1. 완벽한 양의 관계: (1,2,3,4,5) vs (2,4,6,8,10)
x1 = np.arange(1, 6)
y1 = np.arange(2, 11, 2)
cov1 = np.cov(x1, y1)[0, 1]
print(f"🔗 완벽한 양의 관계:")
print(f"   X: {x1}")
print(f"   Y: {y1}")
print(f"   공분산: {cov1:.2f}")

# 2. 크기만 다른 같은 패턴
x2 = np.arange(10, 60, 10)
y2 = np.arange(20, 70, 10)
cov2 = np.cov(x2, y2)[0, 1]
print(f"\n🔗 크기만 다른 같은 패턴:")
print(f"   X: {x2}")
print(f"   Y: {y2}")
print(f"   공분산: {cov2:.2f}")

# 3. 더 큰 크기의 같은 패턴
x3 = np.arange(100, 600, 100)
y3 = np.arange(200, 700, 100)
cov3 = np.cov(x3, y3)[0, 1]
print(f"\n🔗 더 큰 크기의 같은 패턴:")
print(f"   X: {x3}")
print(f"   Y: {y3}")
print(f"   공분산: {cov3:.2f}")

# 4. 한 변수가 일정할 때
x4 = np.arange(1, 6)
y4 = np.array([3, 3, 3, 3, 3])
cov4 = np.cov(x4, y4)[0, 1]
print(f"\n🔗 한 변수가 일정할 때:")
print(f"   X: {x4}")
print(f"   Y: {y4}")
print(f"   공분산: {cov4:.2f}")

# 5. 완벽한 음의 관계
x5 = np.arange(1, 6)
y5 = np.arange(6, 1, -1)
cov5 = np.cov(x5, y5)[0, 1]
print(f"\n🔗 완벽한 음의 관계:")
print(f"   X: {x5}")
print(f"   Y: {y5}")
print(f"   공분산: {cov5:.2f}")

print(f"\n💡 공분산의 한계:")
print(f"   → 같은 패턴이지만 크기에 따라 공분산 값이 달라짐")
print(f"   → 단위의 영향을 받아서 관계의 강도 비교가 어려움")
print(f"   → 이를 해결하기 위해 상관계수를 사용!")
```

---

## 📏 3. 상관계수(Correlation Coefficient): 관계의 강도를 표준화

### 🎯 상관계수란?

**상관계수**는 공분산을 표준화한 값으로, 두 변수 사이의 **선형적 관계의 강도와 방향**을 -1에서 1 사이의 값으로 나타냅니다.

### 📐 상관계수 공식 (피어슨 상관계수)

$$r = \frac{\text{Cov}(X, Y)}{\sigma_X \sigma_Y} = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2} \sqrt{\sum_{i=1}^{n}(y_i - \bar{y})^2}}$$

### 🎯 상관계수의 해석

| 상관계수 범위 | 관계의 강도 | 의미 |
|--------------|-----------|------|
| **0.9 ≤ \|r\| ≤ 1.0** | 매우 강한 관계 | 거의 직선적 관계 |
| **0.7 ≤ \|r\| < 0.9** | 강한 관계 | 뚜렷한 선형 관계 |
| **0.5 ≤ \|r\| < 0.7** | 중간 관계 | 적당한 선형 관계 |
| **0.3 ≤ \|r\| < 0.5** | 약한 관계 | 약한 선형 관계 |
| **\|r\| < 0.3** | 매우 약한 관계 | 거의 관계 없음 |

### 💻 상관계수 실습: 실제 데이터 분석

```python
print("📊 실제 데이터로 공분산과 상관계수 비교하기")
print("=" * 60)

# 실제 데이터 예시
x = [8, 3, 6, 6, 9, 4, 3, 9, 3, 4]  # x 데이터
y = [60, 20, 40, 60, 90, 50, 10, 80, 40, 50]  # y 데이터

print(f"📈 기본 통계량:")
print(f"   X 평균: {np.mean(x):.2f}, 분산: {np.var(x, ddof=1):.2f}")
print(f"   Y 평균: {np.mean(y):.2f}, 분산: {np.var(y, ddof=1):.2f}")

# 공분산 계산
covariance_matrix = np.cov(x, y)
covariance = covariance_matrix[0, 1]
print(f"\n🔗 공분산:")
print(f"   전체 공분산 행렬:")
print(covariance_matrix)
print(f"   X, Y 공분산: {covariance:.2f}")

# 상관계수 계산
correlation_matrix = np.corrcoef(x, y)
correlation = correlation_matrix[0, 1]
print(f"\n📏 상관계수:")
print(f"   전체 상관계수 행렬:")
print(correlation_matrix)
print(f"   X, Y 상관계수: {correlation:.4f}")

# 관계 강도 해석
if abs(correlation) >= 0.9:
    strength = "매우 강한"
elif abs(correlation) >= 0.7:
    strength = "강한"
elif abs(correlation) >= 0.5:
    strength = "중간"
elif abs(correlation) >= 0.3:
    strength = "약한"
else:
    strength = "매우 약한"

direction = "양의" if correlation > 0 else "음의"
print(f"\n🎯 해석:")
print(f"   {direction} {strength} 선형 관계")

# 시각화
plt.figure(figsize=(10, 6))
plt.scatter(x, y, color='red', s=100, alpha=0.7, edgecolors='black')
plt.xlabel('X')
plt.ylabel('Y')
plt.title(f'X와 Y의 관계 (상관계수: {correlation:.4f})')

# 회귀선 추가
z = np.polyfit(x, y, 1)
p = np.poly1d(z)
plt.plot(x, p(x), "r--", alpha=0.8, linewidth=2)

plt.grid(True, alpha=0.3)
plt.show()
```

### ⚠️ 상관계수의 한계: 비선형 관계

```python
print("⚠️ 상관계수의 한계: 비선형 관계에서는 주의!")
print("=" * 60)

# 비선형 관계 예시 (포물선)
m = np.array([-3, -2, -1, 0, 1, 2, 3])  # x 값
n = np.array([9, 4, 1, 0, 1, 4, 9])     # y = x²

nonlinear_corr = np.corrcoef(m, n)[0, 1]
print(f"📊 비선형 데이터:")
print(f"   X: {m}")
print(f"   Y: {n} (Y = X²)")
print(f"   상관계수: {nonlinear_corr:.4f}")
print(f"   → 완벽한 함수 관계임에도 상관계수는 0에 가까움!")

# 시각화
plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
plt.scatter(m, n, color='blue', s=100, alpha=0.7, edgecolors='black')
plt.xlabel('X')
plt.ylabel('Y')
plt.title(f'비선형 관계 (r = {nonlinear_corr:.4f})')
plt.grid(True, alpha=0.3)

# 곡선 맞추기
x_smooth = np.linspace(-3, 3, 100)
y_smooth = x_smooth ** 2
plt.plot(x_smooth, y_smooth, 'r--', alpha=0.8, linewidth=2)

plt.subplot(1, 2, 2)
# 선형 관계와 비교
linear_x = np.array([1, 2, 3, 4, 5])
linear_y = np.array([2, 4, 6, 8, 10])
linear_corr = np.corrcoef(linear_x, linear_y)[0, 1]

plt.scatter(linear_x, linear_y, color='green', s=100, alpha=0.7, edgecolors='black')
plt.xlabel('X')
plt.ylabel('Y')
plt.title(f'선형 관계 (r = {linear_corr:.4f})')
plt.grid(True, alpha=0.3)

# 직선 맞추기
z = np.polyfit(linear_x, linear_y, 1)
p = np.poly1d(z)
plt.plot(linear_x, p(linear_x), "g--", alpha=0.8, linewidth=2)

plt.tight_layout()
plt.show()

print(f"\n💡 핵심 포인트:")
print(f"   • 상관계수는 선형 관계만 측정")
print(f"   • 비선형 관계는 다른 방법 필요 (예: 스피어만 상관계수)")
print(f"   • 항상 산점도와 함께 해석!")
```

---

## 🏥 4. 실무 프로젝트: 음용수 만족도 분석

### 🎯 프로젝트 개요

실제 음용수 만족도 데이터를 사용하여 **친밀도, 적절성, 만족도** 간의 관계를 분석해보겠습니다.

### 💻 완전한 실습 코드

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pandas.plotting import scatter_matrix
import seaborn as sns

plt.rc('font', family='Malgun Gothic')  # 한글 폰트 설정

print("🏥 음용수 만족도 상관관계 분석 프로젝트")
print("=" * 60)

# 데이터 로딩
url = "https://raw.githubusercontent.com/pykwon/python/refs/heads/master/testdata_utf8/drinking_water.csv"
data = pd.read_csv(url)

print("📊 데이터 기본 정보:")
print(data.head(3))
print(f"\n📈 데이터 요약 통계:")
print(data.describe())

# 표준편차 비교
print(f"\n📏 각 변수의 산포도 (표준편차):")
print(f"   친밀도: {np.std(data.친밀도, ddof=1):.4f}")
print(f"   적절성: {np.std(data.적절성, ddof=1):.4f}")
print(f"   만족도: {np.std(data.만족도, ddof=1):.4f}")

# 공분산 분석
print(f"\n🔗 공분산 분석:")
print("개별 공분산:")
cov_친밀_적절 = np.cov(data.친밀도, data.적절성)[0, 1]
cov_친밀_만족 = np.cov(data.친밀도, data.만족도)[0, 1]
cov_적절_만족 = np.cov(data.적절성, data.만족도)[0, 1]

print(f"   친밀도 ↔ 적절성: {cov_친밀_적절:.4f}")
print(f"   친밀도 ↔ 만족도: {cov_친밀_만족:.4f}")
print(f"   적절성 ↔ 만족도: {cov_적절_만족:.4f}")

print(f"\n전체 공분산 행렬:")
print(data.cov())

# 상관계수 분석
print(f"\n📏 상관계수 분석:")
print("개별 상관계수:")
corr_친밀_적절 = np.corrcoef(data.친밀도, data.적절성)[0, 1]
corr_친밀_만족 = np.corrcoef(data.친밀도, data.만족도)[0, 1]
corr_적절_만족 = np.corrcoef(data.적절성, data.만족도)[0, 1]

print(f"   친밀도 ↔ 적절성: {corr_친밀_적절:.4f}")
print(f"   친밀도 ↔ 만족도: {corr_친밀_만족:.4f}")
print(f"   적절성 ↔ 만족도: {corr_적절_만족:.4f}")

print(f"\n전체 상관계수 행렬:")
correlation_matrix = data.corr()
print(correlation_matrix)

# 다양한 상관계수 방법 비교
print(f"\n🔍 상관계수 방법별 비교:")
print("피어슨 (등간/비율 척도):")
print(data.corr(method='pearson'))

print(f"\n스피어만 (서열 척도):")
print(data.corr(method='spearman'))

print(f"\n켄달 (서열 척도):")
print(data.corr(method='kendall'))

# 만족도 기준 상관관계 순위
print(f"\n🏆 만족도에 가장 영향을 주는 요인:")
satisfaction_corr = correlation_matrix['만족도'].sort_values(ascending=False)
print(satisfaction_corr)

# 해석
print(f"\n🎯 분석 결과 해석:")
print(f"   1위: 적절성 (r = {satisfaction_corr['적절성']:.4f}) - 강한 양의 상관관계")
print(f"   2위: 친밀도 (r = {satisfaction_corr['친밀도']:.4f}) - 중간 양의 상관관계")
print(f"   → 음용수 만족도 향상을 위해서는 '적절성' 개선이 가장 중요!")
```

### 📊 시각화: 관계를 눈으로 확인하기

```python
# 시각화 구성
plt.figure(figsize=(15, 12))

# 1. 개별 산점도
plt.subplot(2, 3, 1)
plt.scatter(data.만족도, data.적절성, alpha=0.6, color='red')
plt.xlabel('만족도')
plt.ylabel('적절성')
plt.title(f'만족도 vs 적절성 (r = {corr_적절_만족:.3f})')
plt.grid(True, alpha=0.3)

plt.subplot(2, 3, 2)
plt.scatter(data.친밀도, data.만족도, alpha=0.6, color='blue')
plt.xlabel('친밀도')
plt.ylabel('만족도')
plt.title(f'친밀도 vs 만족도 (r = {corr_친밀_만족:.3f})')
plt.grid(True, alpha=0.3)

plt.subplot(2, 3, 3)
plt.scatter(data.친밀도, data.적절성, alpha=0.6, color='green')
plt.xlabel('친밀도')
plt.ylabel('적절성')
plt.title(f'친밀도 vs 적절성 (r = {corr_친밀_적절:.3f})')
plt.grid(True, alpha=0.3)

# 2. 상관계수 히트맵
plt.subplot(2, 3, 4)
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
            square=True, fmt='.3f')
plt.title('상관계수 히트맵')

# 3. 만족도 기준 막대 그래프
plt.subplot(2, 3, 5)
satisfaction_corr_sorted = satisfaction_corr.drop('만족도')  # 자기 자신 제외
colors = ['red' if x > 0.5 else 'orange' for x in satisfaction_corr_sorted.values]
plt.bar(satisfaction_corr_sorted.index, satisfaction_corr_sorted.values, color=colors, alpha=0.7)
plt.title('만족도 기준 상관계수')
plt.ylabel('상관계수')
plt.xticks(rotation=45)
plt.grid(axis='y', alpha=0.3)

# 4. 산점도 행렬
plt.subplot(2, 3, 6)
# 이 부분은 별도 그래프로 그릴 예정

plt.tight_layout()
plt.show()

# 산점도 행렬 (별도 그래프)
attr = ['친밀도', '적절성', '만족도']
scatter_matrix(data[attr], figsize=(10, 8), alpha=0.6, diagonal='hist')
plt.suptitle('변수 간 산점도 행렬', y=0.95, fontsize=14)
plt.show()
```

---

## 🌏 5. 고급 프로젝트: 외국인 관광객 상관관계 분석

### 🎯 프로젝트 개요

서울시 주요 관광지에 대한 **외국인 입국 수**와 **관광지 방문객 수** 간의 상관관계를 분석해보겠습니다.

### 💻 실무급 데이터 분석 프로젝트

```python
import matplotlib.pyplot as plt
import json
import pandas as pd
import numpy as np

plt.rc("font", family="Malgun Gothic")

def analyze_tourism_correlation():
    """외국인 관광객 상관관계 분석 메인 함수"""
    
    print("🌏 외국인 대상 국내 주요 관광지 방문 상관관계 분석")
    print("=" * 80)
    
    # 데이터 로딩 함수들 (실제 환경에서는 파일 경로 수정 필요)
    def load_tourism_data():
        """관광지 데이터 로딩 (예시 데이터로 대체)"""
        # 실제 데이터 구조를 시뮬레이션
        dates = pd.date_range('2011-01', '2016-12', freq='M')
        tourist_spots = ['경복궁', '창덕궁', '덕수궁', '창경궁', '종묘']
        
        data = []
        np.random.seed(42)
        for date in dates:
            for spot in tourist_spots:
                visitors = np.random.randint(1000, 5000)
                data.append([date.strftime('%Y%m'), spot, visitors])
        
        return pd.DataFrame(data, columns=['yyyymm', 'resNm', 'ForNum'])
    
    def load_country_data(country_name):
        """국가별 방문객 데이터 로딩 (예시 데이터)"""
        dates = pd.date_range('2011-01', '2016-12', freq='M')
        
        # 국가별 기본 방문객 수 설정
        base_visitors = {
            'china': 100000,
            'japan': 80000,
            'usa': 50000
        }
        
        data = []
        np.random.seed(42)
        for date in dates:
            base = base_visitors[country_name]
            visitors = np.random.randint(int(base * 0.8), int(base * 1.2))
            data.append([date.strftime('%Y%m'), visitors])
        
        return pd.DataFrame(data, columns=['yyyymm', f'{country_name}'])
    
    # 데이터 로딩
    print("📁 데이터 로딩 중...")
    tour_table = load_tourism_data()
    tour_table = tour_table.set_index('yyyymm')
    
    china_table = load_country_data('china').set_index('yyyymm')
    japan_table = load_country_data('japan').set_index('yyyymm')
    usa_table = load_country_data('usa').set_index('yyyymm')
    
    # 데이터 병합
    all_table = pd.merge(china_table, japan_table, left_index=True, right_index=True)
    all_table = pd.merge(all_table, usa_table, left_index=True, right_index=True)
    
    print(f"✅ 데이터 로딩 완료")
    print(f"   관광지 데이터: {tour_table.shape}")
    print(f"   외국인 방문 데이터: {all_table.shape}")
    
    # 관광지 목록
    tourist_spots = tour_table.resNm.unique()
    print(f"   분석 대상 관광지: {list(tourist_spots[:5])}")
    
    return tour_table, all_table, tourist_spots

def create_correlation_analysis(tour_table, all_table, spot_name):
    """특정 관광지의 상관관계 분석"""
    
    # 특정 관광지 데이터 추출
    spot_data = tour_table[tour_table.resNm == spot_name]
    
    # 데이터 병합
    merged_data = pd.merge(spot_data, all_table, left_index=True, right_index=True)
    
    if len(merged_data) == 0:
        print(f"⚠️ {spot_name}에 대한 데이터가 없습니다.")
        return None
    
    # 상관계수 계산
    corr_china = merged_data['china'].corr(merged_data['ForNum'])
    corr_japan = merged_data['japan'].corr(merged_data['ForNum'])
    corr_usa = merged_data['usa'].corr(merged_data['ForNum'])
    
    print(f"\n🏛️ {spot_name} 상관관계 분석:")
    print(f"   중국 입국수 ↔ 방문객수: r = {corr_china:.4f}")
    print(f"   일본 입국수 ↔ 방문객수: r = {corr_japan:.4f}")
    print(f"   미국 입국수 ↔ 방문객수: r = {corr_usa:.4f}")
    
    # 시각화
    fig = plt.figure(figsize=(15, 5))
    fig.suptitle(f'{spot_name} 상관관계 분석', fontsize=16, fontweight='bold')
    
    countries = ['china', 'japan', 'usa']
    country_names = ['중국', '일본', '미국']
    colors = ['red', 'blue', 'green']
    correlations = [corr_china, corr_japan, corr_usa]
    
    for i, (country, name, color, corr) in enumerate(zip(countries, country_names, colors, correlations)):
        plt.subplot(1, 3, i+1)
        plt.scatter(merged_data[country], merged_data['ForNum'], 
                   alpha=0.7, s=30, c=color, edgecolors='black', linewidth=0.5)
        plt.xlabel(f'{name}인 입국수')
        plt.ylabel(f'{name}인 입장객수')
        plt.title(f'r = {corr:.4f}')
        plt.grid(True, alpha=0.3)
        
        # 추세선 추가
        if not np.isnan(corr):
            z = np.polyfit(merged_data[country], merged_data['ForNum'], 1)
            p = np.poly1d(z)
            plt.plot(merged_data[country], p(merged_data[country]), 
                    color=color, linestyle='--', alpha=0.8, linewidth=2)
    
    plt.tight_layout()
    plt.show()
    
    return [spot_name, corr_china, corr_japan, corr_usa]

# 메인 실행
def main():
    # 데이터 로딩
    tour_table, all_table, tourist_spots = analyze_tourism_correlation()
    
    # 각 관광지별 상관관계 분석
    results = []
    for spot in tourist_spots[:3]:  # 처음 3개만 분석
        result = create_correlation_analysis(tour_table, all_table, spot)
        if result:
            results.append(result)
    
    # 전체 결과 요약
    if results:
        results_df = pd.DataFrame(results, columns=['관광지', '중국', '일본', '미국'])
        print(f"\n📊 전체 상관관계 분석 결과:")
        print(results_df)
        
        # 결과 시각화
        results_df_indexed = results_df.set_index('관광지')
        
        plt.figure(figsize=(12, 6))
        results_df_indexed.plot(kind='bar', width=0.8, alpha=0.8)
        plt.title('관광지별 국가별 상관계수 비교')
        plt.xlabel('관광지')
        plt.ylabel('상관계수')
        plt.legend(title='국가')
        plt.xticks(rotation=45)
        plt.grid(axis='y', alpha=0.3)
        plt.tight_layout()
        plt.show()
        
        # 분석 결과 해석
        print(f"\n🎯 주요 분석 결과:")
        for _, row in results_df.iterrows():
            spot = row['관광지']
            max_corr_country = results_df_indexed.loc[spot].idxmax()
            max_corr_value = results_df_indexed.loc[spot].max()
            print(f"   • {spot}: {max_corr_country}과 가장 강한 상관관계 (r = {max_corr_value:.3f})")

# 실행
main()
```

---

## 🎓 핵심 정리 및 다음 단계

### ✅ **분산/공분산/상관계수 마스터 체크리스트**

```python
def 학습완료_체크리스트():
    """분산/공분산/상관계수 완전 이해 체크리스트"""
    
    체크리스트 = {
        "✅ 분산 (Variance)": [
            "데이터 흩어짐의 정도 이해",
            "모집단 vs 표본 분산 구분",
            "분산과 표준편차의 관계",
            "Python으로 분산 계산"
        ],
        "✅ 공분산 (Covariance)": [
            "두 변수 함께 변화 패턴 이해",
            "양수/음수/0 값의 의미",
            "공분산의 한계점 파악",
            "단위의 영향 문제 인식"
        ],
        "✅ 상관계수 (Correlation)": [
            "공분산의 표준화 개념",
            "피어슨/스피어만/켄달 차이점",
            "상관계수 크기별 해석",
            "비선형 관계의 한계 이해"
        ],
        "✅ 실무 적용": [
            "실제 데이터셋 상관관계 분석",
            "다양한 시각화 방법 활용",
            "비즈니스 인사이트 도출",
            "다음 단계 회귀분석 연결고리 파악"
        ]
    }
    
    return 체크리스트

# 체크리스트 출력
완료항목 = 학습완료_체크리스트()
for 영역, 항목들 in 완료항목.items():
    print(f"\n{영역}:")
    for 항목 in 항목들:
        print(f"   • {항목}")
```

### 🚀 **다음 학습 단계: 최소제곱법**

```python
def 다음_학습_preview():
    """22.10 최소제곱법 미리보기"""
    
    preview = {
        "22.10 학습목표": "가장 잘 맞는 직선 찾기",
        "핵심질문": "데이터에 가장 잘 맞는 y = wx + b는?",
        "연결점": "상관계수에서 예측 모델로!",
        "학습내용": [
            "오차제곱합 최소화 원리",
            "기울기 w와 절편 b 계산",
            "회귀분석의 수학적 기초",
            "Python으로 최소제곱해 구현"
        ],
        "실무의미": "모든 예측 모델의 수학적 기초!"
    }
    
    return preview

다음단계 = 다음_학습_preview()
print("🔮 다음 학습 미리보기:")
for 항목, 내용 in 다음단계.items():
    if isinstance(내용, list):
        print(f"{항목}:")
        for 세부 in 내용:
            print(f"   • {세부}")
    else:
        print(f"{항목}: {내용}")
```

---

## 💡 최종 메시지

### 🏆 **축하합니다!**

**분산, 공분산, 상관계수**를 완전히 마스터하셨습니다! 🎉

#### **🎯 핵심 성과**
- ✅ **분산**: 데이터의 흩어짐 정도 완벽 이해
- ✅ **공분산**: 두 변수의 함께 변화 패턴 분석 마스터
- ✅ **상관계수**: 관계의 강도를 표준화하여 비교 가능
- ✅ **실무 프로젝트**: 음용수 만족도와 관광지 분석까지 완성

#### **🔗 지금까지의 여정**

```
비율검정 (개별 특성) → 분산/공분산/상관계수 (관계 분석) → 다음: 최소제곱법 (예측 기초)
```

#### **🚀 다음 목표**

이제 **"관계가 있다는 것을 아는 것"**에서 **"그 관계를 수식으로 만드는 것"**으로 진화합니다:

**상관계수 0.8** → **y = 2.3x + 5.1** (구체적 예측 공식)

**"통계는 현상을 이해하는 것에서 시작해서, 미래를 예측하는 것으로 완성됩니다. 변수들의 관계를 파악했으니, 이제 그 관계를 활용해 예측해보겠습니다!"** 🔮✨