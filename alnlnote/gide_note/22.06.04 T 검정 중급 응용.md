# 22.06.03 T검정 핵심요약 완전판

## 🚨 **왜 정규성 검정이 중요한가?** - 실무 관점

### 🎯 정규성 검정이 필요한 **진짜 이유**

많은 사람들이 "그냥 해야 하는 것"이라고 생각하지만, 실제로는 **당신의 분석 결과가 믿을 만한지**를 결정하는 핵심입니다!

#### ⚡ 실무 시나리오로 이해하기

```python
# 시나리오: 신약의 효과를 검증하는 상황
import numpy as np
import scipy.stats as stats
import matplotlib.pyplot as plt

# 상황 1: 정규분포 데이터 (이상적인 경우)
np.random.seed(42)
normal_data = np.random.normal(100, 15, 30)  # 평균 100, 표준편차 15

# 상황 2: 극단값이 있는 비정규 데이터 (현실적인 경우) 
skewed_data = np.concatenate([
    np.random.normal(100, 10, 25),  # 대부분의 환자
    [150, 160, 170, 180, 200]       # 극단적으로 반응이 좋은 5명
])

print("🔍 두 상황 비교:")
print(f"정규분포 데이터 평균: {np.mean(normal_data):.1f}")
print(f"비정규분포 데이터 평균: {np.mean(skewed_data):.1f}")
```

#### 🎭 정규성 위배 시 일어나는 일

```python
# 정규성 검정
print("\n📊 정규성 검정 결과:")
normal_p = stats.shapiro(normal_data)[1]
skewed_p = stats.shapiro(skewed_data)[1]

print(f"정규분포 데이터: p = {normal_p:.6f} {'✅ 정규성 만족' if normal_p > 0.05 else '❌ 정규성 위배'}")
print(f"비정규분포 데이터: p = {skewed_p:.6f} {'✅ 정규성 만족' if skewed_p > 0.05 else '❌ 정규성 위배'}")

# T검정 vs Wilcoxon 검정 비교
print(f"\n🎯 검정 결과 비교 (기준값: 95와 비교):")

# 정규분포 데이터
t_stat1, t_p1 = stats.ttest_1samp(normal_data, 95)
w_stat1, w_p1 = stats.wilcoxon(normal_data - 95)

print(f"정규분포 데이터:")
print(f"  T검정: p = {t_p1:.4f} {'유의함' if t_p1 < 0.05 else '유의하지 않음'}")
print(f"  Wilcoxon: p = {w_p1:.4f} {'유의함' if w_p1 < 0.05 else '유의하지 않음'}")

# 비정규분포 데이터  
t_stat2, t_p2 = stats.ttest_1samp(skewed_data, 95)
w_stat2, w_p2 = stats.wilcoxon(skewed_data - 95)

print(f"비정규분포 데이터:")
print(f"  T검정: p = {t_p2:.4f} {'유의함' if t_p2 < 0.05 else '유의하지 않음'}")
print(f"  Wilcoxon: p = {w_p2:.4f} {'유의함' if w_p2 < 0.05 else '유의하지 않음'}")
```

### 💥 **무시하면 일어나는 참사**

1. **잘못된 의사결정**: 
   - 정규성 위배된 데이터로 T검정 → 거짓 유의성 발견
   - "신약 효과 있다!" → 실제로는 극단값 몇 개 때문

2. **신뢰성 붕괴**:
   - 논문 심사에서 탈락
   - 임상시험 승인 거부  
   - 제품 출시 후 문제 발생

3. **비용 손실**:
   - 잘못된 분석으로 수억 원 투자 실패
   - 재검증에 드는 시간과 비용

### ✅ **올바른 접근법**

```python
def proper_analysis_workflow(data, reference_value=95):
    """올바른 분석 워크플로우"""
    
    print(f"📋 단계별 분석 워크플로우")
    print("-" * 40)
    
    # 1단계: 정규성 검정
    shapiro_stat, shapiro_p = stats.shapiro(data)
    print(f"1️⃣ 정규성 검정: p = {shapiro_p:.6f}")
    
    # 2단계: 적절한 검정 선택
    if shapiro_p > 0.05:
        print("✅ 정규성 만족 → T검정 사용")
        test_stat, p_value = stats.ttest_1samp(data, reference_value)
        test_name = "T검정"
    else:
        print("❌ 정규성 위배 → Wilcoxon 검정 사용")
        test_stat, p_value = stats.wilcoxon(data - reference_value)
        test_name = "Wilcoxon 검정"
    
    # 3단계: 결과 해석
    print(f"2️⃣ {test_name} 결과: p = {p_value:.6f}")
    if p_value < 0.05:
        print("✅ 통계적으로 유의한 차이 있음")
    else:
        print("❌ 통계적으로 유의한 차이 없음")
    
    # 4단계: 신뢰할 수 있는 결론
    print(f"3️⃣ 결론: 정규성 검정을 통해 적절한 방법을 선택했으므로 결과를 신뢰할 수 있음")
    
    return test_name, p_value
```

### 🔥 **핵심 메시지**

> **정규성 검정 = 당신의 분석이 믿을 만한지 확인하는 보험**
> 
> - 5분 투자로 수개월의 잘못된 분석 방지
> - 올바른 검정법 선택으로 신뢰할 수 있는 결과 확보
> - 전문성과 신뢰성을 보여주는 필수 단계

---

## 📊 **Average vs Mean, 왜 구분해야 하나?** - 실무 함정 방지

### 🎯 **둘이 다른 이유**

일반인은 "평균"이라고 하면 다 같은 것이라고 생각하지만, 통계학에서는 **상황에 따라 다른 평균**을 사용합니다!

#### ⚡ 실무 시나리오: 직원 연봉 분석

```python
# 회사 직원 연봉 데이터 (단위: 만원)
salaries = [3000, 3200, 3500, 3800, 4000, 4200, 4500, 15000]  # 마지막은 CEO

print("🏢 직원 연봉 분석:")
print(f"연봉 데이터: {salaries}")

# 1. Average (산술평균) - 일반적인 평균
average_salary = sum(salaries) / len(salaries)
print(f"\n📊 Average (산술평균): {average_salary:,.0f}만원")

# 2. Mean의 다양한 형태

# 2-1. Arithmetic Mean (산술평균) - Average와 동일
arithmetic_mean = np.mean(salaries)
print(f"📊 Arithmetic Mean: {arithmetic_mean:,.0f}만원")

# 2-2. Geometric Mean (기하평균) - 성장률, 비율 데이터에 적합
geometric_mean = stats.gmean(salaries)
print(f"📊 Geometric Mean: {geometric_mean:,.0f}만원")

# 2-3. Harmonic Mean (조화평균) - 비율의 평균
harmonic_mean = stats.hmean(salaries)
print(f"📊 Harmonic Mean: {harmonic_mean:,.0f}만원")

# 2-4. Weighted Mean (가중평균) - 중요도 반영
weights = [1, 1, 1, 1, 1, 1, 1, 0.1]  # CEO 가중치 줄임
weighted_mean = np.average(salaries, weights=weights)
print(f"📊 Weighted Mean: {weighted_mean:,.0f}만원")

# 2-5. Median (중앙값) - 극값에 영향 안 받음
median_salary = np.median(salaries)
print(f"📊 Median: {median_salary:,.0f}만원")
```

### 💥 **잘못 사용하면 일어나는 일**

#### 상황 1: 언론 보도의 함정
```python
print(f"\n📰 언론 보도 시나리오:")
print(f"'이 회사 평균 연봉 {average_salary:,.0f}만원' ← 이거 맞나요?")
print(f"실제 대부분 직원 연봉: 3000-4500만원")
print(f"→ CEO 한 명 때문에 평균이 왜곡됨!")

print(f"\n✅ 올바른 보도:")
print(f"'이 회사 직원 중간값 연봉 {median_salary:,.0f}만원'")
print(f"'평균은 {average_salary:,.0f}만원이지만 CEO 연봉 영향'")
```

#### 상황 2: 투자 수익률 분석
```python
# 월별 수익률 (%)
monthly_returns = [5, -3, 8, -2, 10, -1, 6, -4, 12]

# 잘못된 방법: 산술평균
arithmetic_return = np.mean(monthly_returns)
print(f"\n💰 투자 분석:")
print(f"산술평균 수익률: {arithmetic_return:.2f}%")

# 올바른 방법: 기하평균 (복리 고려)
# 수익률을 곱셈 형태로 변환 (5% → 1.05)
geometric_returns = [(1 + r/100) for r in monthly_returns]
geometric_return = (np.prod(geometric_returns) ** (1/len(geometric_returns)) - 1) * 100
print(f"기하평균 수익률: {geometric_return:.2f}%")
print(f"차이: {arithmetic_return - geometric_return:.2f}%p")
```

### ✅ **언제 뭘 써야 하나?**

```python
def mean_selection_guide():
    """평균 선택 가이드"""
    
    guide = {
        "📊 Arithmetic Mean (산술평균)": {
            "언제": "일반적인 상황, 대칭 분포",
            "예시": "시험 점수, 키, 몸무게",
            "주의": "극값에 민감함"
        },
        
        "📊 Geometric Mean (기하평균)": {
            "언제": "성장률, 수익률, 비율 데이터",
            "예시": "연평균 성장률, 투자 수익률",
            "주의": "음수 불가능"
        },
        
        "📊 Harmonic Mean (조화평균)": {
            "언제": "비율의 평균 (속도, 효율성)",
            "예시": "평균 속도, 가격-수익비율",
            "주의": "작은 값에 민감함"
        },
        
        "📊 Weighted Mean (가중평균)": {
            "언제": "중요도가 다를 때",
            "예시": "학점 계산, 포트폴리오 수익률",
            "주의": "가중치 설정이 중요함"
        },
        
        "📊 Median (중앙값)": {
            "언제": "극값이나 비대칭 분포",
            "예시": "부동산 가격, 연봉",
            "주의": "분포 정보 손실"
        }
    }
    
    print("🎯 평균 선택 가이드")
    print("=" * 30)
    
    for mean_type, details in guide.items():
        print(f"\n{mean_type}:")
        print(f"   언제: {details['언제']}")
        print(f"   예시: {details['예시']}")
        print(f"   주의: {details['주의']}")

mean_selection_guide()
```

### 🔥 **실무 체크포인트**

```python
def practical_checklist():
    """실무에서 확인해야 할 체크포인트"""
    
    checklist = [
        "🤔 내 데이터에 극값(outlier)이 있나?",
        "📊 분포가 대칭인가, 비대칭인가?", 
        "🎯 무엇을 측정하려는가? (절대값 vs 비율 vs 성장률)",
        "👥 보고 대상이 누구인가? (일반인 vs 전문가)",
        "⚖️ 모든 데이터가 동일한 중요도인가?"
    ]
    
    print("✅ 평균 계산 전 체크리스트")
    print("=" * 35)
    
    for item in checklist:
        print(f"   {item}")
    
    print(f"\n💡 기억하세요:")
    print("   Average ≈ 단순 산술평균")
    print("   Mean = 상황에 맞는 다양한 평균들")
    print("   → 데이터와 목적에 맞는 평균 선택이 핵심!")

practical_checklist()
```

### 🎯 **핵심 메시지**

> **Average vs Mean 구분 = 데이터 분석의 정확성과 신뢰성 확보**
> 
> - 잘못된 평균 사용 → 잘못된 결론 → 잘못된 의사결정
> - 올바른 평균 선택 → 정확한 인사이트 → 성공적인 비즈니스 결과
> - 5분의 고민으로 몇 달의 잘못된 분석 방지 가능

**이제 정규성 검정과 Average vs Mean의 진짜 중요성을 아셨죠? 단순한 이론이 아니라 실무에서 반드시 필요한 생존 기술입니다!** 🔥

---

## 📊 데이터 전처리 실무 팁

### 🔄 전치행렬(Transpose) 주의사항

```python
# ❌ 문제 상황: 결측치가 포함된 배열을 전치
data = [[1, 2], [3, np.nan], [5, 6]]  # 2x3 배열
data_t = np.array(data).T  # 3x2로 전치

# 결과: 전체 배열이 object 타입으로 변환됨!
# 숫자 연산 불가능한 상태가 됨
```

```python
# ✅ 올바른 처리 순서
# 1단계: 결측치 제거
data_clean = data.dropna()

# 2단계: 전치 수행  
data_transposed = data_clean.T

# 3단계: 필요시 숫자 타입으로 변환
data_numeric = pd.to_numeric(data_transposed)
```

### 💡 핵심 원리
- **전치행렬은 결측치나 정수나 데이터 형식을 통일하려 함**
- **결측치 포함 배열을 전치하면 → object 타입으로 변환**
- **순서: dropna() → .T → to_numeric() 권장**

---

## 🎯 가설검정 표준 절차

### 📋 완벽한 가설검정 워크플로우

```python
def perfect_hypothesis_testing(data, pop_mean=None):
    """
    완벽한 가설검정 절차
    """
    print("🔍 1단계: 정규성 검정 (Shapiro-Wilk)")
    stat, p_value = stats.shapiro(data)
    print(f"   Statistics: {stat:.6f}")
    print(f"   P-value: {p_value:.6f}")
    
    if p_value > 0.05:
        print("   ✅ 정규성 만족 → T-test 사용")
        
        # 2-1. T-test 수행
        if pop_mean is not None:
            t_stat, t_p = stats.ttest_1samp(data, pop_mean)
            print(f"\n📊 2단계: One-sample T-test")
            test_name = "T-test"
        else:
            print("   모집단 평균을 제공해주세요.")
            return
            
    else:
        print("   ❌ 정규성 위배 → Wilcoxon test 사용")
        
        # 2-2. Wilcoxon test 수행
        if pop_mean is not None:
            w_stat, w_p = stats.wilcoxon(data - pop_mean)
            t_stat, t_p = w_stat, w_p
            print(f"\n📊 2단계: Wilcoxon Signed-Rank Test")
            test_name = "Wilcoxon test"
        else:
            print("   모집단 평균을 제공해주세요.")
            return
    
    print(f"   Test Statistics: {t_stat:.6f}")
    print(f"   P-value: {t_p:.6f}")
    
    print(f"\n📈 3단계: Q-Q Plot으로 시각적 확인")
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # 히스토그램
    ax1.hist(data, bins=10, alpha=0.7, color='skyblue', edgecolor='black')
    ax1.axvline(np.mean(data), color='red', linestyle='--', 
                label=f'표본평균: {np.mean(data):.1f}')
    if pop_mean:
        ax1.axvline(pop_mean, color='green', linestyle='-', 
                    label=f'모집단평균: {pop_mean}')
    ax1.set_title('데이터 분포')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Q-Q plot
    stats.probplot(data, dist="norm", plot=ax2)
    ax2.set_title('Q-Q Plot (정규성 확인)')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print(f"\n🎯 4단계: 결론 도출 (α = 0.05)")
    if t_p < 0.05:
        print(f"   ✅ P-value({t_p:.6f}) < 0.05")
        print("   → 귀무가설 기각, 대립가설 채택")
        print("   → 통계적으로 유의한 차이가 있음")
    else:
        print(f"   ❌ P-value({t_p:.6f}) ≥ 0.05") 
        print("   → 귀무가설 채택, 대립가설 기각")
        print("   → 통계적으로 유의한 차이가 없음")
    
    return {
        'normality_test': {'statistic': stat, 'p_value': p_value},
        'main_test': {'test_name': test_name, 'statistic': t_stat, 'p_value': t_p},
        'conclusion': 'significant' if t_p < 0.05 else 'not_significant'
    }
```

---

## 📚 실습 문제 완전 분석

### 🍼 실습예제 2: 여아 신생아 몸무게 검정

#### 문제 설정
```python
# 가설 설정
# H0 (귀무가설): 여아 신생아의 몸무게 평균 = 2800g  
# H1 (대립가설): 여아 신생아의 몸무게 평균 > 2800g (단측검정)

import pandas as pd
import numpy as np
import scipy.stats as stats
import matplotlib.pyplot as plt
import seaborn as sns

# 데이터 로드
data2 = pd.read_csv('https://raw.githubusercontent.com/pykwon/python/refs/heads/master/testdata_utf8/babyboom.csv')

# 여아만 필터링 (gender == 1)
fdata = data2[data2['gender'] == 1]
print(f"여아 데이터 개수: {len(fdata)}")
print(f"평균 몸무게: {np.mean(fdata.weight):.1f}g")
print(f"표준편차: {np.std(fdata.weight):.1f}g")
```

#### 분석 결과
- **표본 크기**: 18명 (소표본)
- **표본 평균**: 3132.4g  
- **표준편차**: 613.8g
- **기존 알려진 평균**: 2800g

#### 완전한 검정 절차
```python
# 1단계: 정규성 검정
shapiro_stat, shapiro_p = stats.shapiro(fdata.weight)
print(f"Shapiro-Wilk 검정: p-value = {shapiro_p:.6f}")

if shapiro_p < 0.05:
    print("정규성 위배 → Wilcoxon 사용")
    # Wilcoxon signed-rank test
    wilcox_stat, wilcox_p = stats.wilcoxon(fdata.weight - 2800)
    print(f"Wilcoxon 결과: statistic={wilcox_stat}, p-value={wilcox_p:.6f}")
else:
    print("정규성 만족 → T-test 사용")

# T-test도 함께 수행 (비교용)
t_stat, t_p = stats.ttest_1samp(fdata.weight, popmean=2800)
print(f"T-test 결과: statistic={t_stat:.5f}, p-value={t_p:.5f}")

# 결론
print(f"\n🎯 결론:")
print(f"P-value = {t_p:.5f} < 0.05 → 귀무가설 기각")
print(f"여아 신생아의 평균 체중은 2800g보다 유의하게 증가하였다.")
```

### 💡 실습문제 1: 백열전구 수명 검정

```python
# 문제: 새로 개발된 백열전구의 수명이 300시간(250 + 50)인지 검정
# H0: μ = 300시간
# H1: μ ≠ 300시간 (양측검정)

data_bulb = [305, 280, 296, 313, 287, 240, 259, 266, 318, 280, 325, 295, 315, 278]

result = perfect_hypothesis_testing(data_bulb, pop_mean=300)

# 예상 결과: p-value > 0.05 → 귀무가설 채택
# 새로 개발된 전구의 수명은 300시간이 맞다
```

### 🖥️ 실습문제 2: 노트북 배터리 수명 검정

```python
# 노트북 평균 사용 시간이 5.2시간과 다른지 검정
# H0: μ = 5.2시간  
# H1: μ ≠ 5.2시간

# 데이터 전처리
lap_data = pd.read_csv('https://raw.githubusercontent.com/pykwon/python/refs/heads/master/testdata_utf8/one_sample.csv')

# 공백 제거 및 결측치 처리
fdata3 = lap_data['time'].replace(['     ', ""], pd.NA)
fdata3 = fdata3.dropna()
fdata3 = pd.to_numeric(fdata3)

result = perfect_hypothesis_testing(fdata3, pop_mean=5.2)

# 예상 결과: p-value < 0.05 → 귀무가설 기각
# 노트북의 사용시간은 5.2시간과 유의한 차이가 있다
```

---

## 🔧 실무 활용 팁

### 📊 엑셀 데이터 처리 실무

```python
# 엑셀 파일에서 데이터 추출 및 전처리
def process_excel_data(filename, target_value=15000):
    """
    엑셀 파일 처리 및 가설검정 수행
    """
    # 1단계: 데이터 로드
    data4 = pd.read_excel(filename)
    
    # 2단계: 전치 (행/열 바꾸기)
    data4 = data4.T
    
    # 3단계: 불필요한 행 제거
    data4 = data4.drop(['번호', '품목'], errors='ignore')
    
    # 4단계: 결측치 제거
    data4 = data4.dropna()
    
    # 5단계: 필요한 열만 선택
    data4 = data4.iloc[:, [0]]
    data4.columns = ['가격']
    
    # 6단계: 숫자 타입 변환
    price_data = pd.to_numeric(data4['가격'])
    
    # 7단계: 가설검정 수행
    result = stats.ttest_1samp(price_data, popmean=target_value)
    
    print(f"표본 평균: {np.mean(price_data):,.0f}원")
    print(f"모집단 가정 평균: {target_value:,}원")
    print(f"T-statistic: {result.statistic:.6f}")
    print(f"P-value: {result.pvalue:.6f}")
    
    return result, price_data

# 사용 예시
# result, data = process_excel_data('개인서비스지역별_동향(2025-06월)819-11시9분.xlsx')
```

---

## 🎯 핵심 암기 포인트

### 📋 가설검정 체크리스트

```python
def hypothesis_testing_checklist():
    """
    가설검정 완벽 체크리스트
    """
    checklist = {
        "1️⃣ 정규성 검정": "shapiro() 함수로 확인",
        "2️⃣ 검정 방법 선택": {
            "정규성 O": "stats.ttest_1samp() 사용",
            "정규성 X": "stats.wilcoxon() 사용"
        },
        "3️⃣ 시각적 확인": "Q-Q plot으로 종모양 확인",
        "4️⃣ 결과 해석": "p-value < 0.05면 유의함"
    }
    return checklist
```

### 🔍 정규성 검정 3단계

1. **Shapiro-Wilk 검정**: 통계적 정규성 확인
2. **Q-Q Plot**: 시각적 정규성 확인 (종모양인지)
3. **히스토그램**: 분포 모양 직관적 확인

### ⚖️ T-test vs Wilcoxon 선택 기준

| 조건 | 사용 검정 | 이유 |
|------|---------|------|
| **정규성 만족** | T-test | 모수검정, 더 강력함 |
| **정규성 위배** | Wilcoxon | 비모수검정, 가정 완화 |
| **소표본(n<30)** | 정규성 확인 필수 | 중심극한정리 적용 안됨 |
| **대표본(n≥30)** | T-test 주로 사용 | 중심극한정리로 정규성 확보 |

---

## 🏆 마스터 달성 확인

### ✅ 완벽 이해 체크리스트

- [ ] **Average vs Mean 차이 설명 가능**
- [ ] **정규성 검정 3단계 순서 암기**
- [ ] **데이터 전처리 시 전치행렬 주의사항 숙지**
- [ ] **가설검정 4단계 워크플로우 완벽 실행**
- [ ] **T-test와 Wilcoxon 선택 기준 명확히 구분**
- [ ] **Q-Q Plot 해석 능력 보유**
- [ ] **실무 데이터(CSV, Excel) 처리 능력 확보**

### 🎯 다음 단계

이제 다음과 같은 고급 주제로 넘어갈 준비가 되었습니다:

1. **독립표본 T-test**: 두 그룹 간 평균 비교
2. **대응표본 T-test**: 전후 비교 분석  
3. **ANOVA**: 3개 이상 그룹 비교
4. **카이제곱 검정**: 범주형 데이터 분석
5. **회귀분석**: 변수 간 관계 분석

---

## 💡 최종 정리

### 🎉 핵심 메시지

> **"이제부터 어떤 가설을 검정해라 하면"**
> 
> 1. **Shapiro**로 정규성 먼저 검정
> 2. **정규성 성립하면 T-test**  
> 3. **정규성 위배하면 Wilcoxon**
> 4. **Q-Q plot으로 종모양 시각적 확인**
> 
> **이 순서만 기억하면 가설검정 마스터!** 🏆

### 🚀 실무 적용 공식

```python
# 실무에서 바로 사용할 수 있는 함수
def quick_hypothesis_test(data, pop_mean, alpha=0.05):
    """원클릭 가설검정"""
    _, norm_p = stats.shapiro(data)
    
    if norm_p > alpha:
        stat, p = stats.ttest_1samp(data, pop_mean)
        method = "T-test"
    else:
        stat, p = stats.wilcoxon(data - pop_mean)  
        method = "Wilcoxon"
    
    result = "유의함" if p < alpha else "유의하지 않음"
    
    return {
        'method': method,
        'statistic': stat, 
        'p_value': p,
        'result': result
    }
```

## 🔥 독립표본 T검정 (Independent Samples T-test)

### 🎯 독립표본 T검정이란?

**서로 독립인 두 집단의 평균 차이를 검정**하는 방법입니다.

#### 핵심 개념
```python
# 독립표본 T검정의 본질
T검정 = 두 집단의 평균과 표준편차 비율에 대한 대조 검정법

t = (집단간 평균 차이) / (표준오차)
  = (X̄₁ - X̄₂) / (표준편차 비율)
```

### 📊 언제 사용하나요?

- **남녀의 성적 차이** 검정
- **A반과 B반의 점수 차이** 검정  
- **경기도와 충청도의 소득 차이** 검정
- **비 온 날과 안 온 날의 매출 차이** 검정

### ⚡ 핵심 전제조건

#### 1. 정규성 (Normality)
```python
# 정규성 검정
stats.shapiro(group1_data)
stats.shapiro(group2_data) 
# p > 0.05면 정규성 만족
```

#### 2. 등분산성 (Equal Variance)
```python
# 등분산성 검정 - Levene test (가장 일반적)
stats.levene(group1_data, group2_data)
# p > 0.05면 등분산성 만족
```

### 🔧 Python 구현

#### 등분산성 만족하는 경우
```python
# 기본 독립표본 T검정
stat, p = stats.ttest_ind(group1, group2)
print(f"T-statistic: {stat:.5f}")
print(f"P-value: {p:.5f}")
```

#### 등분산성 위배하는 경우  
```python
# Welch's T-test (등분산 가정 없음)
stat, p = stats.ttest_ind(group1, group2, equal_var=False)
print(f"Welch T-statistic: {stat:.5f}")
print(f"P-value: {p:.5f}")
```

---

## 🗃️ 데이터 병합 (Data Merging) 실무

### 📁 여러 파일 합치기

실제 업무에서는 **데이터가 여러 파일로 분산**되어 있는 경우가 많습니다.

#### 예시: 날씨와 매출 데이터 분석

```python
# 1단계: 개별 파일 로드
sales_data = pd.read_csv('t_sales.csv', dtype={'YMD': 'object'})
weather_data = pd.read_csv('t_weather.csv', dtype={'YMD': 'object'})

print(f"매출 데이터: {sales_data.shape}")    # (328, 3)  
print(f"날씨 데이터: {weather_data.shape}")   # (702, 9)

# 2단계: 날짜 형식 통일
# 매출: '2019-05-19', 날씨: '20190519' → 통일 필요

# 3단계: 공통 날짜 기준으로 병합 
merged_data = pd.merge(sales_data, weather_data, on='YMD', how='inner')

# 4단계: 필요한 컬럼만 선택
final_data = merged_data.iloc[:, [0, 1, 7, 8]]  # YMD, AMT, MAX_TEMP, SUM_RN
final_data.columns = ['날짜', '매출액', '최고기온', '강수량']
```

### 💡 데이터 변환 실무 팁

#### 범주형 변수 생성
```python
# 강수량을 이진 변수로 변환
data['rain_yn'] = (data['강수량'] > 0).astype(int)
# 또는
data['rain_yn'] = np.where(data['강수량'] > 0, 1, 0)

# 확인
print(data['rain_yn'].value_counts())
# 0: 비 안온 날
# 1: 비 온 날
```

#### 그룹 분할
```python
# 비 안온 날 매출액
no_rain_sales = data.loc[data['rain_yn'] == 0, '매출액']

# 비 온 날 매출액  
rain_sales = data.loc[data['rain_yn'] == 1, '매출액']

print(f"비 안온 날 평균: {no_rain_sales.mean():.0f}")
print(f"비 온 날 평균: {rain_sales.mean():.0f}")
```

---

## 📈 박스플롯으로 시각화

### 🎨 두 그룹 비교 시각화

```python
import matplotlib.pyplot as plt
import seaborn as sns

# 박스플롯 생성
plt.figure(figsize=(10, 6))
box_data = [no_rain_sales, rain_sales] 
labels = ['비 안온 날', '비 온 날']

bp = plt.boxplot(box_data, labels=labels, patch_artist=True,
                 showmeans=True, meanline=True)

# 박스 색깔 구분
bp['boxes'][0].set_facecolor('lightblue')   # 비 안온 날
bp['boxes'][1].set_facecolor('lightcoral')  # 비 온 날

plt.title('강수 여부에 따른 매출액 분포')
plt.ylabel('매출액')
plt.grid(True, alpha=0.3)
plt.show()

# 평균값 출력
print(f"비 안온 날 평균: {np.mean(no_rain_sales):,.0f}원")
print(f"비 온 날 평균: {np.mean(rain_sales):,.0f}원")
```

---

## 🔥 완벽한 독립표본 T검정 워크플로우

```python
def complete_independent_ttest(data, group_col, value_col, alpha=0.05):
    """
    완벽한 독립표본 T검정 실행
    """
    # 1단계: 그룹 분할
    groups = data.groupby(group_col)[value_col]
    group1 = groups.get_group(0)  # 첫 번째 그룹
    group2 = groups.get_group(1)  # 두 번째 그룹
    
    print("🔍 1단계: 기술통계")
    print(f"그룹1 (n={len(group1)}): 평균 {np.mean(group1):.2f}")
    print(f"그룹2 (n={len(group2)}): 평균 {np.mean(group2):.2f}")
    
    # 2단계: 정규성 검정
    _, p1 = stats.shapiro(group1)
    _, p2 = stats.shapiro(group2)
    print(f"\n📊 2단계: 정규성 검정")
    print(f"그룹1 p-value: {p1:.6f}")
    print(f"그룹2 p-value: {p2:.6f}")
    
    normality = (p1 > alpha) and (p2 > alpha)
    if normality:
        print("✅ 정규성 만족")
    else:
        print("❌ 정규성 위배 → 비모수 검정 고려")
    
    # 3단계: 등분산성 검정
    _, p_levene = stats.levene(group1, group2)
    print(f"\n⚖️ 3단계: 등분산성 검정")
    print(f"Levene test p-value: {p_levene:.6f}")
    
    equal_var = p_levene > alpha
    if equal_var:
        print("✅ 등분산성 만족 → 일반 T검정")
        test_name = "Independent T-test"
    else:
        print("❌ 등분산성 위배 → Welch T검정")
        test_name = "Welch's T-test"
    
    # 4단계: T검정 수행
    t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=equal_var)
    
    print(f"\n🎯 4단계: {test_name}")
    print(f"T-statistic: {t_stat:.5f}")
    print(f"P-value: {p_value:.6f}")
    
    # 5단계: 결론
    print(f"\n📋 5단계: 결론 (α = {alpha})")
    if p_value < alpha:
        print(f"✅ P-value({p_value:.6f}) < {alpha}")
        print("→ 귀무가설 기각, 두 그룹 간 유의한 차이 있음")
        conclusion = "significant"
    else:
        print(f"❌ P-value({p_value:.6f}) ≥ {alpha}")
        print("→ 귀무가설 채택, 두 그룹 간 유의한 차이 없음")
        conclusion = "not_significant"
    
    return {
        'test_name': test_name,
        'statistic': t_stat,
        'p_value': p_value,
        'conclusion': conclusion,
        'normality': normality,
        'equal_variance': equal_var
    }

# 사용 예시
result = complete_independent_ttest(data, 'rain_yn', '매출액')
```

---

## ⚠️ 실무 주의사항

### 📊 표본 크기 불균형
```python
# 문제: 그룹 크기가 너무 다른 경우
print(data['rain_yn'].value_counts())
# 0    250  (비 안온 날 - 많음)
# 1     78  (비 온 날 - 적음)

# 대안1: 층화표본추출로 균형 맞추기
# 대안2: 비모수 검정 사용
# 대안3: 표본 크기 늘리기
```

### 🎯 해석 시 주의점

1. **상관관계 ≠ 인과관계**
   - 비가 와서 매출이 줄었다 (×)
   - 비와 매출 간 연관성이 있다 (○)

2. **다른 요인 고려**
   - 강수량만으로 매출이 결정되지 않음
   - 요일, 계절, 이벤트 등 다양한 변수 존재

3. **실무적 의미 vs 통계적 유의성**
   - p < 0.05여도 실무적으로 무의미할 수 있음
   - 효과크기(Effect Size)도 함께 고려

---

## 🏆 마스터 체크리스트 업데이트

### ✅ 독립표본 T검정 완전 정복

- [ ] **독립표본 T검정의 원리 이해**
- [ ] **정규성 + 등분산성 검정 수행**  
- [ ] **일반 T검정 vs Welch T검정 구분**
- [ ] **여러 파일 병합 및 전처리 능력**
- [ ] **범주형 변수 생성 및 그룹 분할**
- [ ] **박스플롯으로 시각화**
- [ ] **완벽한 워크플로우 구현**
- [ ] **결과 해석 및 실무적 함의 도출**

### 🎯 다음 학습: 대응표본 T검정

이제 **paired samples T-test**(대응표본 T검정)로 넘어갈 준비가 완료되었습니다!

- 전후 비교 (다이어트 프로그램 효과)
- 동일 대상 반복 측정
- 짝지어진 데이터 분석

---

## 🎯 실전 문제 완전 정복

### 📝 문제 1: 포장지 색상과 매출 분석

```python
# [two-sample t 검정 : 문제1] 
# 포장지 색상에 따른 제품 매출액 차이 검정

# H0: 포장지 색상에 따른 매출액은 변동이 없다
# H1: 포장지 색상과 매출액은 관련이 있다

import numpy as np
import pandas as pd
import scipy.stats as stats
from scipy.stats import levene

blue = [70,68,82,78,81,68,67,68,88,60,80]
red = [60,65,55,58,67,59,61,68,77,66,66]

# 1단계: 등분산성 검정
leven_stat, leven_p = levene(blue, red)
print(f'등분산성 검정 - Levene 통계량: {leven_stat:.4f}, p-value: {leven_p:.4f}')
# p = 0.2487 > 0.05 → 등분산성 성립

# 2단계: 독립표본 T검정 
t_stat, p_value = stats.ttest_ind(blue, red, equal_var=True)
print(f'T검정 결과 - t통계량: {t_stat:.4f}, p-value: {p_value:.6f}')

# 결론: p = 0.0056 < 0.05 → 귀무가설 기각
# 포장지 색상과 매출액은 관련이 있다!
```

### 📝 문제 2: 성별 콜레스테롤 차이 분석

```python
# [two-sample t 검정 : 문제2] 
# 남녀 간 혈관 내 콜레스테롤 양 차이 검정

# H0: 콜레스테롤 양은 남녀 성별에 관계가 없다
# H1: 콜레스테롤 양은 남녀 성별에 관계가 있다

import random

man = [0.9,2.2,1.6,2.8,4.2,3.7,2.6,2.9,3.3,1.2,3.2,2.7,3.8,4.5,4,2.2,0.8,0.5,0.3,5.3,5.7,2.3,9.8]
woman = [1.4,2.7,2.1,1.8,3.3,3.2,1.6,1.9,2.3,2.85,2.3,1.4,2.6,3.5,2.1,6.6,7.7,8.8,6.6,6.4]

# 무작위로 15명씩 추출
sample_man = random.sample(man, 15)
sample_woman = random.sample(woman, 15)

# 등분산성 검정
leven_stat, leven_p = levene(sample_man, sample_woman)
print(f'등분산성 검정 - p-value: {leven_p:.4f}')
# p > 0.05 → 등분산성 성립

# 독립표본 T검정
t_stat, p_value = stats.ttest_ind(sample_man, sample_woman, equal_var=True)
print(f'콜레스테롤 T검정 - t: {t_stat:.4f}, p: {p_value:.4f}')

# 결론: p = 0.519 > 0.05 → 귀무가설 채택
# 콜레스테롤 수치는 성별과 관계없다
```

### 📝 문제 3: DB 연동 부서별 연봉 분석

```python
# [two-sample t 검정 : 문제3] 
# DB 데이터로 총무부 vs 영업부 연봉 차이 검정

# H0: 총무부와 영업부 직원의 연봉 격차는 없다
# H1: 총무부와 영업부 직원의 연봉은 부서에 영향받는다

import MySQLdb
import pickle
import sys

try:
    # DB 연결 설정 로드
    with open('./mymaria.dat', mode='rb') as obj:
        config = pickle.load(obj)
    
    # DB 연결 및 쿼리 실행
    conn = MySQLdb.connect(**config)
    cursor = conn.cursor()
    
    sql = """
        SELECT jikwonpay as 연봉, busernum as 부서번호, busername as 부서명
        FROM jikwon INNER JOIN buser
        ON jikwon.busernum = buser.buserno
        WHERE busername IN ('총무부', '영업부')
    """
    cursor.execute(sql)
    df = pd.DataFrame(cursor.fetchall(), 
                     columns=['연봉', '부서번호', '부서명'])
    
    # 부서별 데이터 분리
    chong = df[df['부서명'] == '총무부']['연봉']
    young = df[df['부서명'] == '영업부']['연봉']
    
    # 숫자형으로 변환
    chong = pd.to_numeric(chong)
    young = pd.to_numeric(young)
    
    # 등분산성 검정
    leven_stat, leven_p = levene(young, chong)
    print(f'등분산성 검정 - p-value: {leven_p:.4f}')
    # p = 0.915 > 0.05 → 등분산성 성립
    
    # 독립표본 T검정
    t_stat, p_value = stats.ttest_ind(chong, young, equal_var=True)
    print(f'부서별 연봉 T검정 - t: {t_stat:.4f}, p: {p_value:.4f}')
    
    # 결론: p = 0.652 > 0.05 → 귀무가설 채택
    # 부서별 연봉에는 유의한 차이가 없다
    
except Exception as e:
    print(f'처리 오류: {e}')
finally:
    conn.close()
```

---

## 🌧️ 종합 실습: 날씨와 매출 분석

### 📊 실제 비즈니스 데이터 분석

```python
# 비(눈) 여부에 따른 음식점 매출액 평균 차이 검정
# H0: 강수량에 따른 음식점 매출액 평균의 차이는 없다
# H1: 강수량에 따른 음식점 매출액 평균은 차이가 있다

import numpy as np
import pandas as pd
import scipy.stats as stats
import matplotlib.pyplot as plt

# 1단계: 데이터 로드
sales_data = pd.read_csv('tsales.csv', dtype={'YMD': 'object'})
wt_data = pd.read_csv('tweather.csv')

print(f"매출 데이터: {sales_data.shape}")  # (328, 3)
print(f"날씨 데이터: {wt_data.shape}")    # (702, 9)

# 2단계: 날짜 형식 통일
wt_data['tm'] = wt_data['tm'].map(lambda x: x.replace('-', ''))

# 3단계: 데이터 병합 (매출 기준 LEFT JOIN)
frame = sales_data.merge(wt_data, how='left', left_on='YMD', right_on='tm')
print(f"병합된 데이터: {frame.shape}")

# 4단계: 필요 컬럼만 선택
data = frame.iloc[:, [0,1,7,8]]  # 날짜, 매출액, 최고기온, 강수량
data.columns = ['날짜', '매출액', '최고기온', '강수량']

# 5단계: 결측치 확인
print("결측치 현황:")
print(data.isnull().sum())

# 6단계: 범주형 변수 생성
data['rain_yn'] = (data['강수량'] > 0).astype(int)
print(f"\n강수 여부 분포:")
print(data['rain_yn'].value_counts())

# 7단계: 그룹별 데이터 분할
sp = np.array(data[['매출액', 'rain_yn']])
tg1 = sp[sp[:, 1] == 0, 0]  # 비 안온 날 매출액
tg2 = sp[sp[:, 1] == 1, 0]  # 비 온 날 매출액

print(f"\n그룹별 기술통계:")
print(f"비 안온 날 (n={len(tg1)}): 평균 {np.mean(tg1):,.0f}원")
print(f"비 온 날 (n={len(tg2)}): 평균 {np.mean(tg2):,.0f}원")

# 8단계: 시각화
plt.figure(figsize=(10, 6))
plt.boxplot([tg1, tg2], labels=['비 안온 날', '비 온 날'], 
           meanline=True, showmeans=True, notch=True,
           patch_artist=True)
plt.title('강수 여부에 따른 매출액 분포')
plt.ylabel('매출액 (원)')
plt.grid(True, alpha=0.3)
plt.show()

# 9단계: 전제조건 검정
print("\n🔍 전제조건 검정")
print("-" * 50)

# 정규성 검정
shapiro1 = stats.shapiro(tg1).pvalue
shapiro2 = stats.shapiro(tg2).pvalue
print(f"정규성 검정 - 비 안온 날: {shapiro1:.4f}")
print(f"정규성 검정 - 비 온 날: {shapiro2:.4f}")

# 등분산성 검정  
levene_p = stats.levene(tg1, tg2).pvalue
print(f"등분산성 검정: {levene_p:.4f}")

if levene_p > 0.05:
    print("✅ 등분산성 만족 → 일반 T검정 사용")
    equal_var = True
else:
    print("❌ 등분산성 위배 → Welch T검정 사용")
    equal_var = False

# 10단계: 독립표본 T검정
t_stat, p_value = stats.ttest_ind(tg1, tg2, equal_var=equal_var)

print(f"\n🎯 독립표본 T검정 결과")
print("-" * 50)
print(f"T-statistic: {t_stat:.6f}")
print(f"P-value: {p_value:.6f}")
print(f"자유도: {len(tg1) + len(tg2) - 2}")

# 11단계: 결론
alpha = 0.05
if p_value < alpha:
    print(f"\n✅ 결론: p({p_value:.6f}) < α({alpha})")
    print("→ 귀무가설 기각, 강수 여부에 따른 매출액 차이 있음")
else:
    print(f"\n❌ 결론: p({p_value:.6f}) ≥ α({alpha})")
    print("→ 귀무가설 채택, 강수 여부에 따른 매출액 차이 없음")

# 효과크기 계산 (Cohen's d)
pooled_std = np.sqrt(((len(tg1)-1)*np.var(tg1, ddof=1) + 
                     (len(tg2)-1)*np.var(tg2, ddof=1)) / 
                     (len(tg1)+len(tg2)-2))
cohens_d = (np.mean(tg1) - np.mean(tg2)) / pooled_std
print(f"\n📊 효과크기 (Cohen's d): {cohens_d:.4f}")

if abs(cohens_d) < 0.2:
    print("→ 작은 효과크기")
elif abs(cohens_d) < 0.5:
    print("→ 중간 효과크기")
else:
    print("→ 큰 효과크기")
```

---

## 💡 실무 해석 가이드

### 🎯 결과 해석 체크리스트

#### ✅ 통계적 관점
1. **전제조건 확인**: 정규성, 등분산성 만족 여부
2. **검정통계량**: t값의 크기와 방향
3. **유의확률**: p-value와 유의수준 비교
4. **효과크기**: 실무적 의미 있는 차이인가?

#### ✅ 비즈니스 관점  
1. **실무적 의미**: 통계적 유의성 ≠ 실무적 중요성
2. **다른 요인**: 단일 변수로만 설명하지 말 것
3. **의사결정**: 결과를 어떻게 활용할 것인가?
4. **추가 분석**: 더 깊이 있는 분석이 필요한가?

### 🚨 주의사항

#### 📊 데이터 품질
- **결측치 처리**: 적절한 방법으로 처리했는가?
- **이상치 확인**: 극값들이 결과에 미치는 영향
- **표본 크기**: 충분한 검정력을 확보했는가?

#### 📈 해석 함정
- **다중비교**: 여러 검정 시 α 수준 조정
- **표본선택편향**: 대표성 있는 표본인가?  
- **인과관계**: 상관관계를 인과관계로 해석 금지

---

## 🏆 최종 마스터 체크리스트

### ✅ T검정 완전 정복 확인

#### 🎯 개념 이해
- [ ] **일표본 vs 독립표본 vs 대응표본 구분**
- [ ] **T분포와 정규분포의 차이**
- [ ] **T검정의 핵심 원리 (평균 차이 / 표준오차)**

#### 🔧 기술 구현
- [ ] **전제조건 검정 (정규성, 등분산성)**
- [ ] **적절한 검정법 선택 (일반 vs Welch)**
- [ ] **Python을 활용한 완전 자동화**

#### 📊 데이터 처리
- [ ] **다중 파일 병합 및 전처리**
- [ ] **범주형 변수 생성 및 그룹 분할**
- [ ] **결측치 처리 및 이상치 탐지**

#### 🎨 시각화 & 보고
- [ ] **박스플롯으로 그룹 비교 시각화**
- [ ] **결과 해석 및 비즈니스 인사이트 도출**
- [ ] **완성도 높은 분석 보고서 작성**

#### 💼 실무 활용
- [ ] **DB 연동한 실제 데이터 분석**
- [ ] **비즈니스 문제를 통계 문제로 변환**
- [ ] **의사결정에 활용 가능한 결론 도출**

---

## 🎉 축하합니다!

**🏆 T검정 마스터가 되셨습니다!**

이제 여러분은:
- ✨ **어떤 상황에서든 적절한 T검정을 선택**할 수 있습니다
- 🔧 **완벽한 분석 워크플로우를 구현**할 수 있습니다  
- 📊 **실무 데이터로 의미있는 인사이트를 도출**할 수 있습니다
- 💼 **비즈니스 의사결정을 위한 통계 분석을 수행**할 수 있습니다

### 🚀 다음 단계: 고급 통계 기법

- **ANOVA**: 3개 이상 그룹 비교
- **카이제곱 검정**: 범주형 데이터 분석
- **회귀분석**: 변수 간 관계 모델링
- **다변량 분석**: 복합적 요인 분석

---

# 📊 통계 분석 절차 및 주요 검정 완전 가이드

---

## 🔬 1. 정규성 검정 (Normality Test)

### 1.1 **Shapiro-Wilk 검정 (`stats.shapiro`)** ⭐ 가장 일반적
```python
import scipy.stats as stats

# 정규성 검정
shapiro_stat, shapiro_p = stats.shapiro(data)
print(f"Shapiro-Wilk: 통계량={shapiro_stat:.4f}, p-value={shapiro_p:.6f}")

if shapiro_p > 0.05:
    print("✅ 정규성 만족 → t-test 등 모수 검정 사용 가능")
else:
    print("❌ 정규성 위배 → 비모수 검정 또는 데이터 변환 고려")
```

**해석 기준**:
- **p-value > 0.05** → 정규분포를 따름 (정규성 만족)
- **p-value < 0.05** → 정규분포를 따르지 않음 (정규성 위배)

### 1.2 **Kolmogorov-Smirnov 검정**
```python
# 표본분포와 정규분포 비교
ks_stat, ks_p = stats.kstest(data, 'norm', args=(np.mean(data), np.std(data, ddof=1)))
print(f"K-S test: p-value = {ks_p:.6f}")
```
- 표본분포와 이론적 정규분포 비교
- 작은 표본(n < 50)에서는 신뢰성 제한

### 1.3 **Q-Q Plot (분위수-분위수 도표)** 👁️ 시각적 확인
```python
import matplotlib.pyplot as plt

# Q-Q plot으로 정규성 시각적 확인
stats.probplot(data, dist="norm", plot=plt)
plt.title('Q-Q Plot: 정규성 확인')
plt.grid(True)
plt.show()
```

**해석 방법**:
- **점들이 대각선(45도 직선)을 따라 배열** → 정규성 만족
- **직선에서 크게 벗어남** → 정규성 위배
- **양 끝단에서 곡선** → 꼬리가 두껍거나 얇음

### 1.4 **정규성 위배 시 대처법**

#### 📈 데이터 변환
```python
# 1. 로그 변환 (양의 값만 가능)
log_data = np.log(data)

# 2. 제곱근 변환
sqrt_data = np.sqrt(data)

# 3. Box-Cox 변환 (최적 람다 자동 계산)
from scipy.stats import boxcox
transformed_data, lambda_val = boxcox(data)
print(f"최적 람다: {lambda_val:.3f}")
```

#### 🔄 대안 검정법
- **t-test** → **Mann-Whitney U test**
- **ANOVA** → **Kruskal-Wallis test**
- **대응표본 t-test** → **Wilcoxon signed-rank test**

#### ⭐ 중심극한정리 활용
- **표본 수 > 30** → 평균 분포가 정규분포에 근사
- 개별 데이터는 비정규여도 표본평균은 정규분포

---

## ⚖️ 2. 평균 차이 검정

### 2.1 **T-test** 📊 연속형 데이터의 평균 비교

| 검정 유형 | 상황 | Python 함수 | 예시 |
|----------|------|-------------|------|
| **일표본 t검정** | 1개 집단 vs 기준값 | `ttest_1samp()` | 학급 평균 vs 80점 |
| **독립표본 t검정** | 2개 독립 집단 비교 | `ttest_ind()` | 남성 키 vs 여성 키 |
| **대응표본 t검정** | 같은 집단 전후 비교 | `ttest_rel()` | 약물 복용 전후 |

```python
# 독립표본 t검정 예시
group1 = [23, 25, 27, 22, 24]
group2 = [28, 30, 26, 29, 31]

t_stat, t_p = stats.ttest_ind(group1, group2)
print(f"독립표본 t검정: t={t_stat:.3f}, p={t_p:.4f}")
```

### 2.2 **ANOVA** 📈 3개 이상 집단 평균 비교
```python
# 일원분산분석
group_a = [23, 25, 27, 22, 24]
group_b = [28, 30, 26, 29, 31] 
group_c = [18, 20, 19, 21, 17]

f_stat, anova_p = stats.f_oneway(group_a, group_b, group_c)
print(f"ANOVA: F={f_stat:.3f}, p={anova_p:.4f}")
```

**중요**: 집단이 2개면 t-test와 ANOVA 결과 동일 (F = t²)

### 2.3 **카이제곱 검정** 📋 범주형 데이터
```python
# 독립성 검정 (2x2 분할표)
from scipy.stats import chi2_contingency

observed = [[20, 30], [25, 25]]  # 관찰 빈도
chi2, chi2_p, dof, expected = chi2_contingency(observed)
print(f"카이제곱 검정: χ²={chi2:.3f}, p={chi2_p:.4f}")
```

### 2.4 **Wilcoxon 검정** 🔄 비모수 중앙값 비교
```python
# 정규성 위배 시 t-test 대신 사용
# 1. 단일표본 (중앙값 vs 기준값)
wilcox_stat, wilcox_p = stats.wilcoxon(data - reference_value)

# 2. 대응표본 (전후 비교)
before = [20, 22, 19, 21, 23]
after = [18, 20, 17, 19, 21]
wilcox_stat, wilcox_p = stats.wilcoxon(before, after)
print(f"Wilcoxon 검정: 통계량={wilcox_stat}, p={wilcox_p:.4f}")
```

---

## ⚖️ 3. 등분산성 검정 (Homogeneity of Variance)

### 3.1 **등분산성의 중요성**
- **의미**: 여러 모집단의 분산(퍼짐 정도)이 동일한가?
- **필요성**: 독립표본 t-검정, ANOVA 등의 전제 조건
- **위배 시**: 잘못된 결론, 유의확률 왜곡 가능

### 3.2 **등분산성 검정 방법 비교**

| 검정법 | 정규성 가정 | 장점 | 단점 | 추천 상황 |
|--------|-------------|------|------|----------|
| **Bartlett** | **강함** | 정규분포일 때 가장 정확 | 정규성 위배 시 오류 | 정규분포 확신할 때 |
| **Levene** ⭐ | **약함** | 실무에서 가장 안전 | 보수적 결과 | **일반적 상황** |
| **Fligner** | **없음** | 가장 강건함 | 검정력 약함 | 완전 비모수 상황 |

```python
# 등분산성 검정 비교
group1 = [23, 25, 27, 22, 24, 26, 21]
group2 = [28, 30, 26, 29, 31, 27, 25]
group3 = [18, 20, 19, 21, 17, 22, 16]

# 1. Bartlett 검정 (정규분포 가정 강함)
bartlett_stat, bartlett_p = stats.bartlett(group1, group2, group3)
print(f"Bartlett: 통계량={bartlett_stat:.3f}, p={bartlett_p:.4f}")

# 2. Levene 검정 (실무 추천) ⭐
levene_stat, levene_p = stats.levene(group1, group2, group3)
print(f"Levene: 통계량={levene_stat:.3f}, p={levene_p:.4f}")

# 3. Fligner 검정 (비모수)
fligner_stat, fligner_p = stats.fligner(group1, group2, group3)
print(f"Fligner: 통계량={fligner_stat:.3f}, p={fligner_p:.4f}")
```

### 3.3 **등분산성 검정 선택 가이드**

```python
def choose_variance_test(data_groups):
    """등분산성 검정 선택 가이드"""
    
    # 1단계: 정규성 확인
    normal_groups = []
    for i, group in enumerate(data_groups):
        _, p = stats.shapiro(group)
        normal_groups.append(p > 0.05)
        print(f"그룹 {i+1} 정규성: {'만족' if p > 0.05 else '위배'} (p={p:.4f})")
    
    # 2단계: 적절한 등분산성 검정 추천
    if all(normal_groups):
        print("\n✅ 추천: Bartlett 검정 (모든 그룹이 정규분포)")
        return "bartlett"
    elif any(normal_groups):
        print("\n⚠️ 추천: Levene 검정 (일부 그룹 정규성 위배)")
        return "levene"
    else:
        print("\n🔄 추천: Fligner 검정 (모든 그룹 정규성 위배)")
        return "fligner"

# 사용 예시
recommended_test = choose_variance_test([group1, group2, group3])
```

**등분산성 위배 시 대처법**:
```python
# Welch's t-test (등분산 가정 없음)
t_stat, t_p = stats.ttest_ind(group1, group2, equal_var=False)
print(f"Welch's t-test: t={t_stat:.3f}, p={t_p:.4f}")
```

---

## 🎯 4. 기타 중요 개념

### 4.1 **가설 설정의 철학**
```python
def hypothesis_setting_guide():
    """올바른 가설 설정 가이드"""
    
    print("🎯 가설 설정 원칙")
    print("-" * 30)
    print("1️⃣ 대립가설(H₁)을 먼저 설정 (연구하고 싶은 내용)")
    print("2️⃣ 귀무가설(H₀)은 대립가설의 반대 (기존 통념)")
    print("3️⃣ 대립가설 채택 ≠ 귀무가설 완전 폐기")
    print("4️⃣ '새로운 근거 마련'의 개념으로 이해")
    
    example = {
        "연구 질문": "신약이 기존 치료법보다 효과적인가?",
        "H₁ (대립가설)": "신약의 치료 효과 > 기존 치료법",
        "H₀ (귀무가설)": "신약의 치료 효과 = 기존 치료법",
        "해석": "H₁ 채택 시 '신약 효과의 근거 마련'"
    }
    
    print(f"\n📝 예시:")
    for key, value in example.items():
        print(f"   {key}: {value}")

hypothesis_setting_guide()
```

### 4.2 **모수적 vs 비모수적 검정**

| 구분 | 모수적 검정 | 비모수적 검정 |
|------|-------------|---------------|
| **가정** | 정규분포 등 분포 가정 필요 | 분포 가정 없음 |
| **데이터** | 연속형, 정규분포 | 순위, 중앙값 기반 |
| **검정력** | 가정 만족 시 높음 | 가정 위배 시 안전 |
| **예시** | t-test, ANOVA, 회귀분석 | Mann-Whitney, Kruskal-Wallis |

```python
# 모수 vs 비모수 검정 비교
def parametric_vs_nonparametric_demo():
    """모수 vs 비모수 검정 비교"""
    
    # 정규성 위배 데이터 생성
    np.random.seed(42)
    skewed_data1 = np.concatenate([np.random.normal(50, 10, 40), [100, 110, 120]])
    skewed_data2 = np.concatenate([np.random.normal(55, 12, 38), [95, 105]])
    
    print("📊 모수 vs 비모수 검정 비교")
    print("-" * 40)
    
    # 1. 모수적 검정 (t-test)
    t_stat, t_p = stats.ttest_ind(skewed_data1, skewed_data2)
    print(f"모수적 검정 (t-test): p = {t_p:.4f}")
    
    # 2. 비모수적 검정 (Mann-Whitney U)
    u_stat, u_p = stats.mannwhitneyu(skewed_data1, skewed_data2, alternative='two-sided')
    print(f"비모수적 검정 (Mann-Whitney): p = {u_p:.4f}")
    
    # 정규성 확인
    _, p1 = stats.shapiro(skewed_data1)
    _, p2 = stats.shapiro(skewed_data2)
    print(f"\n정규성 검정:")
    print(f"  그룹1: p = {p1:.4f} {'(정규성 만족)' if p1 > 0.05 else '(정규성 위배)'}")
    print(f"  그룹2: p = {p2:.4f} {'(정규성 만족)' if p2 > 0.05 else '(정규성 위배)'}")
    
    print(f"\n💡 결론: 정규성 위배 시 비모수 검정이 더 신뢰할 만함")

parametric_vs_nonparametric_demo()
```

---

## 💻 5. 실용 코드 모음

### 5.1 **Q-Q Plot 고급 버전**
```python
def advanced_qq_plot(data, title="Q-Q Plot"):
    """개선된 Q-Q Plot"""
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # Q-Q Plot
    stats.probplot(data, dist="norm", plot=ax1)
    ax1.set_title(f'{title}: 정규성 확인')
    ax1.grid(True, alpha=0.3)
    
    # 히스토그램 + 정규분포 곡선
    ax2.hist(data, bins=15, density=True, alpha=0.7, color='skyblue', edgecolor='black')
    
    # 이론적 정규분포 곡선
    x = np.linspace(data.min(), data.max(), 100)
    y = stats.norm.pdf(x, np.mean(data), np.std(data))
    ax2.plot(x, y, 'r-', linewidth=2, label='이론적 정규분포')
    
    ax2.set_title(f'{title}: 히스토그램')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

# 사용 예시
np.random.seed(42)
normal_data = np.random.normal(50, 10, 100)
skewed_data = np.concatenate([np.random.normal(50, 5, 80), [80, 85, 90, 95, 100]])

advanced_qq_plot(normal_data, "정규분포 데이터")
advanced_qq_plot(skewed_data, "왜곡된 데이터")
```

### 5.2 **통합 검정 함수**
```python
def comprehensive_statistical_test(group1, group2=None, test_type='auto'):
    """종합적인 통계 검정 함수"""
    
    print("🔍 종합 통계 검정 결과")
    print("=" * 40)
    
    if group2 is None:
        # 일표본 검정
        print("📊 일표본 분석")
        print(f"   표본 크기: {len(group1)}")
        print(f"   평균: {np.mean(group1):.3f}")
        print(f"   표준편차: {np.std(group1, ddof=1):.3f}")
        
        # 정규성 검정
        _, norm_p = stats.shapiro(group1)
        print(f"   정규성 검정 p-value: {norm_p:.6f}")
        
        if norm_p > 0.05:
            print("   ✅ 정규성 만족 → t검정 적합")
        else:
            print("   ❌ 정규성 위배 → Wilcoxon 검정 고려")
            
    else:
        # 이표본 검정
        print("📊 이표본 분석")
        print(f"   그룹1 크기: {len(group1)}, 평균: {np.mean(group1):.3f}")
        print(f"   그룹2 크기: {len(group2)}, 평균: {np.mean(group2):.3f}")
        
        # 정규성 검정
        _, norm_p1 = stats.shapiro(group1)
        _, norm_p2 = stats.shapiro(group2)
        print(f"   그룹1 정규성: {norm_p1:.6f}")
        print(f"   그룹2 정규성: {norm_p2:.6f}")
        
        # 등분산성 검정
        _, var_p = stats.levene(group1, group2)
        print(f"   등분산성 검정: {var_p:.6f}")
        
        # 검정 방법 추천
        if norm_p1 > 0.05 and norm_p2 > 0.05:
            if var_p > 0.05:
                print("   ✅ 추천: 독립표본 t검정 (등분산)")
                t_stat, t_p = stats.ttest_ind(group1, group2, equal_var=True)
                print(f"   t검정 결과: t={t_stat:.3f}, p={t_p:.6f}")
            else:
                print("   ✅ 추천: Welch's t검정 (이분산)")
                t_stat, t_p = stats.ttest_ind(group1, group2, equal_var=False)
                print(f"   Welch t검정 결과: t={t_stat:.3f}, p={t_p:.6f}")
        else:
            print("   🔄 추천: Mann-Whitney U 검정")
            u_stat, u_p = stats.mannwhitneyu(group1, group2, alternative='two-sided')
            print(f"   Mann-Whitney 결과: U={u_stat:.1f}, p={u_p:.6f}")

# 사용 예시
np.random.seed(42)
sample1 = np.random.normal(50, 10, 30)
sample2 = np.random.normal(55, 8, 35)

comprehensive_statistical_test(sample1, sample2)
```

---

## 📖 6. 핵심 용어 사전

| 용어 | 의미 | 확인 방법 |
|------|------|----------|
| **정규성** | 데이터가 종 모양(정규분포)을 따르는지 | Shapiro-Wilk, Q-Q plot |
| **등분산성** | 여러 집단의 분산(퍼짐)이 같은지 | Levene, Bartlett test |
| **모수 검정** | 분포 가정이 필요한 검정 | t-test, ANOVA, 회귀분석 |
| **비모수 검정** | 분포 가정 없는 순위 기반 검정 | Mann-Whitney, Wilcoxon |
| **검정통계량** | 가설검정에서 계산되는 수치 | t값, F값, χ²값 등 |
| **p-value** | 우연히 관찰될 확률 | < 0.05면 통계적 유의 |
| **자유도** | 독립적으로 변할 수 있는 값의 수 | 보통 n-1 |
| **효과크기** | 실질적 차이의 크기 | Cohen's d 등 |

---

## 🎯 7. 실무 의사결정 플로우차트

```python
def statistical_decision_flowchart():
    """통계 검정 의사결정 플로우차트"""
    
    flowchart = """
    📊 통계 검정 의사결정 플로우
    
    1️⃣ 연구 질문 명확화
       ↓
    2️⃣ 데이터 타입 확인 (연속형 vs 범주형)
       ↓
    3️⃣ 집단 수 확인 (1개 vs 2개 vs 3개+)
       ↓
    4️⃣ 표본 관계 확인 (독립 vs 대응)
       ↓
    5️⃣ 정규성 검정 (Shapiro-Wilk)
       ↓
    6️⃣ 등분산성 검정 (필요시, Levene)
       ↓
    7️⃣ 적절한 검정 선택
       ↓
    8️⃣ 검정 실행 및 해석
       ↓
    9️⃣ 효과크기 계산 (권장)
       ↓
    🔟 결론 도출 및 보고
    """
    
    print(flowchart)
    
    decision_matrix = {
        "연속형 + 1집단": "일표본 t검정 or Wilcoxon",
        "연속형 + 2집단 + 독립": "독립표본 t검정 or Mann-Whitney",
        "연속형 + 2집단 + 대응": "대응표본 t검정 or Wilcoxon",
        "연속형 + 3집단+": "ANOVA or Kruskal-Wallis",
        "범주형": "카이제곱 검정"
    }
    
    print("\n🗺️ 빠른 참조 매트릭스:")
    for situation, test in decision_matrix.items():
        print(f"   {situation}: {test}")

statistical_decision_flowchart()
```

---

## 🏆 완전 마스터 체크리스트

### ✅ 통계 검정 완전 정복 확인

- [ ] **정규성 검정**: Shapiro-Wilk, Q-Q plot 해석 가능
- [ ] **등분산성 검정**: Levene test 이해 및 적용
- [ ] **모수 vs 비모수**: 상황별 적절한 검정 선택
- [ ] **t검정 3종류**: 일표본, 독립표본, 대응표본 구분
- [ ] **ANOVA**: 3개 이상 집단 평균 비교
- [ ] **카이제곱 검정**: 범주형 데이터 분석
- [ ] **효과크기**: Cohen's d 등 실질적 의미 파악
- [ ] **종합 해석**: 통계적 vs 실무적 의미 구분

**🎉 모든 체크리스트 완료 → 통계 검정 마스터!** 

이제 어떤 데이터든 자신 있게 분석할 수 있습니다! 🚀✨