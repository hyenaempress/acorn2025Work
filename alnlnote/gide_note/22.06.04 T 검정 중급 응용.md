# 22.06.03 Tê²€ì • í•µì‹¬ìš”ì•½ ì™„ì „íŒ

## ğŸš¨ **ì™œ ì •ê·œì„± ê²€ì •ì´ ì¤‘ìš”í•œê°€?** - ì‹¤ë¬´ ê´€ì 

### ğŸ¯ ì •ê·œì„± ê²€ì •ì´ í•„ìš”í•œ **ì§„ì§œ ì´ìœ **

ë§ì€ ì‚¬ëŒë“¤ì´ "ê·¸ëƒ¥ í•´ì•¼ í•˜ëŠ” ê²ƒ"ì´ë¼ê³  ìƒê°í•˜ì§€ë§Œ, ì‹¤ì œë¡œëŠ” **ë‹¹ì‹ ì˜ ë¶„ì„ ê²°ê³¼ê°€ ë¯¿ì„ ë§Œí•œì§€**ë¥¼ ê²°ì •í•˜ëŠ” í•µì‹¬ì…ë‹ˆë‹¤!

#### âš¡ ì‹¤ë¬´ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ì´í•´í•˜ê¸°

```python
# ì‹œë‚˜ë¦¬ì˜¤: ì‹ ì•½ì˜ íš¨ê³¼ë¥¼ ê²€ì¦í•˜ëŠ” ìƒí™©
import numpy as np
import scipy.stats as stats
import matplotlib.pyplot as plt

# ìƒí™© 1: ì •ê·œë¶„í¬ ë°ì´í„° (ì´ìƒì ì¸ ê²½ìš°)
np.random.seed(42)
normal_data = np.random.normal(100, 15, 30)  # í‰ê·  100, í‘œì¤€í¸ì°¨ 15

# ìƒí™© 2: ê·¹ë‹¨ê°’ì´ ìˆëŠ” ë¹„ì •ê·œ ë°ì´í„° (í˜„ì‹¤ì ì¸ ê²½ìš°) 
skewed_data = np.concatenate([
    np.random.normal(100, 10, 25),  # ëŒ€ë¶€ë¶„ì˜ í™˜ì
    [150, 160, 170, 180, 200]       # ê·¹ë‹¨ì ìœ¼ë¡œ ë°˜ì‘ì´ ì¢‹ì€ 5ëª…
])

print("ğŸ” ë‘ ìƒí™© ë¹„êµ:")
print(f"ì •ê·œë¶„í¬ ë°ì´í„° í‰ê· : {np.mean(normal_data):.1f}")
print(f"ë¹„ì •ê·œë¶„í¬ ë°ì´í„° í‰ê· : {np.mean(skewed_data):.1f}")
```

#### ğŸ­ ì •ê·œì„± ìœ„ë°° ì‹œ ì¼ì–´ë‚˜ëŠ” ì¼

```python
# ì •ê·œì„± ê²€ì •
print("\nğŸ“Š ì •ê·œì„± ê²€ì • ê²°ê³¼:")
normal_p = stats.shapiro(normal_data)[1]
skewed_p = stats.shapiro(skewed_data)[1]

print(f"ì •ê·œë¶„í¬ ë°ì´í„°: p = {normal_p:.6f} {'âœ… ì •ê·œì„± ë§Œì¡±' if normal_p > 0.05 else 'âŒ ì •ê·œì„± ìœ„ë°°'}")
print(f"ë¹„ì •ê·œë¶„í¬ ë°ì´í„°: p = {skewed_p:.6f} {'âœ… ì •ê·œì„± ë§Œì¡±' if skewed_p > 0.05 else 'âŒ ì •ê·œì„± ìœ„ë°°'}")

# Tê²€ì • vs Wilcoxon ê²€ì • ë¹„êµ
print(f"\nğŸ¯ ê²€ì • ê²°ê³¼ ë¹„êµ (ê¸°ì¤€ê°’: 95ì™€ ë¹„êµ):")

# ì •ê·œë¶„í¬ ë°ì´í„°
t_stat1, t_p1 = stats.ttest_1samp(normal_data, 95)
w_stat1, w_p1 = stats.wilcoxon(normal_data - 95)

print(f"ì •ê·œë¶„í¬ ë°ì´í„°:")
print(f"  Tê²€ì •: p = {t_p1:.4f} {'ìœ ì˜í•¨' if t_p1 < 0.05 else 'ìœ ì˜í•˜ì§€ ì•ŠìŒ'}")
print(f"  Wilcoxon: p = {w_p1:.4f} {'ìœ ì˜í•¨' if w_p1 < 0.05 else 'ìœ ì˜í•˜ì§€ ì•ŠìŒ'}")

# ë¹„ì •ê·œë¶„í¬ ë°ì´í„°  
t_stat2, t_p2 = stats.ttest_1samp(skewed_data, 95)
w_stat2, w_p2 = stats.wilcoxon(skewed_data - 95)

print(f"ë¹„ì •ê·œë¶„í¬ ë°ì´í„°:")
print(f"  Tê²€ì •: p = {t_p2:.4f} {'ìœ ì˜í•¨' if t_p2 < 0.05 else 'ìœ ì˜í•˜ì§€ ì•ŠìŒ'}")
print(f"  Wilcoxon: p = {w_p2:.4f} {'ìœ ì˜í•¨' if w_p2 < 0.05 else 'ìœ ì˜í•˜ì§€ ì•ŠìŒ'}")
```

### ğŸ’¥ **ë¬´ì‹œí•˜ë©´ ì¼ì–´ë‚˜ëŠ” ì°¸ì‚¬**

1. **ì˜ëª»ëœ ì˜ì‚¬ê²°ì •**: 
   - ì •ê·œì„± ìœ„ë°°ëœ ë°ì´í„°ë¡œ Tê²€ì • â†’ ê±°ì§“ ìœ ì˜ì„± ë°œê²¬
   - "ì‹ ì•½ íš¨ê³¼ ìˆë‹¤!" â†’ ì‹¤ì œë¡œëŠ” ê·¹ë‹¨ê°’ ëª‡ ê°œ ë•Œë¬¸

2. **ì‹ ë¢°ì„± ë¶•ê´´**:
   - ë…¼ë¬¸ ì‹¬ì‚¬ì—ì„œ íƒˆë½
   - ì„ìƒì‹œí—˜ ìŠ¹ì¸ ê±°ë¶€  
   - ì œí’ˆ ì¶œì‹œ í›„ ë¬¸ì œ ë°œìƒ

3. **ë¹„ìš© ì†ì‹¤**:
   - ì˜ëª»ëœ ë¶„ì„ìœ¼ë¡œ ìˆ˜ì–µ ì› íˆ¬ì ì‹¤íŒ¨
   - ì¬ê²€ì¦ì— ë“œëŠ” ì‹œê°„ê³¼ ë¹„ìš©

### âœ… **ì˜¬ë°”ë¥¸ ì ‘ê·¼ë²•**

```python
def proper_analysis_workflow(data, reference_value=95):
    """ì˜¬ë°”ë¥¸ ë¶„ì„ ì›Œí¬í”Œë¡œìš°"""
    
    print(f"ğŸ“‹ ë‹¨ê³„ë³„ ë¶„ì„ ì›Œí¬í”Œë¡œìš°")
    print("-" * 40)
    
    # 1ë‹¨ê³„: ì •ê·œì„± ê²€ì •
    shapiro_stat, shapiro_p = stats.shapiro(data)
    print(f"1ï¸âƒ£ ì •ê·œì„± ê²€ì •: p = {shapiro_p:.6f}")
    
    # 2ë‹¨ê³„: ì ì ˆí•œ ê²€ì • ì„ íƒ
    if shapiro_p > 0.05:
        print("âœ… ì •ê·œì„± ë§Œì¡± â†’ Tê²€ì • ì‚¬ìš©")
        test_stat, p_value = stats.ttest_1samp(data, reference_value)
        test_name = "Tê²€ì •"
    else:
        print("âŒ ì •ê·œì„± ìœ„ë°° â†’ Wilcoxon ê²€ì • ì‚¬ìš©")
        test_stat, p_value = stats.wilcoxon(data - reference_value)
        test_name = "Wilcoxon ê²€ì •"
    
    # 3ë‹¨ê³„: ê²°ê³¼ í•´ì„
    print(f"2ï¸âƒ£ {test_name} ê²°ê³¼: p = {p_value:.6f}")
    if p_value < 0.05:
        print("âœ… í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì°¨ì´ ìˆìŒ")
    else:
        print("âŒ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì°¨ì´ ì—†ìŒ")
    
    # 4ë‹¨ê³„: ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²°ë¡ 
    print(f"3ï¸âƒ£ ê²°ë¡ : ì •ê·œì„± ê²€ì •ì„ í†µí•´ ì ì ˆí•œ ë°©ë²•ì„ ì„ íƒí–ˆìœ¼ë¯€ë¡œ ê²°ê³¼ë¥¼ ì‹ ë¢°í•  ìˆ˜ ìˆìŒ")
    
    return test_name, p_value
```

### ğŸ”¥ **í•µì‹¬ ë©”ì‹œì§€**

> **ì •ê·œì„± ê²€ì • = ë‹¹ì‹ ì˜ ë¶„ì„ì´ ë¯¿ì„ ë§Œí•œì§€ í™•ì¸í•˜ëŠ” ë³´í—˜**
> 
> - 5ë¶„ íˆ¬ìë¡œ ìˆ˜ê°œì›”ì˜ ì˜ëª»ëœ ë¶„ì„ ë°©ì§€
> - ì˜¬ë°”ë¥¸ ê²€ì •ë²• ì„ íƒìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²°ê³¼ í™•ë³´
> - ì „ë¬¸ì„±ê³¼ ì‹ ë¢°ì„±ì„ ë³´ì—¬ì£¼ëŠ” í•„ìˆ˜ ë‹¨ê³„

---

## ğŸ“Š **Average vs Mean, ì™œ êµ¬ë¶„í•´ì•¼ í•˜ë‚˜?** - ì‹¤ë¬´ í•¨ì • ë°©ì§€

### ğŸ¯ **ë‘˜ì´ ë‹¤ë¥¸ ì´ìœ **

ì¼ë°˜ì¸ì€ "í‰ê· "ì´ë¼ê³  í•˜ë©´ ë‹¤ ê°™ì€ ê²ƒì´ë¼ê³  ìƒê°í•˜ì§€ë§Œ, í†µê³„í•™ì—ì„œëŠ” **ìƒí™©ì— ë”°ë¼ ë‹¤ë¥¸ í‰ê· **ì„ ì‚¬ìš©í•©ë‹ˆë‹¤!

#### âš¡ ì‹¤ë¬´ ì‹œë‚˜ë¦¬ì˜¤: ì§ì› ì—°ë´‰ ë¶„ì„

```python
# íšŒì‚¬ ì§ì› ì—°ë´‰ ë°ì´í„° (ë‹¨ìœ„: ë§Œì›)
salaries = [3000, 3200, 3500, 3800, 4000, 4200, 4500, 15000]  # ë§ˆì§€ë§‰ì€ CEO

print("ğŸ¢ ì§ì› ì—°ë´‰ ë¶„ì„:")
print(f"ì—°ë´‰ ë°ì´í„°: {salaries}")

# 1. Average (ì‚°ìˆ í‰ê· ) - ì¼ë°˜ì ì¸ í‰ê· 
average_salary = sum(salaries) / len(salaries)
print(f"\nğŸ“Š Average (ì‚°ìˆ í‰ê· ): {average_salary:,.0f}ë§Œì›")

# 2. Meanì˜ ë‹¤ì–‘í•œ í˜•íƒœ

# 2-1. Arithmetic Mean (ì‚°ìˆ í‰ê· ) - Averageì™€ ë™ì¼
arithmetic_mean = np.mean(salaries)
print(f"ğŸ“Š Arithmetic Mean: {arithmetic_mean:,.0f}ë§Œì›")

# 2-2. Geometric Mean (ê¸°í•˜í‰ê· ) - ì„±ì¥ë¥ , ë¹„ìœ¨ ë°ì´í„°ì— ì í•©
geometric_mean = stats.gmean(salaries)
print(f"ğŸ“Š Geometric Mean: {geometric_mean:,.0f}ë§Œì›")

# 2-3. Harmonic Mean (ì¡°í™”í‰ê· ) - ë¹„ìœ¨ì˜ í‰ê· 
harmonic_mean = stats.hmean(salaries)
print(f"ğŸ“Š Harmonic Mean: {harmonic_mean:,.0f}ë§Œì›")

# 2-4. Weighted Mean (ê°€ì¤‘í‰ê· ) - ì¤‘ìš”ë„ ë°˜ì˜
weights = [1, 1, 1, 1, 1, 1, 1, 0.1]  # CEO ê°€ì¤‘ì¹˜ ì¤„ì„
weighted_mean = np.average(salaries, weights=weights)
print(f"ğŸ“Š Weighted Mean: {weighted_mean:,.0f}ë§Œì›")

# 2-5. Median (ì¤‘ì•™ê°’) - ê·¹ê°’ì— ì˜í–¥ ì•ˆ ë°›ìŒ
median_salary = np.median(salaries)
print(f"ğŸ“Š Median: {median_salary:,.0f}ë§Œì›")
```

### ğŸ’¥ **ì˜ëª» ì‚¬ìš©í•˜ë©´ ì¼ì–´ë‚˜ëŠ” ì¼**

#### ìƒí™© 1: ì–¸ë¡  ë³´ë„ì˜ í•¨ì •
```python
print(f"\nğŸ“° ì–¸ë¡  ë³´ë„ ì‹œë‚˜ë¦¬ì˜¤:")
print(f"'ì´ íšŒì‚¬ í‰ê·  ì—°ë´‰ {average_salary:,.0f}ë§Œì›' â† ì´ê±° ë§ë‚˜ìš”?")
print(f"ì‹¤ì œ ëŒ€ë¶€ë¶„ ì§ì› ì—°ë´‰: 3000-4500ë§Œì›")
print(f"â†’ CEO í•œ ëª… ë•Œë¬¸ì— í‰ê· ì´ ì™œê³¡ë¨!")

print(f"\nâœ… ì˜¬ë°”ë¥¸ ë³´ë„:")
print(f"'ì´ íšŒì‚¬ ì§ì› ì¤‘ê°„ê°’ ì—°ë´‰ {median_salary:,.0f}ë§Œì›'")
print(f"'í‰ê· ì€ {average_salary:,.0f}ë§Œì›ì´ì§€ë§Œ CEO ì—°ë´‰ ì˜í–¥'")
```

#### ìƒí™© 2: íˆ¬ì ìˆ˜ìµë¥  ë¶„ì„
```python
# ì›”ë³„ ìˆ˜ìµë¥  (%)
monthly_returns = [5, -3, 8, -2, 10, -1, 6, -4, 12]

# ì˜ëª»ëœ ë°©ë²•: ì‚°ìˆ í‰ê· 
arithmetic_return = np.mean(monthly_returns)
print(f"\nğŸ’° íˆ¬ì ë¶„ì„:")
print(f"ì‚°ìˆ í‰ê·  ìˆ˜ìµë¥ : {arithmetic_return:.2f}%")

# ì˜¬ë°”ë¥¸ ë°©ë²•: ê¸°í•˜í‰ê·  (ë³µë¦¬ ê³ ë ¤)
# ìˆ˜ìµë¥ ì„ ê³±ì…ˆ í˜•íƒœë¡œ ë³€í™˜ (5% â†’ 1.05)
geometric_returns = [(1 + r/100) for r in monthly_returns]
geometric_return = (np.prod(geometric_returns) ** (1/len(geometric_returns)) - 1) * 100
print(f"ê¸°í•˜í‰ê·  ìˆ˜ìµë¥ : {geometric_return:.2f}%")
print(f"ì°¨ì´: {arithmetic_return - geometric_return:.2f}%p")
```

### âœ… **ì–¸ì œ ë­˜ ì¨ì•¼ í•˜ë‚˜?**

```python
def mean_selection_guide():
    """í‰ê·  ì„ íƒ ê°€ì´ë“œ"""
    
    guide = {
        "ğŸ“Š Arithmetic Mean (ì‚°ìˆ í‰ê· )": {
            "ì–¸ì œ": "ì¼ë°˜ì ì¸ ìƒí™©, ëŒ€ì¹­ ë¶„í¬",
            "ì˜ˆì‹œ": "ì‹œí—˜ ì ìˆ˜, í‚¤, ëª¸ë¬´ê²Œ",
            "ì£¼ì˜": "ê·¹ê°’ì— ë¯¼ê°í•¨"
        },
        
        "ğŸ“Š Geometric Mean (ê¸°í•˜í‰ê· )": {
            "ì–¸ì œ": "ì„±ì¥ë¥ , ìˆ˜ìµë¥ , ë¹„ìœ¨ ë°ì´í„°",
            "ì˜ˆì‹œ": "ì—°í‰ê·  ì„±ì¥ë¥ , íˆ¬ì ìˆ˜ìµë¥ ",
            "ì£¼ì˜": "ìŒìˆ˜ ë¶ˆê°€ëŠ¥"
        },
        
        "ğŸ“Š Harmonic Mean (ì¡°í™”í‰ê· )": {
            "ì–¸ì œ": "ë¹„ìœ¨ì˜ í‰ê·  (ì†ë„, íš¨ìœ¨ì„±)",
            "ì˜ˆì‹œ": "í‰ê·  ì†ë„, ê°€ê²©-ìˆ˜ìµë¹„ìœ¨",
            "ì£¼ì˜": "ì‘ì€ ê°’ì— ë¯¼ê°í•¨"
        },
        
        "ğŸ“Š Weighted Mean (ê°€ì¤‘í‰ê· )": {
            "ì–¸ì œ": "ì¤‘ìš”ë„ê°€ ë‹¤ë¥¼ ë•Œ",
            "ì˜ˆì‹œ": "í•™ì  ê³„ì‚°, í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥ ",
            "ì£¼ì˜": "ê°€ì¤‘ì¹˜ ì„¤ì •ì´ ì¤‘ìš”í•¨"
        },
        
        "ğŸ“Š Median (ì¤‘ì•™ê°’)": {
            "ì–¸ì œ": "ê·¹ê°’ì´ë‚˜ ë¹„ëŒ€ì¹­ ë¶„í¬",
            "ì˜ˆì‹œ": "ë¶€ë™ì‚° ê°€ê²©, ì—°ë´‰",
            "ì£¼ì˜": "ë¶„í¬ ì •ë³´ ì†ì‹¤"
        }
    }
    
    print("ğŸ¯ í‰ê·  ì„ íƒ ê°€ì´ë“œ")
    print("=" * 30)
    
    for mean_type, details in guide.items():
        print(f"\n{mean_type}:")
        print(f"   ì–¸ì œ: {details['ì–¸ì œ']}")
        print(f"   ì˜ˆì‹œ: {details['ì˜ˆì‹œ']}")
        print(f"   ì£¼ì˜: {details['ì£¼ì˜']}")

mean_selection_guide()
```

### ğŸ”¥ **ì‹¤ë¬´ ì²´í¬í¬ì¸íŠ¸**

```python
def practical_checklist():
    """ì‹¤ë¬´ì—ì„œ í™•ì¸í•´ì•¼ í•  ì²´í¬í¬ì¸íŠ¸"""
    
    checklist = [
        "ğŸ¤” ë‚´ ë°ì´í„°ì— ê·¹ê°’(outlier)ì´ ìˆë‚˜?",
        "ğŸ“Š ë¶„í¬ê°€ ëŒ€ì¹­ì¸ê°€, ë¹„ëŒ€ì¹­ì¸ê°€?", 
        "ğŸ¯ ë¬´ì—‡ì„ ì¸¡ì •í•˜ë ¤ëŠ”ê°€? (ì ˆëŒ€ê°’ vs ë¹„ìœ¨ vs ì„±ì¥ë¥ )",
        "ğŸ‘¥ ë³´ê³  ëŒ€ìƒì´ ëˆ„êµ¬ì¸ê°€? (ì¼ë°˜ì¸ vs ì „ë¬¸ê°€)",
        "âš–ï¸ ëª¨ë“  ë°ì´í„°ê°€ ë™ì¼í•œ ì¤‘ìš”ë„ì¸ê°€?"
    ]
    
    print("âœ… í‰ê·  ê³„ì‚° ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸")
    print("=" * 35)
    
    for item in checklist:
        print(f"   {item}")
    
    print(f"\nğŸ’¡ ê¸°ì–µí•˜ì„¸ìš”:")
    print("   Average â‰ˆ ë‹¨ìˆœ ì‚°ìˆ í‰ê· ")
    print("   Mean = ìƒí™©ì— ë§ëŠ” ë‹¤ì–‘í•œ í‰ê· ë“¤")
    print("   â†’ ë°ì´í„°ì™€ ëª©ì ì— ë§ëŠ” í‰ê·  ì„ íƒì´ í•µì‹¬!")

practical_checklist()
```

### ğŸ¯ **í•µì‹¬ ë©”ì‹œì§€**

> **Average vs Mean êµ¬ë¶„ = ë°ì´í„° ë¶„ì„ì˜ ì •í™•ì„±ê³¼ ì‹ ë¢°ì„± í™•ë³´**
> 
> - ì˜ëª»ëœ í‰ê·  ì‚¬ìš© â†’ ì˜ëª»ëœ ê²°ë¡  â†’ ì˜ëª»ëœ ì˜ì‚¬ê²°ì •
> - ì˜¬ë°”ë¥¸ í‰ê·  ì„ íƒ â†’ ì •í™•í•œ ì¸ì‚¬ì´íŠ¸ â†’ ì„±ê³µì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ê²°ê³¼
> - 5ë¶„ì˜ ê³ ë¯¼ìœ¼ë¡œ ëª‡ ë‹¬ì˜ ì˜ëª»ëœ ë¶„ì„ ë°©ì§€ ê°€ëŠ¥

**ì´ì œ ì •ê·œì„± ê²€ì •ê³¼ Average vs Meanì˜ ì§„ì§œ ì¤‘ìš”ì„±ì„ ì•„ì…¨ì£ ? ë‹¨ìˆœí•œ ì´ë¡ ì´ ì•„ë‹ˆë¼ ì‹¤ë¬´ì—ì„œ ë°˜ë“œì‹œ í•„ìš”í•œ ìƒì¡´ ê¸°ìˆ ì…ë‹ˆë‹¤!** ğŸ”¥

---

## ğŸ“Š ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤ë¬´ íŒ

### ğŸ”„ ì „ì¹˜í–‰ë ¬(Transpose) ì£¼ì˜ì‚¬í•­

```python
# âŒ ë¬¸ì œ ìƒí™©: ê²°ì¸¡ì¹˜ê°€ í¬í•¨ëœ ë°°ì—´ì„ ì „ì¹˜
data = [[1, 2], [3, np.nan], [5, 6]]  # 2x3 ë°°ì—´
data_t = np.array(data).T  # 3x2ë¡œ ì „ì¹˜

# ê²°ê³¼: ì „ì²´ ë°°ì—´ì´ object íƒ€ì…ìœ¼ë¡œ ë³€í™˜ë¨!
# ìˆ«ì ì—°ì‚° ë¶ˆê°€ëŠ¥í•œ ìƒíƒœê°€ ë¨
```

```python
# âœ… ì˜¬ë°”ë¥¸ ì²˜ë¦¬ ìˆœì„œ
# 1ë‹¨ê³„: ê²°ì¸¡ì¹˜ ì œê±°
data_clean = data.dropna()

# 2ë‹¨ê³„: ì „ì¹˜ ìˆ˜í–‰  
data_transposed = data_clean.T

# 3ë‹¨ê³„: í•„ìš”ì‹œ ìˆ«ì íƒ€ì…ìœ¼ë¡œ ë³€í™˜
data_numeric = pd.to_numeric(data_transposed)
```

### ğŸ’¡ í•µì‹¬ ì›ë¦¬
- **ì „ì¹˜í–‰ë ¬ì€ ê²°ì¸¡ì¹˜ë‚˜ ì •ìˆ˜ë‚˜ ë°ì´í„° í˜•ì‹ì„ í†µì¼í•˜ë ¤ í•¨**
- **ê²°ì¸¡ì¹˜ í¬í•¨ ë°°ì—´ì„ ì „ì¹˜í•˜ë©´ â†’ object íƒ€ì…ìœ¼ë¡œ ë³€í™˜**
- **ìˆœì„œ: dropna() â†’ .T â†’ to_numeric() ê¶Œì¥**

---

## ğŸ¯ ê°€ì„¤ê²€ì • í‘œì¤€ ì ˆì°¨

### ğŸ“‹ ì™„ë²½í•œ ê°€ì„¤ê²€ì • ì›Œí¬í”Œë¡œìš°

```python
def perfect_hypothesis_testing(data, pop_mean=None):
    """
    ì™„ë²½í•œ ê°€ì„¤ê²€ì • ì ˆì°¨
    """
    print("ğŸ” 1ë‹¨ê³„: ì •ê·œì„± ê²€ì • (Shapiro-Wilk)")
    stat, p_value = stats.shapiro(data)
    print(f"   Statistics: {stat:.6f}")
    print(f"   P-value: {p_value:.6f}")
    
    if p_value > 0.05:
        print("   âœ… ì •ê·œì„± ë§Œì¡± â†’ T-test ì‚¬ìš©")
        
        # 2-1. T-test ìˆ˜í–‰
        if pop_mean is not None:
            t_stat, t_p = stats.ttest_1samp(data, pop_mean)
            print(f"\nğŸ“Š 2ë‹¨ê³„: One-sample T-test")
            test_name = "T-test"
        else:
            print("   ëª¨ì§‘ë‹¨ í‰ê· ì„ ì œê³µí•´ì£¼ì„¸ìš”.")
            return
            
    else:
        print("   âŒ ì •ê·œì„± ìœ„ë°° â†’ Wilcoxon test ì‚¬ìš©")
        
        # 2-2. Wilcoxon test ìˆ˜í–‰
        if pop_mean is not None:
            w_stat, w_p = stats.wilcoxon(data - pop_mean)
            t_stat, t_p = w_stat, w_p
            print(f"\nğŸ“Š 2ë‹¨ê³„: Wilcoxon Signed-Rank Test")
            test_name = "Wilcoxon test"
        else:
            print("   ëª¨ì§‘ë‹¨ í‰ê· ì„ ì œê³µí•´ì£¼ì„¸ìš”.")
            return
    
    print(f"   Test Statistics: {t_stat:.6f}")
    print(f"   P-value: {t_p:.6f}")
    
    print(f"\nğŸ“ˆ 3ë‹¨ê³„: Q-Q Plotìœ¼ë¡œ ì‹œê°ì  í™•ì¸")
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # íˆìŠ¤í† ê·¸ë¨
    ax1.hist(data, bins=10, alpha=0.7, color='skyblue', edgecolor='black')
    ax1.axvline(np.mean(data), color='red', linestyle='--', 
                label=f'í‘œë³¸í‰ê· : {np.mean(data):.1f}')
    if pop_mean:
        ax1.axvline(pop_mean, color='green', linestyle='-', 
                    label=f'ëª¨ì§‘ë‹¨í‰ê· : {pop_mean}')
    ax1.set_title('ë°ì´í„° ë¶„í¬')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Q-Q plot
    stats.probplot(data, dist="norm", plot=ax2)
    ax2.set_title('Q-Q Plot (ì •ê·œì„± í™•ì¸)')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print(f"\nğŸ¯ 4ë‹¨ê³„: ê²°ë¡  ë„ì¶œ (Î± = 0.05)")
    if t_p < 0.05:
        print(f"   âœ… P-value({t_p:.6f}) < 0.05")
        print("   â†’ ê·€ë¬´ê°€ì„¤ ê¸°ê°, ëŒ€ë¦½ê°€ì„¤ ì±„íƒ")
        print("   â†’ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì°¨ì´ê°€ ìˆìŒ")
    else:
        print(f"   âŒ P-value({t_p:.6f}) â‰¥ 0.05") 
        print("   â†’ ê·€ë¬´ê°€ì„¤ ì±„íƒ, ëŒ€ë¦½ê°€ì„¤ ê¸°ê°")
        print("   â†’ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì°¨ì´ê°€ ì—†ìŒ")
    
    return {
        'normality_test': {'statistic': stat, 'p_value': p_value},
        'main_test': {'test_name': test_name, 'statistic': t_stat, 'p_value': t_p},
        'conclusion': 'significant' if t_p < 0.05 else 'not_significant'
    }
```

---

## ğŸ“š ì‹¤ìŠµ ë¬¸ì œ ì™„ì „ ë¶„ì„

### ğŸ¼ ì‹¤ìŠµì˜ˆì œ 2: ì—¬ì•„ ì‹ ìƒì•„ ëª¸ë¬´ê²Œ ê²€ì •

#### ë¬¸ì œ ì„¤ì •
```python
# ê°€ì„¤ ì„¤ì •
# H0 (ê·€ë¬´ê°€ì„¤): ì—¬ì•„ ì‹ ìƒì•„ì˜ ëª¸ë¬´ê²Œ í‰ê·  = 2800g  
# H1 (ëŒ€ë¦½ê°€ì„¤): ì—¬ì•„ ì‹ ìƒì•„ì˜ ëª¸ë¬´ê²Œ í‰ê·  > 2800g (ë‹¨ì¸¡ê²€ì •)

import pandas as pd
import numpy as np
import scipy.stats as stats
import matplotlib.pyplot as plt
import seaborn as sns

# ë°ì´í„° ë¡œë“œ
data2 = pd.read_csv('https://raw.githubusercontent.com/pykwon/python/refs/heads/master/testdata_utf8/babyboom.csv')

# ì—¬ì•„ë§Œ í•„í„°ë§ (gender == 1)
fdata = data2[data2['gender'] == 1]
print(f"ì—¬ì•„ ë°ì´í„° ê°œìˆ˜: {len(fdata)}")
print(f"í‰ê·  ëª¸ë¬´ê²Œ: {np.mean(fdata.weight):.1f}g")
print(f"í‘œì¤€í¸ì°¨: {np.std(fdata.weight):.1f}g")
```

#### ë¶„ì„ ê²°ê³¼
- **í‘œë³¸ í¬ê¸°**: 18ëª… (ì†Œí‘œë³¸)
- **í‘œë³¸ í‰ê· **: 3132.4g  
- **í‘œì¤€í¸ì°¨**: 613.8g
- **ê¸°ì¡´ ì•Œë ¤ì§„ í‰ê· **: 2800g

#### ì™„ì „í•œ ê²€ì • ì ˆì°¨
```python
# 1ë‹¨ê³„: ì •ê·œì„± ê²€ì •
shapiro_stat, shapiro_p = stats.shapiro(fdata.weight)
print(f"Shapiro-Wilk ê²€ì •: p-value = {shapiro_p:.6f}")

if shapiro_p < 0.05:
    print("ì •ê·œì„± ìœ„ë°° â†’ Wilcoxon ì‚¬ìš©")
    # Wilcoxon signed-rank test
    wilcox_stat, wilcox_p = stats.wilcoxon(fdata.weight - 2800)
    print(f"Wilcoxon ê²°ê³¼: statistic={wilcox_stat}, p-value={wilcox_p:.6f}")
else:
    print("ì •ê·œì„± ë§Œì¡± â†’ T-test ì‚¬ìš©")

# T-testë„ í•¨ê»˜ ìˆ˜í–‰ (ë¹„êµìš©)
t_stat, t_p = stats.ttest_1samp(fdata.weight, popmean=2800)
print(f"T-test ê²°ê³¼: statistic={t_stat:.5f}, p-value={t_p:.5f}")

# ê²°ë¡ 
print(f"\nğŸ¯ ê²°ë¡ :")
print(f"P-value = {t_p:.5f} < 0.05 â†’ ê·€ë¬´ê°€ì„¤ ê¸°ê°")
print(f"ì—¬ì•„ ì‹ ìƒì•„ì˜ í‰ê·  ì²´ì¤‘ì€ 2800gë³´ë‹¤ ìœ ì˜í•˜ê²Œ ì¦ê°€í•˜ì˜€ë‹¤.")
```

### ğŸ’¡ ì‹¤ìŠµë¬¸ì œ 1: ë°±ì—´ì „êµ¬ ìˆ˜ëª… ê²€ì •

```python
# ë¬¸ì œ: ìƒˆë¡œ ê°œë°œëœ ë°±ì—´ì „êµ¬ì˜ ìˆ˜ëª…ì´ 300ì‹œê°„(250 + 50)ì¸ì§€ ê²€ì •
# H0: Î¼ = 300ì‹œê°„
# H1: Î¼ â‰  300ì‹œê°„ (ì–‘ì¸¡ê²€ì •)

data_bulb = [305, 280, 296, 313, 287, 240, 259, 266, 318, 280, 325, 295, 315, 278]

result = perfect_hypothesis_testing(data_bulb, pop_mean=300)

# ì˜ˆìƒ ê²°ê³¼: p-value > 0.05 â†’ ê·€ë¬´ê°€ì„¤ ì±„íƒ
# ìƒˆë¡œ ê°œë°œëœ ì „êµ¬ì˜ ìˆ˜ëª…ì€ 300ì‹œê°„ì´ ë§ë‹¤
```

### ğŸ–¥ï¸ ì‹¤ìŠµë¬¸ì œ 2: ë…¸íŠ¸ë¶ ë°°í„°ë¦¬ ìˆ˜ëª… ê²€ì •

```python
# ë…¸íŠ¸ë¶ í‰ê·  ì‚¬ìš© ì‹œê°„ì´ 5.2ì‹œê°„ê³¼ ë‹¤ë¥¸ì§€ ê²€ì •
# H0: Î¼ = 5.2ì‹œê°„  
# H1: Î¼ â‰  5.2ì‹œê°„

# ë°ì´í„° ì „ì²˜ë¦¬
lap_data = pd.read_csv('https://raw.githubusercontent.com/pykwon/python/refs/heads/master/testdata_utf8/one_sample.csv')

# ê³µë°± ì œê±° ë° ê²°ì¸¡ì¹˜ ì²˜ë¦¬
fdata3 = lap_data['time'].replace(['     ', ""], pd.NA)
fdata3 = fdata3.dropna()
fdata3 = pd.to_numeric(fdata3)

result = perfect_hypothesis_testing(fdata3, pop_mean=5.2)

# ì˜ˆìƒ ê²°ê³¼: p-value < 0.05 â†’ ê·€ë¬´ê°€ì„¤ ê¸°ê°
# ë…¸íŠ¸ë¶ì˜ ì‚¬ìš©ì‹œê°„ì€ 5.2ì‹œê°„ê³¼ ìœ ì˜í•œ ì°¨ì´ê°€ ìˆë‹¤
```

---

## ğŸ”§ ì‹¤ë¬´ í™œìš© íŒ

### ğŸ“Š ì—‘ì…€ ë°ì´í„° ì²˜ë¦¬ ì‹¤ë¬´

```python
# ì—‘ì…€ íŒŒì¼ì—ì„œ ë°ì´í„° ì¶”ì¶œ ë° ì „ì²˜ë¦¬
def process_excel_data(filename, target_value=15000):
    """
    ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬ ë° ê°€ì„¤ê²€ì • ìˆ˜í–‰
    """
    # 1ë‹¨ê³„: ë°ì´í„° ë¡œë“œ
    data4 = pd.read_excel(filename)
    
    # 2ë‹¨ê³„: ì „ì¹˜ (í–‰/ì—´ ë°”ê¾¸ê¸°)
    data4 = data4.T
    
    # 3ë‹¨ê³„: ë¶ˆí•„ìš”í•œ í–‰ ì œê±°
    data4 = data4.drop(['ë²ˆí˜¸', 'í’ˆëª©'], errors='ignore')
    
    # 4ë‹¨ê³„: ê²°ì¸¡ì¹˜ ì œê±°
    data4 = data4.dropna()
    
    # 5ë‹¨ê³„: í•„ìš”í•œ ì—´ë§Œ ì„ íƒ
    data4 = data4.iloc[:, [0]]
    data4.columns = ['ê°€ê²©']
    
    # 6ë‹¨ê³„: ìˆ«ì íƒ€ì… ë³€í™˜
    price_data = pd.to_numeric(data4['ê°€ê²©'])
    
    # 7ë‹¨ê³„: ê°€ì„¤ê²€ì • ìˆ˜í–‰
    result = stats.ttest_1samp(price_data, popmean=target_value)
    
    print(f"í‘œë³¸ í‰ê· : {np.mean(price_data):,.0f}ì›")
    print(f"ëª¨ì§‘ë‹¨ ê°€ì • í‰ê· : {target_value:,}ì›")
    print(f"T-statistic: {result.statistic:.6f}")
    print(f"P-value: {result.pvalue:.6f}")
    
    return result, price_data

# ì‚¬ìš© ì˜ˆì‹œ
# result, data = process_excel_data('ê°œì¸ì„œë¹„ìŠ¤ì§€ì—­ë³„_ë™í–¥(2025-06ì›”)819-11ì‹œ9ë¶„.xlsx')
```

---

## ğŸ¯ í•µì‹¬ ì•”ê¸° í¬ì¸íŠ¸

### ğŸ“‹ ê°€ì„¤ê²€ì • ì²´í¬ë¦¬ìŠ¤íŠ¸

```python
def hypothesis_testing_checklist():
    """
    ê°€ì„¤ê²€ì • ì™„ë²½ ì²´í¬ë¦¬ìŠ¤íŠ¸
    """
    checklist = {
        "1ï¸âƒ£ ì •ê·œì„± ê²€ì •": "shapiro() í•¨ìˆ˜ë¡œ í™•ì¸",
        "2ï¸âƒ£ ê²€ì • ë°©ë²• ì„ íƒ": {
            "ì •ê·œì„± O": "stats.ttest_1samp() ì‚¬ìš©",
            "ì •ê·œì„± X": "stats.wilcoxon() ì‚¬ìš©"
        },
        "3ï¸âƒ£ ì‹œê°ì  í™•ì¸": "Q-Q plotìœ¼ë¡œ ì¢…ëª¨ì–‘ í™•ì¸",
        "4ï¸âƒ£ ê²°ê³¼ í•´ì„": "p-value < 0.05ë©´ ìœ ì˜í•¨"
    }
    return checklist
```

### ğŸ” ì •ê·œì„± ê²€ì • 3ë‹¨ê³„

1. **Shapiro-Wilk ê²€ì •**: í†µê³„ì  ì •ê·œì„± í™•ì¸
2. **Q-Q Plot**: ì‹œê°ì  ì •ê·œì„± í™•ì¸ (ì¢…ëª¨ì–‘ì¸ì§€)
3. **íˆìŠ¤í† ê·¸ë¨**: ë¶„í¬ ëª¨ì–‘ ì§ê´€ì  í™•ì¸

### âš–ï¸ T-test vs Wilcoxon ì„ íƒ ê¸°ì¤€

| ì¡°ê±´ | ì‚¬ìš© ê²€ì • | ì´ìœ  |
|------|---------|------|
| **ì •ê·œì„± ë§Œì¡±** | T-test | ëª¨ìˆ˜ê²€ì •, ë” ê°•ë ¥í•¨ |
| **ì •ê·œì„± ìœ„ë°°** | Wilcoxon | ë¹„ëª¨ìˆ˜ê²€ì •, ê°€ì • ì™„í™” |
| **ì†Œí‘œë³¸(n<30)** | ì •ê·œì„± í™•ì¸ í•„ìˆ˜ | ì¤‘ì‹¬ê·¹í•œì •ë¦¬ ì ìš© ì•ˆë¨ |
| **ëŒ€í‘œë³¸(nâ‰¥30)** | T-test ì£¼ë¡œ ì‚¬ìš© | ì¤‘ì‹¬ê·¹í•œì •ë¦¬ë¡œ ì •ê·œì„± í™•ë³´ |

---

## ğŸ† ë§ˆìŠ¤í„° ë‹¬ì„± í™•ì¸

### âœ… ì™„ë²½ ì´í•´ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] **Average vs Mean ì°¨ì´ ì„¤ëª… ê°€ëŠ¥**
- [ ] **ì •ê·œì„± ê²€ì • 3ë‹¨ê³„ ìˆœì„œ ì•”ê¸°**
- [ ] **ë°ì´í„° ì „ì²˜ë¦¬ ì‹œ ì „ì¹˜í–‰ë ¬ ì£¼ì˜ì‚¬í•­ ìˆ™ì§€**
- [ ] **ê°€ì„¤ê²€ì • 4ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° ì™„ë²½ ì‹¤í–‰**
- [ ] **T-testì™€ Wilcoxon ì„ íƒ ê¸°ì¤€ ëª…í™•íˆ êµ¬ë¶„**
- [ ] **Q-Q Plot í•´ì„ ëŠ¥ë ¥ ë³´ìœ **
- [ ] **ì‹¤ë¬´ ë°ì´í„°(CSV, Excel) ì²˜ë¦¬ ëŠ¥ë ¥ í™•ë³´**

### ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

ì´ì œ ë‹¤ìŒê³¼ ê°™ì€ ê³ ê¸‰ ì£¼ì œë¡œ ë„˜ì–´ê°ˆ ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤:

1. **ë…ë¦½í‘œë³¸ T-test**: ë‘ ê·¸ë£¹ ê°„ í‰ê·  ë¹„êµ
2. **ëŒ€ì‘í‘œë³¸ T-test**: ì „í›„ ë¹„êµ ë¶„ì„  
3. **ANOVA**: 3ê°œ ì´ìƒ ê·¸ë£¹ ë¹„êµ
4. **ì¹´ì´ì œê³± ê²€ì •**: ë²”ì£¼í˜• ë°ì´í„° ë¶„ì„
5. **íšŒê·€ë¶„ì„**: ë³€ìˆ˜ ê°„ ê´€ê³„ ë¶„ì„

---

## ğŸ’¡ ìµœì¢… ì •ë¦¬

### ğŸ‰ í•µì‹¬ ë©”ì‹œì§€

> **"ì´ì œë¶€í„° ì–´ë–¤ ê°€ì„¤ì„ ê²€ì •í•´ë¼ í•˜ë©´"**
> 
> 1. **Shapiro**ë¡œ ì •ê·œì„± ë¨¼ì € ê²€ì •
> 2. **ì •ê·œì„± ì„±ë¦½í•˜ë©´ T-test**  
> 3. **ì •ê·œì„± ìœ„ë°°í•˜ë©´ Wilcoxon**
> 4. **Q-Q plotìœ¼ë¡œ ì¢…ëª¨ì–‘ ì‹œê°ì  í™•ì¸**
> 
> **ì´ ìˆœì„œë§Œ ê¸°ì–µí•˜ë©´ ê°€ì„¤ê²€ì • ë§ˆìŠ¤í„°!** ğŸ†

### ğŸš€ ì‹¤ë¬´ ì ìš© ê³µì‹

```python
# ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜
def quick_hypothesis_test(data, pop_mean, alpha=0.05):
    """ì›í´ë¦­ ê°€ì„¤ê²€ì •"""
    _, norm_p = stats.shapiro(data)
    
    if norm_p > alpha:
        stat, p = stats.ttest_1samp(data, pop_mean)
        method = "T-test"
    else:
        stat, p = stats.wilcoxon(data - pop_mean)  
        method = "Wilcoxon"
    
    result = "ìœ ì˜í•¨" if p < alpha else "ìœ ì˜í•˜ì§€ ì•ŠìŒ"
    
    return {
        'method': method,
        'statistic': stat, 
        'p_value': p,
        'result': result
    }
```

## ğŸ”¥ ë…ë¦½í‘œë³¸ Tê²€ì • (Independent Samples T-test)

### ğŸ¯ ë…ë¦½í‘œë³¸ Tê²€ì •ì´ë€?

**ì„œë¡œ ë…ë¦½ì¸ ë‘ ì§‘ë‹¨ì˜ í‰ê·  ì°¨ì´ë¥¼ ê²€ì •**í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

#### í•µì‹¬ ê°œë…
```python
# ë…ë¦½í‘œë³¸ Tê²€ì •ì˜ ë³¸ì§ˆ
Tê²€ì • = ë‘ ì§‘ë‹¨ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ë¹„ìœ¨ì— ëŒ€í•œ ëŒ€ì¡° ê²€ì •ë²•

t = (ì§‘ë‹¨ê°„ í‰ê·  ì°¨ì´) / (í‘œì¤€ì˜¤ì°¨)
  = (XÌ„â‚ - XÌ„â‚‚) / (í‘œì¤€í¸ì°¨ ë¹„ìœ¨)
```

### ğŸ“Š ì–¸ì œ ì‚¬ìš©í•˜ë‚˜ìš”?

- **ë‚¨ë…€ì˜ ì„±ì  ì°¨ì´** ê²€ì •
- **Aë°˜ê³¼ Bë°˜ì˜ ì ìˆ˜ ì°¨ì´** ê²€ì •  
- **ê²½ê¸°ë„ì™€ ì¶©ì²­ë„ì˜ ì†Œë“ ì°¨ì´** ê²€ì •
- **ë¹„ ì˜¨ ë‚ ê³¼ ì•ˆ ì˜¨ ë‚ ì˜ ë§¤ì¶œ ì°¨ì´** ê²€ì •

### âš¡ í•µì‹¬ ì „ì œì¡°ê±´

#### 1. ì •ê·œì„± (Normality)
```python
# ì •ê·œì„± ê²€ì •
stats.shapiro(group1_data)
stats.shapiro(group2_data) 
# p > 0.05ë©´ ì •ê·œì„± ë§Œì¡±
```

#### 2. ë“±ë¶„ì‚°ì„± (Equal Variance)
```python
# ë“±ë¶„ì‚°ì„± ê²€ì • - Levene test (ê°€ì¥ ì¼ë°˜ì )
stats.levene(group1_data, group2_data)
# p > 0.05ë©´ ë“±ë¶„ì‚°ì„± ë§Œì¡±
```

### ğŸ”§ Python êµ¬í˜„

#### ë“±ë¶„ì‚°ì„± ë§Œì¡±í•˜ëŠ” ê²½ìš°
```python
# ê¸°ë³¸ ë…ë¦½í‘œë³¸ Tê²€ì •
stat, p = stats.ttest_ind(group1, group2)
print(f"T-statistic: {stat:.5f}")
print(f"P-value: {p:.5f}")
```

#### ë“±ë¶„ì‚°ì„± ìœ„ë°°í•˜ëŠ” ê²½ìš°  
```python
# Welch's T-test (ë“±ë¶„ì‚° ê°€ì • ì—†ìŒ)
stat, p = stats.ttest_ind(group1, group2, equal_var=False)
print(f"Welch T-statistic: {stat:.5f}")
print(f"P-value: {p:.5f}")
```

---

## ğŸ—ƒï¸ ë°ì´í„° ë³‘í•© (Data Merging) ì‹¤ë¬´

### ğŸ“ ì—¬ëŸ¬ íŒŒì¼ í•©ì¹˜ê¸°

ì‹¤ì œ ì—…ë¬´ì—ì„œëŠ” **ë°ì´í„°ê°€ ì—¬ëŸ¬ íŒŒì¼ë¡œ ë¶„ì‚°**ë˜ì–´ ìˆëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.

#### ì˜ˆì‹œ: ë‚ ì”¨ì™€ ë§¤ì¶œ ë°ì´í„° ë¶„ì„

```python
# 1ë‹¨ê³„: ê°œë³„ íŒŒì¼ ë¡œë“œ
sales_data = pd.read_csv('t_sales.csv', dtype={'YMD': 'object'})
weather_data = pd.read_csv('t_weather.csv', dtype={'YMD': 'object'})

print(f"ë§¤ì¶œ ë°ì´í„°: {sales_data.shape}")    # (328, 3)  
print(f"ë‚ ì”¨ ë°ì´í„°: {weather_data.shape}")   # (702, 9)

# 2ë‹¨ê³„: ë‚ ì§œ í˜•ì‹ í†µì¼
# ë§¤ì¶œ: '2019-05-19', ë‚ ì”¨: '20190519' â†’ í†µì¼ í•„ìš”

# 3ë‹¨ê³„: ê³µí†µ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•© 
merged_data = pd.merge(sales_data, weather_data, on='YMD', how='inner')

# 4ë‹¨ê³„: í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
final_data = merged_data.iloc[:, [0, 1, 7, 8]]  # YMD, AMT, MAX_TEMP, SUM_RN
final_data.columns = ['ë‚ ì§œ', 'ë§¤ì¶œì•¡', 'ìµœê³ ê¸°ì˜¨', 'ê°•ìˆ˜ëŸ‰']
```

### ğŸ’¡ ë°ì´í„° ë³€í™˜ ì‹¤ë¬´ íŒ

#### ë²”ì£¼í˜• ë³€ìˆ˜ ìƒì„±
```python
# ê°•ìˆ˜ëŸ‰ì„ ì´ì§„ ë³€ìˆ˜ë¡œ ë³€í™˜
data['rain_yn'] = (data['ê°•ìˆ˜ëŸ‰'] > 0).astype(int)
# ë˜ëŠ”
data['rain_yn'] = np.where(data['ê°•ìˆ˜ëŸ‰'] > 0, 1, 0)

# í™•ì¸
print(data['rain_yn'].value_counts())
# 0: ë¹„ ì•ˆì˜¨ ë‚ 
# 1: ë¹„ ì˜¨ ë‚ 
```

#### ê·¸ë£¹ ë¶„í• 
```python
# ë¹„ ì•ˆì˜¨ ë‚  ë§¤ì¶œì•¡
no_rain_sales = data.loc[data['rain_yn'] == 0, 'ë§¤ì¶œì•¡']

# ë¹„ ì˜¨ ë‚  ë§¤ì¶œì•¡  
rain_sales = data.loc[data['rain_yn'] == 1, 'ë§¤ì¶œì•¡']

print(f"ë¹„ ì•ˆì˜¨ ë‚  í‰ê· : {no_rain_sales.mean():.0f}")
print(f"ë¹„ ì˜¨ ë‚  í‰ê· : {rain_sales.mean():.0f}")
```

---

## ğŸ“ˆ ë°•ìŠ¤í”Œë¡¯ìœ¼ë¡œ ì‹œê°í™”

### ğŸ¨ ë‘ ê·¸ë£¹ ë¹„êµ ì‹œê°í™”

```python
import matplotlib.pyplot as plt
import seaborn as sns

# ë°•ìŠ¤í”Œë¡¯ ìƒì„±
plt.figure(figsize=(10, 6))
box_data = [no_rain_sales, rain_sales] 
labels = ['ë¹„ ì•ˆì˜¨ ë‚ ', 'ë¹„ ì˜¨ ë‚ ']

bp = plt.boxplot(box_data, labels=labels, patch_artist=True,
                 showmeans=True, meanline=True)

# ë°•ìŠ¤ ìƒ‰ê¹” êµ¬ë¶„
bp['boxes'][0].set_facecolor('lightblue')   # ë¹„ ì•ˆì˜¨ ë‚ 
bp['boxes'][1].set_facecolor('lightcoral')  # ë¹„ ì˜¨ ë‚ 

plt.title('ê°•ìˆ˜ ì—¬ë¶€ì— ë”°ë¥¸ ë§¤ì¶œì•¡ ë¶„í¬')
plt.ylabel('ë§¤ì¶œì•¡')
plt.grid(True, alpha=0.3)
plt.show()

# í‰ê· ê°’ ì¶œë ¥
print(f"ë¹„ ì•ˆì˜¨ ë‚  í‰ê· : {np.mean(no_rain_sales):,.0f}ì›")
print(f"ë¹„ ì˜¨ ë‚  í‰ê· : {np.mean(rain_sales):,.0f}ì›")
```

---

## ğŸ”¥ ì™„ë²½í•œ ë…ë¦½í‘œë³¸ Tê²€ì • ì›Œí¬í”Œë¡œìš°

```python
def complete_independent_ttest(data, group_col, value_col, alpha=0.05):
    """
    ì™„ë²½í•œ ë…ë¦½í‘œë³¸ Tê²€ì • ì‹¤í–‰
    """
    # 1ë‹¨ê³„: ê·¸ë£¹ ë¶„í• 
    groups = data.groupby(group_col)[value_col]
    group1 = groups.get_group(0)  # ì²« ë²ˆì§¸ ê·¸ë£¹
    group2 = groups.get_group(1)  # ë‘ ë²ˆì§¸ ê·¸ë£¹
    
    print("ğŸ” 1ë‹¨ê³„: ê¸°ìˆ í†µê³„")
    print(f"ê·¸ë£¹1 (n={len(group1)}): í‰ê·  {np.mean(group1):.2f}")
    print(f"ê·¸ë£¹2 (n={len(group2)}): í‰ê·  {np.mean(group2):.2f}")
    
    # 2ë‹¨ê³„: ì •ê·œì„± ê²€ì •
    _, p1 = stats.shapiro(group1)
    _, p2 = stats.shapiro(group2)
    print(f"\nğŸ“Š 2ë‹¨ê³„: ì •ê·œì„± ê²€ì •")
    print(f"ê·¸ë£¹1 p-value: {p1:.6f}")
    print(f"ê·¸ë£¹2 p-value: {p2:.6f}")
    
    normality = (p1 > alpha) and (p2 > alpha)
    if normality:
        print("âœ… ì •ê·œì„± ë§Œì¡±")
    else:
        print("âŒ ì •ê·œì„± ìœ„ë°° â†’ ë¹„ëª¨ìˆ˜ ê²€ì • ê³ ë ¤")
    
    # 3ë‹¨ê³„: ë“±ë¶„ì‚°ì„± ê²€ì •
    _, p_levene = stats.levene(group1, group2)
    print(f"\nâš–ï¸ 3ë‹¨ê³„: ë“±ë¶„ì‚°ì„± ê²€ì •")
    print(f"Levene test p-value: {p_levene:.6f}")
    
    equal_var = p_levene > alpha
    if equal_var:
        print("âœ… ë“±ë¶„ì‚°ì„± ë§Œì¡± â†’ ì¼ë°˜ Tê²€ì •")
        test_name = "Independent T-test"
    else:
        print("âŒ ë“±ë¶„ì‚°ì„± ìœ„ë°° â†’ Welch Tê²€ì •")
        test_name = "Welch's T-test"
    
    # 4ë‹¨ê³„: Tê²€ì • ìˆ˜í–‰
    t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=equal_var)
    
    print(f"\nğŸ¯ 4ë‹¨ê³„: {test_name}")
    print(f"T-statistic: {t_stat:.5f}")
    print(f"P-value: {p_value:.6f}")
    
    # 5ë‹¨ê³„: ê²°ë¡ 
    print(f"\nğŸ“‹ 5ë‹¨ê³„: ê²°ë¡  (Î± = {alpha})")
    if p_value < alpha:
        print(f"âœ… P-value({p_value:.6f}) < {alpha}")
        print("â†’ ê·€ë¬´ê°€ì„¤ ê¸°ê°, ë‘ ê·¸ë£¹ ê°„ ìœ ì˜í•œ ì°¨ì´ ìˆìŒ")
        conclusion = "significant"
    else:
        print(f"âŒ P-value({p_value:.6f}) â‰¥ {alpha}")
        print("â†’ ê·€ë¬´ê°€ì„¤ ì±„íƒ, ë‘ ê·¸ë£¹ ê°„ ìœ ì˜í•œ ì°¨ì´ ì—†ìŒ")
        conclusion = "not_significant"
    
    return {
        'test_name': test_name,
        'statistic': t_stat,
        'p_value': p_value,
        'conclusion': conclusion,
        'normality': normality,
        'equal_variance': equal_var
    }

# ì‚¬ìš© ì˜ˆì‹œ
result = complete_independent_ttest(data, 'rain_yn', 'ë§¤ì¶œì•¡')
```

---

## âš ï¸ ì‹¤ë¬´ ì£¼ì˜ì‚¬í•­

### ğŸ“Š í‘œë³¸ í¬ê¸° ë¶ˆê· í˜•
```python
# ë¬¸ì œ: ê·¸ë£¹ í¬ê¸°ê°€ ë„ˆë¬´ ë‹¤ë¥¸ ê²½ìš°
print(data['rain_yn'].value_counts())
# 0    250  (ë¹„ ì•ˆì˜¨ ë‚  - ë§ìŒ)
# 1     78  (ë¹„ ì˜¨ ë‚  - ì ìŒ)

# ëŒ€ì•ˆ1: ì¸µí™”í‘œë³¸ì¶”ì¶œë¡œ ê· í˜• ë§ì¶”ê¸°
# ëŒ€ì•ˆ2: ë¹„ëª¨ìˆ˜ ê²€ì • ì‚¬ìš©
# ëŒ€ì•ˆ3: í‘œë³¸ í¬ê¸° ëŠ˜ë¦¬ê¸°
```

### ğŸ¯ í•´ì„ ì‹œ ì£¼ì˜ì 

1. **ìƒê´€ê´€ê³„ â‰  ì¸ê³¼ê´€ê³„**
   - ë¹„ê°€ ì™€ì„œ ë§¤ì¶œì´ ì¤„ì—ˆë‹¤ (Ã—)
   - ë¹„ì™€ ë§¤ì¶œ ê°„ ì—°ê´€ì„±ì´ ìˆë‹¤ (â—‹)

2. **ë‹¤ë¥¸ ìš”ì¸ ê³ ë ¤**
   - ê°•ìˆ˜ëŸ‰ë§Œìœ¼ë¡œ ë§¤ì¶œì´ ê²°ì •ë˜ì§€ ì•ŠìŒ
   - ìš”ì¼, ê³„ì ˆ, ì´ë²¤íŠ¸ ë“± ë‹¤ì–‘í•œ ë³€ìˆ˜ ì¡´ì¬

3. **ì‹¤ë¬´ì  ì˜ë¯¸ vs í†µê³„ì  ìœ ì˜ì„±**
   - p < 0.05ì—¬ë„ ì‹¤ë¬´ì ìœ¼ë¡œ ë¬´ì˜ë¯¸í•  ìˆ˜ ìˆìŒ
   - íš¨ê³¼í¬ê¸°(Effect Size)ë„ í•¨ê»˜ ê³ ë ¤

---

## ğŸ† ë§ˆìŠ¤í„° ì²´í¬ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸

### âœ… ë…ë¦½í‘œë³¸ Tê²€ì • ì™„ì „ ì •ë³µ

- [ ] **ë…ë¦½í‘œë³¸ Tê²€ì •ì˜ ì›ë¦¬ ì´í•´**
- [ ] **ì •ê·œì„± + ë“±ë¶„ì‚°ì„± ê²€ì • ìˆ˜í–‰**  
- [ ] **ì¼ë°˜ Tê²€ì • vs Welch Tê²€ì • êµ¬ë¶„**
- [ ] **ì—¬ëŸ¬ íŒŒì¼ ë³‘í•© ë° ì „ì²˜ë¦¬ ëŠ¥ë ¥**
- [ ] **ë²”ì£¼í˜• ë³€ìˆ˜ ìƒì„± ë° ê·¸ë£¹ ë¶„í• **
- [ ] **ë°•ìŠ¤í”Œë¡¯ìœ¼ë¡œ ì‹œê°í™”**
- [ ] **ì™„ë²½í•œ ì›Œí¬í”Œë¡œìš° êµ¬í˜„**
- [ ] **ê²°ê³¼ í•´ì„ ë° ì‹¤ë¬´ì  í•¨ì˜ ë„ì¶œ**

### ğŸ¯ ë‹¤ìŒ í•™ìŠµ: ëŒ€ì‘í‘œë³¸ Tê²€ì •

ì´ì œ **paired samples T-test**(ëŒ€ì‘í‘œë³¸ Tê²€ì •)ë¡œ ë„˜ì–´ê°ˆ ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!

- ì „í›„ ë¹„êµ (ë‹¤ì´ì–´íŠ¸ í”„ë¡œê·¸ë¨ íš¨ê³¼)
- ë™ì¼ ëŒ€ìƒ ë°˜ë³µ ì¸¡ì •
- ì§ì§€ì–´ì§„ ë°ì´í„° ë¶„ì„

---

## ğŸ¯ ì‹¤ì „ ë¬¸ì œ ì™„ì „ ì •ë³µ

### ğŸ“ ë¬¸ì œ 1: í¬ì¥ì§€ ìƒ‰ìƒê³¼ ë§¤ì¶œ ë¶„ì„

```python
# [two-sample t ê²€ì • : ë¬¸ì œ1] 
# í¬ì¥ì§€ ìƒ‰ìƒì— ë”°ë¥¸ ì œí’ˆ ë§¤ì¶œì•¡ ì°¨ì´ ê²€ì •

# H0: í¬ì¥ì§€ ìƒ‰ìƒì— ë”°ë¥¸ ë§¤ì¶œì•¡ì€ ë³€ë™ì´ ì—†ë‹¤
# H1: í¬ì¥ì§€ ìƒ‰ìƒê³¼ ë§¤ì¶œì•¡ì€ ê´€ë ¨ì´ ìˆë‹¤

import numpy as np
import pandas as pd
import scipy.stats as stats
from scipy.stats import levene

blue = [70,68,82,78,81,68,67,68,88,60,80]
red = [60,65,55,58,67,59,61,68,77,66,66]

# 1ë‹¨ê³„: ë“±ë¶„ì‚°ì„± ê²€ì •
leven_stat, leven_p = levene(blue, red)
print(f'ë“±ë¶„ì‚°ì„± ê²€ì • - Levene í†µê³„ëŸ‰: {leven_stat:.4f}, p-value: {leven_p:.4f}')
# p = 0.2487 > 0.05 â†’ ë“±ë¶„ì‚°ì„± ì„±ë¦½

# 2ë‹¨ê³„: ë…ë¦½í‘œë³¸ Tê²€ì • 
t_stat, p_value = stats.ttest_ind(blue, red, equal_var=True)
print(f'Tê²€ì • ê²°ê³¼ - tí†µê³„ëŸ‰: {t_stat:.4f}, p-value: {p_value:.6f}')

# ê²°ë¡ : p = 0.0056 < 0.05 â†’ ê·€ë¬´ê°€ì„¤ ê¸°ê°
# í¬ì¥ì§€ ìƒ‰ìƒê³¼ ë§¤ì¶œì•¡ì€ ê´€ë ¨ì´ ìˆë‹¤!
```

### ğŸ“ ë¬¸ì œ 2: ì„±ë³„ ì½œë ˆìŠ¤í…Œë¡¤ ì°¨ì´ ë¶„ì„

```python
# [two-sample t ê²€ì • : ë¬¸ì œ2] 
# ë‚¨ë…€ ê°„ í˜ˆê´€ ë‚´ ì½œë ˆìŠ¤í…Œë¡¤ ì–‘ ì°¨ì´ ê²€ì •

# H0: ì½œë ˆìŠ¤í…Œë¡¤ ì–‘ì€ ë‚¨ë…€ ì„±ë³„ì— ê´€ê³„ê°€ ì—†ë‹¤
# H1: ì½œë ˆìŠ¤í…Œë¡¤ ì–‘ì€ ë‚¨ë…€ ì„±ë³„ì— ê´€ê³„ê°€ ìˆë‹¤

import random

man = [0.9,2.2,1.6,2.8,4.2,3.7,2.6,2.9,3.3,1.2,3.2,2.7,3.8,4.5,4,2.2,0.8,0.5,0.3,5.3,5.7,2.3,9.8]
woman = [1.4,2.7,2.1,1.8,3.3,3.2,1.6,1.9,2.3,2.85,2.3,1.4,2.6,3.5,2.1,6.6,7.7,8.8,6.6,6.4]

# ë¬´ì‘ìœ„ë¡œ 15ëª…ì”© ì¶”ì¶œ
sample_man = random.sample(man, 15)
sample_woman = random.sample(woman, 15)

# ë“±ë¶„ì‚°ì„± ê²€ì •
leven_stat, leven_p = levene(sample_man, sample_woman)
print(f'ë“±ë¶„ì‚°ì„± ê²€ì • - p-value: {leven_p:.4f}')
# p > 0.05 â†’ ë“±ë¶„ì‚°ì„± ì„±ë¦½

# ë…ë¦½í‘œë³¸ Tê²€ì •
t_stat, p_value = stats.ttest_ind(sample_man, sample_woman, equal_var=True)
print(f'ì½œë ˆìŠ¤í…Œë¡¤ Tê²€ì • - t: {t_stat:.4f}, p: {p_value:.4f}')

# ê²°ë¡ : p = 0.519 > 0.05 â†’ ê·€ë¬´ê°€ì„¤ ì±„íƒ
# ì½œë ˆìŠ¤í…Œë¡¤ ìˆ˜ì¹˜ëŠ” ì„±ë³„ê³¼ ê´€ê³„ì—†ë‹¤
```

### ğŸ“ ë¬¸ì œ 3: DB ì—°ë™ ë¶€ì„œë³„ ì—°ë´‰ ë¶„ì„

```python
# [two-sample t ê²€ì • : ë¬¸ì œ3] 
# DB ë°ì´í„°ë¡œ ì´ë¬´ë¶€ vs ì˜ì—…ë¶€ ì—°ë´‰ ì°¨ì´ ê²€ì •

# H0: ì´ë¬´ë¶€ì™€ ì˜ì—…ë¶€ ì§ì›ì˜ ì—°ë´‰ ê²©ì°¨ëŠ” ì—†ë‹¤
# H1: ì´ë¬´ë¶€ì™€ ì˜ì—…ë¶€ ì§ì›ì˜ ì—°ë´‰ì€ ë¶€ì„œì— ì˜í–¥ë°›ëŠ”ë‹¤

import MySQLdb
import pickle
import sys

try:
    # DB ì—°ê²° ì„¤ì • ë¡œë“œ
    with open('./mymaria.dat', mode='rb') as obj:
        config = pickle.load(obj)
    
    # DB ì—°ê²° ë° ì¿¼ë¦¬ ì‹¤í–‰
    conn = MySQLdb.connect(**config)
    cursor = conn.cursor()
    
    sql = """
        SELECT jikwonpay as ì—°ë´‰, busernum as ë¶€ì„œë²ˆí˜¸, busername as ë¶€ì„œëª…
        FROM jikwon INNER JOIN buser
        ON jikwon.busernum = buser.buserno
        WHERE busername IN ('ì´ë¬´ë¶€', 'ì˜ì—…ë¶€')
    """
    cursor.execute(sql)
    df = pd.DataFrame(cursor.fetchall(), 
                     columns=['ì—°ë´‰', 'ë¶€ì„œë²ˆí˜¸', 'ë¶€ì„œëª…'])
    
    # ë¶€ì„œë³„ ë°ì´í„° ë¶„ë¦¬
    chong = df[df['ë¶€ì„œëª…'] == 'ì´ë¬´ë¶€']['ì—°ë´‰']
    young = df[df['ë¶€ì„œëª…'] == 'ì˜ì—…ë¶€']['ì—°ë´‰']
    
    # ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜
    chong = pd.to_numeric(chong)
    young = pd.to_numeric(young)
    
    # ë“±ë¶„ì‚°ì„± ê²€ì •
    leven_stat, leven_p = levene(young, chong)
    print(f'ë“±ë¶„ì‚°ì„± ê²€ì • - p-value: {leven_p:.4f}')
    # p = 0.915 > 0.05 â†’ ë“±ë¶„ì‚°ì„± ì„±ë¦½
    
    # ë…ë¦½í‘œë³¸ Tê²€ì •
    t_stat, p_value = stats.ttest_ind(chong, young, equal_var=True)
    print(f'ë¶€ì„œë³„ ì—°ë´‰ Tê²€ì • - t: {t_stat:.4f}, p: {p_value:.4f}')
    
    # ê²°ë¡ : p = 0.652 > 0.05 â†’ ê·€ë¬´ê°€ì„¤ ì±„íƒ
    # ë¶€ì„œë³„ ì—°ë´‰ì—ëŠ” ìœ ì˜í•œ ì°¨ì´ê°€ ì—†ë‹¤
    
except Exception as e:
    print(f'ì²˜ë¦¬ ì˜¤ë¥˜: {e}')
finally:
    conn.close()
```

---

## ğŸŒ§ï¸ ì¢…í•© ì‹¤ìŠµ: ë‚ ì”¨ì™€ ë§¤ì¶œ ë¶„ì„

### ğŸ“Š ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ë°ì´í„° ë¶„ì„

```python
# ë¹„(ëˆˆ) ì—¬ë¶€ì— ë”°ë¥¸ ìŒì‹ì  ë§¤ì¶œì•¡ í‰ê·  ì°¨ì´ ê²€ì •
# H0: ê°•ìˆ˜ëŸ‰ì— ë”°ë¥¸ ìŒì‹ì  ë§¤ì¶œì•¡ í‰ê· ì˜ ì°¨ì´ëŠ” ì—†ë‹¤
# H1: ê°•ìˆ˜ëŸ‰ì— ë”°ë¥¸ ìŒì‹ì  ë§¤ì¶œì•¡ í‰ê· ì€ ì°¨ì´ê°€ ìˆë‹¤

import numpy as np
import pandas as pd
import scipy.stats as stats
import matplotlib.pyplot as plt

# 1ë‹¨ê³„: ë°ì´í„° ë¡œë“œ
sales_data = pd.read_csv('tsales.csv', dtype={'YMD': 'object'})
wt_data = pd.read_csv('tweather.csv')

print(f"ë§¤ì¶œ ë°ì´í„°: {sales_data.shape}")  # (328, 3)
print(f"ë‚ ì”¨ ë°ì´í„°: {wt_data.shape}")    # (702, 9)

# 2ë‹¨ê³„: ë‚ ì§œ í˜•ì‹ í†µì¼
wt_data['tm'] = wt_data['tm'].map(lambda x: x.replace('-', ''))

# 3ë‹¨ê³„: ë°ì´í„° ë³‘í•© (ë§¤ì¶œ ê¸°ì¤€ LEFT JOIN)
frame = sales_data.merge(wt_data, how='left', left_on='YMD', right_on='tm')
print(f"ë³‘í•©ëœ ë°ì´í„°: {frame.shape}")

# 4ë‹¨ê³„: í•„ìš” ì»¬ëŸ¼ë§Œ ì„ íƒ
data = frame.iloc[:, [0,1,7,8]]  # ë‚ ì§œ, ë§¤ì¶œì•¡, ìµœê³ ê¸°ì˜¨, ê°•ìˆ˜ëŸ‰
data.columns = ['ë‚ ì§œ', 'ë§¤ì¶œì•¡', 'ìµœê³ ê¸°ì˜¨', 'ê°•ìˆ˜ëŸ‰']

# 5ë‹¨ê³„: ê²°ì¸¡ì¹˜ í™•ì¸
print("ê²°ì¸¡ì¹˜ í˜„í™©:")
print(data.isnull().sum())

# 6ë‹¨ê³„: ë²”ì£¼í˜• ë³€ìˆ˜ ìƒì„±
data['rain_yn'] = (data['ê°•ìˆ˜ëŸ‰'] > 0).astype(int)
print(f"\nê°•ìˆ˜ ì—¬ë¶€ ë¶„í¬:")
print(data['rain_yn'].value_counts())

# 7ë‹¨ê³„: ê·¸ë£¹ë³„ ë°ì´í„° ë¶„í• 
sp = np.array(data[['ë§¤ì¶œì•¡', 'rain_yn']])
tg1 = sp[sp[:, 1] == 0, 0]  # ë¹„ ì•ˆì˜¨ ë‚  ë§¤ì¶œì•¡
tg2 = sp[sp[:, 1] == 1, 0]  # ë¹„ ì˜¨ ë‚  ë§¤ì¶œì•¡

print(f"\nê·¸ë£¹ë³„ ê¸°ìˆ í†µê³„:")
print(f"ë¹„ ì•ˆì˜¨ ë‚  (n={len(tg1)}): í‰ê·  {np.mean(tg1):,.0f}ì›")
print(f"ë¹„ ì˜¨ ë‚  (n={len(tg2)}): í‰ê·  {np.mean(tg2):,.0f}ì›")

# 8ë‹¨ê³„: ì‹œê°í™”
plt.figure(figsize=(10, 6))
plt.boxplot([tg1, tg2], labels=['ë¹„ ì•ˆì˜¨ ë‚ ', 'ë¹„ ì˜¨ ë‚ '], 
           meanline=True, showmeans=True, notch=True,
           patch_artist=True)
plt.title('ê°•ìˆ˜ ì—¬ë¶€ì— ë”°ë¥¸ ë§¤ì¶œì•¡ ë¶„í¬')
plt.ylabel('ë§¤ì¶œì•¡ (ì›)')
plt.grid(True, alpha=0.3)
plt.show()

# 9ë‹¨ê³„: ì „ì œì¡°ê±´ ê²€ì •
print("\nğŸ” ì „ì œì¡°ê±´ ê²€ì •")
print("-" * 50)

# ì •ê·œì„± ê²€ì •
shapiro1 = stats.shapiro(tg1).pvalue
shapiro2 = stats.shapiro(tg2).pvalue
print(f"ì •ê·œì„± ê²€ì • - ë¹„ ì•ˆì˜¨ ë‚ : {shapiro1:.4f}")
print(f"ì •ê·œì„± ê²€ì • - ë¹„ ì˜¨ ë‚ : {shapiro2:.4f}")

# ë“±ë¶„ì‚°ì„± ê²€ì •  
levene_p = stats.levene(tg1, tg2).pvalue
print(f"ë“±ë¶„ì‚°ì„± ê²€ì •: {levene_p:.4f}")

if levene_p > 0.05:
    print("âœ… ë“±ë¶„ì‚°ì„± ë§Œì¡± â†’ ì¼ë°˜ Tê²€ì • ì‚¬ìš©")
    equal_var = True
else:
    print("âŒ ë“±ë¶„ì‚°ì„± ìœ„ë°° â†’ Welch Tê²€ì • ì‚¬ìš©")
    equal_var = False

# 10ë‹¨ê³„: ë…ë¦½í‘œë³¸ Tê²€ì •
t_stat, p_value = stats.ttest_ind(tg1, tg2, equal_var=equal_var)

print(f"\nğŸ¯ ë…ë¦½í‘œë³¸ Tê²€ì • ê²°ê³¼")
print("-" * 50)
print(f"T-statistic: {t_stat:.6f}")
print(f"P-value: {p_value:.6f}")
print(f"ììœ ë„: {len(tg1) + len(tg2) - 2}")

# 11ë‹¨ê³„: ê²°ë¡ 
alpha = 0.05
if p_value < alpha:
    print(f"\nâœ… ê²°ë¡ : p({p_value:.6f}) < Î±({alpha})")
    print("â†’ ê·€ë¬´ê°€ì„¤ ê¸°ê°, ê°•ìˆ˜ ì—¬ë¶€ì— ë”°ë¥¸ ë§¤ì¶œì•¡ ì°¨ì´ ìˆìŒ")
else:
    print(f"\nâŒ ê²°ë¡ : p({p_value:.6f}) â‰¥ Î±({alpha})")
    print("â†’ ê·€ë¬´ê°€ì„¤ ì±„íƒ, ê°•ìˆ˜ ì—¬ë¶€ì— ë”°ë¥¸ ë§¤ì¶œì•¡ ì°¨ì´ ì—†ìŒ")

# íš¨ê³¼í¬ê¸° ê³„ì‚° (Cohen's d)
pooled_std = np.sqrt(((len(tg1)-1)*np.var(tg1, ddof=1) + 
                     (len(tg2)-1)*np.var(tg2, ddof=1)) / 
                     (len(tg1)+len(tg2)-2))
cohens_d = (np.mean(tg1) - np.mean(tg2)) / pooled_std
print(f"\nğŸ“Š íš¨ê³¼í¬ê¸° (Cohen's d): {cohens_d:.4f}")

if abs(cohens_d) < 0.2:
    print("â†’ ì‘ì€ íš¨ê³¼í¬ê¸°")
elif abs(cohens_d) < 0.5:
    print("â†’ ì¤‘ê°„ íš¨ê³¼í¬ê¸°")
else:
    print("â†’ í° íš¨ê³¼í¬ê¸°")
```

---

## ğŸ’¡ ì‹¤ë¬´ í•´ì„ ê°€ì´ë“œ

### ğŸ¯ ê²°ê³¼ í•´ì„ ì²´í¬ë¦¬ìŠ¤íŠ¸

#### âœ… í†µê³„ì  ê´€ì 
1. **ì „ì œì¡°ê±´ í™•ì¸**: ì •ê·œì„±, ë“±ë¶„ì‚°ì„± ë§Œì¡± ì—¬ë¶€
2. **ê²€ì •í†µê³„ëŸ‰**: tê°’ì˜ í¬ê¸°ì™€ ë°©í–¥
3. **ìœ ì˜í™•ë¥ **: p-valueì™€ ìœ ì˜ìˆ˜ì¤€ ë¹„êµ
4. **íš¨ê³¼í¬ê¸°**: ì‹¤ë¬´ì  ì˜ë¯¸ ìˆëŠ” ì°¨ì´ì¸ê°€?

#### âœ… ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì   
1. **ì‹¤ë¬´ì  ì˜ë¯¸**: í†µê³„ì  ìœ ì˜ì„± â‰  ì‹¤ë¬´ì  ì¤‘ìš”ì„±
2. **ë‹¤ë¥¸ ìš”ì¸**: ë‹¨ì¼ ë³€ìˆ˜ë¡œë§Œ ì„¤ëª…í•˜ì§€ ë§ ê²ƒ
3. **ì˜ì‚¬ê²°ì •**: ê²°ê³¼ë¥¼ ì–´ë–»ê²Œ í™œìš©í•  ê²ƒì¸ê°€?
4. **ì¶”ê°€ ë¶„ì„**: ë” ê¹Šì´ ìˆëŠ” ë¶„ì„ì´ í•„ìš”í•œê°€?

### ğŸš¨ ì£¼ì˜ì‚¬í•­

#### ğŸ“Š ë°ì´í„° í’ˆì§ˆ
- **ê²°ì¸¡ì¹˜ ì²˜ë¦¬**: ì ì ˆí•œ ë°©ë²•ìœ¼ë¡œ ì²˜ë¦¬í–ˆëŠ”ê°€?
- **ì´ìƒì¹˜ í™•ì¸**: ê·¹ê°’ë“¤ì´ ê²°ê³¼ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
- **í‘œë³¸ í¬ê¸°**: ì¶©ë¶„í•œ ê²€ì •ë ¥ì„ í™•ë³´í–ˆëŠ”ê°€?

#### ğŸ“ˆ í•´ì„ í•¨ì •
- **ë‹¤ì¤‘ë¹„êµ**: ì—¬ëŸ¬ ê²€ì • ì‹œ Î± ìˆ˜ì¤€ ì¡°ì •
- **í‘œë³¸ì„ íƒí¸í–¥**: ëŒ€í‘œì„± ìˆëŠ” í‘œë³¸ì¸ê°€?  
- **ì¸ê³¼ê´€ê³„**: ìƒê´€ê´€ê³„ë¥¼ ì¸ê³¼ê´€ê³„ë¡œ í•´ì„ ê¸ˆì§€

---

## ğŸ† ìµœì¢… ë§ˆìŠ¤í„° ì²´í¬ë¦¬ìŠ¤íŠ¸

### âœ… Tê²€ì • ì™„ì „ ì •ë³µ í™•ì¸

#### ğŸ¯ ê°œë… ì´í•´
- [ ] **ì¼í‘œë³¸ vs ë…ë¦½í‘œë³¸ vs ëŒ€ì‘í‘œë³¸ êµ¬ë¶„**
- [ ] **Të¶„í¬ì™€ ì •ê·œë¶„í¬ì˜ ì°¨ì´**
- [ ] **Tê²€ì •ì˜ í•µì‹¬ ì›ë¦¬ (í‰ê·  ì°¨ì´ / í‘œì¤€ì˜¤ì°¨)**

#### ğŸ”§ ê¸°ìˆ  êµ¬í˜„
- [ ] **ì „ì œì¡°ê±´ ê²€ì • (ì •ê·œì„±, ë“±ë¶„ì‚°ì„±)**
- [ ] **ì ì ˆí•œ ê²€ì •ë²• ì„ íƒ (ì¼ë°˜ vs Welch)**
- [ ] **Pythonì„ í™œìš©í•œ ì™„ì „ ìë™í™”**

#### ğŸ“Š ë°ì´í„° ì²˜ë¦¬
- [ ] **ë‹¤ì¤‘ íŒŒì¼ ë³‘í•© ë° ì „ì²˜ë¦¬**
- [ ] **ë²”ì£¼í˜• ë³€ìˆ˜ ìƒì„± ë° ê·¸ë£¹ ë¶„í• **
- [ ] **ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë° ì´ìƒì¹˜ íƒì§€**

#### ğŸ¨ ì‹œê°í™” & ë³´ê³ 
- [ ] **ë°•ìŠ¤í”Œë¡¯ìœ¼ë¡œ ê·¸ë£¹ ë¹„êµ ì‹œê°í™”**
- [ ] **ê²°ê³¼ í•´ì„ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ**
- [ ] **ì™„ì„±ë„ ë†’ì€ ë¶„ì„ ë³´ê³ ì„œ ì‘ì„±**

#### ğŸ’¼ ì‹¤ë¬´ í™œìš©
- [ ] **DB ì—°ë™í•œ ì‹¤ì œ ë°ì´í„° ë¶„ì„**
- [ ] **ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì œë¥¼ í†µê³„ ë¬¸ì œë¡œ ë³€í™˜**
- [ ] **ì˜ì‚¬ê²°ì •ì— í™œìš© ê°€ëŠ¥í•œ ê²°ë¡  ë„ì¶œ**

---

## ğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤!

**ğŸ† Tê²€ì • ë§ˆìŠ¤í„°ê°€ ë˜ì…¨ìŠµë‹ˆë‹¤!**

ì´ì œ ì—¬ëŸ¬ë¶„ì€:
- âœ¨ **ì–´ë–¤ ìƒí™©ì—ì„œë“  ì ì ˆí•œ Tê²€ì •ì„ ì„ íƒ**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ğŸ”§ **ì™„ë²½í•œ ë¶„ì„ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬í˜„**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤  
- ğŸ“Š **ì‹¤ë¬´ ë°ì´í„°ë¡œ ì˜ë¯¸ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œ**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ğŸ’¼ **ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì •ì„ ìœ„í•œ í†µê³„ ë¶„ì„ì„ ìˆ˜í–‰**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

### ğŸš€ ë‹¤ìŒ ë‹¨ê³„: ê³ ê¸‰ í†µê³„ ê¸°ë²•

- **ANOVA**: 3ê°œ ì´ìƒ ê·¸ë£¹ ë¹„êµ
- **ì¹´ì´ì œê³± ê²€ì •**: ë²”ì£¼í˜• ë°ì´í„° ë¶„ì„
- **íšŒê·€ë¶„ì„**: ë³€ìˆ˜ ê°„ ê´€ê³„ ëª¨ë¸ë§
- **ë‹¤ë³€ëŸ‰ ë¶„ì„**: ë³µí•©ì  ìš”ì¸ ë¶„ì„

---

# ğŸ“Š í†µê³„ ë¶„ì„ ì ˆì°¨ ë° ì£¼ìš” ê²€ì • ì™„ì „ ê°€ì´ë“œ

---

## ğŸ”¬ 1. ì •ê·œì„± ê²€ì • (Normality Test)

### 1.1 **Shapiro-Wilk ê²€ì • (`stats.shapiro`)** â­ ê°€ì¥ ì¼ë°˜ì 
```python
import scipy.stats as stats

# ì •ê·œì„± ê²€ì •
shapiro_stat, shapiro_p = stats.shapiro(data)
print(f"Shapiro-Wilk: í†µê³„ëŸ‰={shapiro_stat:.4f}, p-value={shapiro_p:.6f}")

if shapiro_p > 0.05:
    print("âœ… ì •ê·œì„± ë§Œì¡± â†’ t-test ë“± ëª¨ìˆ˜ ê²€ì • ì‚¬ìš© ê°€ëŠ¥")
else:
    print("âŒ ì •ê·œì„± ìœ„ë°° â†’ ë¹„ëª¨ìˆ˜ ê²€ì • ë˜ëŠ” ë°ì´í„° ë³€í™˜ ê³ ë ¤")
```

**í•´ì„ ê¸°ì¤€**:
- **p-value > 0.05** â†’ ì •ê·œë¶„í¬ë¥¼ ë”°ë¦„ (ì •ê·œì„± ë§Œì¡±)
- **p-value < 0.05** â†’ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ì§€ ì•ŠìŒ (ì •ê·œì„± ìœ„ë°°)

### 1.2 **Kolmogorov-Smirnov ê²€ì •**
```python
# í‘œë³¸ë¶„í¬ì™€ ì •ê·œë¶„í¬ ë¹„êµ
ks_stat, ks_p = stats.kstest(data, 'norm', args=(np.mean(data), np.std(data, ddof=1)))
print(f"K-S test: p-value = {ks_p:.6f}")
```
- í‘œë³¸ë¶„í¬ì™€ ì´ë¡ ì  ì •ê·œë¶„í¬ ë¹„êµ
- ì‘ì€ í‘œë³¸(n < 50)ì—ì„œëŠ” ì‹ ë¢°ì„± ì œí•œ

### 1.3 **Q-Q Plot (ë¶„ìœ„ìˆ˜-ë¶„ìœ„ìˆ˜ ë„í‘œ)** ğŸ‘ï¸ ì‹œê°ì  í™•ì¸
```python
import matplotlib.pyplot as plt

# Q-Q plotìœ¼ë¡œ ì •ê·œì„± ì‹œê°ì  í™•ì¸
stats.probplot(data, dist="norm", plot=plt)
plt.title('Q-Q Plot: ì •ê·œì„± í™•ì¸')
plt.grid(True)
plt.show()
```

**í•´ì„ ë°©ë²•**:
- **ì ë“¤ì´ ëŒ€ê°ì„ (45ë„ ì§ì„ )ì„ ë”°ë¼ ë°°ì—´** â†’ ì •ê·œì„± ë§Œì¡±
- **ì§ì„ ì—ì„œ í¬ê²Œ ë²—ì–´ë‚¨** â†’ ì •ê·œì„± ìœ„ë°°
- **ì–‘ ëë‹¨ì—ì„œ ê³¡ì„ ** â†’ ê¼¬ë¦¬ê°€ ë‘ê»ê±°ë‚˜ ì–‡ìŒ

### 1.4 **ì •ê·œì„± ìœ„ë°° ì‹œ ëŒ€ì²˜ë²•**

#### ğŸ“ˆ ë°ì´í„° ë³€í™˜
```python
# 1. ë¡œê·¸ ë³€í™˜ (ì–‘ì˜ ê°’ë§Œ ê°€ëŠ¥)
log_data = np.log(data)

# 2. ì œê³±ê·¼ ë³€í™˜
sqrt_data = np.sqrt(data)

# 3. Box-Cox ë³€í™˜ (ìµœì  ëŒë‹¤ ìë™ ê³„ì‚°)
from scipy.stats import boxcox
transformed_data, lambda_val = boxcox(data)
print(f"ìµœì  ëŒë‹¤: {lambda_val:.3f}")
```

#### ğŸ”„ ëŒ€ì•ˆ ê²€ì •ë²•
- **t-test** â†’ **Mann-Whitney U test**
- **ANOVA** â†’ **Kruskal-Wallis test**
- **ëŒ€ì‘í‘œë³¸ t-test** â†’ **Wilcoxon signed-rank test**

#### â­ ì¤‘ì‹¬ê·¹í•œì •ë¦¬ í™œìš©
- **í‘œë³¸ ìˆ˜ > 30** â†’ í‰ê·  ë¶„í¬ê°€ ì •ê·œë¶„í¬ì— ê·¼ì‚¬
- ê°œë³„ ë°ì´í„°ëŠ” ë¹„ì •ê·œì—¬ë„ í‘œë³¸í‰ê· ì€ ì •ê·œë¶„í¬

---

## âš–ï¸ 2. í‰ê·  ì°¨ì´ ê²€ì •

### 2.1 **T-test** ğŸ“Š ì—°ì†í˜• ë°ì´í„°ì˜ í‰ê·  ë¹„êµ

| ê²€ì • ìœ í˜• | ìƒí™© | Python í•¨ìˆ˜ | ì˜ˆì‹œ |
|----------|------|-------------|------|
| **ì¼í‘œë³¸ tê²€ì •** | 1ê°œ ì§‘ë‹¨ vs ê¸°ì¤€ê°’ | `ttest_1samp()` | í•™ê¸‰ í‰ê·  vs 80ì  |
| **ë…ë¦½í‘œë³¸ tê²€ì •** | 2ê°œ ë…ë¦½ ì§‘ë‹¨ ë¹„êµ | `ttest_ind()` | ë‚¨ì„± í‚¤ vs ì—¬ì„± í‚¤ |
| **ëŒ€ì‘í‘œë³¸ tê²€ì •** | ê°™ì€ ì§‘ë‹¨ ì „í›„ ë¹„êµ | `ttest_rel()` | ì•½ë¬¼ ë³µìš© ì „í›„ |

```python
# ë…ë¦½í‘œë³¸ tê²€ì • ì˜ˆì‹œ
group1 = [23, 25, 27, 22, 24]
group2 = [28, 30, 26, 29, 31]

t_stat, t_p = stats.ttest_ind(group1, group2)
print(f"ë…ë¦½í‘œë³¸ tê²€ì •: t={t_stat:.3f}, p={t_p:.4f}")
```

### 2.2 **ANOVA** ğŸ“ˆ 3ê°œ ì´ìƒ ì§‘ë‹¨ í‰ê·  ë¹„êµ
```python
# ì¼ì›ë¶„ì‚°ë¶„ì„
group_a = [23, 25, 27, 22, 24]
group_b = [28, 30, 26, 29, 31] 
group_c = [18, 20, 19, 21, 17]

f_stat, anova_p = stats.f_oneway(group_a, group_b, group_c)
print(f"ANOVA: F={f_stat:.3f}, p={anova_p:.4f}")
```

**ì¤‘ìš”**: ì§‘ë‹¨ì´ 2ê°œë©´ t-testì™€ ANOVA ê²°ê³¼ ë™ì¼ (F = tÂ²)

### 2.3 **ì¹´ì´ì œê³± ê²€ì •** ğŸ“‹ ë²”ì£¼í˜• ë°ì´í„°
```python
# ë…ë¦½ì„± ê²€ì • (2x2 ë¶„í• í‘œ)
from scipy.stats import chi2_contingency

observed = [[20, 30], [25, 25]]  # ê´€ì°° ë¹ˆë„
chi2, chi2_p, dof, expected = chi2_contingency(observed)
print(f"ì¹´ì´ì œê³± ê²€ì •: Ï‡Â²={chi2:.3f}, p={chi2_p:.4f}")
```

### 2.4 **Wilcoxon ê²€ì •** ğŸ”„ ë¹„ëª¨ìˆ˜ ì¤‘ì•™ê°’ ë¹„êµ
```python
# ì •ê·œì„± ìœ„ë°° ì‹œ t-test ëŒ€ì‹  ì‚¬ìš©
# 1. ë‹¨ì¼í‘œë³¸ (ì¤‘ì•™ê°’ vs ê¸°ì¤€ê°’)
wilcox_stat, wilcox_p = stats.wilcoxon(data - reference_value)

# 2. ëŒ€ì‘í‘œë³¸ (ì „í›„ ë¹„êµ)
before = [20, 22, 19, 21, 23]
after = [18, 20, 17, 19, 21]
wilcox_stat, wilcox_p = stats.wilcoxon(before, after)
print(f"Wilcoxon ê²€ì •: í†µê³„ëŸ‰={wilcox_stat}, p={wilcox_p:.4f}")
```

---

## âš–ï¸ 3. ë“±ë¶„ì‚°ì„± ê²€ì • (Homogeneity of Variance)

### 3.1 **ë“±ë¶„ì‚°ì„±ì˜ ì¤‘ìš”ì„±**
- **ì˜ë¯¸**: ì—¬ëŸ¬ ëª¨ì§‘ë‹¨ì˜ ë¶„ì‚°(í¼ì§ ì •ë„)ì´ ë™ì¼í•œê°€?
- **í•„ìš”ì„±**: ë…ë¦½í‘œë³¸ t-ê²€ì •, ANOVA ë“±ì˜ ì „ì œ ì¡°ê±´
- **ìœ„ë°° ì‹œ**: ì˜ëª»ëœ ê²°ë¡ , ìœ ì˜í™•ë¥  ì™œê³¡ ê°€ëŠ¥

### 3.2 **ë“±ë¶„ì‚°ì„± ê²€ì • ë°©ë²• ë¹„êµ**

| ê²€ì •ë²• | ì •ê·œì„± ê°€ì • | ì¥ì  | ë‹¨ì  | ì¶”ì²œ ìƒí™© |
|--------|-------------|------|------|----------|
| **Bartlett** | **ê°•í•¨** | ì •ê·œë¶„í¬ì¼ ë•Œ ê°€ì¥ ì •í™• | ì •ê·œì„± ìœ„ë°° ì‹œ ì˜¤ë¥˜ | ì •ê·œë¶„í¬ í™•ì‹ í•  ë•Œ |
| **Levene** â­ | **ì•½í•¨** | ì‹¤ë¬´ì—ì„œ ê°€ì¥ ì•ˆì „ | ë³´ìˆ˜ì  ê²°ê³¼ | **ì¼ë°˜ì  ìƒí™©** |
| **Fligner** | **ì—†ìŒ** | ê°€ì¥ ê°•ê±´í•¨ | ê²€ì •ë ¥ ì•½í•¨ | ì™„ì „ ë¹„ëª¨ìˆ˜ ìƒí™© |

```python
# ë“±ë¶„ì‚°ì„± ê²€ì • ë¹„êµ
group1 = [23, 25, 27, 22, 24, 26, 21]
group2 = [28, 30, 26, 29, 31, 27, 25]
group3 = [18, 20, 19, 21, 17, 22, 16]

# 1. Bartlett ê²€ì • (ì •ê·œë¶„í¬ ê°€ì • ê°•í•¨)
bartlett_stat, bartlett_p = stats.bartlett(group1, group2, group3)
print(f"Bartlett: í†µê³„ëŸ‰={bartlett_stat:.3f}, p={bartlett_p:.4f}")

# 2. Levene ê²€ì • (ì‹¤ë¬´ ì¶”ì²œ) â­
levene_stat, levene_p = stats.levene(group1, group2, group3)
print(f"Levene: í†µê³„ëŸ‰={levene_stat:.3f}, p={levene_p:.4f}")

# 3. Fligner ê²€ì • (ë¹„ëª¨ìˆ˜)
fligner_stat, fligner_p = stats.fligner(group1, group2, group3)
print(f"Fligner: í†µê³„ëŸ‰={fligner_stat:.3f}, p={fligner_p:.4f}")
```

### 3.3 **ë“±ë¶„ì‚°ì„± ê²€ì • ì„ íƒ ê°€ì´ë“œ**

```python
def choose_variance_test(data_groups):
    """ë“±ë¶„ì‚°ì„± ê²€ì • ì„ íƒ ê°€ì´ë“œ"""
    
    # 1ë‹¨ê³„: ì •ê·œì„± í™•ì¸
    normal_groups = []
    for i, group in enumerate(data_groups):
        _, p = stats.shapiro(group)
        normal_groups.append(p > 0.05)
        print(f"ê·¸ë£¹ {i+1} ì •ê·œì„±: {'ë§Œì¡±' if p > 0.05 else 'ìœ„ë°°'} (p={p:.4f})")
    
    # 2ë‹¨ê³„: ì ì ˆí•œ ë“±ë¶„ì‚°ì„± ê²€ì • ì¶”ì²œ
    if all(normal_groups):
        print("\nâœ… ì¶”ì²œ: Bartlett ê²€ì • (ëª¨ë“  ê·¸ë£¹ì´ ì •ê·œë¶„í¬)")
        return "bartlett"
    elif any(normal_groups):
        print("\nâš ï¸ ì¶”ì²œ: Levene ê²€ì • (ì¼ë¶€ ê·¸ë£¹ ì •ê·œì„± ìœ„ë°°)")
        return "levene"
    else:
        print("\nğŸ”„ ì¶”ì²œ: Fligner ê²€ì • (ëª¨ë“  ê·¸ë£¹ ì •ê·œì„± ìœ„ë°°)")
        return "fligner"

# ì‚¬ìš© ì˜ˆì‹œ
recommended_test = choose_variance_test([group1, group2, group3])
```

**ë“±ë¶„ì‚°ì„± ìœ„ë°° ì‹œ ëŒ€ì²˜ë²•**:
```python
# Welch's t-test (ë“±ë¶„ì‚° ê°€ì • ì—†ìŒ)
t_stat, t_p = stats.ttest_ind(group1, group2, equal_var=False)
print(f"Welch's t-test: t={t_stat:.3f}, p={t_p:.4f}")
```

---

## ğŸ¯ 4. ê¸°íƒ€ ì¤‘ìš” ê°œë…

### 4.1 **ê°€ì„¤ ì„¤ì •ì˜ ì² í•™**
```python
def hypothesis_setting_guide():
    """ì˜¬ë°”ë¥¸ ê°€ì„¤ ì„¤ì • ê°€ì´ë“œ"""
    
    print("ğŸ¯ ê°€ì„¤ ì„¤ì • ì›ì¹™")
    print("-" * 30)
    print("1ï¸âƒ£ ëŒ€ë¦½ê°€ì„¤(Hâ‚)ì„ ë¨¼ì € ì„¤ì • (ì—°êµ¬í•˜ê³  ì‹¶ì€ ë‚´ìš©)")
    print("2ï¸âƒ£ ê·€ë¬´ê°€ì„¤(Hâ‚€)ì€ ëŒ€ë¦½ê°€ì„¤ì˜ ë°˜ëŒ€ (ê¸°ì¡´ í†µë…)")
    print("3ï¸âƒ£ ëŒ€ë¦½ê°€ì„¤ ì±„íƒ â‰  ê·€ë¬´ê°€ì„¤ ì™„ì „ íê¸°")
    print("4ï¸âƒ£ 'ìƒˆë¡œìš´ ê·¼ê±° ë§ˆë ¨'ì˜ ê°œë…ìœ¼ë¡œ ì´í•´")
    
    example = {
        "ì—°êµ¬ ì§ˆë¬¸": "ì‹ ì•½ì´ ê¸°ì¡´ ì¹˜ë£Œë²•ë³´ë‹¤ íš¨ê³¼ì ì¸ê°€?",
        "Hâ‚ (ëŒ€ë¦½ê°€ì„¤)": "ì‹ ì•½ì˜ ì¹˜ë£Œ íš¨ê³¼ > ê¸°ì¡´ ì¹˜ë£Œë²•",
        "Hâ‚€ (ê·€ë¬´ê°€ì„¤)": "ì‹ ì•½ì˜ ì¹˜ë£Œ íš¨ê³¼ = ê¸°ì¡´ ì¹˜ë£Œë²•",
        "í•´ì„": "Hâ‚ ì±„íƒ ì‹œ 'ì‹ ì•½ íš¨ê³¼ì˜ ê·¼ê±° ë§ˆë ¨'"
    }
    
    print(f"\nğŸ“ ì˜ˆì‹œ:")
    for key, value in example.items():
        print(f"   {key}: {value}")

hypothesis_setting_guide()
```

### 4.2 **ëª¨ìˆ˜ì  vs ë¹„ëª¨ìˆ˜ì  ê²€ì •**

| êµ¬ë¶„ | ëª¨ìˆ˜ì  ê²€ì • | ë¹„ëª¨ìˆ˜ì  ê²€ì • |
|------|-------------|---------------|
| **ê°€ì •** | ì •ê·œë¶„í¬ ë“± ë¶„í¬ ê°€ì • í•„ìš” | ë¶„í¬ ê°€ì • ì—†ìŒ |
| **ë°ì´í„°** | ì—°ì†í˜•, ì •ê·œë¶„í¬ | ìˆœìœ„, ì¤‘ì•™ê°’ ê¸°ë°˜ |
| **ê²€ì •ë ¥** | ê°€ì • ë§Œì¡± ì‹œ ë†’ìŒ | ê°€ì • ìœ„ë°° ì‹œ ì•ˆì „ |
| **ì˜ˆì‹œ** | t-test, ANOVA, íšŒê·€ë¶„ì„ | Mann-Whitney, Kruskal-Wallis |

```python
# ëª¨ìˆ˜ vs ë¹„ëª¨ìˆ˜ ê²€ì • ë¹„êµ
def parametric_vs_nonparametric_demo():
    """ëª¨ìˆ˜ vs ë¹„ëª¨ìˆ˜ ê²€ì • ë¹„êµ"""
    
    # ì •ê·œì„± ìœ„ë°° ë°ì´í„° ìƒì„±
    np.random.seed(42)
    skewed_data1 = np.concatenate([np.random.normal(50, 10, 40), [100, 110, 120]])
    skewed_data2 = np.concatenate([np.random.normal(55, 12, 38), [95, 105]])
    
    print("ğŸ“Š ëª¨ìˆ˜ vs ë¹„ëª¨ìˆ˜ ê²€ì • ë¹„êµ")
    print("-" * 40)
    
    # 1. ëª¨ìˆ˜ì  ê²€ì • (t-test)
    t_stat, t_p = stats.ttest_ind(skewed_data1, skewed_data2)
    print(f"ëª¨ìˆ˜ì  ê²€ì • (t-test): p = {t_p:.4f}")
    
    # 2. ë¹„ëª¨ìˆ˜ì  ê²€ì • (Mann-Whitney U)
    u_stat, u_p = stats.mannwhitneyu(skewed_data1, skewed_data2, alternative='two-sided')
    print(f"ë¹„ëª¨ìˆ˜ì  ê²€ì • (Mann-Whitney): p = {u_p:.4f}")
    
    # ì •ê·œì„± í™•ì¸
    _, p1 = stats.shapiro(skewed_data1)
    _, p2 = stats.shapiro(skewed_data2)
    print(f"\nì •ê·œì„± ê²€ì •:")
    print(f"  ê·¸ë£¹1: p = {p1:.4f} {'(ì •ê·œì„± ë§Œì¡±)' if p1 > 0.05 else '(ì •ê·œì„± ìœ„ë°°)'}")
    print(f"  ê·¸ë£¹2: p = {p2:.4f} {'(ì •ê·œì„± ë§Œì¡±)' if p2 > 0.05 else '(ì •ê·œì„± ìœ„ë°°)'}")
    
    print(f"\nğŸ’¡ ê²°ë¡ : ì •ê·œì„± ìœ„ë°° ì‹œ ë¹„ëª¨ìˆ˜ ê²€ì •ì´ ë” ì‹ ë¢°í•  ë§Œí•¨")

parametric_vs_nonparametric_demo()
```

---

## ğŸ’» 5. ì‹¤ìš© ì½”ë“œ ëª¨ìŒ

### 5.1 **Q-Q Plot ê³ ê¸‰ ë²„ì „**
```python
def advanced_qq_plot(data, title="Q-Q Plot"):
    """ê°œì„ ëœ Q-Q Plot"""
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # Q-Q Plot
    stats.probplot(data, dist="norm", plot=ax1)
    ax1.set_title(f'{title}: ì •ê·œì„± í™•ì¸')
    ax1.grid(True, alpha=0.3)
    
    # íˆìŠ¤í† ê·¸ë¨ + ì •ê·œë¶„í¬ ê³¡ì„ 
    ax2.hist(data, bins=15, density=True, alpha=0.7, color='skyblue', edgecolor='black')
    
    # ì´ë¡ ì  ì •ê·œë¶„í¬ ê³¡ì„ 
    x = np.linspace(data.min(), data.max(), 100)
    y = stats.norm.pdf(x, np.mean(data), np.std(data))
    ax2.plot(x, y, 'r-', linewidth=2, label='ì´ë¡ ì  ì •ê·œë¶„í¬')
    
    ax2.set_title(f'{title}: íˆìŠ¤í† ê·¸ë¨')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

# ì‚¬ìš© ì˜ˆì‹œ
np.random.seed(42)
normal_data = np.random.normal(50, 10, 100)
skewed_data = np.concatenate([np.random.normal(50, 5, 80), [80, 85, 90, 95, 100]])

advanced_qq_plot(normal_data, "ì •ê·œë¶„í¬ ë°ì´í„°")
advanced_qq_plot(skewed_data, "ì™œê³¡ëœ ë°ì´í„°")
```

### 5.2 **í†µí•© ê²€ì • í•¨ìˆ˜**
```python
def comprehensive_statistical_test(group1, group2=None, test_type='auto'):
    """ì¢…í•©ì ì¸ í†µê³„ ê²€ì • í•¨ìˆ˜"""
    
    print("ğŸ” ì¢…í•© í†µê³„ ê²€ì • ê²°ê³¼")
    print("=" * 40)
    
    if group2 is None:
        # ì¼í‘œë³¸ ê²€ì •
        print("ğŸ“Š ì¼í‘œë³¸ ë¶„ì„")
        print(f"   í‘œë³¸ í¬ê¸°: {len(group1)}")
        print(f"   í‰ê· : {np.mean(group1):.3f}")
        print(f"   í‘œì¤€í¸ì°¨: {np.std(group1, ddof=1):.3f}")
        
        # ì •ê·œì„± ê²€ì •
        _, norm_p = stats.shapiro(group1)
        print(f"   ì •ê·œì„± ê²€ì • p-value: {norm_p:.6f}")
        
        if norm_p > 0.05:
            print("   âœ… ì •ê·œì„± ë§Œì¡± â†’ tê²€ì • ì í•©")
        else:
            print("   âŒ ì •ê·œì„± ìœ„ë°° â†’ Wilcoxon ê²€ì • ê³ ë ¤")
            
    else:
        # ì´í‘œë³¸ ê²€ì •
        print("ğŸ“Š ì´í‘œë³¸ ë¶„ì„")
        print(f"   ê·¸ë£¹1 í¬ê¸°: {len(group1)}, í‰ê· : {np.mean(group1):.3f}")
        print(f"   ê·¸ë£¹2 í¬ê¸°: {len(group2)}, í‰ê· : {np.mean(group2):.3f}")
        
        # ì •ê·œì„± ê²€ì •
        _, norm_p1 = stats.shapiro(group1)
        _, norm_p2 = stats.shapiro(group2)
        print(f"   ê·¸ë£¹1 ì •ê·œì„±: {norm_p1:.6f}")
        print(f"   ê·¸ë£¹2 ì •ê·œì„±: {norm_p2:.6f}")
        
        # ë“±ë¶„ì‚°ì„± ê²€ì •
        _, var_p = stats.levene(group1, group2)
        print(f"   ë“±ë¶„ì‚°ì„± ê²€ì •: {var_p:.6f}")
        
        # ê²€ì • ë°©ë²• ì¶”ì²œ
        if norm_p1 > 0.05 and norm_p2 > 0.05:
            if var_p > 0.05:
                print("   âœ… ì¶”ì²œ: ë…ë¦½í‘œë³¸ tê²€ì • (ë“±ë¶„ì‚°)")
                t_stat, t_p = stats.ttest_ind(group1, group2, equal_var=True)
                print(f"   tê²€ì • ê²°ê³¼: t={t_stat:.3f}, p={t_p:.6f}")
            else:
                print("   âœ… ì¶”ì²œ: Welch's tê²€ì • (ì´ë¶„ì‚°)")
                t_stat, t_p = stats.ttest_ind(group1, group2, equal_var=False)
                print(f"   Welch tê²€ì • ê²°ê³¼: t={t_stat:.3f}, p={t_p:.6f}")
        else:
            print("   ğŸ”„ ì¶”ì²œ: Mann-Whitney U ê²€ì •")
            u_stat, u_p = stats.mannwhitneyu(group1, group2, alternative='two-sided')
            print(f"   Mann-Whitney ê²°ê³¼: U={u_stat:.1f}, p={u_p:.6f}")

# ì‚¬ìš© ì˜ˆì‹œ
np.random.seed(42)
sample1 = np.random.normal(50, 10, 30)
sample2 = np.random.normal(55, 8, 35)

comprehensive_statistical_test(sample1, sample2)
```

---

## ğŸ“– 6. í•µì‹¬ ìš©ì–´ ì‚¬ì „

| ìš©ì–´ | ì˜ë¯¸ | í™•ì¸ ë°©ë²• |
|------|------|----------|
| **ì •ê·œì„±** | ë°ì´í„°ê°€ ì¢… ëª¨ì–‘(ì •ê·œë¶„í¬)ì„ ë”°ë¥´ëŠ”ì§€ | Shapiro-Wilk, Q-Q plot |
| **ë“±ë¶„ì‚°ì„±** | ì—¬ëŸ¬ ì§‘ë‹¨ì˜ ë¶„ì‚°(í¼ì§)ì´ ê°™ì€ì§€ | Levene, Bartlett test |
| **ëª¨ìˆ˜ ê²€ì •** | ë¶„í¬ ê°€ì •ì´ í•„ìš”í•œ ê²€ì • | t-test, ANOVA, íšŒê·€ë¶„ì„ |
| **ë¹„ëª¨ìˆ˜ ê²€ì •** | ë¶„í¬ ê°€ì • ì—†ëŠ” ìˆœìœ„ ê¸°ë°˜ ê²€ì • | Mann-Whitney, Wilcoxon |
| **ê²€ì •í†µê³„ëŸ‰** | ê°€ì„¤ê²€ì •ì—ì„œ ê³„ì‚°ë˜ëŠ” ìˆ˜ì¹˜ | tê°’, Fê°’, Ï‡Â²ê°’ ë“± |
| **p-value** | ìš°ì—°íˆ ê´€ì°°ë  í™•ë¥  | < 0.05ë©´ í†µê³„ì  ìœ ì˜ |
| **ììœ ë„** | ë…ë¦½ì ìœ¼ë¡œ ë³€í•  ìˆ˜ ìˆëŠ” ê°’ì˜ ìˆ˜ | ë³´í†µ n-1 |
| **íš¨ê³¼í¬ê¸°** | ì‹¤ì§ˆì  ì°¨ì´ì˜ í¬ê¸° | Cohen's d ë“± |

---

## ğŸ¯ 7. ì‹¤ë¬´ ì˜ì‚¬ê²°ì • í”Œë¡œìš°ì°¨íŠ¸

```python
def statistical_decision_flowchart():
    """í†µê³„ ê²€ì • ì˜ì‚¬ê²°ì • í”Œë¡œìš°ì°¨íŠ¸"""
    
    flowchart = """
    ğŸ“Š í†µê³„ ê²€ì • ì˜ì‚¬ê²°ì • í”Œë¡œìš°
    
    1ï¸âƒ£ ì—°êµ¬ ì§ˆë¬¸ ëª…í™•í™”
       â†“
    2ï¸âƒ£ ë°ì´í„° íƒ€ì… í™•ì¸ (ì—°ì†í˜• vs ë²”ì£¼í˜•)
       â†“
    3ï¸âƒ£ ì§‘ë‹¨ ìˆ˜ í™•ì¸ (1ê°œ vs 2ê°œ vs 3ê°œ+)
       â†“
    4ï¸âƒ£ í‘œë³¸ ê´€ê³„ í™•ì¸ (ë…ë¦½ vs ëŒ€ì‘)
       â†“
    5ï¸âƒ£ ì •ê·œì„± ê²€ì • (Shapiro-Wilk)
       â†“
    6ï¸âƒ£ ë“±ë¶„ì‚°ì„± ê²€ì • (í•„ìš”ì‹œ, Levene)
       â†“
    7ï¸âƒ£ ì ì ˆí•œ ê²€ì • ì„ íƒ
       â†“
    8ï¸âƒ£ ê²€ì • ì‹¤í–‰ ë° í•´ì„
       â†“
    9ï¸âƒ£ íš¨ê³¼í¬ê¸° ê³„ì‚° (ê¶Œì¥)
       â†“
    ğŸ”Ÿ ê²°ë¡  ë„ì¶œ ë° ë³´ê³ 
    """
    
    print(flowchart)
    
    decision_matrix = {
        "ì—°ì†í˜• + 1ì§‘ë‹¨": "ì¼í‘œë³¸ tê²€ì • or Wilcoxon",
        "ì—°ì†í˜• + 2ì§‘ë‹¨ + ë…ë¦½": "ë…ë¦½í‘œë³¸ tê²€ì • or Mann-Whitney",
        "ì—°ì†í˜• + 2ì§‘ë‹¨ + ëŒ€ì‘": "ëŒ€ì‘í‘œë³¸ tê²€ì • or Wilcoxon",
        "ì—°ì†í˜• + 3ì§‘ë‹¨+": "ANOVA or Kruskal-Wallis",
        "ë²”ì£¼í˜•": "ì¹´ì´ì œê³± ê²€ì •"
    }
    
    print("\nğŸ—ºï¸ ë¹ ë¥¸ ì°¸ì¡° ë§¤íŠ¸ë¦­ìŠ¤:")
    for situation, test in decision_matrix.items():
        print(f"   {situation}: {test}")

statistical_decision_flowchart()
```

---

## ğŸ† ì™„ì „ ë§ˆìŠ¤í„° ì²´í¬ë¦¬ìŠ¤íŠ¸

### âœ… í†µê³„ ê²€ì • ì™„ì „ ì •ë³µ í™•ì¸

- [ ] **ì •ê·œì„± ê²€ì •**: Shapiro-Wilk, Q-Q plot í•´ì„ ê°€ëŠ¥
- [ ] **ë“±ë¶„ì‚°ì„± ê²€ì •**: Levene test ì´í•´ ë° ì ìš©
- [ ] **ëª¨ìˆ˜ vs ë¹„ëª¨ìˆ˜**: ìƒí™©ë³„ ì ì ˆí•œ ê²€ì • ì„ íƒ
- [ ] **tê²€ì • 3ì¢…ë¥˜**: ì¼í‘œë³¸, ë…ë¦½í‘œë³¸, ëŒ€ì‘í‘œë³¸ êµ¬ë¶„
- [ ] **ANOVA**: 3ê°œ ì´ìƒ ì§‘ë‹¨ í‰ê·  ë¹„êµ
- [ ] **ì¹´ì´ì œê³± ê²€ì •**: ë²”ì£¼í˜• ë°ì´í„° ë¶„ì„
- [ ] **íš¨ê³¼í¬ê¸°**: Cohen's d ë“± ì‹¤ì§ˆì  ì˜ë¯¸ íŒŒì•…
- [ ] **ì¢…í•© í•´ì„**: í†µê³„ì  vs ì‹¤ë¬´ì  ì˜ë¯¸ êµ¬ë¶„

**ğŸ‰ ëª¨ë“  ì²´í¬ë¦¬ìŠ¤íŠ¸ ì™„ë£Œ â†’ í†µê³„ ê²€ì • ë§ˆìŠ¤í„°!** 

ì´ì œ ì–´ë–¤ ë°ì´í„°ë“  ìì‹  ìˆê²Œ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸš€âœ¨