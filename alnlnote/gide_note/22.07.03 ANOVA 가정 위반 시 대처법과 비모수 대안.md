# 22.07.03 ANOVA ê°€ì • ìœ„ë°˜ ì‹œ ëŒ€ì²˜ë²•ê³¼ ë¹„ëª¨ìˆ˜ ëŒ€ì•ˆ
*í˜„ì‹¤ ë°ì´í„°ëŠ” ì™„ë²½í•˜ì§€ ì•Šë‹¤ - ì‹¤ë¬´ì—ì„œ ë§ˆì£¼ì¹˜ëŠ” ë¬¸ì œë“¤ê³¼ í•´ê²°ì±…*

---

## ğŸš¨ í˜„ì‹¤ì˜ ë²½: ANOVA ê°€ì •ë“¤ì´ ê¹¨ì§ˆ ë•Œ

ì‹¤ë¬´ì—ì„œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ë‹¤ ë³´ë©´ **"êµê³¼ì„œì ì¸ ì™„ë²½í•œ ë°ì´í„°"**ëŠ” ê±°ì˜ ì—†ìŠµë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ ì‹¤ì œ ë°ì´í„°ëŠ” ANOVAì˜ ê¸°ë³¸ ê°€ì •ì„ ìœ„ë°˜í•˜ëŠ” ê²½ìš°ê°€ ë§ì£ .

### ğŸ¯ ANOVAì˜ 3ëŒ€ í•µì‹¬ ê°€ì •

| ê°€ì • | ì˜ë¯¸ | ìœ„ë°˜ ì‹œ ë¬¸ì œì  |
|------|------|-------------|
| **ì •ê·œì„±** | ê° ì§‘ë‹¨ ë°ì´í„°ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¦„ | ì˜ëª»ëœ p-value, ì‹ ë¢°êµ¬ê°„ ì™œê³¡ |
| **ë“±ë¶„ì‚°ì„±** | ëª¨ë“  ì§‘ë‹¨ì˜ ë¶„ì‚°ì´ ë™ì¼í•¨ | ì œ1ì¢…/ì œ2ì¢… ì˜¤ë¥˜ìœ¨ ì¦ê°€ |
| **ë…ë¦½ì„±** | ê´€ì¸¡ê°’ë“¤ì´ ì„œë¡œ ë…ë¦½ì ì„ | ììœ ë„ ì˜¤í•´ì„, ê²€ì •ë ¥ ë¬¸ì œ |

---

## ğŸ” ê°€ì • ìœ„ë°˜ ì§„ë‹¨ë²•

### ğŸ“Š 1. ì •ê·œì„± ê²€ì •

#### ğŸ§ª í†µê³„ì  ê²€ì •ë²•

```python
import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns

def check_normality(data, group_col, value_col):
    """ì •ê·œì„± ê²€ì • ì¢…í•© í•¨ìˆ˜"""
    
    print("=== ì •ê·œì„± ê²€ì • ê²°ê³¼ ===")
    
    groups = data[group_col].unique()
    results = {}
    
    for group in groups:
        group_data = data[data[group_col] == group][value_col]
        
        # 1. Shapiro-Wilk ê²€ì • (n < 50 ê¶Œì¥)
        shapiro_stat, shapiro_p = stats.shapiro(group_data)
        
        # 2. Anderson-Darling ê²€ì • (ë” ê°•ë ¥í•¨)
        anderson_result = stats.anderson(group_data, dist='norm')
        
        # 3. Kolmogorov-Smirnov ê²€ì •
        ks_stat, ks_p = stats.kstest(group_data, 'norm',
                                    args=(group_data.mean(), group_data.std()))
        
        results[group] = {
            'shapiro_p': shapiro_p,
            'anderson_stat': anderson_result.statistic,
            'ks_p': ks_p,
            'sample_size': len(group_data)
        }
        
        print(f"\n--- {group} ì§‘ë‹¨ (n={len(group_data)}) ---")
        print(f"Shapiro-Wilk: p = {shapiro_p:.4f}")
        print(f"Anderson-Darling: í†µê³„ëŸ‰ = {anderson_result.statistic:.4f}")
        print(f"KS ê²€ì •: p = {ks_p:.4f}")
        
        # íŒì •
        if shapiro_p > 0.05:
            print("âœ… ì •ê·œì„± ê°€ì • ë§Œì¡±")
        else:
            print("âŒ ì •ê·œì„± ê°€ì • ìœ„ë°˜")
    
    return results

# ì‚¬ìš© ì˜ˆì‹œ
# normality_results = check_normality(data, 'treatment', 'score')
```

#### ğŸ“ˆ ì‹œê°ì  ì§„ë‹¨ë²•

```python
def plot_normality_diagnostics(data, group_col, value_col):
    """ì •ê·œì„± ì‹œê°ì  ì§„ë‹¨"""
    
    groups = data[group_col].unique()
    n_groups = len(groups)
    
    fig, axes = plt.subplots(2, n_groups, figsize=(4*n_groups, 8))
    
    for i, group in enumerate(groups):
        group_data = data[data[group_col] == group][value_col]
        
        # 1. Q-Q Plot (ê°€ì¥ ì¤‘ìš”!)
        stats.probplot(group_data, dist="norm", plot=axes[0, i])
        axes[0, i].set_title(f'{group} - Q-Q Plot')
        axes[0, i].grid(True)
        
        # 2. íˆìŠ¤í† ê·¸ë¨ + ì •ê·œë¶„í¬ ê³¡ì„ 
        axes[1, i].hist(group_data, bins=15, density=True, alpha=0.7, 
                       color='skyblue', edgecolor='black')
        
        # ì •ê·œë¶„í¬ ê³¡ì„  ê·¸ë¦¬ê¸°
        x = np.linspace(group_data.min(), group_data.max(), 100)
        normal_curve = stats.norm.pdf(x, group_data.mean(), group_data.std())
        axes[1, i].plot(x, normal_curve, 'r-', linewidth=2, label='ì •ê·œë¶„í¬')
        
        axes[1, i].set_title(f'{group} - ë¶„í¬ ë¹„êµ')
        axes[1, i].legend()
        axes[1, i].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

# Q-Q Plot í•´ì„ë²•
print("""
ğŸ“Š Q-Q Plot í•´ì„ ê°€ì´ë“œ:
âœ… ì ë“¤ì´ ì§ì„  ìœ„ì— ìœ„ì¹˜ â†’ ì •ê·œë¶„í¬
âŒ Sì ê³¡ì„  â†’ ì¹˜ìš°ì¹¨(skewness)
âŒ ê³¡ì„  í˜•íƒœ â†’ ì²¨ë„(kurtosis) ë¬¸ì œ  
âŒ ëë¶€ë¶„ ë²—ì–´ë‚¨ â†’ ì´ìƒì¹˜ ì¡´ì¬
""")
```

### âš–ï¸ 2. ë“±ë¶„ì‚°ì„± ê²€ì •

```python
def check_homogeneity(data, group_col, value_col):
    """ë“±ë¶„ì‚°ì„± ê²€ì • ì¢…í•© í•¨ìˆ˜"""
    
    print("=== ë“±ë¶„ì‚°ì„± ê²€ì • ê²°ê³¼ ===")
    
    groups = [data[data[group_col] == group][value_col] 
              for group in data[group_col].unique()]
    
    # 1. Levene ê²€ì • (ê°€ì¥ ì¼ë°˜ì , ì •ê·œì„± ê°€ì • ì•½í•¨)
    levene_stat, levene_p = stats.levene(*groups)
    
    # 2. Bartlett ê²€ì • (ì •ê·œì„± ê°€ì • ê°•í•¨, ë” ë¯¼ê°)
    bartlett_stat, bartlett_p = stats.bartlett(*groups)
    
    # 3. Fligner-Killeen ê²€ì • (ë¹„ëª¨ìˆ˜ì , ê°€ì¥ ê°•ê±´í•¨)
    fligner_stat, fligner_p = stats.fligner(*groups)
    
    print(f"Levene ê²€ì •: F = {levene_stat:.4f}, p = {levene_p:.4f}")
    print(f"Bartlett ê²€ì •: Ï‡Â² = {bartlett_stat:.4f}, p = {bartlett_p:.4f}")
    print(f"Fligner ê²€ì •: Ï‡Â² = {fligner_stat:.4f}, p = {fligner_p:.4f}")
    
    # ì¢…í•© íŒì •
    tests_passed = sum([levene_p > 0.05, bartlett_p > 0.05, fligner_p > 0.05])
    
    if tests_passed >= 2:
        print("âœ… ë“±ë¶„ì‚°ì„± ê°€ì • ëŒ€ì²´ë¡œ ë§Œì¡±")
    else:
        print("âŒ ë“±ë¶„ì‚°ì„± ê°€ì • ìœ„ë°˜ ì˜ì‹¬")
        print("ğŸ’¡ Welch's ANOVA ë˜ëŠ” ë¹„ëª¨ìˆ˜ ê²€ì • ê³ ë ¤")
    
    return {
        'levene_p': levene_p,
        'bartlett_p': bartlett_p, 
        'fligner_p': fligner_p
    }

# ì‹œê°ì  ë“±ë¶„ì‚°ì„± ì§„ë‹¨
def plot_homogeneity_diagnostics(data, group_col, value_col):
    """ë“±ë¶„ì‚°ì„± ì‹œê°ì  ì§„ë‹¨"""
    
    plt.figure(figsize=(15, 5))
    
    # 1. ë°•ìŠ¤í”Œë¡¯ (ë¶„ì‚° ì°¨ì´ í™•ì¸)
    plt.subplot(1, 3, 1)
    sns.boxplot(x=group_col, y=value_col, data=data)
    plt.title('ì§‘ë‹¨ë³„ ë¶„ì‚° ë¹„êµ (ë°•ìŠ¤í”Œë¡¯)')
    plt.xticks(rotation=45)
    
    # 2. í‘œì¤€í¸ì°¨ ë¹„êµ
    plt.subplot(1, 3, 2)
    group_stats = data.groupby(group_col)[value_col].agg(['mean', 'std'])
    plt.bar(group_stats.index, group_stats['std'], alpha=0.7)
    plt.title('ì§‘ë‹¨ë³„ í‘œì¤€í¸ì°¨')
    plt.ylabel('í‘œì¤€í¸ì°¨')
    plt.xticks(rotation=45)
    
    # 3. ì”ì°¨ ì‚°ì ë„ (Residual Plot)
    plt.subplot(1, 3, 3)
    for group in data[group_col].unique():
        group_data = data[data[group_col] == group]
        group_mean = group_data[value_col].mean()
        residuals = group_data[value_col] - group_mean
        fitted = [group_mean] * len(residuals)
        plt.scatter(fitted, residuals, alpha=0.6, label=group)
    
    plt.axhline(y=0, color='red', linestyle='--')
    plt.xlabel('ì í•©ê°’')
    plt.ylabel('ì”ì°¨')
    plt.title('ì”ì°¨ ì‚°ì ë„')
    plt.legend()
    
    plt.tight_layout()
    plt.show()
```

### ğŸ”— 3. ë…ë¦½ì„± ê²€ì •

```python
def check_independence(data, group_col, value_col, id_col=None):
    """ë…ë¦½ì„± ì§„ë‹¨"""
    
    print("=== ë…ë¦½ì„± ì§„ë‹¨ ===")
    
    # 1. ë°ì´í„° ìˆ˜ì§‘ ë°©ë²• í™•ì¸
    print("ğŸ” ë‹¤ìŒ ì‚¬í•­ë“¤ì„ í™•ì¸í•˜ì„¸ìš”:")
    print("   â€¢ ë¬´ì‘ìœ„ í‘œì§‘ì¸ê°€?")
    print("   â€¢ ê°™ì€ ëŒ€ìƒì˜ ë°˜ë³µ ì¸¡ì •ì¸ê°€?")
    print("   â€¢ ì‹œê°„ìˆœ ë°ì´í„°ì¸ê°€?")
    print("   â€¢ ê³µê°„ì  êµ°ì§‘ì´ ìˆëŠ”ê°€?")
    
    # 2. ìê¸°ìƒê´€ ê²€ì • (ì‹œê³„ì—´ ë°ì´í„°ì¸ ê²½ìš°)
    if id_col:
        from statsmodels.stats.diagnostic import acorr_ljungbox
        
        # ê° ì§‘ë‹¨ë³„ë¡œ ìê¸°ìƒê´€ ê²€ì •
        for group in data[group_col].unique():
            group_data = data[data[group_col] == group].sort_values(id_col)
            
            if len(group_data) > 10:  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ
                lb_stat, lb_p = acorr_ljungbox(group_data[value_col], 
                                               lags=1, return_df=False)
                print(f"{group}: Ljung-Box p-value = {lb_p[0]:.4f}")
                
                if lb_p[0] < 0.05:
                    print(f"   âŒ {group}ì—ì„œ ìê¸°ìƒê´€ ì˜ì‹¬")
                else:
                    print(f"   âœ… {group}ì—ì„œ ë…ë¦½ì„± ë§Œì¡±")
    
    # 3. í´ëŸ¬ìŠ¤í„°ë§ íš¨ê³¼ í™•ì¸
    print(f"\nğŸ“Š ë°ì´í„° ë¶„í¬ í™•ì¸:")
    print(f"   ì´ ê´€ì¸¡ì¹˜ ìˆ˜: {len(data)}")
    print(f"   ì§‘ë‹¨ë³„ ê´€ì¸¡ì¹˜ ìˆ˜:")
    print(data[group_col].value_counts())
```

---

## ğŸ› ï¸ ê°€ì • ìœ„ë°˜ ì‹œ ëŒ€ì²˜ë²•

### ğŸ“ˆ 1. ì •ê·œì„± ìœ„ë°˜ ëŒ€ì²˜ë²•

#### ğŸ”„ ë°ì´í„° ë³€í™˜ë²•

```python
def data_transformation_options(data, value_col):
    """ë°ì´í„° ë³€í™˜ ì˜µì…˜ë“¤"""
    
    original_data = data[value_col]
    
    transformations = {
        'log': np.log(original_data + 1),  # +1: 0ê°’ ì²˜ë¦¬
        'sqrt': np.sqrt(original_data),
        'reciprocal': 1 / (original_data + 1),
        'square': original_data ** 2,
        'cube_root': np.cbrt(original_data)
    }
    
    plt.figure(figsize=(15, 10))
    
    # ì›ë³¸ ë°ì´í„°
    plt.subplot(2, 3, 1)
    plt.hist(original_data, bins=20, alpha=0.7, color='blue')
    plt.title('ì›ë³¸ ë°ì´í„°')
    
    # ë³€í™˜ëœ ë°ì´í„°ë“¤
    for i, (name, transformed) in enumerate(transformations.items(), 2):
        plt.subplot(2, 3, i)
        plt.hist(transformed, bins=20, alpha=0.7, color='red')
        plt.title(f'{name.title()} ë³€í™˜')
    
    plt.tight_layout()
    plt.show()
    
    # ê° ë³€í™˜ì— ëŒ€í•´ ì •ê·œì„± ê²€ì •
    print("=== ë³€í™˜ í›„ ì •ê·œì„± ê²€ì • ===")
    for name, transformed in transformations.items():
        if not np.isnan(transformed).any() and not np.isinf(transformed).any():
            _, p_value = stats.shapiro(transformed[:5000])  # í‘œë³¸ í¬ê¸° ì œí•œ
            print(f"{name.title()} ë³€í™˜: p = {p_value:.4f}")

# Box-Cox ë³€í™˜ (ìë™ ìµœì í™”)
def boxcox_transformation(data, value_col):
    """Box-Cox ë³€í™˜ (ìë™ìœ¼ë¡œ ìµœì  ëŒë‹¤ ì°¾ê¸°)"""
    
    from scipy.stats import boxcox
    
    # ì–‘ìˆ˜ë§Œ ê°€ëŠ¥í•˜ë¯€ë¡œ ì¡°ì •
    original_data = data[value_col]
    if original_data.min() <= 0:
        adjusted_data = original_data - original_data.min() + 1
    else:
        adjusted_data = original_data
    
    # Box-Cox ë³€í™˜
    transformed_data, optimal_lambda = boxcox(adjusted_data)
    
    print(f"ìµœì  ëŒë‹¤ ê°’: {optimal_lambda:.4f}")
    
    # ë³€í™˜ ì „í›„ ë¹„êµ
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 2, 1)
    plt.hist(adjusted_data, bins=20, alpha=0.7, color='blue')
    plt.title('ë³€í™˜ ì „')
    
    plt.subplot(1, 2, 2)
    plt.hist(transformed_data, bins=20, alpha=0.7, color='red')
    plt.title(f'Box-Cox ë³€í™˜ í›„ (Î»={optimal_lambda:.3f})')
    
    plt.tight_layout()
    plt.show()
    
    # ì •ê·œì„± ê²€ì •
    _, p_before = stats.shapiro(adjusted_data[:5000])
    _, p_after = stats.shapiro(transformed_data[:5000])
    
    print(f"ë³€í™˜ ì „ ì •ê·œì„±: p = {p_before:.4f}")
    print(f"ë³€í™˜ í›„ ì •ê·œì„±: p = {p_after:.4f}")
    
    return transformed_data, optimal_lambda
```

#### ğŸ¯ ë³€í™˜ ì„ íƒ ê°€ì´ë“œ

| ë°ì´í„° íŠ¹ì„± | ì¶”ì²œ ë³€í™˜ | ì„¤ëª… |
|------------|----------|------|
| **ì˜¤ë¥¸ìª½ ì¹˜ìš°ì¹¨** | log, sqrt | í° ê°’ë“¤ì„ ì••ì¶• |
| **ì™¼ìª½ ì¹˜ìš°ì¹¨** | square | ì‘ì€ ê°’ë“¤ì„ í™•ì¥ |
| **ì–‘ê·¹ë‹¨ ì´ìƒì¹˜** | reciprocal | ê·¹ê°’ë“¤ì„ ì¤‘ì•™ìœ¼ë¡œ |
| **ëª¨ë“  ì–‘ìˆ˜ ë°ì´í„°** | Box-Cox | ìë™ìœ¼ë¡œ ìµœì  ë³€í™˜ ì°¾ê¸° |

### âš–ï¸ 2. ë“±ë¶„ì‚°ì„± ìœ„ë°˜ ëŒ€ì²˜ë²•

#### ğŸ”§ Welch's ANOVA (ìˆ˜ì •ëœ F-ê²€ì •)

```python
def welch_anova(data, group_col, value_col):
    """Welch's ANOVA (ë“±ë¶„ì‚° ê°€ì • ì—†ìŒ)"""
    
    from scipy.stats import f_oneway
    
    groups = [data[data[group_col] == group][value_col] 
              for group in data[group_col].unique()]
    
    # ì¼ë°˜ ANOVA (ë“±ë¶„ì‚° ê°€ì •)
    f_stat_regular, p_regular = f_oneway(*groups)
    
    # Welch's ANOVA (ë“±ë¶„ì‚° ê°€ì • ì—†ìŒ)
    # scipyì—ëŠ” ì§ì ‘ êµ¬í˜„ì´ ì—†ì–´ì„œ ìˆ˜ë™ ê³„ì‚°
    def welch_f_statistic(groups):
        k = len(groups)  # ì§‘ë‹¨ ìˆ˜
        n_total = sum(len(group) for group in groups)
        
        # ê° ì§‘ë‹¨ì˜ í†µê³„ëŸ‰
        means = [np.mean(group) for group in groups]
        vars = [np.var(group, ddof=1) for group in groups]
        ns = [len(group) for group in groups]
        
        # ê°€ì¤‘ í‰ê· 
        weights = [n/var for n, var in zip(ns, vars)]
        weighted_mean = sum(w*m for w, m in zip(weights, means)) / sum(weights)
        
        # Welch F-í†µê³„ëŸ‰
        numerator = sum(w * (m - weighted_mean)**2 for w, m in zip(weights, means)) / (k - 1)
        
        # ìˆ˜ì •ëœ ë¶„ëª¨
        denominator_parts = [(1 - w/sum(weights))**2 / (n-1) 
                           for w, n in zip(weights, ns)]
        denominator = 1 + (2 * (k-2) / (k**2 - 1)) * sum(denominator_parts)
        
        welch_f = numerator / denominator
        
        # ììœ ë„ ê³„ì‚°
        df1 = k - 1
        df2 = (k**2 - 1) / (3 * sum(denominator_parts))
        
        return welch_f, df1, df2
    
    welch_f, df1, df2 = welch_f_statistic(groups)
    p_welch = 1 - stats.f.cdf(welch_f, df1, df2)
    
    print("=== ANOVA ê²°ê³¼ ë¹„êµ ===")
    print(f"ì¼ë°˜ ANOVA:  F = {f_stat_regular:.4f}, p = {p_regular:.4f}")
    print(f"Welch ANOVA: F = {welch_f:.4f}, p = {p_welch:.4f}")
    
    if abs(p_regular - p_welch) > 0.01:
        print("âš ï¸  ë‘ ê²°ê³¼ê°€ ë‹¤ë¦…ë‹ˆë‹¤. Welch ê²°ê³¼ë¥¼ ì‹ ë¢°í•˜ì„¸ìš”.")
    
    return {
        'regular_f': f_stat_regular,
        'regular_p': p_regular,
        'welch_f': welch_f,
        'welch_p': p_welch
    }
```

#### ğŸ¨ ë¶„ì‚° ì•ˆì •í™” ë³€í™˜

```python
def variance_stabilizing_transforms(data, value_col):
    """ë¶„ì‚° ì•ˆì •í™” ë³€í™˜ë“¤"""
    
    original = data[value_col]
    
    transforms = {
        'sqrt': np.sqrt(original),
        'arcsine': np.arcsin(np.sqrt(original / original.max())),  # ë¹„ìœ¨ ë°ì´í„°ìš©
        'log': np.log(original + 1)
    }
    
    # ë³€í™˜ë³„ ë¶„ì‚° ë¹„êµ
    print("=== ë³€í™˜ë³„ ë¶„ì‚° ë¹„êµ ===")
    print(f"ì›ë³¸ ë°ì´í„° ë¶„ì‚°: {original.var():.4f}")
    
    for name, transformed in transforms.items():
        if not np.isnan(transformed).any():
            print(f"{name.title()} ë³€í™˜ í›„ ë¶„ì‚°: {transformed.var():.4f}")
```

---

## ğŸ”„ ë¹„ëª¨ìˆ˜ ëŒ€ì•ˆë“¤

ì •ê·œì„±ì´ë‚˜ ë“±ë¶„ì‚°ì„± ê°€ì •ì´ ì‹¬ê°í•˜ê²Œ ìœ„ë°˜ëœ ê²½ìš°, **ë¹„ëª¨ìˆ˜ ê²€ì •**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

### ğŸ¯ 1. ì¼ì›ë¶„ì‚°ë¶„ì„ â†’ Kruskal-Wallis ê²€ì •

```python
def kruskal_wallis_test(data, group_col, value_col):
    """Kruskal-Wallis ê²€ì • (ë¹„ëª¨ìˆ˜ ì¼ì›ë¶„ì‚°ë¶„ì„)"""
    
    from scipy.stats import kruskal
    
    groups = [data[data[group_col] == group][value_col] 
              for group in data[group_col].unique()]
    
    # Kruskal-Wallis ê²€ì •
    h_stat, p_value = kruskal(*groups)
    
    print("=== Kruskal-Wallis ê²€ì • ê²°ê³¼ ===")
    print(f"H-í†µê³„ëŸ‰: {h_stat:.4f}")
    print(f"p-value: {p_value:.4f}")
    
    if p_value < 0.05:
        print("âœ… ì§‘ë‹¨ ê°„ ìœ ì˜í•œ ì°¨ì´ ì¡´ì¬")
        print("ğŸ’¡ ì‚¬í›„ê²€ì •(Dunn's test) í•„ìš”")
    else:
        print("âŒ ì§‘ë‹¨ ê°„ ìœ ì˜í•œ ì°¨ì´ ì—†ìŒ")
    
    # íš¨ê³¼í¬ê¸° ê³„ì‚° (Eta-squared ê·¼ì‚¬)
    n = len(data)
    k = len(groups)
    eta_squared = (h_stat - k + 1) / (n - k)
    print(f"íš¨ê³¼í¬ê¸° (Î·Â²): {eta_squared:.4f}")
    
    return h_stat, p_value

# Kruskal-Wallis ì‚¬í›„ê²€ì • (Dunn's test)
def dunn_test(data, group_col, value_col):
    """Dunn's ì‚¬í›„ê²€ì •"""
    
    try:
        import scikit_posthocs as sp
        
        # Dunn's test
        dunn_results = sp.posthoc_dunn(data, val_col=value_col, 
                                      group_col=group_col, p_adjust='bonferroni')
        
        print("=== Dunn's ì‚¬í›„ê²€ì • ê²°ê³¼ ===")
        print("(Bonferroni ë³´ì •ëœ p-values)")
        print(dunn_results)
        
        return dunn_results
        
    except ImportError:
        print("scikit-posthocs íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install scikit-posthocs")
        
        # ìˆ˜ë™ êµ¬í˜„ (ê°„ë‹¨ ë²„ì „)
        from itertools import combinations
        from scipy.stats import rankdata
        
        groups = data[group_col].unique()
        n_comparisons = len(list(combinations(groups, 2)))
        
        print(f"ğŸ“Š {n_comparisons}ê°œì˜ ìŒë³„ ë¹„êµ í•„ìš”")
        print("ğŸ’¡ ê° ìŒì— ëŒ€í•´ Mann-Whitney U ê²€ì • ì‹¤ì‹œ ê¶Œì¥")
```

### ğŸ¯ 2. ì´ì›ë¶„ì‚°ë¶„ì„ â†’ Aligned Rank Transform (ART)

```python
def aligned_rank_transform_anova(data, factor1, factor2, value_col):
    """Aligned Rank Transform ANOVA (ë¹„ëª¨ìˆ˜ ì´ì›ë¶„ì‚°ë¶„ì„)"""
    
    print("=== Aligned Rank Transform ANOVA ===")
    print("ë³µì¡í•œ ì ˆì°¨ì´ë¯€ë¡œ Rì˜ ARTool íŒ¨í‚¤ì§€ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
    
    # ê°„ë‹¨í•œ ëŒ€ì•ˆ: ê° ìš”ì¸ë³„ë¡œ Kruskal-Wallis ê²€ì •
    print("\nğŸ”§ ê°„ë‹¨í•œ ëŒ€ì•ˆ:")
    
    # ìš”ì¸1 íš¨ê³¼
    print(f"--- {factor1} ì£¼íš¨ê³¼ ---")
    h1, p1 = kruskal_wallis_test(data, factor1, value_col)
    
    # ìš”ì¸2 íš¨ê³¼  
    print(f"\n--- {factor2} ì£¼íš¨ê³¼ ---")
    h2, p2 = kruskal_wallis_test(data, factor2, value_col)
    
    print(f"\nâš ï¸  ìƒí˜¸ì‘ìš© íš¨ê³¼ëŠ” ë³„ë„ ë¶„ì„ í•„ìš”")
    print(f"ğŸ’¡ Scheirer-Ray-Hare ê²€ì • ë˜ëŠ” Rì˜ ARTool ì‚¬ìš© ê¶Œì¥")
    
    return {'factor1_p': p1, 'factor2_p': p2}
```

### ğŸ¯ 3. ëŒ€ì‘í‘œë³¸ â†’ Friedman ê²€ì •

```python
def friedman_test(data, subject_col, condition_col, value_col):
    """Friedman ê²€ì • (ë¹„ëª¨ìˆ˜ ë°˜ë³µì¸¡ì • ANOVA)"""
    
    from scipy.stats import friedmanchisquare
    
    # ë°ì´í„°ë¥¼ ì¡°ê±´ë³„ë¡œ ë¶„ë¦¬
    conditions = data[condition_col].unique()
    condition_data = []
    
    for condition in conditions:
        condition_values = data[data[condition_col] == condition][value_col]
        condition_data.append(condition_values)
    
    # Friedman ê²€ì •
    chi2_stat, p_value = friedmanchisquare(*condition_data)
    
    print("=== Friedman ê²€ì • ê²°ê³¼ ===")
    print(f"Ï‡Â² í†µê³„ëŸ‰: {chi2_stat:.4f}")
    print(f"p-value: {p_value:.4f}")
    
    if p_value < 0.05:
        print("âœ… ì¡°ê±´ ê°„ ìœ ì˜í•œ ì°¨ì´ ì¡´ì¬")
        print("ğŸ’¡ Wilcoxon ë¶€í˜¸ìˆœìœ„ ê²€ì •ìœ¼ë¡œ ì‚¬í›„ë¶„ì„ í•„ìš”")
    else:
        print("âŒ ì¡°ê±´ ê°„ ìœ ì˜í•œ ì°¨ì´ ì—†ìŒ")
    
    return chi2_stat, p_value
```

---

## ğŸ¯ ë¹„ëª¨ìˆ˜ ê²€ì • ì„ íƒ ê°€ì´ë“œ

### ğŸ“Š ìƒí™©ë³„ ë¹„ëª¨ìˆ˜ ëŒ€ì•ˆ

| ëª¨ìˆ˜ ê²€ì • | ë¹„ëª¨ìˆ˜ ëŒ€ì•ˆ | ì–¸ì œ ì‚¬ìš©? |
|----------|------------|----------|
| **ì¼ì› ANOVA** | **Kruskal-Wallis** | ì •ê·œì„± ìœ„ë°˜, ì„œì—´ì²™ë„ ë°ì´í„° |
| **ì´ì› ANOVA** | **ART ANOVA** | ë³µì¡í•œ ì„¤ê³„ì˜ ë¹„ëª¨ìˆ˜ ë¶„ì„ |
| **ëŒ€ì‘í‘œë³¸ ANOVA** | **Friedman** | ë°˜ë³µì¸¡ì •, ì •ê·œì„± ìœ„ë°˜ |
| **ë…ë¦½í‘œë³¸ t-ê²€ì •** | **Mann-Whitney U** | ë‘ ì§‘ë‹¨, ì •ê·œì„± ìœ„ë°˜ |
| **ëŒ€ì‘í‘œë³¸ t-ê²€ì •** | **Wilcoxon ë¶€í˜¸ìˆœìœ„** | ìŒì²´ ë¹„êµ, ì •ê·œì„± ìœ„ë°˜ |

### ğŸ” ë¹„ëª¨ìˆ˜ ê²€ì •ì˜ ì¥ë‹¨ì 

#### âœ… ì¥ì 
- **ë¶„í¬ ê°€ì • ì—†ìŒ**: ì •ê·œì„±, ë“±ë¶„ì‚°ì„± ë¶ˆí•„ìš”
- **ì´ìƒì¹˜ì— ê°•ê±´í•¨**: ê·¹ê°’ì˜ ì˜í–¥ ìµœì†Œí™”
- **ì„œì—´ì²™ë„ ì ìš© ê°€ëŠ¥**: ìˆœìœ„ ê¸°ë°˜ ë¶„ì„
- **í•´ì„ ì§ê´€ì **: ì¤‘ì•™ê°’ ê¸°ë°˜ ë¹„êµ

#### âŒ ë‹¨ì 
- **ê²€ì •ë ¥ ì†ì‹¤**: ëª¨ìˆ˜ ê²€ì •ë³´ë‹¤ ì•½ê°„ ë‚®ìŒ
- **ìƒí˜¸ì‘ìš© ë¶„ì„ ì–´ë ¤ì›€**: ë³µì¡í•œ ì„¤ê³„ ì œí•œì 
- **íš¨ê³¼í¬ê¸° ê³„ì‚° ë³µì¡**: í‘œì¤€í™”ëœ ì§€í‘œ ë¶€ì¡±
- **ì†Œí”„íŠ¸ì›¨ì–´ ì§€ì› ì œí•œ**: ì¼ë¶€ ê³ ê¸‰ ë¶„ì„ ì–´ë ¤ì›€

---

## ğŸš€ ì‹¤ë¬´ ì˜ì‚¬ê²°ì • í”Œë¡œìš°ì°¨íŠ¸

### ğŸ“‹ ANOVA ê°€ì • ê²€í†  â†’ ë¶„ì„ë²• ì„ íƒ

```mermaid
flowchart TD
    A[ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ] --> B{í‘œë³¸ í¬ê¸° ì¶©ë¶„?<br/>ê° ì§‘ë‹¨ nâ‰¥15}
    
    B -->|No| C[ë¹„ëª¨ìˆ˜ ê²€ì • ì„ íƒ<br/>ë˜ëŠ” ë°ì´í„° ì¶”ê°€ ìˆ˜ì§‘]
    B -->|Yes| D[ì •ê·œì„± ê²€ì • ì‹¤ì‹œ]
    
    D --> E{ì •ê·œì„± ë§Œì¡±?<br/>p > 0.05}
    E -->|No| F[ë°ì´í„° ë³€í™˜ ì‹œë„<br/>Box-Cox, log ë“±]
    F --> G{ë³€í™˜ í›„ ì •ê·œì„±?}
    G -->|No| H[ë¹„ëª¨ìˆ˜ ê²€ì • ì„ íƒ]
    G -->|Yes| I[ë“±ë¶„ì‚°ì„± ê²€ì •]
    
    E -->|Yes| I[ë“±ë¶„ì‚°ì„± ê²€ì • ì‹¤ì‹œ]
    I --> J{ë“±ë¶„ì‚°ì„± ë§Œì¡±?<br/>p > 0.05}
    
    J -->|No| K[Welch's ANOVA<br/>ë˜ëŠ” ë¹„ëª¨ìˆ˜ ê²€ì •]
    J -->|Yes| L[ë…ë¦½ì„± í™•ì¸]
    
    L --> M{ë…ë¦½ì„± ë§Œì¡±?}
    M -->|No| N[í˜¼í•©íš¨ê³¼ ëª¨ë¸<br/>ë˜ëŠ” ë°˜ë³µì¸¡ì • ì„¤ê³„]
    M -->|Yes| O[í‘œì¤€ ANOVA ì‹¤ì‹œ]
    
    H --> P[Kruskal-Wallis<br/>Friedman ë“±]
    K --> Q[ê²°ê³¼ í•´ì„]
    O --> Q[ê²°ê³¼ í•´ì„]
    P --> Q
```

---

## ğŸ“Š ì‹¤ì „ ì˜ˆì œ: ë¬¸ì œ í•´ê²° ê³¼ì •

### ğŸ¥ ì˜ë£Œ ë°ì´í„° ë¶„ì„ ì‚¬ë¡€

```python
# ê°€ìƒì˜ ì˜ë£Œ ë°ì´í„°
np.random.seed(42)

# ì •ê·œì„±ê³¼ ë“±ë¶„ì‚°ì„±ì„ ìœ„ë°˜í•˜ëŠ” ë°ì´í„° ìƒì„±
treatment_a = np.random.exponential(2, 30)  # ì§€ìˆ˜ë¶„í¬ (ì¹˜ìš°ì¹¨)
treatment_b = np.random.normal(5, 1, 30)    # ì •ê·œë¶„í¬
treatment_c = np.random.lognormal(1, 0.5, 30)  # ë¡œê·¸ì •ê·œë¶„í¬ (í° ë¶„ì‚°)

medical_data = pd.DataFrame({
    'treatment': ['A']*30 + ['B']*30 + ['C']*30,
    'recovery_time': np.concatenate([treatment_a, treatment_b, treatment_c])
})

print("=== ì˜ë£Œ ë°ì´í„° ë¶„ì„: ì¹˜ë£Œë²•ë³„ íšŒë³µì‹œê°„ ë¹„êµ ===")

# 1ë‹¨ê³„: ê¸°ìˆ í†µê³„
print("\n1ï¸âƒ£ ê¸°ìˆ í†µê³„")
print(medical_data.groupby('treatment')['recovery_time'].describe())

# 2ë‹¨ê³„: ê°€ì • ê²€í† 
print("\n2ï¸âƒ£ ANOVA ê°€ì • ê²€í† ")

# ì •ê·œì„± ê²€ì •
normality_results = check_normality(medical_data, 'treatment', 'recovery_time')

# ë“±ë¶„ì‚°ì„± ê²€ì •
homogeneity_results = check_homogeneity(medical_data, 'treatment', 'recovery_time')

# 3ë‹¨ê³„: ì ì ˆí•œ ë¶„ì„ë²• ì„ íƒ
print("\n3ï¸âƒ£ ë¶„ì„ë²• ì„ íƒ ë° ì‹¤ì‹œ")

if any(result['shapiro_p'] < 0.05 for result in normality_results.values()):
    print("âš ï¸  ì •ê·œì„± ê°€ì • ìœ„ë°˜ â†’ ë¹„ëª¨ìˆ˜ ê²€ì • ì‹¤ì‹œ")
    
    # Kruskal-Wallis ê²€ì •
    kruskal_results = kruskal_wallis_test(medical_data, 'treatment', 'recovery_time')
    
    # ì‚¬í›„ê²€ì •
    if kruskal_results[1] < 0.05:  # p-value
        print("\nì‚¬í›„ê²€ì • ì‹¤ì‹œ...")
        dunn_results = dunn_test(medical_data, 'treatment', 'recovery_time')

else:
    print("âœ… ì •ê·œì„± ê°€ì • ë§Œì¡±")
    
    if homogeneity_results['levene_p'] < 0.05:
        print("âš ï¸  ë“±ë¶„ì‚°ì„± ìœ„ë°˜ â†’ Welch's ANOVA ì‹¤ì‹œ")
        welch_results = welch_anova(medical_data, 'treatment', 'recovery_time')
    else:
        print("âœ… ë“±ë¶„ì‚°ì„± ê°€ì • ë§Œì¡± â†’ í‘œì¤€ ANOVA ì‹¤ì‹œ")
        # í‘œì¤€ ANOVA ì‹¤í–‰...

# 4ë‹¨ê³„: ê²°ê³¼ ì‹œê°í™”
print("\n4ï¸âƒ£ ê²°ê³¼ ì‹œê°í™”")
plot_normality_diagnostics(medical_data, 'treatment', 'recovery_time')
plot_homogeneity_diagnostics(medical_data, 'treatment', 'recovery_time')
```

---

## ğŸ’¡ ì‹¤ë¬´ íŒê³¼ ì£¼ì˜ì‚¬í•­

### ğŸ¯ ìì£¼ í•˜ëŠ” ì‹¤ìˆ˜ë“¤

#### âŒ **í•˜ì§€ ë§ì•„ì•¼ í•  ê²ƒë“¤**

1. **ê°€ì • ê²€í†  ìƒëµ**: "ëŒ€ì¶© ì •ê·œë¶„í¬ê² ì§€"
2. **ìœ ì˜ì„±ë§Œ ë³´ê³  íŒë‹¨**: íš¨ê³¼í¬ê¸° ë¬´ì‹œ
3. **ë³€í™˜ ë‚¨ë°œ**: í•´ì„ì´ ì–´ë ¤ì›Œì§
4. **ë¹„ëª¨ìˆ˜ ë§ŒëŠ¥ì£¼ì˜**: í•­ìƒ ë” ì¢‹ì€ ê±´ ì•„ë‹˜
5. **ì†Œí”„íŠ¸ì›¨ì–´ ë§¹ì‹ **: ê²°ê³¼ì˜ ì˜ë¯¸ íŒŒì•… ì—†ì´ ì‚¬ìš©

#### âœ… **í•´ì•¼ í•  ê²ƒë“¤**

1. **í•­ìƒ íƒìƒ‰ì  ë¶„ì„ ë¨¼ì €**: ë°ì´í„° ë¶„í¬ í™•ì¸
2. **ì—¬ëŸ¬ ê°€ì • ê²€í† **: í•˜ë‚˜ì”© ì°¨ë¡€ëŒ€ë¡œ
3. **ë³€í™˜ ì „í›„ ë¹„êµ**: í•´ì„ ê°€ëŠ¥ì„± ê³ ë ¤
4. **íš¨ê³¼í¬ê¸° ë³‘ê¸°**: í†µê³„ì  + ì‹¤ë¬´ì  ìœ ì˜ì„±
5. **ê²°ê³¼ì˜ í•œê³„ ëª…ì‹œ**: ê°€ì • ìœ„ë°˜ ì‹œ ì£¼ì˜ì  ì–¸ê¸‰

### ğŸ”§ ì†Œí”„íŠ¸ì›¨ì–´ë³„ êµ¬í˜„

#### Python íŒ¨í‚¤ì§€ ì¶”ì²œ
```python
# í•„ìˆ˜ íŒ¨í‚¤ì§€ë“¤
import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns

# ê³ ê¸‰ ë¶„ì„ìš©
# pip install scikit-posthocs  # ë¹„ëª¨ìˆ˜ ì‚¬í›„ê²€ì •
# pip install pingouin        # í†µê³„ë¶„ì„ íŠ¹í™”
# pip install statsmodels     # ê³ ê¸‰ í†µê³„ëª¨ë¸
```

#### R íŒ¨í‚¤ì§€ (ì°¸ê³ ìš©)
```r
# ë¹„ëª¨ìˆ˜ ë¶„ì„ì— íŠ¹íˆ ê°•í•¨
library(ARTool)     # Aligned Rank Transform
library(coin)       # ë¹„ëª¨ìˆ˜ ê²€ì • ëª¨ìŒ
library(PMCMRplus)  # ì‚¬í›„ê²€ì • ëª¨ìŒ
library(car)        # ANOVA ì§„ë‹¨
```

---

## ğŸ“ í•µì‹¬ ìš”ì•½

### ğŸ“Š ê°€ì •ë³„ ëŒ€ì²˜ ì „ëµ

| ê°€ì • ìœ„ë°˜ | 1ì°¨ ëŒ€ì²˜ | 2ì°¨ ëŒ€ì²˜ | ìµœì¢… ëŒ€ì•ˆ |
|---------|---------|---------|----------|
| **ì •ê·œì„±** | ë°ì´í„° ë³€í™˜ | ëŒ€í‘œë³¸ í™œìš© | ë¹„ëª¨ìˆ˜ ê²€ì • |
| **ë“±ë¶„ì‚°ì„±** | ë³€í™˜/Welch | ê°•ê±´í•œ í‘œì¤€ì˜¤ì°¨ | ë¹„ëª¨ìˆ˜ ê²€ì • |
| **ë…ë¦½ì„±** | ì„¤ê³„ ìˆ˜ì • | í˜¼í•©íš¨ê³¼ ëª¨ë¸ | í´ëŸ¬ìŠ¤í„°ë§ ë³´ì • |

### ğŸ¯ ì˜ì‚¬ê²°ì • ìš°ì„ ìˆœìœ„

1. **ë°ì´í„° í’ˆì§ˆ í™•ë³´**: ì¶©ë¶„í•œ í‘œë³¸ í¬ê¸°ì™€ ì ì ˆí•œ ìˆ˜ì§‘
2. **ê°€ì • ì§„ë‹¨**: í†µê³„ì  ê²€ì • + ì‹œê°ì  í™•ì¸
3. **ë³€í™˜ ì‹œë„**: í•´ì„ ê°€ëŠ¥ì„±ì„ í•´ì¹˜ì§€ ì•ŠëŠ” ì„ ì—ì„œ
4. **ì ì ˆí•œ ëŒ€ì•ˆ ì„ íƒ**: ì—°êµ¬ ëª©ì ì— ë§ëŠ” ë°©ë²•
5. **ê²°ê³¼ í•´ì„ ì‹ ì¤‘**: í•œê³„ì ê³¼ í•¨ê»˜ ë³´ê³ 

### ğŸ’« ì‹¤ë¬´ìë¥¼ ìœ„í•œ í™©ê¸ˆë¥ 

> **"ì™„ë²½í•œ ë°ì´í„°ëŠ” ì—†ë‹¤. í•˜ì§€ë§Œ ì ì ˆí•œ ë°©ë²•ì€ í•­ìƒ ìˆë‹¤."**

- ğŸ” **ì§„ë‹¨ì´ ë¨¼ì €**: ê°€ì • í™•ì¸ â†’ ë°©ë²• ì„ íƒ
- ğŸ¯ **ëª©ì ì— ë§ëŠ” ì„ íƒ**: íƒìƒ‰ì  vs í™•ì¦ì 
- ğŸ“Š **íˆ¬ëª…í•œ ë³´ê³ **: ì‚¬ìš©í•œ ë°©ë²•ê³¼ ê·¸ ì´ìœ  ëª…ì‹œ
- ğŸš€ **ì§€ì†ì  í•™ìŠµ**: ìƒˆë¡œìš´ ë°©ë²•ë¡  ì—…ë°ì´íŠ¸

---

**ë‹¤ìŒ 22.07.04ì—ì„œëŠ” ANOVA ê²°ê³¼ì˜ íš¨ê³¼í¬ê¸° ê³„ì‚°ê³¼ ì‹¤ë¬´ì  í•´ì„ì— ëŒ€í•´ ê¹Šì´ ë‹¤ë¤„ë³´ê² ìŠµë‹ˆë‹¤!** ğŸ¯