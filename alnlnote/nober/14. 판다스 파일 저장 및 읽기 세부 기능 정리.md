# 14. íŒë‹¤ìŠ¤ íŒŒì¼ ì €ì¥ ë° ì½ê¸° ì„¸ë¶€ ê¸°ëŠ¥ ì •ë¦¬

## ğŸ“‹ ê°œìš”

íŒë‹¤ìŠ¤(Pandas)ëŠ” ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ì½ê³  ì €ì¥í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ I/O ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ê°€ì´ë“œëŠ” ì‹¤ë¬´ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” íŒŒì¼ ì…ì¶œë ¥ ê¸°ëŠ¥ë“¤ì„ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ê³ , ì‹¤ì œ ì½”ë“œ ì˜ˆì œì™€ í•¨ê»˜ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ”§ ì£¼ìš” íŒŒì¼ í˜•ì‹ ì§€ì›

| í˜•ì‹ | ì½ê¸° í•¨ìˆ˜ | ì €ì¥ ë©”ì„œë“œ | íŠ¹ì§• |
|------|----------|-------------|------|
| CSV | `pd.read_csv()` | `df.to_csv()` | ë²”ìš©ì , ê²½ëŸ‰ |
| Excel | `pd.read_excel()` | `df.to_excel()` | ë‹¤ì¤‘ ì‹œíŠ¸ ì§€ì› |
| JSON | `pd.read_json()` | `df.to_json()` | ì›¹ API í˜¸í™˜ |
| HTML | `pd.read_html()` | `df.to_html()` | ì›¹ ìŠ¤í¬ë˜í•‘ |
| í…ìŠ¤íŠ¸ | `pd.read_table()` | - | êµ¬ë¶„ì ì§€ì • |
| FWF | `pd.read_fwf()` | - | ê³ ì • í­ íŒŒì¼ |

---

## ğŸ“‚ CSV íŒŒì¼ ì²˜ë¦¬

### ê¸°ë³¸ CSV ì½ê¸° ë° ì €ì¥

```python
import pandas as pd
import numpy as np

# ê¸°ë³¸ CSV íŒŒì¼ ì½ê¸°
df = pd.read_csv('data.csv')
print(df.head())

# êµ¬ë¶„ì ì§€ì •í•˜ì—¬ ì½ê¸°
df = pd.read_csv('data.csv', sep=',')  # ê¸°ë³¸ê°’
df = pd.read_csv('data.txt', sep='\s+')  # ê³µë°±ìœ¼ë¡œ êµ¬ë¶„

# ê¸°ë³¸ CSV ì €ì¥
df.to_csv('output.csv', index=False)  # ì¸ë±ìŠ¤ ì œì™¸í•˜ê³  ì €ì¥
```

### ê³ ê¸‰ CSV ì˜µì…˜

```python
# í—¤ë” ì²˜ë¦¬
df = pd.read_csv('data.csv', header=None)  # ì²« ì¤„ì„ í—¤ë”ë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
df = pd.read_csv('data.csv', names=['A', 'B', 'C'])  # ì‚¬ìš©ì ì •ì˜ ì»¬ëŸ¼ëª…

# íŠ¹ì • í–‰ ê±´ë„ˆë›°ê¸°
df = pd.read_csv('data.csv', skiprows=1)  # ì²« ë²ˆì§¸ í–‰ ê±´ë„ˆë›°ê¸°
df = pd.read_csv('data.csv', skiprows=[0, 2])  # 0ë²ˆì§¸, 2ë²ˆì§¸ í–‰ ê±´ë„ˆë›°ê¸°

# ì¸ì½”ë”© ì²˜ë¦¬
df = pd.read_csv('korean_data.csv', encoding='utf-8-sig')  # í•œê¸€ íŒŒì¼
df = pd.read_csv('data.csv', encoding='cp949')  # ìœˆë„ìš° í•œê¸€

# ê²°ì¸¡ê°’ ì²˜ë¦¬
df = pd.read_csv('data.csv', na_values=['N/A', 'NULL', '-'])

# ë°ì´í„° íƒ€ì… ì§€ì •
dtype_dict = {'id': str, 'score': int}
df = pd.read_csv('data.csv', dtype=dtype_dict)
```

### ì •ê·œí‘œí˜„ì‹ì„ ì´ìš©í•œ êµ¬ë¶„ì ì²˜ë¦¬

```python
# ê³µë°±ìœ¼ë¡œ êµ¬ë¶„ëœ íŒŒì¼ ì½ê¸° (ì •ê·œí‘œí˜„ì‹ ì‚¬ìš©)
df = pd.read_table('data.txt', sep=r'\s+')

# ì—¬ëŸ¬ ì¢…ë¥˜ì˜ êµ¬ë¶„ì ì²˜ë¦¬
df = pd.read_csv('data.csv', sep=r'[,;|\t]', engine='python')
```

**ğŸ’¡ ì •ê·œí‘œí˜„ì‹ íŒ¨í„´**
- `\s+`: í•˜ë‚˜ ì´ìƒì˜ ê³µë°± ë¬¸ì
- `[,;|\t]`: ì‰¼í‘œ, ì„¸ë¯¸ì½œë¡ , íŒŒì´í”„, íƒ­ ì¤‘ í•˜ë‚˜
- ë³µì¡í•œ íŒ¨í„´ ì²˜ë¦¬ ì‹œ `engine='python'` í•„ìš”

---

## ğŸ“ ì •ê·œí‘œí˜„ì‹(Regular Expression) ì™„ì „ ê°€ì´ë“œ

### ê¸°ë³¸ ë©”íƒ€ë¬¸ì

| íŒ¨í„´ | ì„¤ëª… | ì˜ˆì‹œ | ë§¤ì¹­ ê²°ê³¼ |
|------|------|------|-----------|
| `.` | ì„ì˜ì˜ í•œ ë¬¸ì (ì¤„ë°”ê¿ˆ ì œì™¸) | `a.c` | abc, aac, a1c |
| `^` | ë¬¸ìì—´ì˜ ì‹œì‘ | `^abc` | abcë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ìì—´ |
| `# 14. íŒë‹¤ìŠ¤ íŒŒì¼ ì €ì¥ ë° ì½ê¸° ì„¸ë¶€ ê¸°ëŠ¥ ì •ë¦¬

## ğŸ“‹ ê°œìš”

íŒë‹¤ìŠ¤(Pandas)ëŠ” ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ì½ê³  ì €ì¥í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ I/O ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ê°€ì´ë“œëŠ” ì‹¤ë¬´ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” íŒŒì¼ ì…ì¶œë ¥ ê¸°ëŠ¥ë“¤ì„ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ê³ , ì‹¤ì œ ì½”ë“œ ì˜ˆì œì™€ í•¨ê»˜ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ”§ ì£¼ìš” íŒŒì¼ í˜•ì‹ ì§€ì›

| í˜•ì‹ | ì½ê¸° í•¨ìˆ˜ | ì €ì¥ ë©”ì„œë“œ | íŠ¹ì§• |
|------|----------|-------------|------|
| CSV | `pd.read_csv()` | `df.to_csv()` | ë²”ìš©ì , ê²½ëŸ‰ |
| Excel | `pd.read_excel()` | `df.to_excel()` | ë‹¤ì¤‘ ì‹œíŠ¸ ì§€ì› |
| JSON | `pd.read_json()` | `df.to_json()` | ì›¹ API í˜¸í™˜ |
| HTML | `pd.read_html()` | `df.to_html()` | ì›¹ ìŠ¤í¬ë˜í•‘ |
| í…ìŠ¤íŠ¸ | `pd.read_table()` | - | êµ¬ë¶„ì ì§€ì • |
| FWF | `pd.read_fwf()` | - | ê³ ì • í­ íŒŒì¼ |

---

## ğŸ“‚ CSV íŒŒì¼ ì²˜ë¦¬

### ê¸°ë³¸ CSV ì½ê¸° ë° ì €ì¥

```python
import pandas as pd
import numpy as np

# ê¸°ë³¸ CSV íŒŒì¼ ì½ê¸°
df = pd.read_csv('data.csv')
print(df.head())

# êµ¬ë¶„ì ì§€ì •í•˜ì—¬ ì½ê¸°
df = pd.read_csv('data.csv', sep=',')  # ê¸°ë³¸ê°’
df = pd.read_csv('data.txt', sep='\s+')  # ê³µë°±ìœ¼ë¡œ êµ¬ë¶„

# ê¸°ë³¸ CSV ì €ì¥
df.to_csv('output.csv', index=False)  # ì¸ë±ìŠ¤ ì œì™¸í•˜ê³  ì €ì¥
```

### ê³ ê¸‰ CSV ì˜µì…˜

```python
# í—¤ë” ì²˜ë¦¬
df = pd.read_csv('data.csv', header=None)  # ì²« ì¤„ì„ í—¤ë”ë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
df = pd.read_csv('data.csv', names=['A', 'B', 'C'])  # ì‚¬ìš©ì ì •ì˜ ì»¬ëŸ¼ëª…

# íŠ¹ì • í–‰ ê±´ë„ˆë›°ê¸°
df = pd.read_csv('data.csv', skiprows=1)  # ì²« ë²ˆì§¸ í–‰ ê±´ë„ˆë›°ê¸°
df = pd.read_csv('data.csv', skiprows=[0, 2])  # 0ë²ˆì§¸, 2ë²ˆì§¸ í–‰ ê±´ë„ˆë›°ê¸°

# ì¸ì½”ë”© ì²˜ë¦¬
df = pd.read_csv('korean_data.csv', encoding='utf-8-sig')  # í•œê¸€ íŒŒì¼
df = pd.read_csv('data.csv', encoding='cp949')  # ìœˆë„ìš° í•œê¸€

# ê²°ì¸¡ê°’ ì²˜ë¦¬
df = pd.read_csv('data.csv', na_values=['N/A', 'NULL', '-'])

# ë°ì´í„° íƒ€ì… ì§€ì •
dtype_dict = {'id': str, 'score': int}
df = pd.read_csv('data.csv', dtype=dtype_dict)
```

 | ë¬¸ìì—´ì˜ ë | `abc# 14. íŒë‹¤ìŠ¤ íŒŒì¼ ì €ì¥ ë° ì½ê¸° ì„¸ë¶€ ê¸°ëŠ¥ ì •ë¦¬

## ğŸ“‹ ê°œìš”

íŒë‹¤ìŠ¤(Pandas)ëŠ” ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ì½ê³  ì €ì¥í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ I/O ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ê°€ì´ë“œëŠ” ì‹¤ë¬´ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” íŒŒì¼ ì…ì¶œë ¥ ê¸°ëŠ¥ë“¤ì„ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ê³ , ì‹¤ì œ ì½”ë“œ ì˜ˆì œì™€ í•¨ê»˜ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ”§ ì£¼ìš” íŒŒì¼ í˜•ì‹ ì§€ì›

| í˜•ì‹ | ì½ê¸° í•¨ìˆ˜ | ì €ì¥ ë©”ì„œë“œ | íŠ¹ì§• |
|------|----------|-------------|------|
| CSV | `pd.read_csv()` | `df.to_csv()` | ë²”ìš©ì , ê²½ëŸ‰ |
| Excel | `pd.read_excel()` | `df.to_excel()` | ë‹¤ì¤‘ ì‹œíŠ¸ ì§€ì› |
| JSON | `pd.read_json()` | `df.to_json()` | ì›¹ API í˜¸í™˜ |
| HTML | `pd.read_html()` | `df.to_html()` | ì›¹ ìŠ¤í¬ë˜í•‘ |
| í…ìŠ¤íŠ¸ | `pd.read_table()` | - | êµ¬ë¶„ì ì§€ì • |
| FWF | `pd.read_fwf()` | - | ê³ ì • í­ íŒŒì¼ |

---

## ğŸ“‚ CSV íŒŒì¼ ì²˜ë¦¬

### ê¸°ë³¸ CSV ì½ê¸° ë° ì €ì¥

```python
import pandas as pd
import numpy as np

# ê¸°ë³¸ CSV íŒŒì¼ ì½ê¸°
df = pd.read_csv('data.csv')
print(df.head())

# êµ¬ë¶„ì ì§€ì •í•˜ì—¬ ì½ê¸°
df = pd.read_csv('data.csv', sep=',')  # ê¸°ë³¸ê°’
df = pd.read_csv('data.txt', sep='\s+')  # ê³µë°±ìœ¼ë¡œ êµ¬ë¶„

# ê¸°ë³¸ CSV ì €ì¥
df.to_csv('output.csv', index=False)  # ì¸ë±ìŠ¤ ì œì™¸í•˜ê³  ì €ì¥
```

### ê³ ê¸‰ CSV ì˜µì…˜

```python
# í—¤ë” ì²˜ë¦¬
df = pd.read_csv('data.csv', header=None)  # ì²« ì¤„ì„ í—¤ë”ë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
df = pd.read_csv('data.csv', names=['A', 'B', 'C'])  # ì‚¬ìš©ì ì •ì˜ ì»¬ëŸ¼ëª…

# íŠ¹ì • í–‰ ê±´ë„ˆë›°ê¸°
df = pd.read_csv('data.csv', skiprows=1)  # ì²« ë²ˆì§¸ í–‰ ê±´ë„ˆë›°ê¸°
df = pd.read_csv('data.csv', skiprows=[0, 2])  # 0ë²ˆì§¸, 2ë²ˆì§¸ í–‰ ê±´ë„ˆë›°ê¸°

# ì¸ì½”ë”© ì²˜ë¦¬
df = pd.read_csv('korean_data.csv', encoding='utf-8-sig')  # í•œê¸€ íŒŒì¼
df = pd.read_csv('data.csv', encoding='cp949')  # ìœˆë„ìš° í•œê¸€

# ê²°ì¸¡ê°’ ì²˜ë¦¬
df = pd.read_csv('data.csv', na_values=['N/A', 'NULL', '-'])

# ë°ì´í„° íƒ€ì… ì§€ì •
dtype_dict = {'id': str, 'score': int}
df = pd.read_csv('data.csv', dtype=dtype_dict)
```

 | abcë¡œ ëë‚˜ëŠ” ë¬¸ìì—´ |
| `*` | 0íšŒ ì´ìƒ ë°˜ë³µ | `ab*c` | ac, abc, abbc, abbbc |
| `+` | 1íšŒ ì´ìƒ ë°˜ë³µ | `ab+c` | abc, abbc, abbbc |
| `?` | 0íšŒ ë˜ëŠ” 1íšŒ | `ab?c` | ac, abc |
| `\` | ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì | `a\.c` | a.c (ì  ë¬¸ì ê·¸ëŒ€ë¡œ) |

### ë¬¸ì í´ë˜ìŠ¤

```python
import re
import pandas as pd

# ë¬¸ì í´ë˜ìŠ¤ íŒ¨í„´ ì˜ˆì‹œ
patterns = {
    r'\d+': 'í•˜ë‚˜ ì´ìƒì˜ ìˆ«ì',           # 123, 4567
    r'\D+': 'ìˆ«ìê°€ ì•„ë‹Œ ë¬¸ì',            # abc, def
    r'\w+': 'ë‹¨ì–´ ë¬¸ì (ì˜ë¬¸, ìˆ«ì, _)',    # hello, test_123
    r'\W+': 'ë‹¨ì–´ ë¬¸ìê°€ ì•„ë‹Œ ê²ƒ',          # !@#, ê³µë°±
    r'\s+': 'í•˜ë‚˜ ì´ìƒì˜ ê³µë°±ë¬¸ì',         # ìŠ¤í˜ì´ìŠ¤, íƒ­, ì¤„ë°”ê¿ˆ
    r'\S+': 'ê³µë°±ì´ ì•„ë‹Œ ë¬¸ì',            # hello, 123
}

for pattern, description in patterns.items():
    print(f"{pattern:8} : {description}")
```

### ì‹¤ë¬´ì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” íŒ¨í„´

#### 1. êµ¬ë¶„ì íŒ¨í„´
```python
# ë‹¤ì–‘í•œ êµ¬ë¶„ì ì²˜ë¦¬
separators = {
    r',': 'ì‰¼í‘œ',
    r'\t': 'íƒ­',
    r'\s+': 'í•˜ë‚˜ ì´ìƒì˜ ê³µë°±',
    r'[,;\t]': 'ì‰¼í‘œ, ì„¸ë¯¸ì½œë¡ , íƒ­ ì¤‘ í•˜ë‚˜',
    r'[,\s]+': 'ì‰¼í‘œ ë˜ëŠ” ê³µë°±',
    r'\s*,\s*': 'ì‰¼í‘œ ì•ë’¤ ê³µë°± í¬í•¨',
    r'\|': 'íŒŒì´í”„ ë¬¸ì',
    r'::': 'ë”ë¸” ì½œë¡ '
}

# ì‚¬ìš© ì˜ˆì‹œ
df = pd.read_csv('data.txt', sep=r'\s*,\s*', engine='python')  # ì‰¼í‘œ ì•ë’¤ ê³µë°± ë¬´ì‹œ
df = pd.read_csv('data.txt', sep=r'[,;\t]', engine='python')   # ë‹¤ì¤‘ êµ¬ë¶„ì
```

#### 2. ìˆ«ì íŒ¨í„´
```python
number_patterns = {
    r'\d+': 'ì •ìˆ˜',                    # 123, 456
    r'\d+\.\d+': 'ì†Œìˆ˜',              # 123.45, 67.89
    r'-?\d+': 'ìŒìˆ˜ í¬í•¨ ì •ìˆ˜',        # -123, 456, -78
    r'[+-]?\d+\.?\d*': 'ì‹¤ìˆ˜ ì „ë°˜',    # +123.45, -67, 89.0
    r'\d{1,3}(,\d{3})*': 'ì²œë‹¨ìœ„ êµ¬ë¶„', # 1,234, 567,890
}

# ìˆ«ì ë°ì´í„° ì²˜ë¦¬ ì˜ˆì‹œ
text_with_numbers = "ê°€ê²©: 1,234,567ì›, í• ì¸ìœ¨: -15.5%"
price = re.findall(r'\d{1,3}(,\d{3})*', text_with_numbers)
discount = re.findall(r'-?\d+\.?\d*', text_with_numbers)
```

#### 3. ë‚ ì§œ/ì‹œê°„ íŒ¨í„´
```python
date_patterns = {
    r'\d{4}-\d{2}-\d{2}': 'YYYY-MM-DD',        # 2024-01-15
    r'\d{2}/\d{2}/\d{4}': 'MM/DD/YYYY',        # 01/15/2024
    r'\d{4}\.\d{2}\.\d{2}': 'YYYY.MM.DD',      # 2024.01.15
    r'\d{2}:\d{2}:\d{2}': 'HH:MM:SS',          # 14:30:25
    r'\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}': 'DATETIME', # 2024-01-15 14:30:25
}

# ë‚ ì§œ ë°ì´í„° ì²˜ë¦¬
date_text = "íšŒì˜ ì¼ì •: 2024-01-15 14:30:00"
datetime_match = re.search(r'\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}', date_text)
if datetime_match:
    print(f"ì¶”ì¶œëœ ë‚ ì§œì‹œê°„: {datetime_match.group()}")
```

#### 4. ì´ë©”ì¼/URL íŒ¨í„´
```python
contact_patterns = {
    r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}': 'ì´ë©”ì¼',
    r'https?://[^\s]+': 'URL',
    r'\d{3}-\d{4}-\d{4}': 'ì „í™”ë²ˆí˜¸ (010-1234-5678)',
    r'\([0-9]{3}\)\s?[0-9]{3}-[0-9]{4}': 'ë¯¸êµ­ì‹ ì „í™”ë²ˆí˜¸',
}

# ì—°ë½ì²˜ ì •ë³´ ì¶”ì¶œ
contact_info = """
ì´ë©”ì¼: user@example.com
ì›¹ì‚¬ì´íŠ¸: https://www.example.com
ì „í™”: 010-1234-5678
"""

emails = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', contact_info)
urls = re.findall(r'https?://[^\s]+', contact_info)
phones = re.findall(r'\d{3}-\d{4}-\d{4}', contact_info)
```

### ìˆ˜ëŸ‰ì(Quantifiers)

```python
quantifier_examples = {
    r'a{3}': 'aê°€ ì •í™•íˆ 3ë²ˆ',          # aaa
    r'a{2,5}': 'aê°€ 2~5ë²ˆ',            # aa, aaa, aaaa, aaaaa
    r'a{3,}': 'aê°€ 3ë²ˆ ì´ìƒ',          # aaa, aaaa, aaaaa...
    r'a*': 'aê°€ 0ë²ˆ ì´ìƒ',             # '', a, aa, aaa...
    r'a+': 'aê°€ 1ë²ˆ ì´ìƒ',             # a, aa, aaa...
    r'a?': 'aê°€ 0ë²ˆ ë˜ëŠ” 1ë²ˆ',         # '', a
}

# ì‹¤ì œ ë°ì´í„°ì—ì„œ í™œìš©
data_validation = {
    r'^\d{4}-\d{2}-\d{2}

---

## ğŸ“Š Excel íŒŒì¼ ì²˜ë¦¬

### ê¸°ë³¸ Excel ì½ê¸° ë° ì €ì¥

```python
# Excel íŒŒì¼ ì½ê¸°
df = pd.read_excel('data.xlsx')  # ì²« ë²ˆì§¸ ì‹œíŠ¸
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')  # íŠ¹ì • ì‹œíŠ¸

# Excel íŒŒì¼ ì €ì¥
df.to_excel('output.xlsx', index=False)
```

### ë‹¤ì¤‘ ì‹œíŠ¸ ì²˜ë¦¬

```python
# ì—¬ëŸ¬ ì‹œíŠ¸ ë™ì‹œ ì½ê¸°
excel_dict = pd.read_excel('data.xlsx', sheet_name=None)  # ëª¨ë“  ì‹œíŠ¸
print(excel_dict.keys())  # ì‹œíŠ¸ ì´ë¦„ë“¤

# íŠ¹ì • ì‹œíŠ¸ë“¤ë§Œ ì½ê¸°
sheets_dict = pd.read_excel('data.xlsx', sheet_name=['Sheet1', 'Sheet2'])

# ì—¬ëŸ¬ ì‹œíŠ¸ë¡œ ì €ì¥
with pd.ExcelWriter('multi_sheet.xlsx') as writer:
    df1.to_excel(writer, sheet_name='ë°ì´í„°1', index=False)
    df2.to_excel(writer, sheet_name='ë°ì´í„°2', index=False)
```

### ì‹¤ë¬´ ì˜ˆì œ: ì œí’ˆ ë°ì´í„° Excel ì²˜ë¦¬

```python
# ì œí’ˆ ë°ì´í„° ìƒì„±
product_data = {
    'name': ['Mouse', 'Keyboard', 'Monitor'],
    'price': [25000, 45000, 250000],
    'stock': [15, 8, 3]
}
df = pd.DataFrame(product_data)

# Excelë¡œ ì €ì¥ (ë‹¤ì–‘í•œ ì˜µì…˜)
df.to_excel('products.xlsx', 
           index=False,           # ì¸ë±ìŠ¤ ì œì™¸
           sheet_name='ì œí’ˆëª©ë¡',  # ì‹œíŠ¸ëª… ì§€ì •
           encoding='utf-8')      # ì¸ì½”ë”© ì§€ì •

# Excelì—ì„œ ì½ê¸°
df_read = pd.read_excel('products.xlsx', sheet_name='ì œí’ˆëª©ë¡')
print(df_read)
```

---

## ğŸŒ JSON íŒŒì¼ ì²˜ë¦¬

### JSON ê¸°ë³¸ ì²˜ë¦¬

```python
# JSON íŒŒì¼ë¡œ ì €ì¥
df.to_json('data.json')
df.to_json('data.json', orient='records')  # ë ˆì½”ë“œ í˜•íƒœ
df.to_json('data.json', orient='index')    # ì¸ë±ìŠ¤ ê¸°ë°˜

# JSON íŒŒì¼ ì½ê¸°
df = pd.read_json('data.json')

# ë¬¸ìì—´ JSON ì²˜ë¦¬
json_string = df.to_json(orient='records')
df_from_json = pd.read_json(json_string)
```

### JSON í˜•íƒœë³„ ì €ì¥ ë°©ì‹

```python
import pandas as pd

# ìƒ˜í”Œ ë°ì´í„°
data = {'apple': {'count': 10, 'price': 1500},
        'orange': {'count': 4, 'price': 700}}
df = pd.DataFrame(data)

print("1. ê¸°ë³¸ í˜•íƒœ:")
print(df.to_json())

print("\n2. ë ˆì½”ë“œ í˜•íƒœ (ì›¹ APIì— ì í•©):")
print(df.to_json(orient='records'))

print("\n3. ì¸ë±ìŠ¤ í˜•íƒœ:")
print(df.to_json(orient='index'))

print("\n4. ê°’ë§Œ ì €ì¥:")
print(df.to_json(orient='values'))
```

---

## ğŸŒ HTML ë° ì›¹ ë°ì´í„° ì²˜ë¦¬

### ì›¹ í…Œì´ë¸” ì½ê¸°

```python
# ì›¹ í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ì½ê¸°
url = "https://ko.wikipedia.org/wiki/ë¦¬ëˆ…ìŠ¤"
tables = pd.read_html(url, encoding='utf-8')
print(f"ì´ {len(tables)}ê°œì˜ í…Œì´ë¸” ë°œê²¬")

# ì²« ë²ˆì§¸ í…Œì´ë¸” í™•ì¸
if tables:
    first_table = tables[0]
    print(first_table.head())
```

### HTMLë¡œ ì €ì¥

```python
# HTML í˜•íƒœë¡œ ì €ì¥
html_string = df.to_html()
print(html_string)

# íŒŒì¼ë¡œ ì €ì¥
df.to_html('table.html', index=False)
```

---

## ğŸ“‹ í´ë¦½ë³´ë“œ í™œìš©

### í´ë¦½ë³´ë“œì™€ ë°ì´í„° êµí™˜

```python
# í´ë¦½ë³´ë“œë¡œ ë³µì‚¬ (Excelì—ì„œ ë°”ë¡œ ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥)
df.to_clipboard(index=False)
print("ë°ì´í„°ê°€ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

# í´ë¦½ë³´ë“œì—ì„œ ì½ê¸° (Excelì—ì„œ ë³µì‚¬í•œ ë°ì´í„°)
# df_from_clipboard = pd.read_clipboard()
```

---

## ğŸ”„ ëŒ€ìš©ëŸ‰ ë°ì´í„°: ì²­í¬(Chunk) ì²˜ë¦¬

### ì²­í¬ ì²˜ë¦¬ ê¸°ë³¸

```python
# ëŒ€ìš©ëŸ‰ CSV íŒŒì¼ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
chunk_size = 1000
chunks = []

# ì²­í¬ ë‹¨ìœ„ë¡œ ì½ì–´ì„œ ì²˜ë¦¬
for chunk in pd.read_csv('large_file.csv', chunksize=chunk_size):
    # ê° ì²­í¬ì— ëŒ€í•œ ì²˜ë¦¬
    processed_chunk = chunk[chunk['score'] > 80]  # ì˜ˆì‹œ í•„í„°ë§
    chunks.append(processed_chunk)

# ëª¨ë“  ì²­í¬ ê²°í•©
final_df = pd.concat(chunks, ignore_index=True)
```

### ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì²˜ë¦¬

```python
import time

# ì¼ë°˜ì ì¸ ë°©ë²• vs ì²­í¬ ì²˜ë¦¬ ì„±ëŠ¥ ë¹„êµ
def process_normal(filepath):
    start = time.time()
    df = pd.read_csv(filepath)
    result = df.groupby('category').mean()
    end = time.time()
    return result, end - start

def process_chunks(filepath, chunk_size=1000):
    start = time.time()
    results = []
    
    for chunk in pd.read_csv(filepath, chunksize=chunk_size):
        chunk_result = chunk.groupby('category').mean()
        results.append(chunk_result)
    
    final_result = pd.concat(results).groupby(level=0).mean()
    end = time.time()
    return final_result, end - start
```

**ğŸ’¡ ì²­í¬ ì²˜ë¦¬ì˜ ì¥ë‹¨ì **

**ì¥ì :**
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì ˆì•½
- ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ê°€ëŠ¥
- ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ì²˜ë¦¬

**ë‹¨ì :**
- ì²˜ë¦¬ ì†ë„ ì•½ê°„ ì €í•˜
- ë³µì¡í•œ ì½”ë“œ êµ¬ì¡°
- ì „ì²´ ë°ì´í„° ê¸°ë°˜ ì—°ì‚° ì–´ë ¤ì›€

---

## ğŸ”§ ê³ ì •í­ íŒŒì¼(FWF) ì²˜ë¦¬

### ê³ ì •í­ ë°ì´í„° ì½ê¸°

```python
# ê³ ì •í­ íŒŒì¼ ì½ê¸° ì˜ˆì‹œ
# ë°ì´í„° í˜•íƒœ: ì´ë¦„(10ì) + ë‚˜ì´(3ì) + ì ìˆ˜(5ì)
df = pd.read_fwf('fixed_width.txt',
                 widths=[10, 3, 5],  # ê° ì»¬ëŸ¼ì˜ í­
                 names=['name', 'age', 'score'],
                 encoding='utf-8')
print(df)
```

---

## ğŸ“Š ë‹¤ì–‘í•œ ì €ì¥ í˜•ì‹ ë¹„êµ

### í˜•ì‹ë³„ ì €ì¥ ì˜ˆì œ

```python
# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
sample_data = {
    'product': ['Mouse', 'Keyboard', 'Monitor'],
    'price': [25000, 45000, 250000],
    'stock': [15, 8, 3]
}
df = pd.DataFrame(sample_data)

# 1. CSV ì €ì¥ (êµ¬ë¶„ì ì˜µì…˜)
df.to_csv('data.csv', index=False, sep=',')
df.to_csv('data_tab.txt', index=False, sep='\t')  # íƒ­ êµ¬ë¶„

# 2. Excel ì €ì¥
df.to_excel('data.xlsx', index=False)

# 3. JSON ì €ì¥
df.to_json('data.json', orient='records', force_ascii=False)

# 4. ì „ì¹˜(Transpose) ì €ì¥
df_transposed = df.T  # í–‰ê³¼ ì—´ ë°”ê¾¸ê¸°
df_transposed.to_csv('data_transposed.csv')
```

### íŠ¸ëœìŠ¤í¬ì¦ˆ(Transpose) í™œìš©

```python
# ë°ì´í„° êµ¬ì¡° ë³€ê²½
items = {
    'apple': {'count': 10, 'price': 1500},
    'orange': {'count': 4, 'price': 700}
}
df = pd.DataFrame(items)
print("ì›ë³¸ ë°ì´í„°:")
print(df)

# í–‰ê³¼ ì—´ ë°”ê¾¸ê¸°
df_t = df.T
print("\nì „ì¹˜ëœ ë°ì´í„°:")
print(df_t)

# ì „ì¹˜ëœ ë°ì´í„° ì €ì¥
df_t.to_csv('transposed_data.csv')
```

---

## âš™ï¸ ì‹¤ë¬´ íŒ ë° ëª¨ë²” ì‚¬ë¡€

### 1. ì¸ì½”ë”© ë¬¸ì œ í•´ê²°

```python
# í•œê¸€ íŒŒì¼ ì²˜ë¦¬ ì‹œ ê¶Œì¥ ì„¤ì •
encodings_to_try = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr']

for encoding in encodings_to_try:
    try:
        df = pd.read_csv('korean_data.csv', encoding=encoding)
        print(f"ì„±ê³µ: {encoding}")
        break
    except UnicodeDecodeError:
        print(f"ì‹¤íŒ¨: {encoding}")
        continue
```

### 2. íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸

```python
import os

def safe_read_csv(filepath):
    if os.path.exists(filepath):
        return pd.read_csv(filepath)
    else:
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
        return None

# ì‚¬ìš© ì˜ˆì‹œ
df = safe_read_csv('data.csv')
if df is not None:
    print(df.head())
```

### 3. ë©”ëª¨ë¦¬ ìµœì í™” ë°ì´í„° íƒ€ì…

```python
# ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°ì´í„° íƒ€ì… ì§€ì •
efficient_dtypes = {
    'id': 'int32',      # int64 â†’ int32
    'category': 'category',  # object â†’ category
    'score': 'float32'  # float64 â†’ float32
}

df = pd.read_csv('data.csv', dtype=efficient_dtypes)
print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum()} bytes")
```

### 4. ë°°ì¹˜ íŒŒì¼ ì²˜ë¦¬

```python
import glob

# ì—¬ëŸ¬ CSV íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
csv_files = glob.glob("data_*.csv")
dataframes = []

for file in csv_files:
    df_temp = pd.read_csv(file)
    df_temp['source_file'] = file  # ì¶œì²˜ íŒŒì¼ëª… ì¶”ê°€
    dataframes.append(df_temp)

# ëª¨ë“  íŒŒì¼ ê²°í•©
combined_df = pd.concat(dataframes, ignore_index=True)
combined_df.to_csv('combined_data.csv', index=False)
```

---

## ğŸ¯ ì„±ëŠ¥ ë¹„êµ ë° ì„ íƒ ê°€ì´ë“œ

### íŒŒì¼ í˜•ì‹ë³„ ì„±ëŠ¥ íŠ¹ì„±

| í˜•ì‹ | ì½ê¸° ì†ë„ | íŒŒì¼ í¬ê¸° | í˜¸í™˜ì„± | ì‚¬ìš© ì‚¬ë¡€ |
|------|-----------|-----------|--------|-----------|
| CSV | ë¹ ë¦„ | ë³´í†µ | ë†’ìŒ | ë²”ìš© ë°ì´í„° êµí™˜ |
| Excel | ë³´í†µ | í¼ | ë³´í†µ | ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì„œ |
| JSON | ë³´í†µ | í¼ | ë†’ìŒ | ì›¹ API, ì„¤ì • íŒŒì¼ |
| Parquet | ë§¤ìš° ë¹ ë¦„ | ì‘ìŒ | ë‚®ìŒ | ë¹…ë°ì´í„° ë¶„ì„ |

### ìƒí™©ë³„ ê¶Œì¥ í˜•ì‹

```python
# ìƒí™©ë³„ ê¶Œì¥ íŒŒì¼ í˜•ì‹

# 1. ë²”ìš© ë°ì´í„° êµí™˜ â†’ CSV
df.to_csv('data.csv', index=False)

# 2. ë¹„ì¦ˆë‹ˆìŠ¤ ë³´ê³ ì„œ â†’ Excel
df.to_excel('report.xlsx', index=False)

# 3. ì›¹ API ë°ì´í„° â†’ JSON
df.to_json('api_data.json', orient='records')

# 4. ëŒ€ìš©ëŸ‰ ë¶„ì„ ë°ì´í„° â†’ Parquet (ë³„ë„ ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”)
# df.to_parquet('big_data.parquet')

# 5. ì›¹ í‘œì‹œìš© â†’ HTML
df.to_html('table.html', index=False, table_id='data-table')
```

---

## ğŸ“‹ ì¢…í•© ì‹¤ìŠµ ì˜ˆì œ

```python
def comprehensive_file_io_example():
    """
    íŒë‹¤ìŠ¤ íŒŒì¼ ì…ì¶œë ¥ ì¢…í•© ì˜ˆì œ
    """
    
    # 1. ë°ì´í„° ìƒì„±
    print("1. ìƒ˜í”Œ ë°ì´í„° ìƒì„±")
    data = {
        'product_id': range(1, 101),
        'product_name': [f'Product_{i}' for i in range(1, 101)],
        'price': np.random.randint(1000, 100000, 100),
        'category': np.random.choice(['A', 'B', 'C'], 100),
        'stock': np.random.randint(0, 50, 100)
    }
    df = pd.DataFrame(data)
    print(f"ë°ì´í„° í˜•íƒœ: {df.shape}")
    
    # 2. ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥
    print("\n2. ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥")
    
    # CSV (ê¸°ë³¸)
    df.to_csv('products.csv', index=False)
    
    # Excel (ë‹¤ì¤‘ ì‹œíŠ¸)
    with pd.ExcelWriter('products_multi.xlsx') as writer:
        df.to_excel(writer, sheet_name='ì „ì²´', index=False)
        df[df['category'] == 'A'].to_excel(writer, sheet_name='ì¹´í…Œê³ ë¦¬A', index=False)
        df[df['stock'] < 10].to_excel(writer, sheet_name='ì¬ê³ ë¶€ì¡±', index=False)
    
    # JSON (ë ˆì½”ë“œ í˜•íƒœ)
    df.to_json('products.json', orient='records', force_ascii=False)
    
    # 3. íŒŒì¼ ì½ê¸° ë° ê²€ì¦
    print("\n3. íŒŒì¼ ì½ê¸° ë° ê²€ì¦")
    
    df_csv = pd.read_csv('products.csv')
    df_excel = pd.read_excel('products_multi.xlsx', sheet_name='ì „ì²´')
    df_json = pd.read_json('products.json')
    
    # ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸
    print(f"CSV ì½ê¸°: {df_csv.shape}")
    print(f"Excel ì½ê¸°: {df_excel.shape}")
    print(f"JSON ì½ê¸°: {df_json.shape}")
    
    # 4. í†µê³„ ì •ë³´ ì¶œë ¥
    print("\n4. í†µê³„ ì •ë³´")
    print(df.groupby('category')['price'].agg(['mean', 'count', 'sum']))
    
    print("\níŒŒì¼ ì…ì¶œë ¥ ì˜ˆì œ ì™„ë£Œ!")

# ì‹¤í–‰
comprehensive_file_io_example()
```

---

## ğŸ” ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œì™€ í•´ê²°ì±…

#### 1. ì¸ì½”ë”© ì˜¤ë¥˜
```python
# ë¬¸ì œ: UnicodeDecodeError
# í•´ê²°: ì ì ˆí•œ ì¸ì½”ë”© ì§€ì •
df = pd.read_csv('data.csv', encoding='utf-8-sig')
```

#### 2. ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# ë¬¸ì œ: MemoryError
# í•´ê²°: ì²­í¬ ì²˜ë¦¬ ë˜ëŠ” ë°ì´í„° íƒ€ì… ìµœì í™”
for chunk in pd.read_csv('big_file.csv', chunksize=1000):
    process(chunk)
```

#### 3. ë‚ ì§œ í˜•ì‹ ë¬¸ì œ
```python
# ë¬¸ì œ: ë‚ ì§œ ì»¬ëŸ¼ì´ ë¬¸ìì—´ë¡œ ì½í˜
# í•´ê²°: parse_dates ì˜µì…˜ ì‚¬ìš©
df = pd.read_csv('data.csv', parse_dates=['date_column'])
```

#### 4. êµ¬ë¶„ì ë¬¸ì œ
```python
# ë¬¸ì œ: ë°ì´í„°ê°€ ì œëŒ€ë¡œ ë¶„ë¦¬ë˜ì§€ ì•ŠìŒ
# í•´ê²°: ì •í™•í•œ êµ¬ë¶„ì ì§€ì •
df = pd.read_csv('data.txt', sep='\t')  # íƒ­ êµ¬ë¶„
df = pd.read_csv('data.txt', sep=r'\s+')  # ê³µë°± êµ¬ë¶„
```

---

## ğŸ“š ì¶”ì²œ í•™ìŠµ ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Pandas I/O Tools](https://pandas.pydata.org/docs/user_guide/io.html)
- [CSV íŒŒì¼ ì²˜ë¦¬ ê°€ì´ë“œ](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)

### ì‹¤ë¬´ í™œìš©
- ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ í™œìš©
- í•œê¸€ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì¸ì½”ë”© ì£¼ì˜
- ì›¹ ìŠ¤í¬ë˜í•‘ ì‹œ HTML í…Œì´ë¸” ì½ê¸° ê¸°ëŠ¥ í™œìš©
- API ë°ì´í„° ì²˜ë¦¬ ì‹œ JSON í˜•ì‹ í™œìš©

---

## ğŸ¯ í•µì‹¬ ìš”ì•½

### ë°˜ë“œì‹œ ê¸°ì–µí•  í¬ì¸íŠ¸

1. **íŒŒì¼ í˜•ì‹ë³„ íŠ¹ì§• ì´í•´**
   - CSV: ë²”ìš©ì„±, ê°€ë²¼ì›€
   - Excel: ë¹„ì¦ˆë‹ˆìŠ¤ ì¹œí™”ì , ë‹¤ì¤‘ ì‹œíŠ¸
   - JSON: ì›¹ ì¹œí™”ì , êµ¬ì¡°ì 

2. **ì¸ì½”ë”© ì²˜ë¦¬**
   - í•œê¸€ íŒŒì¼: `encoding='utf-8-sig'` ë˜ëŠ” `encoding='cp949'`
   - ì›¹ ë°ì´í„°: `encoding='utf-8'`

3. **ë©”ëª¨ë¦¬ ê´€ë¦¬**
   - ëŒ€ìš©ëŸ‰ íŒŒì¼: ì²­í¬ ì²˜ë¦¬ í™œìš©
   - ë°ì´í„° íƒ€ì… ìµœì í™”ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½

4. **ì‹¤ë¬´ í™œìš© íŒ¨í„´**
   - íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
   - ì˜ˆì™¸ ì²˜ë¦¬ êµ¬í˜„
   - ë°°ì¹˜ ì²˜ë¦¬ ìë™í™”

íŒë‹¤ìŠ¤ì˜ íŒŒì¼ I/O ê¸°ëŠ¥ì„ ë§ˆìŠ¤í„°í•˜ë©´ ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ì˜ ì—°ë™ì´ ê°€ëŠ¥í•´ì§€ë©°, ì‹¤ë¬´ì—ì„œì˜ ë°ì´í„° ì²˜ë¦¬ íš¨ìœ¨ì„±ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤! ğŸ’ª: 'ë‚ ì§œ í˜•ì‹ ê²€ì¦',
    r'^[A-Z]{2,3}\d{3,4}

---

## ğŸ“Š Excel íŒŒì¼ ì²˜ë¦¬

### ê¸°ë³¸ Excel ì½ê¸° ë° ì €ì¥

```python
# Excel íŒŒì¼ ì½ê¸°
df = pd.read_excel('data.xlsx')  # ì²« ë²ˆì§¸ ì‹œíŠ¸
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')  # íŠ¹ì • ì‹œíŠ¸

# Excel íŒŒì¼ ì €ì¥
df.to_excel('output.xlsx', index=False)
```

### ë‹¤ì¤‘ ì‹œíŠ¸ ì²˜ë¦¬

```python
# ì—¬ëŸ¬ ì‹œíŠ¸ ë™ì‹œ ì½ê¸°
excel_dict = pd.read_excel('data.xlsx', sheet_name=None)  # ëª¨ë“  ì‹œíŠ¸
print(excel_dict.keys())  # ì‹œíŠ¸ ì´ë¦„ë“¤

# íŠ¹ì • ì‹œíŠ¸ë“¤ë§Œ ì½ê¸°
sheets_dict = pd.read_excel('data.xlsx', sheet_name=['Sheet1', 'Sheet2'])

# ì—¬ëŸ¬ ì‹œíŠ¸ë¡œ ì €ì¥
with pd.ExcelWriter('multi_sheet.xlsx') as writer:
    df1.to_excel(writer, sheet_name='ë°ì´í„°1', index=False)
    df2.to_excel(writer, sheet_name='ë°ì´í„°2', index=False)
```

### ì‹¤ë¬´ ì˜ˆì œ: ì œí’ˆ ë°ì´í„° Excel ì²˜ë¦¬

```python
# ì œí’ˆ ë°ì´í„° ìƒì„±
product_data = {
    'name': ['Mouse', 'Keyboard', 'Monitor'],
    'price': [25000, 45000, 250000],
    'stock': [15, 8, 3]
}
df = pd.DataFrame(product_data)

# Excelë¡œ ì €ì¥ (ë‹¤ì–‘í•œ ì˜µì…˜)
df.to_excel('products.xlsx', 
           index=False,           # ì¸ë±ìŠ¤ ì œì™¸
           sheet_name='ì œí’ˆëª©ë¡',  # ì‹œíŠ¸ëª… ì§€ì •
           encoding='utf-8')      # ì¸ì½”ë”© ì§€ì •

# Excelì—ì„œ ì½ê¸°
df_read = pd.read_excel('products.xlsx', sheet_name='ì œí’ˆëª©ë¡')
print(df_read)
```

---

## ğŸŒ JSON íŒŒì¼ ì²˜ë¦¬

### JSON ê¸°ë³¸ ì²˜ë¦¬

```python
# JSON íŒŒì¼ë¡œ ì €ì¥
df.to_json('data.json')
df.to_json('data.json', orient='records')  # ë ˆì½”ë“œ í˜•íƒœ
df.to_json('data.json', orient='index')    # ì¸ë±ìŠ¤ ê¸°ë°˜

# JSON íŒŒì¼ ì½ê¸°
df = pd.read_json('data.json')

# ë¬¸ìì—´ JSON ì²˜ë¦¬
json_string = df.to_json(orient='records')
df_from_json = pd.read_json(json_string)
```

### JSON í˜•íƒœë³„ ì €ì¥ ë°©ì‹

```python
import pandas as pd

# ìƒ˜í”Œ ë°ì´í„°
data = {'apple': {'count': 10, 'price': 1500},
        'orange': {'count': 4, 'price': 700}}
df = pd.DataFrame(data)

print("1. ê¸°ë³¸ í˜•íƒœ:")
print(df.to_json())

print("\n2. ë ˆì½”ë“œ í˜•íƒœ (ì›¹ APIì— ì í•©):")
print(df.to_json(orient='records'))

print("\n3. ì¸ë±ìŠ¤ í˜•íƒœ:")
print(df.to_json(orient='index'))

print("\n4. ê°’ë§Œ ì €ì¥:")
print(df.to_json(orient='values'))
```

---

## ğŸŒ HTML ë° ì›¹ ë°ì´í„° ì²˜ë¦¬

### ì›¹ í…Œì´ë¸” ì½ê¸°

```python
# ì›¹ í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ì½ê¸°
url = "https://ko.wikipedia.org/wiki/ë¦¬ëˆ…ìŠ¤"
tables = pd.read_html(url, encoding='utf-8')
print(f"ì´ {len(tables)}ê°œì˜ í…Œì´ë¸” ë°œê²¬")

# ì²« ë²ˆì§¸ í…Œì´ë¸” í™•ì¸
if tables:
    first_table = tables[0]
    print(first_table.head())
```

### HTMLë¡œ ì €ì¥

```python
# HTML í˜•íƒœë¡œ ì €ì¥
html_string = df.to_html()
print(html_string)

# íŒŒì¼ë¡œ ì €ì¥
df.to_html('table.html', index=False)
```

---

## ğŸ“‹ í´ë¦½ë³´ë“œ í™œìš©

### í´ë¦½ë³´ë“œì™€ ë°ì´í„° êµí™˜

```python
# í´ë¦½ë³´ë“œë¡œ ë³µì‚¬ (Excelì—ì„œ ë°”ë¡œ ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥)
df.to_clipboard(index=False)
print("ë°ì´í„°ê°€ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

# í´ë¦½ë³´ë“œì—ì„œ ì½ê¸° (Excelì—ì„œ ë³µì‚¬í•œ ë°ì´í„°)
# df_from_clipboard = pd.read_clipboard()
```

---

## ğŸ”„ ëŒ€ìš©ëŸ‰ ë°ì´í„°: ì²­í¬(Chunk) ì²˜ë¦¬

### ì²­í¬ ì²˜ë¦¬ ê¸°ë³¸

```python
# ëŒ€ìš©ëŸ‰ CSV íŒŒì¼ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
chunk_size = 1000
chunks = []

# ì²­í¬ ë‹¨ìœ„ë¡œ ì½ì–´ì„œ ì²˜ë¦¬
for chunk in pd.read_csv('large_file.csv', chunksize=chunk_size):
    # ê° ì²­í¬ì— ëŒ€í•œ ì²˜ë¦¬
    processed_chunk = chunk[chunk['score'] > 80]  # ì˜ˆì‹œ í•„í„°ë§
    chunks.append(processed_chunk)

# ëª¨ë“  ì²­í¬ ê²°í•©
final_df = pd.concat(chunks, ignore_index=True)
```

### ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì²˜ë¦¬

```python
import time

# ì¼ë°˜ì ì¸ ë°©ë²• vs ì²­í¬ ì²˜ë¦¬ ì„±ëŠ¥ ë¹„êµ
def process_normal(filepath):
    start = time.time()
    df = pd.read_csv(filepath)
    result = df.groupby('category').mean()
    end = time.time()
    return result, end - start

def process_chunks(filepath, chunk_size=1000):
    start = time.time()
    results = []
    
    for chunk in pd.read_csv(filepath, chunksize=chunk_size):
        chunk_result = chunk.groupby('category').mean()
        results.append(chunk_result)
    
    final_result = pd.concat(results).groupby(level=0).mean()
    end = time.time()
    return final_result, end - start
```

**ğŸ’¡ ì²­í¬ ì²˜ë¦¬ì˜ ì¥ë‹¨ì **

**ì¥ì :**
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì ˆì•½
- ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ê°€ëŠ¥
- ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ì²˜ë¦¬

**ë‹¨ì :**
- ì²˜ë¦¬ ì†ë„ ì•½ê°„ ì €í•˜
- ë³µì¡í•œ ì½”ë“œ êµ¬ì¡°
- ì „ì²´ ë°ì´í„° ê¸°ë°˜ ì—°ì‚° ì–´ë ¤ì›€

---

## ğŸ”§ ê³ ì •í­ íŒŒì¼(FWF) ì²˜ë¦¬

### ê³ ì •í­ ë°ì´í„° ì½ê¸°

```python
# ê³ ì •í­ íŒŒì¼ ì½ê¸° ì˜ˆì‹œ
# ë°ì´í„° í˜•íƒœ: ì´ë¦„(10ì) + ë‚˜ì´(3ì) + ì ìˆ˜(5ì)
df = pd.read_fwf('fixed_width.txt',
                 widths=[10, 3, 5],  # ê° ì»¬ëŸ¼ì˜ í­
                 names=['name', 'age', 'score'],
                 encoding='utf-8')
print(df)
```

---

## ğŸ“Š ë‹¤ì–‘í•œ ì €ì¥ í˜•ì‹ ë¹„êµ

### í˜•ì‹ë³„ ì €ì¥ ì˜ˆì œ

```python
# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
sample_data = {
    'product': ['Mouse', 'Keyboard', 'Monitor'],
    'price': [25000, 45000, 250000],
    'stock': [15, 8, 3]
}
df = pd.DataFrame(sample_data)

# 1. CSV ì €ì¥ (êµ¬ë¶„ì ì˜µì…˜)
df.to_csv('data.csv', index=False, sep=',')
df.to_csv('data_tab.txt', index=False, sep='\t')  # íƒ­ êµ¬ë¶„

# 2. Excel ì €ì¥
df.to_excel('data.xlsx', index=False)

# 3. JSON ì €ì¥
df.to_json('data.json', orient='records', force_ascii=False)

# 4. ì „ì¹˜(Transpose) ì €ì¥
df_transposed = df.T  # í–‰ê³¼ ì—´ ë°”ê¾¸ê¸°
df_transposed.to_csv('data_transposed.csv')
```

### íŠ¸ëœìŠ¤í¬ì¦ˆ(Transpose) í™œìš©

```python
# ë°ì´í„° êµ¬ì¡° ë³€ê²½
items = {
    'apple': {'count': 10, 'price': 1500},
    'orange': {'count': 4, 'price': 700}
}
df = pd.DataFrame(items)
print("ì›ë³¸ ë°ì´í„°:")
print(df)

# í–‰ê³¼ ì—´ ë°”ê¾¸ê¸°
df_t = df.T
print("\nì „ì¹˜ëœ ë°ì´í„°:")
print(df_t)

# ì „ì¹˜ëœ ë°ì´í„° ì €ì¥
df_t.to_csv('transposed_data.csv')
```

---

## âš™ï¸ ì‹¤ë¬´ íŒ ë° ëª¨ë²” ì‚¬ë¡€

### 1. ì¸ì½”ë”© ë¬¸ì œ í•´ê²°

```python
# í•œê¸€ íŒŒì¼ ì²˜ë¦¬ ì‹œ ê¶Œì¥ ì„¤ì •
encodings_to_try = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr']

for encoding in encodings_to_try:
    try:
        df = pd.read_csv('korean_data.csv', encoding=encoding)
        print(f"ì„±ê³µ: {encoding}")
        break
    except UnicodeDecodeError:
        print(f"ì‹¤íŒ¨: {encoding}")
        continue
```

### 2. íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸

```python
import os

def safe_read_csv(filepath):
    if os.path.exists(filepath):
        return pd.read_csv(filepath)
    else:
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
        return None

# ì‚¬ìš© ì˜ˆì‹œ
df = safe_read_csv('data.csv')
if df is not None:
    print(df.head())
```

### 3. ë©”ëª¨ë¦¬ ìµœì í™” ë°ì´í„° íƒ€ì…

```python
# ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°ì´í„° íƒ€ì… ì§€ì •
efficient_dtypes = {
    'id': 'int32',      # int64 â†’ int32
    'category': 'category',  # object â†’ category
    'score': 'float32'  # float64 â†’ float32
}

df = pd.read_csv('data.csv', dtype=efficient_dtypes)
print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum()} bytes")
```

### 4. ë°°ì¹˜ íŒŒì¼ ì²˜ë¦¬

```python
import glob

# ì—¬ëŸ¬ CSV íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
csv_files = glob.glob("data_*.csv")
dataframes = []

for file in csv_files:
    df_temp = pd.read_csv(file)
    df_temp['source_file'] = file  # ì¶œì²˜ íŒŒì¼ëª… ì¶”ê°€
    dataframes.append(df_temp)

# ëª¨ë“  íŒŒì¼ ê²°í•©
combined_df = pd.concat(dataframes, ignore_index=True)
combined_df.to_csv('combined_data.csv', index=False)
```

---

## ğŸ¯ ì„±ëŠ¥ ë¹„êµ ë° ì„ íƒ ê°€ì´ë“œ

### íŒŒì¼ í˜•ì‹ë³„ ì„±ëŠ¥ íŠ¹ì„±

| í˜•ì‹ | ì½ê¸° ì†ë„ | íŒŒì¼ í¬ê¸° | í˜¸í™˜ì„± | ì‚¬ìš© ì‚¬ë¡€ |
|------|-----------|-----------|--------|-----------|
| CSV | ë¹ ë¦„ | ë³´í†µ | ë†’ìŒ | ë²”ìš© ë°ì´í„° êµí™˜ |
| Excel | ë³´í†µ | í¼ | ë³´í†µ | ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì„œ |
| JSON | ë³´í†µ | í¼ | ë†’ìŒ | ì›¹ API, ì„¤ì • íŒŒì¼ |
| Parquet | ë§¤ìš° ë¹ ë¦„ | ì‘ìŒ | ë‚®ìŒ | ë¹…ë°ì´í„° ë¶„ì„ |

### ìƒí™©ë³„ ê¶Œì¥ í˜•ì‹

```python
# ìƒí™©ë³„ ê¶Œì¥ íŒŒì¼ í˜•ì‹

# 1. ë²”ìš© ë°ì´í„° êµí™˜ â†’ CSV
df.to_csv('data.csv', index=False)

# 2. ë¹„ì¦ˆë‹ˆìŠ¤ ë³´ê³ ì„œ â†’ Excel
df.to_excel('report.xlsx', index=False)

# 3. ì›¹ API ë°ì´í„° â†’ JSON
df.to_json('api_data.json', orient='records')

# 4. ëŒ€ìš©ëŸ‰ ë¶„ì„ ë°ì´í„° â†’ Parquet (ë³„ë„ ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”)
# df.to_parquet('big_data.parquet')

# 5. ì›¹ í‘œì‹œìš© â†’ HTML
df.to_html('table.html', index=False, table_id='data-table')
```

---

## ğŸ“‹ ì¢…í•© ì‹¤ìŠµ ì˜ˆì œ

```python
def comprehensive_file_io_example():
    """
    íŒë‹¤ìŠ¤ íŒŒì¼ ì…ì¶œë ¥ ì¢…í•© ì˜ˆì œ
    """
    
    # 1. ë°ì´í„° ìƒì„±
    print("1. ìƒ˜í”Œ ë°ì´í„° ìƒì„±")
    data = {
        'product_id': range(1, 101),
        'product_name': [f'Product_{i}' for i in range(1, 101)],
        'price': np.random.randint(1000, 100000, 100),
        'category': np.random.choice(['A', 'B', 'C'], 100),
        'stock': np.random.randint(0, 50, 100)
    }
    df = pd.DataFrame(data)
    print(f"ë°ì´í„° í˜•íƒœ: {df.shape}")
    
    # 2. ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥
    print("\n2. ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥")
    
    # CSV (ê¸°ë³¸)
    df.to_csv('products.csv', index=False)
    
    # Excel (ë‹¤ì¤‘ ì‹œíŠ¸)
    with pd.ExcelWriter('products_multi.xlsx') as writer:
        df.to_excel(writer, sheet_name='ì „ì²´', index=False)
        df[df['category'] == 'A'].to_excel(writer, sheet_name='ì¹´í…Œê³ ë¦¬A', index=False)
        df[df['stock'] < 10].to_excel(writer, sheet_name='ì¬ê³ ë¶€ì¡±', index=False)
    
    # JSON (ë ˆì½”ë“œ í˜•íƒœ)
    df.to_json('products.json', orient='records', force_ascii=False)
    
    # 3. íŒŒì¼ ì½ê¸° ë° ê²€ì¦
    print("\n3. íŒŒì¼ ì½ê¸° ë° ê²€ì¦")
    
    df_csv = pd.read_csv('products.csv')
    df_excel = pd.read_excel('products_multi.xlsx', sheet_name='ì „ì²´')
    df_json = pd.read_json('products.json')
    
    # ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸
    print(f"CSV ì½ê¸°: {df_csv.shape}")
    print(f"Excel ì½ê¸°: {df_excel.shape}")
    print(f"JSON ì½ê¸°: {df_json.shape}")
    
    # 4. í†µê³„ ì •ë³´ ì¶œë ¥
    print("\n4. í†µê³„ ì •ë³´")
    print(df.groupby('category')['price'].agg(['mean', 'count', 'sum']))
    
    print("\níŒŒì¼ ì…ì¶œë ¥ ì˜ˆì œ ì™„ë£Œ!")

# ì‹¤í–‰
comprehensive_file_io_example()
```

---

## ğŸ” ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œì™€ í•´ê²°ì±…

#### 1. ì¸ì½”ë”© ì˜¤ë¥˜
```python
# ë¬¸ì œ: UnicodeDecodeError
# í•´ê²°: ì ì ˆí•œ ì¸ì½”ë”© ì§€ì •
df = pd.read_csv('data.csv', encoding='utf-8-sig')
```

#### 2. ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# ë¬¸ì œ: MemoryError
# í•´ê²°: ì²­í¬ ì²˜ë¦¬ ë˜ëŠ” ë°ì´í„° íƒ€ì… ìµœì í™”
for chunk in pd.read_csv('big_file.csv', chunksize=1000):
    process(chunk)
```

#### 3. ë‚ ì§œ í˜•ì‹ ë¬¸ì œ
```python
# ë¬¸ì œ: ë‚ ì§œ ì»¬ëŸ¼ì´ ë¬¸ìì—´ë¡œ ì½í˜
# í•´ê²°: parse_dates ì˜µì…˜ ì‚¬ìš©
df = pd.read_csv('data.csv', parse_dates=['date_column'])
```

#### 4. êµ¬ë¶„ì ë¬¸ì œ
```python
# ë¬¸ì œ: ë°ì´í„°ê°€ ì œëŒ€ë¡œ ë¶„ë¦¬ë˜ì§€ ì•ŠìŒ
# í•´ê²°: ì •í™•í•œ êµ¬ë¶„ì ì§€ì •
df = pd.read_csv('data.txt', sep='\t')  # íƒ­ êµ¬ë¶„
df = pd.read_csv('data.txt', sep=r'\s+')  # ê³µë°± êµ¬ë¶„
```

---

## ğŸ“š ì¶”ì²œ í•™ìŠµ ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Pandas I/O Tools](https://pandas.pydata.org/docs/user_guide/io.html)
- [CSV íŒŒì¼ ì²˜ë¦¬ ê°€ì´ë“œ](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)

### ì‹¤ë¬´ í™œìš©
- ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ í™œìš©
- í•œê¸€ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì¸ì½”ë”© ì£¼ì˜
- ì›¹ ìŠ¤í¬ë˜í•‘ ì‹œ HTML í…Œì´ë¸” ì½ê¸° ê¸°ëŠ¥ í™œìš©
- API ë°ì´í„° ì²˜ë¦¬ ì‹œ JSON í˜•ì‹ í™œìš©

---

## ğŸ¯ í•µì‹¬ ìš”ì•½

### ë°˜ë“œì‹œ ê¸°ì–µí•  í¬ì¸íŠ¸

1. **íŒŒì¼ í˜•ì‹ë³„ íŠ¹ì§• ì´í•´**
   - CSV: ë²”ìš©ì„±, ê°€ë²¼ì›€
   - Excel: ë¹„ì¦ˆë‹ˆìŠ¤ ì¹œí™”ì , ë‹¤ì¤‘ ì‹œíŠ¸
   - JSON: ì›¹ ì¹œí™”ì , êµ¬ì¡°ì 

2. **ì¸ì½”ë”© ì²˜ë¦¬**
   - í•œê¸€ íŒŒì¼: `encoding='utf-8-sig'` ë˜ëŠ” `encoding='cp949'`
   - ì›¹ ë°ì´í„°: `encoding='utf-8'`

3. **ë©”ëª¨ë¦¬ ê´€ë¦¬**
   - ëŒ€ìš©ëŸ‰ íŒŒì¼: ì²­í¬ ì²˜ë¦¬ í™œìš©
   - ë°ì´í„° íƒ€ì… ìµœì í™”ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½

4. **ì‹¤ë¬´ í™œìš© íŒ¨í„´**
   - íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
   - ì˜ˆì™¸ ì²˜ë¦¬ êµ¬í˜„
   - ë°°ì¹˜ ì²˜ë¦¬ ìë™í™”

íŒë‹¤ìŠ¤ì˜ íŒŒì¼ I/O ê¸°ëŠ¥ì„ ë§ˆìŠ¤í„°í•˜ë©´ ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ì˜ ì—°ë™ì´ ê°€ëŠ¥í•´ì§€ë©°, ì‹¤ë¬´ì—ì„œì˜ ë°ì´í„° ì²˜ë¦¬ íš¨ìœ¨ì„±ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤! ğŸ’ª: 'ìƒí’ˆì½”ë“œ ê²€ì¦ (AB123, ABC1234)',
    r'^\w{8,20}

---

## ğŸ“Š Excel íŒŒì¼ ì²˜ë¦¬

### ê¸°ë³¸ Excel ì½ê¸° ë° ì €ì¥

```python
# Excel íŒŒì¼ ì½ê¸°
df = pd.read_excel('data.xlsx')  # ì²« ë²ˆì§¸ ì‹œíŠ¸
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')  # íŠ¹ì • ì‹œíŠ¸

# Excel íŒŒì¼ ì €ì¥
df.to_excel('output.xlsx', index=False)
```

### ë‹¤ì¤‘ ì‹œíŠ¸ ì²˜ë¦¬

```python
# ì—¬ëŸ¬ ì‹œíŠ¸ ë™ì‹œ ì½ê¸°
excel_dict = pd.read_excel('data.xlsx', sheet_name=None)  # ëª¨ë“  ì‹œíŠ¸
print(excel_dict.keys())  # ì‹œíŠ¸ ì´ë¦„ë“¤

# íŠ¹ì • ì‹œíŠ¸ë“¤ë§Œ ì½ê¸°
sheets_dict = pd.read_excel('data.xlsx', sheet_name=['Sheet1', 'Sheet2'])

# ì—¬ëŸ¬ ì‹œíŠ¸ë¡œ ì €ì¥
with pd.ExcelWriter('multi_sheet.xlsx') as writer:
    df1.to_excel(writer, sheet_name='ë°ì´í„°1', index=False)
    df2.to_excel(writer, sheet_name='ë°ì´í„°2', index=False)
```

### ì‹¤ë¬´ ì˜ˆì œ: ì œí’ˆ ë°ì´í„° Excel ì²˜ë¦¬

```python
# ì œí’ˆ ë°ì´í„° ìƒì„±
product_data = {
    'name': ['Mouse', 'Keyboard', 'Monitor'],
    'price': [25000, 45000, 250000],
    'stock': [15, 8, 3]
}
df = pd.DataFrame(product_data)

# Excelë¡œ ì €ì¥ (ë‹¤ì–‘í•œ ì˜µì…˜)
df.to_excel('products.xlsx', 
           index=False,           # ì¸ë±ìŠ¤ ì œì™¸
           sheet_name='ì œí’ˆëª©ë¡',  # ì‹œíŠ¸ëª… ì§€ì •
           encoding='utf-8')      # ì¸ì½”ë”© ì§€ì •

# Excelì—ì„œ ì½ê¸°
df_read = pd.read_excel('products.xlsx', sheet_name='ì œí’ˆëª©ë¡')
print(df_read)
```

---

## ğŸŒ JSON íŒŒì¼ ì²˜ë¦¬

### JSON ê¸°ë³¸ ì²˜ë¦¬

```python
# JSON íŒŒì¼ë¡œ ì €ì¥
df.to_json('data.json')
df.to_json('data.json', orient='records')  # ë ˆì½”ë“œ í˜•íƒœ
df.to_json('data.json', orient='index')    # ì¸ë±ìŠ¤ ê¸°ë°˜

# JSON íŒŒì¼ ì½ê¸°
df = pd.read_json('data.json')

# ë¬¸ìì—´ JSON ì²˜ë¦¬
json_string = df.to_json(orient='records')
df_from_json = pd.read_json(json_string)
```

### JSON í˜•íƒœë³„ ì €ì¥ ë°©ì‹

```python
import pandas as pd

# ìƒ˜í”Œ ë°ì´í„°
data = {'apple': {'count': 10, 'price': 1500},
        'orange': {'count': 4, 'price': 700}}
df = pd.DataFrame(data)

print("1. ê¸°ë³¸ í˜•íƒœ:")
print(df.to_json())

print("\n2. ë ˆì½”ë“œ í˜•íƒœ (ì›¹ APIì— ì í•©):")
print(df.to_json(orient='records'))

print("\n3. ì¸ë±ìŠ¤ í˜•íƒœ:")
print(df.to_json(orient='index'))

print("\n4. ê°’ë§Œ ì €ì¥:")
print(df.to_json(orient='values'))
```

---

## ğŸŒ HTML ë° ì›¹ ë°ì´í„° ì²˜ë¦¬

### ì›¹ í…Œì´ë¸” ì½ê¸°

```python
# ì›¹ í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ì½ê¸°
url = "https://ko.wikipedia.org/wiki/ë¦¬ëˆ…ìŠ¤"
tables = pd.read_html(url, encoding='utf-8')
print(f"ì´ {len(tables)}ê°œì˜ í…Œì´ë¸” ë°œê²¬")

# ì²« ë²ˆì§¸ í…Œì´ë¸” í™•ì¸
if tables:
    first_table = tables[0]
    print(first_table.head())
```

### HTMLë¡œ ì €ì¥

```python
# HTML í˜•íƒœë¡œ ì €ì¥
html_string = df.to_html()
print(html_string)

# íŒŒì¼ë¡œ ì €ì¥
df.to_html('table.html', index=False)
```

---

## ğŸ“‹ í´ë¦½ë³´ë“œ í™œìš©

### í´ë¦½ë³´ë“œì™€ ë°ì´í„° êµí™˜

```python
# í´ë¦½ë³´ë“œë¡œ ë³µì‚¬ (Excelì—ì„œ ë°”ë¡œ ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥)
df.to_clipboard(index=False)
print("ë°ì´í„°ê°€ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

# í´ë¦½ë³´ë“œì—ì„œ ì½ê¸° (Excelì—ì„œ ë³µì‚¬í•œ ë°ì´í„°)
# df_from_clipboard = pd.read_clipboard()
```

---

## ğŸ”„ ëŒ€ìš©ëŸ‰ ë°ì´í„°: ì²­í¬(Chunk) ì²˜ë¦¬

### ì²­í¬ ì²˜ë¦¬ ê¸°ë³¸

```python
# ëŒ€ìš©ëŸ‰ CSV íŒŒì¼ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
chunk_size = 1000
chunks = []

# ì²­í¬ ë‹¨ìœ„ë¡œ ì½ì–´ì„œ ì²˜ë¦¬
for chunk in pd.read_csv('large_file.csv', chunksize=chunk_size):
    # ê° ì²­í¬ì— ëŒ€í•œ ì²˜ë¦¬
    processed_chunk = chunk[chunk['score'] > 80]  # ì˜ˆì‹œ í•„í„°ë§
    chunks.append(processed_chunk)

# ëª¨ë“  ì²­í¬ ê²°í•©
final_df = pd.concat(chunks, ignore_index=True)
```

### ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì²˜ë¦¬

```python
import time

# ì¼ë°˜ì ì¸ ë°©ë²• vs ì²­í¬ ì²˜ë¦¬ ì„±ëŠ¥ ë¹„êµ
def process_normal(filepath):
    start = time.time()
    df = pd.read_csv(filepath)
    result = df.groupby('category').mean()
    end = time.time()
    return result, end - start

def process_chunks(filepath, chunk_size=1000):
    start = time.time()
    results = []
    
    for chunk in pd.read_csv(filepath, chunksize=chunk_size):
        chunk_result = chunk.groupby('category').mean()
        results.append(chunk_result)
    
    final_result = pd.concat(results).groupby(level=0).mean()
    end = time.time()
    return final_result, end - start
```

**ğŸ’¡ ì²­í¬ ì²˜ë¦¬ì˜ ì¥ë‹¨ì **

**ì¥ì :**
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì ˆì•½
- ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ê°€ëŠ¥
- ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ì²˜ë¦¬

**ë‹¨ì :**
- ì²˜ë¦¬ ì†ë„ ì•½ê°„ ì €í•˜
- ë³µì¡í•œ ì½”ë“œ êµ¬ì¡°
- ì „ì²´ ë°ì´í„° ê¸°ë°˜ ì—°ì‚° ì–´ë ¤ì›€

---

## ğŸ”§ ê³ ì •í­ íŒŒì¼(FWF) ì²˜ë¦¬

### ê³ ì •í­ ë°ì´í„° ì½ê¸°

```python
# ê³ ì •í­ íŒŒì¼ ì½ê¸° ì˜ˆì‹œ
# ë°ì´í„° í˜•íƒœ: ì´ë¦„(10ì) + ë‚˜ì´(3ì) + ì ìˆ˜(5ì)
df = pd.read_fwf('fixed_width.txt',
                 widths=[10, 3, 5],  # ê° ì»¬ëŸ¼ì˜ í­
                 names=['name', 'age', 'score'],
                 encoding='utf-8')
print(df)
```

---

## ğŸ“Š ë‹¤ì–‘í•œ ì €ì¥ í˜•ì‹ ë¹„êµ

### í˜•ì‹ë³„ ì €ì¥ ì˜ˆì œ

```python
# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
sample_data = {
    'product': ['Mouse', 'Keyboard', 'Monitor'],
    'price': [25000, 45000, 250000],
    'stock': [15, 8, 3]
}
df = pd.DataFrame(sample_data)

# 1. CSV ì €ì¥ (êµ¬ë¶„ì ì˜µì…˜)
df.to_csv('data.csv', index=False, sep=',')
df.to_csv('data_tab.txt', index=False, sep='\t')  # íƒ­ êµ¬ë¶„

# 2. Excel ì €ì¥
df.to_excel('data.xlsx', index=False)

# 3. JSON ì €ì¥
df.to_json('data.json', orient='records', force_ascii=False)

# 4. ì „ì¹˜(Transpose) ì €ì¥
df_transposed = df.T  # í–‰ê³¼ ì—´ ë°”ê¾¸ê¸°
df_transposed.to_csv('data_transposed.csv')
```

### íŠ¸ëœìŠ¤í¬ì¦ˆ(Transpose) í™œìš©

```python
# ë°ì´í„° êµ¬ì¡° ë³€ê²½
items = {
    'apple': {'count': 10, 'price': 1500},
    'orange': {'count': 4, 'price': 700}
}
df = pd.DataFrame(items)
print("ì›ë³¸ ë°ì´í„°:")
print(df)

# í–‰ê³¼ ì—´ ë°”ê¾¸ê¸°
df_t = df.T
print("\nì „ì¹˜ëœ ë°ì´í„°:")
print(df_t)

# ì „ì¹˜ëœ ë°ì´í„° ì €ì¥
df_t.to_csv('transposed_data.csv')
```

---

## âš™ï¸ ì‹¤ë¬´ íŒ ë° ëª¨ë²” ì‚¬ë¡€

### 1. ì¸ì½”ë”© ë¬¸ì œ í•´ê²°

```python
# í•œê¸€ íŒŒì¼ ì²˜ë¦¬ ì‹œ ê¶Œì¥ ì„¤ì •
encodings_to_try = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr']

for encoding in encodings_to_try:
    try:
        df = pd.read_csv('korean_data.csv', encoding=encoding)
        print(f"ì„±ê³µ: {encoding}")
        break
    except UnicodeDecodeError:
        print(f"ì‹¤íŒ¨: {encoding}")
        continue
```

### 2. íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸

```python
import os

def safe_read_csv(filepath):
    if os.path.exists(filepath):
        return pd.read_csv(filepath)
    else:
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
        return None

# ì‚¬ìš© ì˜ˆì‹œ
df = safe_read_csv('data.csv')
if df is not None:
    print(df.head())
```

### 3. ë©”ëª¨ë¦¬ ìµœì í™” ë°ì´í„° íƒ€ì…

```python
# ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°ì´í„° íƒ€ì… ì§€ì •
efficient_dtypes = {
    'id': 'int32',      # int64 â†’ int32
    'category': 'category',  # object â†’ category
    'score': 'float32'  # float64 â†’ float32
}

df = pd.read_csv('data.csv', dtype=efficient_dtypes)
print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum()} bytes")
```

### 4. ë°°ì¹˜ íŒŒì¼ ì²˜ë¦¬

```python
import glob

# ì—¬ëŸ¬ CSV íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
csv_files = glob.glob("data_*.csv")
dataframes = []

for file in csv_files:
    df_temp = pd.read_csv(file)
    df_temp['source_file'] = file  # ì¶œì²˜ íŒŒì¼ëª… ì¶”ê°€
    dataframes.append(df_temp)

# ëª¨ë“  íŒŒì¼ ê²°í•©
combined_df = pd.concat(dataframes, ignore_index=True)
combined_df.to_csv('combined_data.csv', index=False)
```

---

## ğŸ¯ ì„±ëŠ¥ ë¹„êµ ë° ì„ íƒ ê°€ì´ë“œ

### íŒŒì¼ í˜•ì‹ë³„ ì„±ëŠ¥ íŠ¹ì„±

| í˜•ì‹ | ì½ê¸° ì†ë„ | íŒŒì¼ í¬ê¸° | í˜¸í™˜ì„± | ì‚¬ìš© ì‚¬ë¡€ |
|------|-----------|-----------|--------|-----------|
| CSV | ë¹ ë¦„ | ë³´í†µ | ë†’ìŒ | ë²”ìš© ë°ì´í„° êµí™˜ |
| Excel | ë³´í†µ | í¼ | ë³´í†µ | ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì„œ |
| JSON | ë³´í†µ | í¼ | ë†’ìŒ | ì›¹ API, ì„¤ì • íŒŒì¼ |
| Parquet | ë§¤ìš° ë¹ ë¦„ | ì‘ìŒ | ë‚®ìŒ | ë¹…ë°ì´í„° ë¶„ì„ |

### ìƒí™©ë³„ ê¶Œì¥ í˜•ì‹

```python
# ìƒí™©ë³„ ê¶Œì¥ íŒŒì¼ í˜•ì‹

# 1. ë²”ìš© ë°ì´í„° êµí™˜ â†’ CSV
df.to_csv('data.csv', index=False)

# 2. ë¹„ì¦ˆë‹ˆìŠ¤ ë³´ê³ ì„œ â†’ Excel
df.to_excel('report.xlsx', index=False)

# 3. ì›¹ API ë°ì´í„° â†’ JSON
df.to_json('api_data.json', orient='records')

# 4. ëŒ€ìš©ëŸ‰ ë¶„ì„ ë°ì´í„° â†’ Parquet (ë³„ë„ ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”)
# df.to_parquet('big_data.parquet')

# 5. ì›¹ í‘œì‹œìš© â†’ HTML
df.to_html('table.html', index=False, table_id='data-table')
```

---

## ğŸ“‹ ì¢…í•© ì‹¤ìŠµ ì˜ˆì œ

```python
def comprehensive_file_io_example():
    """
    íŒë‹¤ìŠ¤ íŒŒì¼ ì…ì¶œë ¥ ì¢…í•© ì˜ˆì œ
    """
    
    # 1. ë°ì´í„° ìƒì„±
    print("1. ìƒ˜í”Œ ë°ì´í„° ìƒì„±")
    data = {
        'product_id': range(1, 101),
        'product_name': [f'Product_{i}' for i in range(1, 101)],
        'price': np.random.randint(1000, 100000, 100),
        'category': np.random.choice(['A', 'B', 'C'], 100),
        'stock': np.random.randint(0, 50, 100)
    }
    df = pd.DataFrame(data)
    print(f"ë°ì´í„° í˜•íƒœ: {df.shape}")
    
    # 2. ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥
    print("\n2. ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥")
    
    # CSV (ê¸°ë³¸)
    df.to_csv('products.csv', index=False)
    
    # Excel (ë‹¤ì¤‘ ì‹œíŠ¸)
    with pd.ExcelWriter('products_multi.xlsx') as writer:
        df.to_excel(writer, sheet_name='ì „ì²´', index=False)
        df[df['category'] == 'A'].to_excel(writer, sheet_name='ì¹´í…Œê³ ë¦¬A', index=False)
        df[df['stock'] < 10].to_excel(writer, sheet_name='ì¬ê³ ë¶€ì¡±', index=False)
    
    # JSON (ë ˆì½”ë“œ í˜•íƒœ)
    df.to_json('products.json', orient='records', force_ascii=False)
    
    # 3. íŒŒì¼ ì½ê¸° ë° ê²€ì¦
    print("\n3. íŒŒì¼ ì½ê¸° ë° ê²€ì¦")
    
    df_csv = pd.read_csv('products.csv')
    df_excel = pd.read_excel('products_multi.xlsx', sheet_name='ì „ì²´')
    df_json = pd.read_json('products.json')
    
    # ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸
    print(f"CSV ì½ê¸°: {df_csv.shape}")
    print(f"Excel ì½ê¸°: {df_excel.shape}")
    print(f"JSON ì½ê¸°: {df_json.shape}")
    
    # 4. í†µê³„ ì •ë³´ ì¶œë ¥
    print("\n4. í†µê³„ ì •ë³´")
    print(df.groupby('category')['price'].agg(['mean', 'count', 'sum']))
    
    print("\níŒŒì¼ ì…ì¶œë ¥ ì˜ˆì œ ì™„ë£Œ!")

# ì‹¤í–‰
comprehensive_file_io_example()
```

---

## ğŸ” ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œì™€ í•´ê²°ì±…

#### 1. ì¸ì½”ë”© ì˜¤ë¥˜
```python
# ë¬¸ì œ: UnicodeDecodeError
# í•´ê²°: ì ì ˆí•œ ì¸ì½”ë”© ì§€ì •
df = pd.read_csv('data.csv', encoding='utf-8-sig')
```

#### 2. ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# ë¬¸ì œ: MemoryError
# í•´ê²°: ì²­í¬ ì²˜ë¦¬ ë˜ëŠ” ë°ì´í„° íƒ€ì… ìµœì í™”
for chunk in pd.read_csv('big_file.csv', chunksize=1000):
    process(chunk)
```

#### 3. ë‚ ì§œ í˜•ì‹ ë¬¸ì œ
```python
# ë¬¸ì œ: ë‚ ì§œ ì»¬ëŸ¼ì´ ë¬¸ìì—´ë¡œ ì½í˜
# í•´ê²°: parse_dates ì˜µì…˜ ì‚¬ìš©
df = pd.read_csv('data.csv', parse_dates=['date_column'])
```

#### 4. êµ¬ë¶„ì ë¬¸ì œ
```python
# ë¬¸ì œ: ë°ì´í„°ê°€ ì œëŒ€ë¡œ ë¶„ë¦¬ë˜ì§€ ì•ŠìŒ
# í•´ê²°: ì •í™•í•œ êµ¬ë¶„ì ì§€ì •
df = pd.read_csv('data.txt', sep='\t')  # íƒ­ êµ¬ë¶„
df = pd.read_csv('data.txt', sep=r'\s+')  # ê³µë°± êµ¬ë¶„
```

---

## ğŸ“š ì¶”ì²œ í•™ìŠµ ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Pandas I/O Tools](https://pandas.pydata.org/docs/user_guide/io.html)
- [CSV íŒŒì¼ ì²˜ë¦¬ ê°€ì´ë“œ](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)

### ì‹¤ë¬´ í™œìš©
- ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ í™œìš©
- í•œê¸€ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì¸ì½”ë”© ì£¼ì˜
- ì›¹ ìŠ¤í¬ë˜í•‘ ì‹œ HTML í…Œì´ë¸” ì½ê¸° ê¸°ëŠ¥ í™œìš©
- API ë°ì´í„° ì²˜ë¦¬ ì‹œ JSON í˜•ì‹ í™œìš©

---

## ğŸ¯ í•µì‹¬ ìš”ì•½

### ë°˜ë“œì‹œ ê¸°ì–µí•  í¬ì¸íŠ¸

1. **íŒŒì¼ í˜•ì‹ë³„ íŠ¹ì§• ì´í•´**
   - CSV: ë²”ìš©ì„±, ê°€ë²¼ì›€
   - Excel: ë¹„ì¦ˆë‹ˆìŠ¤ ì¹œí™”ì , ë‹¤ì¤‘ ì‹œíŠ¸
   - JSON: ì›¹ ì¹œí™”ì , êµ¬ì¡°ì 

2. **ì¸ì½”ë”© ì²˜ë¦¬**
   - í•œê¸€ íŒŒì¼: `encoding='utf-8-sig'` ë˜ëŠ” `encoding='cp949'`
   - ì›¹ ë°ì´í„°: `encoding='utf-8'`

3. **ë©”ëª¨ë¦¬ ê´€ë¦¬**
   - ëŒ€ìš©ëŸ‰ íŒŒì¼: ì²­í¬ ì²˜ë¦¬ í™œìš©
   - ë°ì´í„° íƒ€ì… ìµœì í™”ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½

4. **ì‹¤ë¬´ í™œìš© íŒ¨í„´**
   - íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
   - ì˜ˆì™¸ ì²˜ë¦¬ êµ¬í˜„
   - ë°°ì¹˜ ì²˜ë¦¬ ìë™í™”

íŒë‹¤ìŠ¤ì˜ íŒŒì¼ I/O ê¸°ëŠ¥ì„ ë§ˆìŠ¤í„°í•˜ë©´ ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ì˜ ì—°ë™ì´ ê°€ëŠ¥í•´ì§€ë©°, ì‹¤ë¬´ì—ì„œì˜ ë°ì´í„° ì²˜ë¦¬ íš¨ìœ¨ì„±ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤! ğŸ’ª: 'ì‚¬ìš©ìëª… ê²€ì¦ (8-20ì)',
    r'^\d{2,3}-\d{3,4}-\d{4}

---

## ğŸ“Š Excel íŒŒì¼ ì²˜ë¦¬

### ê¸°ë³¸ Excel ì½ê¸° ë° ì €ì¥

```python
# Excel íŒŒì¼ ì½ê¸°
df = pd.read_excel('data.xlsx')  # ì²« ë²ˆì§¸ ì‹œíŠ¸
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')  # íŠ¹ì • ì‹œíŠ¸

# Excel íŒŒì¼ ì €ì¥
df.to_excel('output.xlsx', index=False)
```

### ë‹¤ì¤‘ ì‹œíŠ¸ ì²˜ë¦¬

```python
# ì—¬ëŸ¬ ì‹œíŠ¸ ë™ì‹œ ì½ê¸°
excel_dict = pd.read_excel('data.xlsx', sheet_name=None)  # ëª¨ë“  ì‹œíŠ¸
print(excel_dict.keys())  # ì‹œíŠ¸ ì´ë¦„ë“¤

# íŠ¹ì • ì‹œíŠ¸ë“¤ë§Œ ì½ê¸°
sheets_dict = pd.read_excel('data.xlsx', sheet_name=['Sheet1', 'Sheet2'])

# ì—¬ëŸ¬ ì‹œíŠ¸ë¡œ ì €ì¥
with pd.ExcelWriter('multi_sheet.xlsx') as writer:
    df1.to_excel(writer, sheet_name='ë°ì´í„°1', index=False)
    df2.to_excel(writer, sheet_name='ë°ì´í„°2', index=False)
```

### ì‹¤ë¬´ ì˜ˆì œ: ì œí’ˆ ë°ì´í„° Excel ì²˜ë¦¬

```python
# ì œí’ˆ ë°ì´í„° ìƒì„±
product_data = {
    'name': ['Mouse', 'Keyboard', 'Monitor'],
    'price': [25000, 45000, 250000],
    'stock': [15, 8, 3]
}
df = pd.DataFrame(product_data)

# Excelë¡œ ì €ì¥ (ë‹¤ì–‘í•œ ì˜µì…˜)
df.to_excel('products.xlsx', 
           index=False,           # ì¸ë±ìŠ¤ ì œì™¸
           sheet_name='ì œí’ˆëª©ë¡',  # ì‹œíŠ¸ëª… ì§€ì •
           encoding='utf-8')      # ì¸ì½”ë”© ì§€ì •

# Excelì—ì„œ ì½ê¸°
df_read = pd.read_excel('products.xlsx', sheet_name='ì œí’ˆëª©ë¡')
print(df_read)
```

---

## ğŸŒ JSON íŒŒì¼ ì²˜ë¦¬

### JSON ê¸°ë³¸ ì²˜ë¦¬

```python
# JSON íŒŒì¼ë¡œ ì €ì¥
df.to_json('data.json')
df.to_json('data.json', orient='records')  # ë ˆì½”ë“œ í˜•íƒœ
df.to_json('data.json', orient='index')    # ì¸ë±ìŠ¤ ê¸°ë°˜

# JSON íŒŒì¼ ì½ê¸°
df = pd.read_json('data.json')

# ë¬¸ìì—´ JSON ì²˜ë¦¬
json_string = df.to_json(orient='records')
df_from_json = pd.read_json(json_string)
```

### JSON í˜•íƒœë³„ ì €ì¥ ë°©ì‹

```python
import pandas as pd

# ìƒ˜í”Œ ë°ì´í„°
data = {'apple': {'count': 10, 'price': 1500},
        'orange': {'count': 4, 'price': 700}}
df = pd.DataFrame(data)

print("1. ê¸°ë³¸ í˜•íƒœ:")
print(df.to_json())

print("\n2. ë ˆì½”ë“œ í˜•íƒœ (ì›¹ APIì— ì í•©):")
print(df.to_json(orient='records'))

print("\n3. ì¸ë±ìŠ¤ í˜•íƒœ:")
print(df.to_json(orient='index'))

print("\n4. ê°’ë§Œ ì €ì¥:")
print(df.to_json(orient='values'))
```

---

## ğŸŒ HTML ë° ì›¹ ë°ì´í„° ì²˜ë¦¬

### ì›¹ í…Œì´ë¸” ì½ê¸°

```python
# ì›¹ í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ì½ê¸°
url = "https://ko.wikipedia.org/wiki/ë¦¬ëˆ…ìŠ¤"
tables = pd.read_html(url, encoding='utf-8')
print(f"ì´ {len(tables)}ê°œì˜ í…Œì´ë¸” ë°œê²¬")

# ì²« ë²ˆì§¸ í…Œì´ë¸” í™•ì¸
if tables:
    first_table = tables[0]
    print(first_table.head())
```

### HTMLë¡œ ì €ì¥

```python
# HTML í˜•íƒœë¡œ ì €ì¥
html_string = df.to_html()
print(html_string)

# íŒŒì¼ë¡œ ì €ì¥
df.to_html('table.html', index=False)
```

---

## ğŸ“‹ í´ë¦½ë³´ë“œ í™œìš©

### í´ë¦½ë³´ë“œì™€ ë°ì´í„° êµí™˜

```python
# í´ë¦½ë³´ë“œë¡œ ë³µì‚¬ (Excelì—ì„œ ë°”ë¡œ ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥)
df.to_clipboard(index=False)
print("ë°ì´í„°ê°€ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

# í´ë¦½ë³´ë“œì—ì„œ ì½ê¸° (Excelì—ì„œ ë³µì‚¬í•œ ë°ì´í„°)
# df_from_clipboard = pd.read_clipboard()
```

---

## ğŸ”„ ëŒ€ìš©ëŸ‰ ë°ì´í„°: ì²­í¬(Chunk) ì²˜ë¦¬

### ì²­í¬ ì²˜ë¦¬ ê¸°ë³¸

```python
# ëŒ€ìš©ëŸ‰ CSV íŒŒì¼ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
chunk_size = 1000
chunks = []

# ì²­í¬ ë‹¨ìœ„ë¡œ ì½ì–´ì„œ ì²˜ë¦¬
for chunk in pd.read_csv('large_file.csv', chunksize=chunk_size):
    # ê° ì²­í¬ì— ëŒ€í•œ ì²˜ë¦¬
    processed_chunk = chunk[chunk['score'] > 80]  # ì˜ˆì‹œ í•„í„°ë§
    chunks.append(processed_chunk)

# ëª¨ë“  ì²­í¬ ê²°í•©
final_df = pd.concat(chunks, ignore_index=True)
```

### ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì²˜ë¦¬

```python
import time

# ì¼ë°˜ì ì¸ ë°©ë²• vs ì²­í¬ ì²˜ë¦¬ ì„±ëŠ¥ ë¹„êµ
def process_normal(filepath):
    start = time.time()
    df = pd.read_csv(filepath)
    result = df.groupby('category').mean()
    end = time.time()
    return result, end - start

def process_chunks(filepath, chunk_size=1000):
    start = time.time()
    results = []
    
    for chunk in pd.read_csv(filepath, chunksize=chunk_size):
        chunk_result = chunk.groupby('category').mean()
        results.append(chunk_result)
    
    final_result = pd.concat(results).groupby(level=0).mean()
    end = time.time()
    return final_result, end - start
```

**ğŸ’¡ ì²­í¬ ì²˜ë¦¬ì˜ ì¥ë‹¨ì **

**ì¥ì :**
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì ˆì•½
- ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ê°€ëŠ¥
- ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ì²˜ë¦¬

**ë‹¨ì :**
- ì²˜ë¦¬ ì†ë„ ì•½ê°„ ì €í•˜
- ë³µì¡í•œ ì½”ë“œ êµ¬ì¡°
- ì „ì²´ ë°ì´í„° ê¸°ë°˜ ì—°ì‚° ì–´ë ¤ì›€

---

## ğŸ”§ ê³ ì •í­ íŒŒì¼(FWF) ì²˜ë¦¬

### ê³ ì •í­ ë°ì´í„° ì½ê¸°

```python
# ê³ ì •í­ íŒŒì¼ ì½ê¸° ì˜ˆì‹œ
# ë°ì´í„° í˜•íƒœ: ì´ë¦„(10ì) + ë‚˜ì´(3ì) + ì ìˆ˜(5ì)
df = pd.read_fwf('fixed_width.txt',
                 widths=[10, 3, 5],  # ê° ì»¬ëŸ¼ì˜ í­
                 names=['name', 'age', 'score'],
                 encoding='utf-8')
print(df)
```

---

## ğŸ“Š ë‹¤ì–‘í•œ ì €ì¥ í˜•ì‹ ë¹„êµ

### í˜•ì‹ë³„ ì €ì¥ ì˜ˆì œ

```python
# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
sample_data = {
    'product': ['Mouse', 'Keyboard', 'Monitor'],
    'price': [25000, 45000, 250000],
    'stock': [15, 8, 3]
}
df = pd.DataFrame(sample_data)

# 1. CSV ì €ì¥ (êµ¬ë¶„ì ì˜µì…˜)
df.to_csv('data.csv', index=False, sep=',')
df.to_csv('data_tab.txt', index=False, sep='\t')  # íƒ­ êµ¬ë¶„

# 2. Excel ì €ì¥
df.to_excel('data.xlsx', index=False)

# 3. JSON ì €ì¥
df.to_json('data.json', orient='records', force_ascii=False)

# 4. ì „ì¹˜(Transpose) ì €ì¥
df_transposed = df.T  # í–‰ê³¼ ì—´ ë°”ê¾¸ê¸°
df_transposed.to_csv('data_transposed.csv')
```

### íŠ¸ëœìŠ¤í¬ì¦ˆ(Transpose) í™œìš©

```python
# ë°ì´í„° êµ¬ì¡° ë³€ê²½
items = {
    'apple': {'count': 10, 'price': 1500},
    'orange': {'count': 4, 'price': 700}
}
df = pd.DataFrame(items)
print("ì›ë³¸ ë°ì´í„°:")
print(df)

# í–‰ê³¼ ì—´ ë°”ê¾¸ê¸°
df_t = df.T
print("\nì „ì¹˜ëœ ë°ì´í„°:")
print(df_t)

# ì „ì¹˜ëœ ë°ì´í„° ì €ì¥
df_t.to_csv('transposed_data.csv')
```

---

## âš™ï¸ ì‹¤ë¬´ íŒ ë° ëª¨ë²” ì‚¬ë¡€

### 1. ì¸ì½”ë”© ë¬¸ì œ í•´ê²°

```python
# í•œê¸€ íŒŒì¼ ì²˜ë¦¬ ì‹œ ê¶Œì¥ ì„¤ì •
encodings_to_try = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr']

for encoding in encodings_to_try:
    try:
        df = pd.read_csv('korean_data.csv', encoding=encoding)
        print(f"ì„±ê³µ: {encoding}")
        break
    except UnicodeDecodeError:
        print(f"ì‹¤íŒ¨: {encoding}")
        continue
```

### 2. íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸

```python
import os

def safe_read_csv(filepath):
    if os.path.exists(filepath):
        return pd.read_csv(filepath)
    else:
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
        return None

# ì‚¬ìš© ì˜ˆì‹œ
df = safe_read_csv('data.csv')
if df is not None:
    print(df.head())
```

### 3. ë©”ëª¨ë¦¬ ìµœì í™” ë°ì´í„° íƒ€ì…

```python
# ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°ì´í„° íƒ€ì… ì§€ì •
efficient_dtypes = {
    'id': 'int32',      # int64 â†’ int32
    'category': 'category',  # object â†’ category
    'score': 'float32'  # float64 â†’ float32
}

df = pd.read_csv('data.csv', dtype=efficient_dtypes)
print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum()} bytes")
```

### 4. ë°°ì¹˜ íŒŒì¼ ì²˜ë¦¬

```python
import glob

# ì—¬ëŸ¬ CSV íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
csv_files = glob.glob("data_*.csv")
dataframes = []

for file in csv_files:
    df_temp = pd.read_csv(file)
    df_temp['source_file'] = file  # ì¶œì²˜ íŒŒì¼ëª… ì¶”ê°€
    dataframes.append(df_temp)

# ëª¨ë“  íŒŒì¼ ê²°í•©
combined_df = pd.concat(dataframes, ignore_index=True)
combined_df.to_csv('combined_data.csv', index=False)
```

---

## ğŸ¯ ì„±ëŠ¥ ë¹„êµ ë° ì„ íƒ ê°€ì´ë“œ

### íŒŒì¼ í˜•ì‹ë³„ ì„±ëŠ¥ íŠ¹ì„±

| í˜•ì‹ | ì½ê¸° ì†ë„ | íŒŒì¼ í¬ê¸° | í˜¸í™˜ì„± | ì‚¬ìš© ì‚¬ë¡€ |
|------|-----------|-----------|--------|-----------|
| CSV | ë¹ ë¦„ | ë³´í†µ | ë†’ìŒ | ë²”ìš© ë°ì´í„° êµí™˜ |
| Excel | ë³´í†µ | í¼ | ë³´í†µ | ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì„œ |
| JSON | ë³´í†µ | í¼ | ë†’ìŒ | ì›¹ API, ì„¤ì • íŒŒì¼ |
| Parquet | ë§¤ìš° ë¹ ë¦„ | ì‘ìŒ | ë‚®ìŒ | ë¹…ë°ì´í„° ë¶„ì„ |

### ìƒí™©ë³„ ê¶Œì¥ í˜•ì‹

```python
# ìƒí™©ë³„ ê¶Œì¥ íŒŒì¼ í˜•ì‹

# 1. ë²”ìš© ë°ì´í„° êµí™˜ â†’ CSV
df.to_csv('data.csv', index=False)

# 2. ë¹„ì¦ˆë‹ˆìŠ¤ ë³´ê³ ì„œ â†’ Excel
df.to_excel('report.xlsx', index=False)

# 3. ì›¹ API ë°ì´í„° â†’ JSON
df.to_json('api_data.json', orient='records')

# 4. ëŒ€ìš©ëŸ‰ ë¶„ì„ ë°ì´í„° â†’ Parquet (ë³„ë„ ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”)
# df.to_parquet('big_data.parquet')

# 5. ì›¹ í‘œì‹œìš© â†’ HTML
df.to_html('table.html', index=False, table_id='data-table')
```

---

## ğŸ“‹ ì¢…í•© ì‹¤ìŠµ ì˜ˆì œ

```python
def comprehensive_file_io_example():
    """
    íŒë‹¤ìŠ¤ íŒŒì¼ ì…ì¶œë ¥ ì¢…í•© ì˜ˆì œ
    """
    
    # 1. ë°ì´í„° ìƒì„±
    print("1. ìƒ˜í”Œ ë°ì´í„° ìƒì„±")
    data = {
        'product_id': range(1, 101),
        'product_name': [f'Product_{i}' for i in range(1, 101)],
        'price': np.random.randint(1000, 100000, 100),
        'category': np.random.choice(['A', 'B', 'C'], 100),
        'stock': np.random.randint(0, 50, 100)
    }
    df = pd.DataFrame(data)
    print(f"ë°ì´í„° í˜•íƒœ: {df.shape}")
    
    # 2. ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥
    print("\n2. ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥")
    
    # CSV (ê¸°ë³¸)
    df.to_csv('products.csv', index=False)
    
    # Excel (ë‹¤ì¤‘ ì‹œíŠ¸)
    with pd.ExcelWriter('products_multi.xlsx') as writer:
        df.to_excel(writer, sheet_name='ì „ì²´', index=False)
        df[df['category'] == 'A'].to_excel(writer, sheet_name='ì¹´í…Œê³ ë¦¬A', index=False)
        df[df['stock'] < 10].to_excel(writer, sheet_name='ì¬ê³ ë¶€ì¡±', index=False)
    
    # JSON (ë ˆì½”ë“œ í˜•íƒœ)
    df.to_json('products.json', orient='records', force_ascii=False)
    
    # 3. íŒŒì¼ ì½ê¸° ë° ê²€ì¦
    print("\n3. íŒŒì¼ ì½ê¸° ë° ê²€ì¦")
    
    df_csv = pd.read_csv('products.csv')
    df_excel = pd.read_excel('products_multi.xlsx', sheet_name='ì „ì²´')
    df_json = pd.read_json('products.json')
    
    # ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸
    print(f"CSV ì½ê¸°: {df_csv.shape}")
    print(f"Excel ì½ê¸°: {df_excel.shape}")
    print(f"JSON ì½ê¸°: {df_json.shape}")
    
    # 4. í†µê³„ ì •ë³´ ì¶œë ¥
    print("\n4. í†µê³„ ì •ë³´")
    print(df.groupby('category')['price'].agg(['mean', 'count', 'sum']))
    
    print("\níŒŒì¼ ì…ì¶œë ¥ ì˜ˆì œ ì™„ë£Œ!")

# ì‹¤í–‰
comprehensive_file_io_example()
```

---

## ğŸ” ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œì™€ í•´ê²°ì±…

#### 1. ì¸ì½”ë”© ì˜¤ë¥˜
```python
# ë¬¸ì œ: UnicodeDecodeError
# í•´ê²°: ì ì ˆí•œ ì¸ì½”ë”© ì§€ì •
df = pd.read_csv('data.csv', encoding='utf-8-sig')
```

#### 2. ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# ë¬¸ì œ: MemoryError
# í•´ê²°: ì²­í¬ ì²˜ë¦¬ ë˜ëŠ” ë°ì´í„° íƒ€ì… ìµœì í™”
for chunk in pd.read_csv('big_file.csv', chunksize=1000):
    process(chunk)
```

#### 3. ë‚ ì§œ í˜•ì‹ ë¬¸ì œ
```python
# ë¬¸ì œ: ë‚ ì§œ ì»¬ëŸ¼ì´ ë¬¸ìì—´ë¡œ ì½í˜
# í•´ê²°: parse_dates ì˜µì…˜ ì‚¬ìš©
df = pd.read_csv('data.csv', parse_dates=['date_column'])
```

#### 4. êµ¬ë¶„ì ë¬¸ì œ
```python
# ë¬¸ì œ: ë°ì´í„°ê°€ ì œëŒ€ë¡œ ë¶„ë¦¬ë˜ì§€ ì•ŠìŒ
# í•´ê²°: ì •í™•í•œ êµ¬ë¶„ì ì§€ì •
df = pd.read_csv('data.txt', sep='\t')  # íƒ­ êµ¬ë¶„
df = pd.read_csv('data.txt', sep=r'\s+')  # ê³µë°± êµ¬ë¶„
```

---

## ğŸ“š ì¶”ì²œ í•™ìŠµ ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Pandas I/O Tools](https://pandas.pydata.org/docs/user_guide/io.html)
- [CSV íŒŒì¼ ì²˜ë¦¬ ê°€ì´ë“œ](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)

### ì‹¤ë¬´ í™œìš©
- ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ í™œìš©
- í•œê¸€ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì¸ì½”ë”© ì£¼ì˜
- ì›¹ ìŠ¤í¬ë˜í•‘ ì‹œ HTML í…Œì´ë¸” ì½ê¸° ê¸°ëŠ¥ í™œìš©
- API ë°ì´í„° ì²˜ë¦¬ ì‹œ JSON í˜•ì‹ í™œìš©

---

## ğŸ¯ í•µì‹¬ ìš”ì•½

### ë°˜ë“œì‹œ ê¸°ì–µí•  í¬ì¸íŠ¸

1. **íŒŒì¼ í˜•ì‹ë³„ íŠ¹ì§• ì´í•´**
   - CSV: ë²”ìš©ì„±, ê°€ë²¼ì›€
   - Excel: ë¹„ì¦ˆë‹ˆìŠ¤ ì¹œí™”ì , ë‹¤ì¤‘ ì‹œíŠ¸
   - JSON: ì›¹ ì¹œí™”ì , êµ¬ì¡°ì 

2. **ì¸ì½”ë”© ì²˜ë¦¬**
   - í•œê¸€ íŒŒì¼: `encoding='utf-8-sig'` ë˜ëŠ” `encoding='cp949'`
   - ì›¹ ë°ì´í„°: `encoding='utf-8'`

3. **ë©”ëª¨ë¦¬ ê´€ë¦¬**
   - ëŒ€ìš©ëŸ‰ íŒŒì¼: ì²­í¬ ì²˜ë¦¬ í™œìš©
   - ë°ì´í„° íƒ€ì… ìµœì í™”ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½

4. **ì‹¤ë¬´ í™œìš© íŒ¨í„´**
   - íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
   - ì˜ˆì™¸ ì²˜ë¦¬ êµ¬í˜„
   - ë°°ì¹˜ ì²˜ë¦¬ ìë™í™”

íŒë‹¤ìŠ¤ì˜ íŒŒì¼ I/O ê¸°ëŠ¥ì„ ë§ˆìŠ¤í„°í•˜ë©´ ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ì˜ ì—°ë™ì´ ê°€ëŠ¥í•´ì§€ë©°, ì‹¤ë¬´ì—ì„œì˜ ë°ì´í„° ì²˜ë¦¬ íš¨ìœ¨ì„±ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤! ğŸ’ª: 'ì „í™”ë²ˆí˜¸ í˜•ì‹',
}
```

### ê·¸ë£¹í™”ì™€ ìº¡ì²˜

```python
# ê·¸ë£¹í™” íŒ¨í„´
group_patterns = {
    r'(\d{4})-(\d{2})-(\d{2})': 'ë‚ ì§œ ê·¸ë£¹í™”',
    r'([a-zA-Z]+)@([a-zA-Z0-9.-]+)': 'ì´ë©”ì¼ ê·¸ë£¹í™”',
    r'(\d+)\.(\d+)\.(\d+)\.(\d+)': 'IP ì£¼ì†Œ ê·¸ë£¹í™”',
    r'(?P<year>\d{4})-(?P<month>\d{2})-(?P<day>\d{2})': 'ëª…ëª…ëœ ê·¸ë£¹',
}

# ê·¸ë£¹ ì‚¬ìš© ì˜ˆì‹œ
log_entry = "2024-01-15 14:30:25 INFO: User login successful"
log_pattern = r'(?P<date>\d{4}-\d{2}-\d{2})\s+(?P<time>\d{2}:\d{2}:\d{2})\s+(?P<level>\w+):\s+(?P<message>.*)'
match = re.match(log_pattern, log_entry)

if match:
    print(f"ë‚ ì§œ: {match.group('date')}")
    print(f"ì‹œê°„: {match.group('time')}")
    print(f"ë ˆë²¨: {match.group('level')}")
    print(f"ë©”ì‹œì§€: {match.group('message')}")
```

### íŒë‹¤ìŠ¤ì™€ ì •ê·œí‘œí˜„ì‹ í™œìš©

#### 1. ë°ì´í„° í´ë¦¬ë‹
```python
# ë¬¸ìì—´ ì»¬ëŸ¼ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ
df['price_clean'] = df['price_text'].str.extract(r'(\d+)')
df['price_clean'] = df['price_clean'].astype(int)

# ì „í™”ë²ˆí˜¸ í˜•ì‹ í†µì¼
df['phone_clean'] = df['phone'].str.replace(r'[^\d]', '', regex=True)
df['phone_format'] = df['phone_clean'].str.replace(r'(\d{3})(\d{4})(\d{4})', r'\1-\2-\3', regex=True)

# ì´ë©”ì¼ ë„ë©”ì¸ ì¶”ì¶œ
df['domain'] = df['email'].str.extract(r'@([a-zA-Z0-9.-]+)')
```

#### 2. ë°ì´í„° ê²€ì¦
```python
# ì´ë©”ì¼ í˜•ì‹ ê²€ì¦
email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}

---

## ğŸ“Š Excel íŒŒì¼ ì²˜ë¦¬

### ê¸°ë³¸ Excel ì½ê¸° ë° ì €ì¥

```python
# Excel íŒŒì¼ ì½ê¸°
df = pd.read_excel('data.xlsx')  # ì²« ë²ˆì§¸ ì‹œíŠ¸
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')  # íŠ¹ì • ì‹œíŠ¸

# Excel íŒŒì¼ ì €ì¥
df.to_excel('output.xlsx', index=False)
```

### ë‹¤ì¤‘ ì‹œíŠ¸ ì²˜ë¦¬

```python
# ì—¬ëŸ¬ ì‹œíŠ¸ ë™ì‹œ ì½ê¸°
excel_dict = pd.read_excel('data.xlsx', sheet_name=None)  # ëª¨ë“  ì‹œíŠ¸
print(excel_dict.keys())  # ì‹œíŠ¸ ì´ë¦„ë“¤

# íŠ¹ì • ì‹œíŠ¸ë“¤ë§Œ ì½ê¸°
sheets_dict = pd.read_excel('data.xlsx', sheet_name=['Sheet1', 'Sheet2'])

# ì—¬ëŸ¬ ì‹œíŠ¸ë¡œ ì €ì¥
with pd.ExcelWriter('multi_sheet.xlsx') as writer:
    df1.to_excel(writer, sheet_name='ë°ì´í„°1', index=False)
    df2.to_excel(writer, sheet_name='ë°ì´í„°2', index=False)
```

### ì‹¤ë¬´ ì˜ˆì œ: ì œí’ˆ ë°ì´í„° Excel ì²˜ë¦¬

```python
# ì œí’ˆ ë°ì´í„° ìƒì„±
product_data = {
    'name': ['Mouse', 'Keyboard', 'Monitor'],
    'price': [25000, 45000, 250000],
    'stock': [15, 8, 3]
}
df = pd.DataFrame(product_data)

# Excelë¡œ ì €ì¥ (ë‹¤ì–‘í•œ ì˜µì…˜)
df.to_excel('products.xlsx', 
           index=False,           # ì¸ë±ìŠ¤ ì œì™¸
           sheet_name='ì œí’ˆëª©ë¡',  # ì‹œíŠ¸ëª… ì§€ì •
           encoding='utf-8')      # ì¸ì½”ë”© ì§€ì •

# Excelì—ì„œ ì½ê¸°
df_read = pd.read_excel('products.xlsx', sheet_name='ì œí’ˆëª©ë¡')
print(df_read)
```

---

## ğŸŒ JSON íŒŒì¼ ì²˜ë¦¬

### JSON ê¸°ë³¸ ì²˜ë¦¬

```python
# JSON íŒŒì¼ë¡œ ì €ì¥
df.to_json('data.json')
df.to_json('data.json', orient='records')  # ë ˆì½”ë“œ í˜•íƒœ
df.to_json('data.json', orient='index')    # ì¸ë±ìŠ¤ ê¸°ë°˜

# JSON íŒŒì¼ ì½ê¸°
df = pd.read_json('data.json')

# ë¬¸ìì—´ JSON ì²˜ë¦¬
json_string = df.to_json(orient='records')
df_from_json = pd.read_json(json_string)
```

### JSON í˜•íƒœë³„ ì €ì¥ ë°©ì‹

```python
import pandas as pd

# ìƒ˜í”Œ ë°ì´í„°
data = {'apple': {'count': 10, 'price': 1500},
        'orange': {'count': 4, 'price': 700}}
df = pd.DataFrame(data)

print("1. ê¸°ë³¸ í˜•íƒœ:")
print(df.to_json())

print("\n2. ë ˆì½”ë“œ í˜•íƒœ (ì›¹ APIì— ì í•©):")
print(df.to_json(orient='records'))

print("\n3. ì¸ë±ìŠ¤ í˜•íƒœ:")
print(df.to_json(orient='index'))

print("\n4. ê°’ë§Œ ì €ì¥:")
print(df.to_json(orient='values'))
```

---

## ğŸŒ HTML ë° ì›¹ ë°ì´í„° ì²˜ë¦¬

### ì›¹ í…Œì´ë¸” ì½ê¸°

```python
# ì›¹ í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ì½ê¸°
url = "https://ko.wikipedia.org/wiki/ë¦¬ëˆ…ìŠ¤"
tables = pd.read_html(url, encoding='utf-8')
print(f"ì´ {len(tables)}ê°œì˜ í…Œì´ë¸” ë°œê²¬")

# ì²« ë²ˆì§¸ í…Œì´ë¸” í™•ì¸
if tables:
    first_table = tables[0]
    print(first_table.head())
```

### HTMLë¡œ ì €ì¥

```python
# HTML í˜•íƒœë¡œ ì €ì¥
html_string = df.to_html()
print(html_string)

# íŒŒì¼ë¡œ ì €ì¥
df.to_html('table.html', index=False)
```

---

## ğŸ“‹ í´ë¦½ë³´ë“œ í™œìš©

### í´ë¦½ë³´ë“œì™€ ë°ì´í„° êµí™˜

```python
# í´ë¦½ë³´ë“œë¡œ ë³µì‚¬ (Excelì—ì„œ ë°”ë¡œ ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥)
df.to_clipboard(index=False)
print("ë°ì´í„°ê°€ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

# í´ë¦½ë³´ë“œì—ì„œ ì½ê¸° (Excelì—ì„œ ë³µì‚¬í•œ ë°ì´í„°)
# df_from_clipboard = pd.read_clipboard()
```

---

## ğŸ”„ ëŒ€ìš©ëŸ‰ ë°ì´í„°: ì²­í¬(Chunk) ì²˜ë¦¬

### ì²­í¬ ì²˜ë¦¬ ê¸°ë³¸

```python
# ëŒ€ìš©ëŸ‰ CSV íŒŒì¼ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
chunk_size = 1000
chunks = []

# ì²­í¬ ë‹¨ìœ„ë¡œ ì½ì–´ì„œ ì²˜ë¦¬
for chunk in pd.read_csv('large_file.csv', chunksize=chunk_size):
    # ê° ì²­í¬ì— ëŒ€í•œ ì²˜ë¦¬
    processed_chunk = chunk[chunk['score'] > 80]  # ì˜ˆì‹œ í•„í„°ë§
    chunks.append(processed_chunk)

# ëª¨ë“  ì²­í¬ ê²°í•©
final_df = pd.concat(chunks, ignore_index=True)
```

### ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì²˜ë¦¬

```python
import time

# ì¼ë°˜ì ì¸ ë°©ë²• vs ì²­í¬ ì²˜ë¦¬ ì„±ëŠ¥ ë¹„êµ
def process_normal(filepath):
    start = time.time()
    df = pd.read_csv(filepath)
    result = df.groupby('category').mean()
    end = time.time()
    return result, end - start

def process_chunks(filepath, chunk_size=1000):
    start = time.time()
    results = []
    
    for chunk in pd.read_csv(filepath, chunksize=chunk_size):
        chunk_result = chunk.groupby('category').mean()
        results.append(chunk_result)
    
    final_result = pd.concat(results).groupby(level=0).mean()
    end = time.time()
    return final_result, end - start
```

**ğŸ’¡ ì²­í¬ ì²˜ë¦¬ì˜ ì¥ë‹¨ì **

**ì¥ì :**
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì ˆì•½
- ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ê°€ëŠ¥
- ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ì²˜ë¦¬

**ë‹¨ì :**
- ì²˜ë¦¬ ì†ë„ ì•½ê°„ ì €í•˜
- ë³µì¡í•œ ì½”ë“œ êµ¬ì¡°
- ì „ì²´ ë°ì´í„° ê¸°ë°˜ ì—°ì‚° ì–´ë ¤ì›€

---

## ğŸ”§ ê³ ì •í­ íŒŒì¼(FWF) ì²˜ë¦¬

### ê³ ì •í­ ë°ì´í„° ì½ê¸°

```python
# ê³ ì •í­ íŒŒì¼ ì½ê¸° ì˜ˆì‹œ
# ë°ì´í„° í˜•íƒœ: ì´ë¦„(10ì) + ë‚˜ì´(3ì) + ì ìˆ˜(5ì)
df = pd.read_fwf('fixed_width.txt',
                 widths=[10, 3, 5],  # ê° ì»¬ëŸ¼ì˜ í­
                 names=['name', 'age', 'score'],
                 encoding='utf-8')
print(df)
```

---

## ğŸ“Š ë‹¤ì–‘í•œ ì €ì¥ í˜•ì‹ ë¹„êµ

### í˜•ì‹ë³„ ì €ì¥ ì˜ˆì œ

```python
# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
sample_data = {
    'product': ['Mouse', 'Keyboard', 'Monitor'],
    'price': [25000, 45000, 250000],
    'stock': [15, 8, 3]
}
df = pd.DataFrame(sample_data)

# 1. CSV ì €ì¥ (êµ¬ë¶„ì ì˜µì…˜)
df.to_csv('data.csv', index=False, sep=',')
df.to_csv('data_tab.txt', index=False, sep='\t')  # íƒ­ êµ¬ë¶„

# 2. Excel ì €ì¥
df.to_excel('data.xlsx', index=False)

# 3. JSON ì €ì¥
df.to_json('data.json', orient='records', force_ascii=False)

# 4. ì „ì¹˜(Transpose) ì €ì¥
df_transposed = df.T  # í–‰ê³¼ ì—´ ë°”ê¾¸ê¸°
df_transposed.to_csv('data_transposed.csv')
```

### íŠ¸ëœìŠ¤í¬ì¦ˆ(Transpose) í™œìš©

```python
# ë°ì´í„° êµ¬ì¡° ë³€ê²½
items = {
    'apple': {'count': 10, 'price': 1500},
    'orange': {'count': 4, 'price': 700}
}
df = pd.DataFrame(items)
print("ì›ë³¸ ë°ì´í„°:")
print(df)

# í–‰ê³¼ ì—´ ë°”ê¾¸ê¸°
df_t = df.T
print("\nì „ì¹˜ëœ ë°ì´í„°:")
print(df_t)

# ì „ì¹˜ëœ ë°ì´í„° ì €ì¥
df_t.to_csv('transposed_data.csv')
```

---

## âš™ï¸ ì‹¤ë¬´ íŒ ë° ëª¨ë²” ì‚¬ë¡€

### 1. ì¸ì½”ë”© ë¬¸ì œ í•´ê²°

```python
# í•œê¸€ íŒŒì¼ ì²˜ë¦¬ ì‹œ ê¶Œì¥ ì„¤ì •
encodings_to_try = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr']

for encoding in encodings_to_try:
    try:
        df = pd.read_csv('korean_data.csv', encoding=encoding)
        print(f"ì„±ê³µ: {encoding}")
        break
    except UnicodeDecodeError:
        print(f"ì‹¤íŒ¨: {encoding}")
        continue
```

### 2. íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸

```python
import os

def safe_read_csv(filepath):
    if os.path.exists(filepath):
        return pd.read_csv(filepath)
    else:
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
        return None

# ì‚¬ìš© ì˜ˆì‹œ
df = safe_read_csv('data.csv')
if df is not None:
    print(df.head())
```

### 3. ë©”ëª¨ë¦¬ ìµœì í™” ë°ì´í„° íƒ€ì…

```python
# ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°ì´í„° íƒ€ì… ì§€ì •
efficient_dtypes = {
    'id': 'int32',      # int64 â†’ int32
    'category': 'category',  # object â†’ category
    'score': 'float32'  # float64 â†’ float32
}

df = pd.read_csv('data.csv', dtype=efficient_dtypes)
print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum()} bytes")
```

### 4. ë°°ì¹˜ íŒŒì¼ ì²˜ë¦¬

```python
import glob

# ì—¬ëŸ¬ CSV íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
csv_files = glob.glob("data_*.csv")
dataframes = []

for file in csv_files:
    df_temp = pd.read_csv(file)
    df_temp['source_file'] = file  # ì¶œì²˜ íŒŒì¼ëª… ì¶”ê°€
    dataframes.append(df_temp)

# ëª¨ë“  íŒŒì¼ ê²°í•©
combined_df = pd.concat(dataframes, ignore_index=True)
combined_df.to_csv('combined_data.csv', index=False)
```

---

## ğŸ¯ ì„±ëŠ¥ ë¹„êµ ë° ì„ íƒ ê°€ì´ë“œ

### íŒŒì¼ í˜•ì‹ë³„ ì„±ëŠ¥ íŠ¹ì„±

| í˜•ì‹ | ì½ê¸° ì†ë„ | íŒŒì¼ í¬ê¸° | í˜¸í™˜ì„± | ì‚¬ìš© ì‚¬ë¡€ |
|------|-----------|-----------|--------|-----------|
| CSV | ë¹ ë¦„ | ë³´í†µ | ë†’ìŒ | ë²”ìš© ë°ì´í„° êµí™˜ |
| Excel | ë³´í†µ | í¼ | ë³´í†µ | ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì„œ |
| JSON | ë³´í†µ | í¼ | ë†’ìŒ | ì›¹ API, ì„¤ì • íŒŒì¼ |
| Parquet | ë§¤ìš° ë¹ ë¦„ | ì‘ìŒ | ë‚®ìŒ | ë¹…ë°ì´í„° ë¶„ì„ |

### ìƒí™©ë³„ ê¶Œì¥ í˜•ì‹

```python
# ìƒí™©ë³„ ê¶Œì¥ íŒŒì¼ í˜•ì‹

# 1. ë²”ìš© ë°ì´í„° êµí™˜ â†’ CSV
df.to_csv('data.csv', index=False)

# 2. ë¹„ì¦ˆë‹ˆìŠ¤ ë³´ê³ ì„œ â†’ Excel
df.to_excel('report.xlsx', index=False)

# 3. ì›¹ API ë°ì´í„° â†’ JSON
df.to_json('api_data.json', orient='records')

# 4. ëŒ€ìš©ëŸ‰ ë¶„ì„ ë°ì´í„° â†’ Parquet (ë³„ë„ ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”)
# df.to_parquet('big_data.parquet')

# 5. ì›¹ í‘œì‹œìš© â†’ HTML
df.to_html('table.html', index=False, table_id='data-table')
```

---

## ğŸ“‹ ì¢…í•© ì‹¤ìŠµ ì˜ˆì œ

```python
def comprehensive_file_io_example():
    """
    íŒë‹¤ìŠ¤ íŒŒì¼ ì…ì¶œë ¥ ì¢…í•© ì˜ˆì œ
    """
    
    # 1. ë°ì´í„° ìƒì„±
    print("1. ìƒ˜í”Œ ë°ì´í„° ìƒì„±")
    data = {
        'product_id': range(1, 101),
        'product_name': [f'Product_{i}' for i in range(1, 101)],
        'price': np.random.randint(1000, 100000, 100),
        'category': np.random.choice(['A', 'B', 'C'], 100),
        'stock': np.random.randint(0, 50, 100)
    }
    df = pd.DataFrame(data)
    print(f"ë°ì´í„° í˜•íƒœ: {df.shape}")
    
    # 2. ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥
    print("\n2. ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥")
    
    # CSV (ê¸°ë³¸)
    df.to_csv('products.csv', index=False)
    
    # Excel (ë‹¤ì¤‘ ì‹œíŠ¸)
    with pd.ExcelWriter('products_multi.xlsx') as writer:
        df.to_excel(writer, sheet_name='ì „ì²´', index=False)
        df[df['category'] == 'A'].to_excel(writer, sheet_name='ì¹´í…Œê³ ë¦¬A', index=False)
        df[df['stock'] < 10].to_excel(writer, sheet_name='ì¬ê³ ë¶€ì¡±', index=False)
    
    # JSON (ë ˆì½”ë“œ í˜•íƒœ)
    df.to_json('products.json', orient='records', force_ascii=False)
    
    # 3. íŒŒì¼ ì½ê¸° ë° ê²€ì¦
    print("\n3. íŒŒì¼ ì½ê¸° ë° ê²€ì¦")
    
    df_csv = pd.read_csv('products.csv')
    df_excel = pd.read_excel('products_multi.xlsx', sheet_name='ì „ì²´')
    df_json = pd.read_json('products.json')
    
    # ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸
    print(f"CSV ì½ê¸°: {df_csv.shape}")
    print(f"Excel ì½ê¸°: {df_excel.shape}")
    print(f"JSON ì½ê¸°: {df_json.shape}")
    
    # 4. í†µê³„ ì •ë³´ ì¶œë ¥
    print("\n4. í†µê³„ ì •ë³´")
    print(df.groupby('category')['price'].agg(['mean', 'count', 'sum']))
    
    print("\níŒŒì¼ ì…ì¶œë ¥ ì˜ˆì œ ì™„ë£Œ!")

# ì‹¤í–‰
comprehensive_file_io_example()
```

---

## ğŸ” ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œì™€ í•´ê²°ì±…

#### 1. ì¸ì½”ë”© ì˜¤ë¥˜
```python
# ë¬¸ì œ: UnicodeDecodeError
# í•´ê²°: ì ì ˆí•œ ì¸ì½”ë”© ì§€ì •
df = pd.read_csv('data.csv', encoding='utf-8-sig')
```

#### 2. ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# ë¬¸ì œ: MemoryError
# í•´ê²°: ì²­í¬ ì²˜ë¦¬ ë˜ëŠ” ë°ì´í„° íƒ€ì… ìµœì í™”
for chunk in pd.read_csv('big_file.csv', chunksize=1000):
    process(chunk)
```

#### 3. ë‚ ì§œ í˜•ì‹ ë¬¸ì œ
```python
# ë¬¸ì œ: ë‚ ì§œ ì»¬ëŸ¼ì´ ë¬¸ìì—´ë¡œ ì½í˜
# í•´ê²°: parse_dates ì˜µì…˜ ì‚¬ìš©
df = pd.read_csv('data.csv', parse_dates=['date_column'])
```

#### 4. êµ¬ë¶„ì ë¬¸ì œ
```python
# ë¬¸ì œ: ë°ì´í„°ê°€ ì œëŒ€ë¡œ ë¶„ë¦¬ë˜ì§€ ì•ŠìŒ
# í•´ê²°: ì •í™•í•œ êµ¬ë¶„ì ì§€ì •
df = pd.read_csv('data.txt', sep='\t')  # íƒ­ êµ¬ë¶„
df = pd.read_csv('data.txt', sep=r'\s+')  # ê³µë°± êµ¬ë¶„
```

---

## ğŸ“š ì¶”ì²œ í•™ìŠµ ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Pandas I/O Tools](https://pandas.pydata.org/docs/user_guide/io.html)
- [CSV íŒŒì¼ ì²˜ë¦¬ ê°€ì´ë“œ](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)

### ì‹¤ë¬´ í™œìš©
- ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ í™œìš©
- í•œê¸€ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì¸ì½”ë”© ì£¼ì˜
- ì›¹ ìŠ¤í¬ë˜í•‘ ì‹œ HTML í…Œì´ë¸” ì½ê¸° ê¸°ëŠ¥ í™œìš©
- API ë°ì´í„° ì²˜ë¦¬ ì‹œ JSON í˜•ì‹ í™œìš©

---

## ğŸ¯ í•µì‹¬ ìš”ì•½

### ë°˜ë“œì‹œ ê¸°ì–µí•  í¬ì¸íŠ¸

1. **íŒŒì¼ í˜•ì‹ë³„ íŠ¹ì§• ì´í•´**
   - CSV: ë²”ìš©ì„±, ê°€ë²¼ì›€
   - Excel: ë¹„ì¦ˆë‹ˆìŠ¤ ì¹œí™”ì , ë‹¤ì¤‘ ì‹œíŠ¸
   - JSON: ì›¹ ì¹œí™”ì , êµ¬ì¡°ì 

2. **ì¸ì½”ë”© ì²˜ë¦¬**
   - í•œê¸€ íŒŒì¼: `encoding='utf-8-sig'` ë˜ëŠ” `encoding='cp949'`
   - ì›¹ ë°ì´í„°: `encoding='utf-8'`

3. **ë©”ëª¨ë¦¬ ê´€ë¦¬**
   - ëŒ€ìš©ëŸ‰ íŒŒì¼: ì²­í¬ ì²˜ë¦¬ í™œìš©
   - ë°ì´í„° íƒ€ì… ìµœì í™”ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½

4. **ì‹¤ë¬´ í™œìš© íŒ¨í„´**
   - íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
   - ì˜ˆì™¸ ì²˜ë¦¬ êµ¬í˜„
   - ë°°ì¹˜ ì²˜ë¦¬ ìë™í™”

íŒë‹¤ìŠ¤ì˜ íŒŒì¼ I/O ê¸°ëŠ¥ì„ ë§ˆìŠ¤í„°í•˜ë©´ ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ì˜ ì—°ë™ì´ ê°€ëŠ¥í•´ì§€ë©°, ì‹¤ë¬´ì—ì„œì˜ ë°ì´í„° ì²˜ë¦¬ íš¨ìœ¨ì„±ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤! ğŸ’ª
df['valid_email'] = df['email'].str.match(email_pattern)

# ë‚ ì§œ í˜•ì‹ ê²€ì¦
date_pattern = r'^\d{4}-\d{2}-\d{2}

---

## ğŸ“Š Excel íŒŒì¼ ì²˜ë¦¬

### ê¸°ë³¸ Excel ì½ê¸° ë° ì €ì¥

```python
# Excel íŒŒì¼ ì½ê¸°
df = pd.read_excel('data.xlsx')  # ì²« ë²ˆì§¸ ì‹œíŠ¸
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')  # íŠ¹ì • ì‹œíŠ¸

# Excel íŒŒì¼ ì €ì¥
df.to_excel('output.xlsx', index=False)
```

### ë‹¤ì¤‘ ì‹œíŠ¸ ì²˜ë¦¬

```python
# ì—¬ëŸ¬ ì‹œíŠ¸ ë™ì‹œ ì½ê¸°
excel_dict = pd.read_excel('data.xlsx', sheet_name=None)  # ëª¨ë“  ì‹œíŠ¸
print(excel_dict.keys())  # ì‹œíŠ¸ ì´ë¦„ë“¤

# íŠ¹ì • ì‹œíŠ¸ë“¤ë§Œ ì½ê¸°
sheets_dict = pd.read_excel('data.xlsx', sheet_name=['Sheet1', 'Sheet2'])

# ì—¬ëŸ¬ ì‹œíŠ¸ë¡œ ì €ì¥
with pd.ExcelWriter('multi_sheet.xlsx') as writer:
    df1.to_excel(writer, sheet_name='ë°ì´í„°1', index=False)
    df2.to_excel(writer, sheet_name='ë°ì´í„°2', index=False)
```

### ì‹¤ë¬´ ì˜ˆì œ: ì œí’ˆ ë°ì´í„° Excel ì²˜ë¦¬

```python
# ì œí’ˆ ë°ì´í„° ìƒì„±
product_data = {
    'name': ['Mouse', 'Keyboard', 'Monitor'],
    'price': [25000, 45000, 250000],
    'stock': [15, 8, 3]
}
df = pd.DataFrame(product_data)

# Excelë¡œ ì €ì¥ (ë‹¤ì–‘í•œ ì˜µì…˜)
df.to_excel('products.xlsx', 
           index=False,           # ì¸ë±ìŠ¤ ì œì™¸
           sheet_name='ì œí’ˆëª©ë¡',  # ì‹œíŠ¸ëª… ì§€ì •
           encoding='utf-8')      # ì¸ì½”ë”© ì§€ì •

# Excelì—ì„œ ì½ê¸°
df_read = pd.read_excel('products.xlsx', sheet_name='ì œí’ˆëª©ë¡')
print(df_read)
```

---

## ğŸŒ JSON íŒŒì¼ ì²˜ë¦¬

### JSON ê¸°ë³¸ ì²˜ë¦¬

```python
# JSON íŒŒì¼ë¡œ ì €ì¥
df.to_json('data.json')
df.to_json('data.json', orient='records')  # ë ˆì½”ë“œ í˜•íƒœ
df.to_json('data.json', orient='index')    # ì¸ë±ìŠ¤ ê¸°ë°˜

# JSON íŒŒì¼ ì½ê¸°
df = pd.read_json('data.json')

# ë¬¸ìì—´ JSON ì²˜ë¦¬
json_string = df.to_json(orient='records')
df_from_json = pd.read_json(json_string)
```

### JSON í˜•íƒœë³„ ì €ì¥ ë°©ì‹

```python
import pandas as pd

# ìƒ˜í”Œ ë°ì´í„°
data = {'apple': {'count': 10, 'price': 1500},
        'orange': {'count': 4, 'price': 700}}
df = pd.DataFrame(data)

print("1. ê¸°ë³¸ í˜•íƒœ:")
print(df.to_json())

print("\n2. ë ˆì½”ë“œ í˜•íƒœ (ì›¹ APIì— ì í•©):")
print(df.to_json(orient='records'))

print("\n3. ì¸ë±ìŠ¤ í˜•íƒœ:")
print(df.to_json(orient='index'))

print("\n4. ê°’ë§Œ ì €ì¥:")
print(df.to_json(orient='values'))
```

---

## ğŸŒ HTML ë° ì›¹ ë°ì´í„° ì²˜ë¦¬

### ì›¹ í…Œì´ë¸” ì½ê¸°

```python
# ì›¹ í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ì½ê¸°
url = "https://ko.wikipedia.org/wiki/ë¦¬ëˆ…ìŠ¤"
tables = pd.read_html(url, encoding='utf-8')
print(f"ì´ {len(tables)}ê°œì˜ í…Œì´ë¸” ë°œê²¬")

# ì²« ë²ˆì§¸ í…Œì´ë¸” í™•ì¸
if tables:
    first_table = tables[0]
    print(first_table.head())
```

### HTMLë¡œ ì €ì¥

```python
# HTML í˜•íƒœë¡œ ì €ì¥
html_string = df.to_html()
print(html_string)

# íŒŒì¼ë¡œ ì €ì¥
df.to_html('table.html', index=False)
```

---

## ğŸ“‹ í´ë¦½ë³´ë“œ í™œìš©

### í´ë¦½ë³´ë“œì™€ ë°ì´í„° êµí™˜

```python
# í´ë¦½ë³´ë“œë¡œ ë³µì‚¬ (Excelì—ì„œ ë°”ë¡œ ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥)
df.to_clipboard(index=False)
print("ë°ì´í„°ê°€ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

# í´ë¦½ë³´ë“œì—ì„œ ì½ê¸° (Excelì—ì„œ ë³µì‚¬í•œ ë°ì´í„°)
# df_from_clipboard = pd.read_clipboard()
```

---

## ğŸ”„ ëŒ€ìš©ëŸ‰ ë°ì´í„°: ì²­í¬(Chunk) ì²˜ë¦¬

### ì²­í¬ ì²˜ë¦¬ ê¸°ë³¸

```python
# ëŒ€ìš©ëŸ‰ CSV íŒŒì¼ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
chunk_size = 1000
chunks = []

# ì²­í¬ ë‹¨ìœ„ë¡œ ì½ì–´ì„œ ì²˜ë¦¬
for chunk in pd.read_csv('large_file.csv', chunksize=chunk_size):
    # ê° ì²­í¬ì— ëŒ€í•œ ì²˜ë¦¬
    processed_chunk = chunk[chunk['score'] > 80]  # ì˜ˆì‹œ í•„í„°ë§
    chunks.append(processed_chunk)

# ëª¨ë“  ì²­í¬ ê²°í•©
final_df = pd.concat(chunks, ignore_index=True)
```

### ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì²˜ë¦¬

```python
import time

# ì¼ë°˜ì ì¸ ë°©ë²• vs ì²­í¬ ì²˜ë¦¬ ì„±ëŠ¥ ë¹„êµ
def process_normal(filepath):
    start = time.time()
    df = pd.read_csv(filepath)
    result = df.groupby('category').mean()
    end = time.time()
    return result, end - start

def process_chunks(filepath, chunk_size=1000):
    start = time.time()
    results = []
    
    for chunk in pd.read_csv(filepath, chunksize=chunk_size):
        chunk_result = chunk.groupby('category').mean()
        results.append(chunk_result)
    
    final_result = pd.concat(results).groupby(level=0).mean()
    end = time.time()
    return final_result, end - start
```

**ğŸ’¡ ì²­í¬ ì²˜ë¦¬ì˜ ì¥ë‹¨ì **

**ì¥ì :**
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì ˆì•½
- ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ê°€ëŠ¥
- ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ì²˜ë¦¬

**ë‹¨ì :**
- ì²˜ë¦¬ ì†ë„ ì•½ê°„ ì €í•˜
- ë³µì¡í•œ ì½”ë“œ êµ¬ì¡°
- ì „ì²´ ë°ì´í„° ê¸°ë°˜ ì—°ì‚° ì–´ë ¤ì›€

---

## ğŸ”§ ê³ ì •í­ íŒŒì¼(FWF) ì²˜ë¦¬

### ê³ ì •í­ ë°ì´í„° ì½ê¸°

```python
# ê³ ì •í­ íŒŒì¼ ì½ê¸° ì˜ˆì‹œ
# ë°ì´í„° í˜•íƒœ: ì´ë¦„(10ì) + ë‚˜ì´(3ì) + ì ìˆ˜(5ì)
df = pd.read_fwf('fixed_width.txt',
                 widths=[10, 3, 5],  # ê° ì»¬ëŸ¼ì˜ í­
                 names=['name', 'age', 'score'],
                 encoding='utf-8')
print(df)
```

---

## ğŸ“Š ë‹¤ì–‘í•œ ì €ì¥ í˜•ì‹ ë¹„êµ

### í˜•ì‹ë³„ ì €ì¥ ì˜ˆì œ

```python
# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
sample_data = {
    'product': ['Mouse', 'Keyboard', 'Monitor'],
    'price': [25000, 45000, 250000],
    'stock': [15, 8, 3]
}
df = pd.DataFrame(sample_data)

# 1. CSV ì €ì¥ (êµ¬ë¶„ì ì˜µì…˜)
df.to_csv('data.csv', index=False, sep=',')
df.to_csv('data_tab.txt', index=False, sep='\t')  # íƒ­ êµ¬ë¶„

# 2. Excel ì €ì¥
df.to_excel('data.xlsx', index=False)

# 3. JSON ì €ì¥
df.to_json('data.json', orient='records', force_ascii=False)

# 4. ì „ì¹˜(Transpose) ì €ì¥
df_transposed = df.T  # í–‰ê³¼ ì—´ ë°”ê¾¸ê¸°
df_transposed.to_csv('data_transposed.csv')
```

### íŠ¸ëœìŠ¤í¬ì¦ˆ(Transpose) í™œìš©

```python
# ë°ì´í„° êµ¬ì¡° ë³€ê²½
items = {
    'apple': {'count': 10, 'price': 1500},
    'orange': {'count': 4, 'price': 700}
}
df = pd.DataFrame(items)
print("ì›ë³¸ ë°ì´í„°:")
print(df)

# í–‰ê³¼ ì—´ ë°”ê¾¸ê¸°
df_t = df.T
print("\nì „ì¹˜ëœ ë°ì´í„°:")
print(df_t)

# ì „ì¹˜ëœ ë°ì´í„° ì €ì¥
df_t.to_csv('transposed_data.csv')
```

---

## âš™ï¸ ì‹¤ë¬´ íŒ ë° ëª¨ë²” ì‚¬ë¡€

### 1. ì¸ì½”ë”© ë¬¸ì œ í•´ê²°

```python
# í•œê¸€ íŒŒì¼ ì²˜ë¦¬ ì‹œ ê¶Œì¥ ì„¤ì •
encodings_to_try = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr']

for encoding in encodings_to_try:
    try:
        df = pd.read_csv('korean_data.csv', encoding=encoding)
        print(f"ì„±ê³µ: {encoding}")
        break
    except UnicodeDecodeError:
        print(f"ì‹¤íŒ¨: {encoding}")
        continue
```

### 2. íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸

```python
import os

def safe_read_csv(filepath):
    if os.path.exists(filepath):
        return pd.read_csv(filepath)
    else:
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
        return None

# ì‚¬ìš© ì˜ˆì‹œ
df = safe_read_csv('data.csv')
if df is not None:
    print(df.head())
```

### 3. ë©”ëª¨ë¦¬ ìµœì í™” ë°ì´í„° íƒ€ì…

```python
# ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°ì´í„° íƒ€ì… ì§€ì •
efficient_dtypes = {
    'id': 'int32',      # int64 â†’ int32
    'category': 'category',  # object â†’ category
    'score': 'float32'  # float64 â†’ float32
}

df = pd.read_csv('data.csv', dtype=efficient_dtypes)
print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum()} bytes")
```

### 4. ë°°ì¹˜ íŒŒì¼ ì²˜ë¦¬

```python
import glob

# ì—¬ëŸ¬ CSV íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
csv_files = glob.glob("data_*.csv")
dataframes = []

for file in csv_files:
    df_temp = pd.read_csv(file)
    df_temp['source_file'] = file  # ì¶œì²˜ íŒŒì¼ëª… ì¶”ê°€
    dataframes.append(df_temp)

# ëª¨ë“  íŒŒì¼ ê²°í•©
combined_df = pd.concat(dataframes, ignore_index=True)
combined_df.to_csv('combined_data.csv', index=False)
```

---

## ğŸ¯ ì„±ëŠ¥ ë¹„êµ ë° ì„ íƒ ê°€ì´ë“œ

### íŒŒì¼ í˜•ì‹ë³„ ì„±ëŠ¥ íŠ¹ì„±

| í˜•ì‹ | ì½ê¸° ì†ë„ | íŒŒì¼ í¬ê¸° | í˜¸í™˜ì„± | ì‚¬ìš© ì‚¬ë¡€ |
|------|-----------|-----------|--------|-----------|
| CSV | ë¹ ë¦„ | ë³´í†µ | ë†’ìŒ | ë²”ìš© ë°ì´í„° êµí™˜ |
| Excel | ë³´í†µ | í¼ | ë³´í†µ | ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì„œ |
| JSON | ë³´í†µ | í¼ | ë†’ìŒ | ì›¹ API, ì„¤ì • íŒŒì¼ |
| Parquet | ë§¤ìš° ë¹ ë¦„ | ì‘ìŒ | ë‚®ìŒ | ë¹…ë°ì´í„° ë¶„ì„ |

### ìƒí™©ë³„ ê¶Œì¥ í˜•ì‹

```python
# ìƒí™©ë³„ ê¶Œì¥ íŒŒì¼ í˜•ì‹

# 1. ë²”ìš© ë°ì´í„° êµí™˜ â†’ CSV
df.to_csv('data.csv', index=False)

# 2. ë¹„ì¦ˆë‹ˆìŠ¤ ë³´ê³ ì„œ â†’ Excel
df.to_excel('report.xlsx', index=False)

# 3. ì›¹ API ë°ì´í„° â†’ JSON
df.to_json('api_data.json', orient='records')

# 4. ëŒ€ìš©ëŸ‰ ë¶„ì„ ë°ì´í„° â†’ Parquet (ë³„ë„ ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”)
# df.to_parquet('big_data.parquet')

# 5. ì›¹ í‘œì‹œìš© â†’ HTML
df.to_html('table.html', index=False, table_id='data-table')
```

---

## ğŸ“‹ ì¢…í•© ì‹¤ìŠµ ì˜ˆì œ

```python
def comprehensive_file_io_example():
    """
    íŒë‹¤ìŠ¤ íŒŒì¼ ì…ì¶œë ¥ ì¢…í•© ì˜ˆì œ
    """
    
    # 1. ë°ì´í„° ìƒì„±
    print("1. ìƒ˜í”Œ ë°ì´í„° ìƒì„±")
    data = {
        'product_id': range(1, 101),
        'product_name': [f'Product_{i}' for i in range(1, 101)],
        'price': np.random.randint(1000, 100000, 100),
        'category': np.random.choice(['A', 'B', 'C'], 100),
        'stock': np.random.randint(0, 50, 100)
    }
    df = pd.DataFrame(data)
    print(f"ë°ì´í„° í˜•íƒœ: {df.shape}")
    
    # 2. ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥
    print("\n2. ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥")
    
    # CSV (ê¸°ë³¸)
    df.to_csv('products.csv', index=False)
    
    # Excel (ë‹¤ì¤‘ ì‹œíŠ¸)
    with pd.ExcelWriter('products_multi.xlsx') as writer:
        df.to_excel(writer, sheet_name='ì „ì²´', index=False)
        df[df['category'] == 'A'].to_excel(writer, sheet_name='ì¹´í…Œê³ ë¦¬A', index=False)
        df[df['stock'] < 10].to_excel(writer, sheet_name='ì¬ê³ ë¶€ì¡±', index=False)
    
    # JSON (ë ˆì½”ë“œ í˜•íƒœ)
    df.to_json('products.json', orient='records', force_ascii=False)
    
    # 3. íŒŒì¼ ì½ê¸° ë° ê²€ì¦
    print("\n3. íŒŒì¼ ì½ê¸° ë° ê²€ì¦")
    
    df_csv = pd.read_csv('products.csv')
    df_excel = pd.read_excel('products_multi.xlsx', sheet_name='ì „ì²´')
    df_json = pd.read_json('products.json')
    
    # ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸
    print(f"CSV ì½ê¸°: {df_csv.shape}")
    print(f"Excel ì½ê¸°: {df_excel.shape}")
    print(f"JSON ì½ê¸°: {df_json.shape}")
    
    # 4. í†µê³„ ì •ë³´ ì¶œë ¥
    print("\n4. í†µê³„ ì •ë³´")
    print(df.groupby('category')['price'].agg(['mean', 'count', 'sum']))
    
    print("\níŒŒì¼ ì…ì¶œë ¥ ì˜ˆì œ ì™„ë£Œ!")

# ì‹¤í–‰
comprehensive_file_io_example()
```

---

## ğŸ” ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œì™€ í•´ê²°ì±…

#### 1. ì¸ì½”ë”© ì˜¤ë¥˜
```python
# ë¬¸ì œ: UnicodeDecodeError
# í•´ê²°: ì ì ˆí•œ ì¸ì½”ë”© ì§€ì •
df = pd.read_csv('data.csv', encoding='utf-8-sig')
```

#### 2. ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# ë¬¸ì œ: MemoryError
# í•´ê²°: ì²­í¬ ì²˜ë¦¬ ë˜ëŠ” ë°ì´í„° íƒ€ì… ìµœì í™”
for chunk in pd.read_csv('big_file.csv', chunksize=1000):
    process(chunk)
```

#### 3. ë‚ ì§œ í˜•ì‹ ë¬¸ì œ
```python
# ë¬¸ì œ: ë‚ ì§œ ì»¬ëŸ¼ì´ ë¬¸ìì—´ë¡œ ì½í˜
# í•´ê²°: parse_dates ì˜µì…˜ ì‚¬ìš©
df = pd.read_csv('data.csv', parse_dates=['date_column'])
```

#### 4. êµ¬ë¶„ì ë¬¸ì œ
```python
# ë¬¸ì œ: ë°ì´í„°ê°€ ì œëŒ€ë¡œ ë¶„ë¦¬ë˜ì§€ ì•ŠìŒ
# í•´ê²°: ì •í™•í•œ êµ¬ë¶„ì ì§€ì •
df = pd.read_csv('data.txt', sep='\t')  # íƒ­ êµ¬ë¶„
df = pd.read_csv('data.txt', sep=r'\s+')  # ê³µë°± êµ¬ë¶„
```

---

## ğŸ“š ì¶”ì²œ í•™ìŠµ ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Pandas I/O Tools](https://pandas.pydata.org/docs/user_guide/io.html)
- [CSV íŒŒì¼ ì²˜ë¦¬ ê°€ì´ë“œ](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)

### ì‹¤ë¬´ í™œìš©
- ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ í™œìš©
- í•œê¸€ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì¸ì½”ë”© ì£¼ì˜
- ì›¹ ìŠ¤í¬ë˜í•‘ ì‹œ HTML í…Œì´ë¸” ì½ê¸° ê¸°ëŠ¥ í™œìš©
- API ë°ì´í„° ì²˜ë¦¬ ì‹œ JSON í˜•ì‹ í™œìš©

---

## ğŸ¯ í•µì‹¬ ìš”ì•½

### ë°˜ë“œì‹œ ê¸°ì–µí•  í¬ì¸íŠ¸

1. **íŒŒì¼ í˜•ì‹ë³„ íŠ¹ì§• ì´í•´**
   - CSV: ë²”ìš©ì„±, ê°€ë²¼ì›€
   - Excel: ë¹„ì¦ˆë‹ˆìŠ¤ ì¹œí™”ì , ë‹¤ì¤‘ ì‹œíŠ¸
   - JSON: ì›¹ ì¹œí™”ì , êµ¬ì¡°ì 

2. **ì¸ì½”ë”© ì²˜ë¦¬**
   - í•œê¸€ íŒŒì¼: `encoding='utf-8-sig'` ë˜ëŠ” `encoding='cp949'`
   - ì›¹ ë°ì´í„°: `encoding='utf-8'`

3. **ë©”ëª¨ë¦¬ ê´€ë¦¬**
   - ëŒ€ìš©ëŸ‰ íŒŒì¼: ì²­í¬ ì²˜ë¦¬ í™œìš©
   - ë°ì´í„° íƒ€ì… ìµœì í™”ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½

4. **ì‹¤ë¬´ í™œìš© íŒ¨í„´**
   - íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
   - ì˜ˆì™¸ ì²˜ë¦¬ êµ¬í˜„
   - ë°°ì¹˜ ì²˜ë¦¬ ìë™í™”

íŒë‹¤ìŠ¤ì˜ íŒŒì¼ I/O ê¸°ëŠ¥ì„ ë§ˆìŠ¤í„°í•˜ë©´ ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ì˜ ì—°ë™ì´ ê°€ëŠ¥í•´ì§€ë©°, ì‹¤ë¬´ì—ì„œì˜ ë°ì´í„° ì²˜ë¦¬ íš¨ìœ¨ì„±ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤! ğŸ’ª
df['valid_date'] = df['date_string'].str.match(date_pattern)

# ì˜ëª»ëœ í˜•ì‹ í•„í„°ë§
invalid_emails = df[~df['valid_email']]
```

#### 3. ë°ì´í„° ë¶„í• 
```python
# ì´ë¦„ì„ ì„±ê³¼ ì´ë¦„ìœ¼ë¡œ ë¶„í• 
df[['first_name', 'last_name']] = df['full_name'].str.extract(r'(\w+)\s+(\w+)')

# ì£¼ì†Œì—ì„œ ìš°í¸ë²ˆí˜¸ ì¶”ì¶œ
df['zipcode'] = df['address'].str.extract(r'(\d{5})')

# ì œí’ˆì½”ë“œì—ì„œ ì¹´í…Œê³ ë¦¬ì™€ ë²ˆí˜¸ ë¶„ë¦¬
df[['category', 'number']] = df['product_code'].str.extract(r'([A-Z]+)(\d+)')
```

### ê³ ê¸‰ ì •ê·œí‘œí˜„ì‹ ê¸°ë²•

#### 1. ì „ë°©íƒìƒ‰(Lookahead)ê³¼ í›„ë°©íƒìƒ‰(Lookbehind)
```python
advanced_patterns = {
    r'(?=.*\d)(?=.*[a-z])(?=.*[A-Z]).{8,}': 'ê°•ë ¥í•œ ë¹„ë°€ë²ˆí˜¸ (ëŒ€ì†Œë¬¸ì+ìˆ«ì, 8ì ì´ìƒ)',
    r'\d+(?=ì›)': 'ì› ì•ì˜ ìˆ«ì',
    r'(?<=\$)\d+': 'ë‹¬ëŸ¬ ê¸°í˜¸ ë’¤ì˜ ìˆ«ì',
    r'\b\w+(?=@gmail\.com)': 'gmail ì•ì˜ ì‚¬ìš©ìëª…',
}

# ì‚¬ìš© ì˜ˆì‹œ
text = "ë¹„ë°€ë²ˆí˜¸: MyPass123, ê°€ê²©: 15000ì›, ê¸‰ì—¬: $3000"
price_won = re.findall(r'\d+(?=ì›)', text)      # ['15000']
salary_dollar = re.findall(r'(?<=\$)\d+', text) # ['3000']
```

#### 2. íƒìš•ì (Greedy) vs ë¹„íƒìš•ì (Non-greedy) ë§¤ì¹­
```python
text = "<div>ì²« ë²ˆì§¸</div><div>ë‘ ë²ˆì§¸</div>"

greedy = re.findall(r'<div>.*</div>', text)      # ['<div>ì²« ë²ˆì§¸</div><div>ë‘ ë²ˆì§¸</div>']
non_greedy = re.findall(r'<div>.*?</div>', text) # ['<div>ì²« ë²ˆì§¸</div>', '<div>ë‘ ë²ˆì§¸</div>']
```

### ì‹¤ë¬´ ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ ë¼ì´ë¸ŒëŸ¬ë¦¬

```python
class RegexPatterns:
    """ì‹¤ë¬´ì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ ëª¨ìŒ"""
    
    # ê¸°ë³¸ ë°ì´í„° íƒ€ì…
    INTEGER = r'-?\d+'
    FLOAT = r'-?\d+\.?\d*'
    PERCENTAGE = r'-?\d+\.?\d*%'
    
    # ë‚ ì§œ/ì‹œê°„
    DATE_YYYY_MM_DD = r'\d{4}-\d{2}-\d{2}'
    DATE_MM_DD_YYYY = r'\d{2}/\d{2}/\d{4}'
    TIME_HH_MM_SS = r'\d{2}:\d{2}:\d{2}'
    DATETIME_ISO = r'\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}'
    
    # ì—°ë½ì²˜ ì •ë³´
    EMAIL = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
    PHONE_KR = r'\d{2,3}-\d{3,4}-\d{4}'
    URL = r'https?://[^\s]+'
    
    # ì‹ë³„ì
    UUID = r'[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}'
    IP_ADDRESS = r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}'
    MAC_ADDRESS = r'[0-9a-fA-F]{2}:[0-9a-fA-F]{2}:[0-9a-fA-F]{2}:[0-9a-fA-F]{2}:[0-9a-fA-F]{2}:[0-9a-fA-F]{2}'
    
    # ê¸ˆìœµ/í™”í
    CURRENCY_KRW = r'\d{1,3}(,\d{3})*ì›?'
    CURRENCY_USD = r'\$\d{1,3}(,\d{3})*\.?\d{0,2}'
    CREDIT_CARD = r'\d{4}-?\d{4}-?\d{4}-?\d{4}'
    
    # êµ¬ë¶„ì
    CSV_DELIMITER = r','
    TSV_DELIMITER = r'\t'
    MULTI_DELIMITER = r'[,;\t|]'
    WHITESPACE = r'\s+'
    WHITESPACE_OR_COMMA = r'[,\s]+'

# ì‚¬ìš© ì˜ˆì‹œ
def clean_phone_numbers(df, column_name):
    """ì „í™”ë²ˆí˜¸ ì»¬ëŸ¼ ì •ë¦¬"""
    # ìˆ«ìë§Œ ì¶”ì¶œ
    df[f'{column_name}_digits'] = df[column_name].str.replace(r'[^\d]', '', regex=True)
    
    # í•œêµ­ ì „í™”ë²ˆí˜¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    df[f'{column_name}_formatted'] = df[f'{column_name}_digits'].str.replace(
        r'(\d{3})(\d{4})(\d{4})', r'\1-\2-\3', regex=True
    )
    
    # ìœ íš¨ì„± ê²€ì¦
    df[f'{column_name}_valid'] = df[f'{column_name}_formatted'].str.match(RegexPatterns.PHONE_KR)
    
    return df

# ì´ë©”ì¼ ë„ë©”ì¸ë³„ í†µê³„
def analyze_email_domains(df, email_column):
    """ì´ë©”ì¼ ë„ë©”ì¸ë³„ ë¶„ì„"""
    df['domain'] = df[email_column].str.extract(f'@([a-zA-Z0-9.-]+)')
    domain_stats = df['domain'].value_counts()
    return domain_stats
```

### ì„±ëŠ¥ ìµœì í™” íŒ

```python
import re
import time

# 1. ì»´íŒŒì¼ëœ íŒ¨í„´ ì‚¬ìš© (ë°˜ë³µ ì‚¬ìš© ì‹œ ì„±ëŠ¥ í–¥ìƒ)
compiled_email = re.compile(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}')

def extract_emails_compiled(text_list):
    return [compiled_email.findall(text) for text in text_list]

# 2. íŒë‹¤ìŠ¤ ë²¡í„°í™” ì—°ì‚° í™œìš©
def clean_data_vectorized(df):
    # âœ… ë²¡í„°í™”ëœ ì—°ì‚° (ë¹ ë¦„)
    df['clean_phone'] = df['phone'].str.replace(r'[^\d]', '', regex=True)
    
    # âŒ ë°˜ë³µë¬¸ ì‚¬ìš© (ëŠë¦¼)
    # for idx, row in df.iterrows():
    #     df.loc[idx, 'clean_phone'] = re.sub(r'[^\d]', '', row['phone'])

# 3. í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì •ê·œí‘œí˜„ì‹ ì‚¬ìš©
def smart_cleaning(df):
    # ê°„ë‹¨í•œ ê²½ìš°: ë¬¸ìì—´ ë©”ì„œë“œ ì‚¬ìš©
    df['upper_name'] = df['name'].str.upper()
    
    # ë³µì¡í•œ ê²½ìš°: ì •ê·œí‘œí˜„ì‹ ì‚¬ìš©
    df['extracted_numbers'] = df['mixed_text'].str.extract(r'(\d+)')
```

---

## ğŸ“Š Excel íŒŒì¼ ì²˜ë¦¬

### ê¸°ë³¸ Excel ì½ê¸° ë° ì €ì¥

```python
# Excel íŒŒì¼ ì½ê¸°
df = pd.read_excel('data.xlsx')  # ì²« ë²ˆì§¸ ì‹œíŠ¸
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')  # íŠ¹ì • ì‹œíŠ¸

# Excel íŒŒì¼ ì €ì¥
df.to_excel('output.xlsx', index=False)
```

### ë‹¤ì¤‘ ì‹œíŠ¸ ì²˜ë¦¬

```python
# ì—¬ëŸ¬ ì‹œíŠ¸ ë™ì‹œ ì½ê¸°
excel_dict = pd.read_excel('data.xlsx', sheet_name=None)  # ëª¨ë“  ì‹œíŠ¸
print(excel_dict.keys())  # ì‹œíŠ¸ ì´ë¦„ë“¤

# íŠ¹ì • ì‹œíŠ¸ë“¤ë§Œ ì½ê¸°
sheets_dict = pd.read_excel('data.xlsx', sheet_name=['Sheet1', 'Sheet2'])

# ì—¬ëŸ¬ ì‹œíŠ¸ë¡œ ì €ì¥
with pd.ExcelWriter('multi_sheet.xlsx') as writer:
    df1.to_excel(writer, sheet_name='ë°ì´í„°1', index=False)
    df2.to_excel(writer, sheet_name='ë°ì´í„°2', index=False)
```

### ì‹¤ë¬´ ì˜ˆì œ: ì œí’ˆ ë°ì´í„° Excel ì²˜ë¦¬

```python
# ì œí’ˆ ë°ì´í„° ìƒì„±
product_data = {
    'name': ['Mouse', 'Keyboard', 'Monitor'],
    'price': [25000, 45000, 250000],
    'stock': [15, 8, 3]
}
df = pd.DataFrame(product_data)

# Excelë¡œ ì €ì¥ (ë‹¤ì–‘í•œ ì˜µì…˜)
df.to_excel('products.xlsx', 
           index=False,           # ì¸ë±ìŠ¤ ì œì™¸
           sheet_name='ì œí’ˆëª©ë¡',  # ì‹œíŠ¸ëª… ì§€ì •
           encoding='utf-8')      # ì¸ì½”ë”© ì§€ì •

# Excelì—ì„œ ì½ê¸°
df_read = pd.read_excel('products.xlsx', sheet_name='ì œí’ˆëª©ë¡')
print(df_read)
```

---

## ğŸŒ JSON íŒŒì¼ ì²˜ë¦¬

### JSON ê¸°ë³¸ ì²˜ë¦¬

```python
# JSON íŒŒì¼ë¡œ ì €ì¥
df.to_json('data.json')
df.to_json('data.json', orient='records')  # ë ˆì½”ë“œ í˜•íƒœ
df.to_json('data.json', orient='index')    # ì¸ë±ìŠ¤ ê¸°ë°˜

# JSON íŒŒì¼ ì½ê¸°
df = pd.read_json('data.json')

# ë¬¸ìì—´ JSON ì²˜ë¦¬
json_string = df.to_json(orient='records')
df_from_json = pd.read_json(json_string)
```

### JSON í˜•íƒœë³„ ì €ì¥ ë°©ì‹

```python
import pandas as pd

# ìƒ˜í”Œ ë°ì´í„°
data = {'apple': {'count': 10, 'price': 1500},
        'orange': {'count': 4, 'price': 700}}
df = pd.DataFrame(data)

print("1. ê¸°ë³¸ í˜•íƒœ:")
print(df.to_json())

print("\n2. ë ˆì½”ë“œ í˜•íƒœ (ì›¹ APIì— ì í•©):")
print(df.to_json(orient='records'))

print("\n3. ì¸ë±ìŠ¤ í˜•íƒœ:")
print(df.to_json(orient='index'))

print("\n4. ê°’ë§Œ ì €ì¥:")
print(df.to_json(orient='values'))
```

---

## ğŸŒ HTML ë° ì›¹ ë°ì´í„° ì²˜ë¦¬

### ì›¹ í…Œì´ë¸” ì½ê¸°

```python
# ì›¹ í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ì½ê¸°
url = "https://ko.wikipedia.org/wiki/ë¦¬ëˆ…ìŠ¤"
tables = pd.read_html(url, encoding='utf-8')
print(f"ì´ {len(tables)}ê°œì˜ í…Œì´ë¸” ë°œê²¬")

# ì²« ë²ˆì§¸ í…Œì´ë¸” í™•ì¸
if tables:
    first_table = tables[0]
    print(first_table.head())
```

### HTMLë¡œ ì €ì¥

```python
# HTML í˜•íƒœë¡œ ì €ì¥
html_string = df.to_html()
print(html_string)

# íŒŒì¼ë¡œ ì €ì¥
df.to_html('table.html', index=False)
```

---

## ğŸ“‹ í´ë¦½ë³´ë“œ í™œìš©

### í´ë¦½ë³´ë“œì™€ ë°ì´í„° êµí™˜

```python
# í´ë¦½ë³´ë“œë¡œ ë³µì‚¬ (Excelì—ì„œ ë°”ë¡œ ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥)
df.to_clipboard(index=False)
print("ë°ì´í„°ê°€ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

# í´ë¦½ë³´ë“œì—ì„œ ì½ê¸° (Excelì—ì„œ ë³µì‚¬í•œ ë°ì´í„°)
# df_from_clipboard = pd.read_clipboard()
```

---

## ğŸ”„ ëŒ€ìš©ëŸ‰ ë°ì´í„°: ì²­í¬(Chunk) ì²˜ë¦¬

### ì²­í¬ ì²˜ë¦¬ ê¸°ë³¸

```python
# ëŒ€ìš©ëŸ‰ CSV íŒŒì¼ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
chunk_size = 1000
chunks = []

# ì²­í¬ ë‹¨ìœ„ë¡œ ì½ì–´ì„œ ì²˜ë¦¬
for chunk in pd.read_csv('large_file.csv', chunksize=chunk_size):
    # ê° ì²­í¬ì— ëŒ€í•œ ì²˜ë¦¬
    processed_chunk = chunk[chunk['score'] > 80]  # ì˜ˆì‹œ í•„í„°ë§
    chunks.append(processed_chunk)

# ëª¨ë“  ì²­í¬ ê²°í•©
final_df = pd.concat(chunks, ignore_index=True)
```

### ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì²˜ë¦¬

```python
import time

# ì¼ë°˜ì ì¸ ë°©ë²• vs ì²­í¬ ì²˜ë¦¬ ì„±ëŠ¥ ë¹„êµ
def process_normal(filepath):
    start = time.time()
    df = pd.read_csv(filepath)
    result = df.groupby('category').mean()
    end = time.time()
    return result, end - start

def process_chunks(filepath, chunk_size=1000):
    start = time.time()
    results = []
    
    for chunk in pd.read_csv(filepath, chunksize=chunk_size):
        chunk_result = chunk.groupby('category').mean()
        results.append(chunk_result)
    
    final_result = pd.concat(results).groupby(level=0).mean()
    end = time.time()
    return final_result, end - start
```

**ğŸ’¡ ì²­í¬ ì²˜ë¦¬ì˜ ì¥ë‹¨ì **

**ì¥ì :**
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì ˆì•½
- ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ê°€ëŠ¥
- ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ì²˜ë¦¬

**ë‹¨ì :**
- ì²˜ë¦¬ ì†ë„ ì•½ê°„ ì €í•˜
- ë³µì¡í•œ ì½”ë“œ êµ¬ì¡°
- ì „ì²´ ë°ì´í„° ê¸°ë°˜ ì—°ì‚° ì–´ë ¤ì›€

---

## ğŸ”§ ê³ ì •í­ íŒŒì¼(FWF) ì²˜ë¦¬

### ê³ ì •í­ ë°ì´í„° ì½ê¸°

```python
# ê³ ì •í­ íŒŒì¼ ì½ê¸° ì˜ˆì‹œ
# ë°ì´í„° í˜•íƒœ: ì´ë¦„(10ì) + ë‚˜ì´(3ì) + ì ìˆ˜(5ì)
df = pd.read_fwf('fixed_width.txt',
                 widths=[10, 3, 5],  # ê° ì»¬ëŸ¼ì˜ í­
                 names=['name', 'age', 'score'],
                 encoding='utf-8')
print(df)
```

---

## ğŸ“Š ë‹¤ì–‘í•œ ì €ì¥ í˜•ì‹ ë¹„êµ

### í˜•ì‹ë³„ ì €ì¥ ì˜ˆì œ

```python
# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
sample_data = {
    'product': ['Mouse', 'Keyboard', 'Monitor'],
    'price': [25000, 45000, 250000],
    'stock': [15, 8, 3]
}
df = pd.DataFrame(sample_data)

# 1. CSV ì €ì¥ (êµ¬ë¶„ì ì˜µì…˜)
df.to_csv('data.csv', index=False, sep=',')
df.to_csv('data_tab.txt', index=False, sep='\t')  # íƒ­ êµ¬ë¶„

# 2. Excel ì €ì¥
df.to_excel('data.xlsx', index=False)

# 3. JSON ì €ì¥
df.to_json('data.json', orient='records', force_ascii=False)

# 4. ì „ì¹˜(Transpose) ì €ì¥
df_transposed = df.T  # í–‰ê³¼ ì—´ ë°”ê¾¸ê¸°
df_transposed.to_csv('data_transposed.csv')
```

### íŠ¸ëœìŠ¤í¬ì¦ˆ(Transpose) í™œìš©

```python
# ë°ì´í„° êµ¬ì¡° ë³€ê²½
items = {
    'apple': {'count': 10, 'price': 1500},
    'orange': {'count': 4, 'price': 700}
}
df = pd.DataFrame(items)
print("ì›ë³¸ ë°ì´í„°:")
print(df)

# í–‰ê³¼ ì—´ ë°”ê¾¸ê¸°
df_t = df.T
print("\nì „ì¹˜ëœ ë°ì´í„°:")
print(df_t)

# ì „ì¹˜ëœ ë°ì´í„° ì €ì¥
df_t.to_csv('transposed_data.csv')
```

---

## âš™ï¸ ì‹¤ë¬´ íŒ ë° ëª¨ë²” ì‚¬ë¡€

### 1. ì¸ì½”ë”© ë¬¸ì œ í•´ê²°

```python
# í•œê¸€ íŒŒì¼ ì²˜ë¦¬ ì‹œ ê¶Œì¥ ì„¤ì •
encodings_to_try = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr']

for encoding in encodings_to_try:
    try:
        df = pd.read_csv('korean_data.csv', encoding=encoding)
        print(f"ì„±ê³µ: {encoding}")
        break
    except UnicodeDecodeError:
        print(f"ì‹¤íŒ¨: {encoding}")
        continue
```

### 2. íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸

```python
import os

def safe_read_csv(filepath):
    if os.path.exists(filepath):
        return pd.read_csv(filepath)
    else:
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
        return None

# ì‚¬ìš© ì˜ˆì‹œ
df = safe_read_csv('data.csv')
if df is not None:
    print(df.head())
```

### 3. ë©”ëª¨ë¦¬ ìµœì í™” ë°ì´í„° íƒ€ì…

```python
# ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°ì´í„° íƒ€ì… ì§€ì •
efficient_dtypes = {
    'id': 'int32',      # int64 â†’ int32
    'category': 'category',  # object â†’ category
    'score': 'float32'  # float64 â†’ float32
}

df = pd.read_csv('data.csv', dtype=efficient_dtypes)
print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum()} bytes")
```

### 4. ë°°ì¹˜ íŒŒì¼ ì²˜ë¦¬

```python
import glob

# ì—¬ëŸ¬ CSV íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
csv_files = glob.glob("data_*.csv")
dataframes = []

for file in csv_files:
    df_temp = pd.read_csv(file)
    df_temp['source_file'] = file  # ì¶œì²˜ íŒŒì¼ëª… ì¶”ê°€
    dataframes.append(df_temp)

# ëª¨ë“  íŒŒì¼ ê²°í•©
combined_df = pd.concat(dataframes, ignore_index=True)
combined_df.to_csv('combined_data.csv', index=False)
```

---

## ğŸ¯ ì„±ëŠ¥ ë¹„êµ ë° ì„ íƒ ê°€ì´ë“œ

### íŒŒì¼ í˜•ì‹ë³„ ì„±ëŠ¥ íŠ¹ì„±

| í˜•ì‹ | ì½ê¸° ì†ë„ | íŒŒì¼ í¬ê¸° | í˜¸í™˜ì„± | ì‚¬ìš© ì‚¬ë¡€ |
|------|-----------|-----------|--------|-----------|
| CSV | ë¹ ë¦„ | ë³´í†µ | ë†’ìŒ | ë²”ìš© ë°ì´í„° êµí™˜ |
| Excel | ë³´í†µ | í¼ | ë³´í†µ | ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì„œ |
| JSON | ë³´í†µ | í¼ | ë†’ìŒ | ì›¹ API, ì„¤ì • íŒŒì¼ |
| Parquet | ë§¤ìš° ë¹ ë¦„ | ì‘ìŒ | ë‚®ìŒ | ë¹…ë°ì´í„° ë¶„ì„ |

### ìƒí™©ë³„ ê¶Œì¥ í˜•ì‹

```python
# ìƒí™©ë³„ ê¶Œì¥ íŒŒì¼ í˜•ì‹

# 1. ë²”ìš© ë°ì´í„° êµí™˜ â†’ CSV
df.to_csv('data.csv', index=False)

# 2. ë¹„ì¦ˆë‹ˆìŠ¤ ë³´ê³ ì„œ â†’ Excel
df.to_excel('report.xlsx', index=False)

# 3. ì›¹ API ë°ì´í„° â†’ JSON
df.to_json('api_data.json', orient='records')

# 4. ëŒ€ìš©ëŸ‰ ë¶„ì„ ë°ì´í„° â†’ Parquet (ë³„ë„ ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”)
# df.to_parquet('big_data.parquet')

# 5. ì›¹ í‘œì‹œìš© â†’ HTML
df.to_html('table.html', index=False, table_id='data-table')
```

---

## ğŸ“‹ ì¢…í•© ì‹¤ìŠµ ì˜ˆì œ

```python
def comprehensive_file_io_example():
    """
    íŒë‹¤ìŠ¤ íŒŒì¼ ì…ì¶œë ¥ ì¢…í•© ì˜ˆì œ
    """
    
    # 1. ë°ì´í„° ìƒì„±
    print("1. ìƒ˜í”Œ ë°ì´í„° ìƒì„±")
    data = {
        'product_id': range(1, 101),
        'product_name': [f'Product_{i}' for i in range(1, 101)],
        'price': np.random.randint(1000, 100000, 100),
        'category': np.random.choice(['A', 'B', 'C'], 100),
        'stock': np.random.randint(0, 50, 100)
    }
    df = pd.DataFrame(data)
    print(f"ë°ì´í„° í˜•íƒœ: {df.shape}")
    
    # 2. ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥
    print("\n2. ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥")
    
    # CSV (ê¸°ë³¸)
    df.to_csv('products.csv', index=False)
    
    # Excel (ë‹¤ì¤‘ ì‹œíŠ¸)
    with pd.ExcelWriter('products_multi.xlsx') as writer:
        df.to_excel(writer, sheet_name='ì „ì²´', index=False)
        df[df['category'] == 'A'].to_excel(writer, sheet_name='ì¹´í…Œê³ ë¦¬A', index=False)
        df[df['stock'] < 10].to_excel(writer, sheet_name='ì¬ê³ ë¶€ì¡±', index=False)
    
    # JSON (ë ˆì½”ë“œ í˜•íƒœ)
    df.to_json('products.json', orient='records', force_ascii=False)
    
    # 3. íŒŒì¼ ì½ê¸° ë° ê²€ì¦
    print("\n3. íŒŒì¼ ì½ê¸° ë° ê²€ì¦")
    
    df_csv = pd.read_csv('products.csv')
    df_excel = pd.read_excel('products_multi.xlsx', sheet_name='ì „ì²´')
    df_json = pd.read_json('products.json')
    
    # ë°ì´í„° ì¼ì¹˜ì„± í™•ì¸
    print(f"CSV ì½ê¸°: {df_csv.shape}")
    print(f"Excel ì½ê¸°: {df_excel.shape}")
    print(f"JSON ì½ê¸°: {df_json.shape}")
    
    # 4. í†µê³„ ì •ë³´ ì¶œë ¥
    print("\n4. í†µê³„ ì •ë³´")
    print(df.groupby('category')['price'].agg(['mean', 'count', 'sum']))
    
    print("\níŒŒì¼ ì…ì¶œë ¥ ì˜ˆì œ ì™„ë£Œ!")

# ì‹¤í–‰
comprehensive_file_io_example()
```

---

## ğŸ” ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œì™€ í•´ê²°ì±…

#### 1. ì¸ì½”ë”© ì˜¤ë¥˜
```python
# ë¬¸ì œ: UnicodeDecodeError
# í•´ê²°: ì ì ˆí•œ ì¸ì½”ë”© ì§€ì •
df = pd.read_csv('data.csv', encoding='utf-8-sig')
```

#### 2. ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# ë¬¸ì œ: MemoryError
# í•´ê²°: ì²­í¬ ì²˜ë¦¬ ë˜ëŠ” ë°ì´í„° íƒ€ì… ìµœì í™”
for chunk in pd.read_csv('big_file.csv', chunksize=1000):
    process(chunk)
```

#### 3. ë‚ ì§œ í˜•ì‹ ë¬¸ì œ
```python
# ë¬¸ì œ: ë‚ ì§œ ì»¬ëŸ¼ì´ ë¬¸ìì—´ë¡œ ì½í˜
# í•´ê²°: parse_dates ì˜µì…˜ ì‚¬ìš©
df = pd.read_csv('data.csv', parse_dates=['date_column'])
```

#### 4. êµ¬ë¶„ì ë¬¸ì œ
```python
# ë¬¸ì œ: ë°ì´í„°ê°€ ì œëŒ€ë¡œ ë¶„ë¦¬ë˜ì§€ ì•ŠìŒ
# í•´ê²°: ì •í™•í•œ êµ¬ë¶„ì ì§€ì •
df = pd.read_csv('data.txt', sep='\t')  # íƒ­ êµ¬ë¶„
df = pd.read_csv('data.txt', sep=r'\s+')  # ê³µë°± êµ¬ë¶„
```

---

## ğŸ“š ì¶”ì²œ í•™ìŠµ ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Pandas I/O Tools](https://pandas.pydata.org/docs/user_guide/io.html)
- [CSV íŒŒì¼ ì²˜ë¦¬ ê°€ì´ë“œ](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)

### ì‹¤ë¬´ í™œìš©
- ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ í™œìš©
- í•œê¸€ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì¸ì½”ë”© ì£¼ì˜
- ì›¹ ìŠ¤í¬ë˜í•‘ ì‹œ HTML í…Œì´ë¸” ì½ê¸° ê¸°ëŠ¥ í™œìš©
- API ë°ì´í„° ì²˜ë¦¬ ì‹œ JSON í˜•ì‹ í™œìš©

---

## ğŸ¯ í•µì‹¬ ìš”ì•½

### ë°˜ë“œì‹œ ê¸°ì–µí•  í¬ì¸íŠ¸

1. **íŒŒì¼ í˜•ì‹ë³„ íŠ¹ì§• ì´í•´**
   - CSV: ë²”ìš©ì„±, ê°€ë²¼ì›€
   - Excel: ë¹„ì¦ˆë‹ˆìŠ¤ ì¹œí™”ì , ë‹¤ì¤‘ ì‹œíŠ¸
   - JSON: ì›¹ ì¹œí™”ì , êµ¬ì¡°ì 

2. **ì¸ì½”ë”© ì²˜ë¦¬**
   - í•œê¸€ íŒŒì¼: `encoding='utf-8-sig'` ë˜ëŠ” `encoding='cp949'`
   - ì›¹ ë°ì´í„°: `encoding='utf-8'`

3. **ë©”ëª¨ë¦¬ ê´€ë¦¬**
   - ëŒ€ìš©ëŸ‰ íŒŒì¼: ì²­í¬ ì²˜ë¦¬ í™œìš©
   - ë°ì´í„° íƒ€ì… ìµœì í™”ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½

4. **ì‹¤ë¬´ í™œìš© íŒ¨í„´**
   - íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
   - ì˜ˆì™¸ ì²˜ë¦¬ êµ¬í˜„
   - ë°°ì¹˜ ì²˜ë¦¬ ìë™í™”

íŒë‹¤ìŠ¤ì˜ íŒŒì¼ I/O ê¸°ëŠ¥ì„ ë§ˆìŠ¤í„°í•˜ë©´ ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ì˜ ì—°ë™ì´ ê°€ëŠ¥í•´ì§€ë©°, ì‹¤ë¬´ì—ì„œì˜ ë°ì´í„° ì²˜ë¦¬ íš¨ìœ¨ì„±ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤! ğŸ’ª